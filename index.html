<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>完整版 3D 知識圖譜（嵌入資料）</title>
  <style>
    html, body { margin: 0; overflow: hidden; background: #000; }
    #overlay {
      position: absolute; top: 10px; left: 10px;
      background: rgba(255,255,255,0.95); color: black;
      padding: 12px; font-family: 'Microsoft JhengHei'; font-size: 14px;
      border-radius: 5px; max-width: 500px; display: none; z-index: 10;
    }
  </style>
</head>
<body>
<div id="overlay"></div>
<script src="js/three.min.js"></script>
<script src="js/3d-force-graph.min.js"></script>
<script src="js/mathjax.js"></script>
<script>
const GraphData = {"nodes": [{"id": "b1e26336-7640-424a-9a12-24eca44b6c52", "label": "第1章：引言", "level": 1, "group": "chapter-1", "type": "章節"}, {"id": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "label": "1.1：本书面向的读者", "level": 2, "group": "chapter-1", "type": "子章節"}, {"id": "9f4b3115-654d-4379-8c96-20a4412b6321", "label": "摘要1", "info": "本书对各类读者都有一定的用处，但主要是为两类受众而写的。其中，；一类受众是学习机器学习的大学生（本科或研究生），包括那些已经开；始职业生涯的深度学习和人工智能研究者。另一类受众是没有机器学习", "keywords": "一类受众是学习机器学习的大学生, 本书对各类读者都有一定的用处, 其中, 另一类受众是没有机器学习, 但主要是为两类受众而写的", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e4a4d50c-1dca-418e-8f67-f4e7d0df6461", "label": "摘要2", "info": "为了更好地服务各类读者，我们将本书组织为3个部分。第1部分介绍基", "keywords": "我们将本书组织为, 个部分, 为了更好地服务各类读者, 部分介绍基", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "fd8d2abd-2512-4510-b761-a9cc391c9757", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；本的数学工具和机器学习的概念。第2部分介绍最成熟的深度学习算；法，这些技术基本上已经得到解决。第3部分讨论某些具有展望性的想", "keywords": "这些技术基本上已经得到解决, 部分介绍最成熟的深度学习算, 本的数学工具和机器学习的概念, 部分讨论某些具有展望性的想", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "225f0983-5080-44f0-ba8f-47221fd90357", "label": "摘要4", "info": "读者可以随意跳过不感兴趣或与自己背景不相关的部分。熟悉线性代；数、概率和基本机器学习概念的读者可以跳过第1部分。若读者只是想；实现一个能工作的系统，则不需要阅读超出第2部分的内容。为了帮助", "keywords": "为了帮助, 部分, 若读者只是想, 部分的内容, 实现一个能工作的系统", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ceaf5214-10b5-4128-b0db-1f55f8f52cab", "label": "摘要5", "info": "图1.6　本书的高层组织结构的流程图。从一章到另一章的箭头表示前一章是理解后一章的必备；内容", "keywords": "内容, 本书的高层组织结构的流程图, 从一章到另一章的箭头表示前一章是理解后一章的必备", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "588ea5a9-feef-4cf7-bd60-70de292f30a1", "label": "摘要6", "info": "我们假设所有读者都具备计算机科学背景。也假设读者熟悉编程，并且；对计算的性能问题、复杂性理论、入门级微积分和一些图论术语有基本；的了解。", "keywords": "也假设读者熟悉编程, 我们假设所有读者都具备计算机科学背景, 的了解, 入门级微积分和一些图论术语有基本, 复杂性理论", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "4277579b-0d2e-4d01-b164-e1d92dbc58c9", "label": "摘要7", "info": "《深度学习》英文版配套网站是www.deeplearningbook.org。网站上提供", "keywords": "英文版配套网站是, 深度学习, 网站上提供", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "791ba814-b889-493c-98a2-293d054c607c", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；了各种补充材料，包括练习、讲义幻灯片、错误更正以及其他应该对读；者和讲师有用的资源。", "keywords": "者和讲师有用的资源, 了各种补充材料, 讲义幻灯片, 包括练习, 错误更正以及其他应该对读", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "7147dd1b-ee39-46d0-b991-08d38ff04a11", "label": "摘要9", "info": "《深度学习》中文版的读者，可访问人民邮电出版社异步社区网站；www.epubit.com.cn，获取更多图书信息。", "keywords": "可访问人民邮电出版社异步社区网站, 中文版的读者, 深度学习, 获取更多图书信息", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e35185cf-8088-438d-9f20-75a96c68cf18", "label": "1.2：深度学习的历史趋势", "level": 2, "group": "chapter-1", "type": "子章節"}, {"id": "6387d188-e834-495d-abce-563f5977d55f", "label": "摘要1", "info": "1.2.1　神经网络的众多名称和命运变迁", "keywords": "神经网络的众多名称和命运变迁", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e36e49e0-1ca4-4295-9638-d64cce5b8d94", "label": "摘要2", "info": "1.2.2　与日俱增的数据量", "keywords": "与日俱增的数据量", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e7b8ea8a-f5ca-4ccf-bca2-e56c3a992c98", "label": "摘要3", "info": "1.2.3　与日俱增的模型规模", "keywords": "与日俱增的模型规模", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "fc2b1c9d-489a-4282-a629-d491f40b6a64", "label": "摘要4", "info": "1.2.4　与日俱增的精度、复杂度和对现实世界的冲击", "keywords": "与日俱增的精度, 复杂度和对现实世界的冲击", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "cdef7096-cef8-4427-9ccb-c425db65a5e1", "label": "摘要5", "info": "第1部分　应用数学与机器学习基础", "keywords": "应用数学与机器学习基础, 部分", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "cfd890be-e469-440c-a589-928b2577034e", "label": "摘要6", "info": "通过历史背景了解深度学习是最简单的方式。这里我们仅指出深度学习；的几个关键趋势，而不是提供其详细的历史：", "keywords": "的几个关键趋势, 这里我们仅指出深度学习, 而不是提供其详细的历史, 通过历史背景了解深度学习是最简单的方式", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "0dbfa544-880b-496a-b612-3787e07139ae", "label": "摘要7", "info": "深度学习有着悠久而丰富的历史，但随着许多不同哲学观点的渐渐；消逝，与之对应的名称也渐渐尘封。；随着可用的训练数据量不断增加，深度学习变得更加有用。", "keywords": "但随着许多不同哲学观点的渐渐, 消逝, 深度学习有着悠久而丰富的历史, 与之对应的名称也渐渐尘封, 随着可用的训练数据量不断增加", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "f715dcdb-a501-457b-ade8-4c2b00a52702", "label": "摘要8", "info": "1.2.1　神经网络的众多名称和命运变迁", "keywords": "神经网络的众多名称和命运变迁", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "d0fec474-8527-46d0-81b6-b155bc1a1997", "label": "摘要9", "info": "我们期待这本书的许多读者都听说过深度学习这一激动人心的新技术，；并对一本书提及一个新兴领域的“历史”而感到惊讶。事实上，深度学习；的历史可以追溯到20世纪40年代。深度学习看似是一个全新的领域，只", "keywords": "历史, 深度学习, 事实上, 世纪, 我们期待这本书的许多读者都听说过深度学习这一激动人心的新技术", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1df51456-91a6-47fe-8963-68fc2c6d0231", "label": "摘要10", "info": "全面地讲述深度学习的历史超出了本书的范围。然而，一些基本的背景；对理解深度学习是有用的。一般认为，迄今为止深度学习已经经历了3；次发展浪潮：20世纪40年代到60年代，深度学习的雏形出现在控制论", "keywords": "深度学习的雏形出现在控制论, 一些基本的背景, 对理解深度学习是有用的, 世纪, 迄今为止深度学习已经经历了", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "0b58f591-2302-4cd5-9d8d-b4e0ee37c921", "label": "摘要11", "info": "图1.7　根据Google图书中短语“控制论”“联结主义”或“神经网络”频率衡量的人工神经网络研究；的历史浪潮（图中展示了3次浪潮的前两次，第3次最近才出现）。第1次浪潮开始于20世纪40年；代到20世纪60年代的控制论，随着生物学习理论的发展（McCulloch and Pitts，1943；Hebb，", "keywords": "图书中短语, 图中展示了, 联结主义, 控制论, 根据", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "cd1d4d17-c8bd-4306-a5c2-602672cfcdd5", "label": "摘要12", "info": "我们今天知道的一些最早的学习算法，旨在模拟生物学习的计算模型，；即大脑怎样学习或为什么能学习的模型。其结果是深度学习以人工神经；网络 （artificial neural network，ANN）之名而淡去。彼时，深度学习模", "keywords": "网络, 之名而淡去, 其结果是深度学习以人工神经, 即大脑怎样学习或为什么能学习的模型, 彼时", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "6e84b316-cd2a-4262-a021-3defbceb3d39", "label": "摘要13", "info": "现代术语“深度学习”超越了目前机器学习模型的神经科学观点。它诉诸；于学习多层次组合这一更普遍的原理，这一原理也可以应用于那些并非；受神经科学启发的机器学习框架。", "keywords": "现代术语, 超越了目前机器学习模型的神经科学观点, 深度学习, 这一原理也可以应用于那些并非, 受神经科学启发的机器学习框架", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "4d289b5a-6f42-4e72-8ca5-80e2491ef236", "label": "摘要14", "info": "现代深度学习最早的前身是从神经科学的角度出发的简单线性模型。这；些模型设计为使用一组n个输入x  1  ，···，x  n  ，并将它们与一个输出y相", "keywords": "并将它们与一个输出, 些模型设计为使用一组, 现代深度学习最早的前身是从神经科学的角度出发的简单线性模型, 个输入", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "71369d75-3318-4198-8e75-53ed6b77c17b", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；关联。这些模型希望学习一组权重w  1  ，···，w  n  ，并计算它们的输出；f(x,w)=x 1 w 1 +···+x n w n 。如图1.7所示，第一次神经网络研究浪潮称为", "keywords": "关联, 所示, 第一次神经网络研究浪潮称为, 如图, 并计算它们的输出", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e8fb83f2-e13c-43c6-a7d7-c5ea79ac2b8c", "label": "摘要16", "info": "McCulloch-Pitts神经元（McCulloch  and  Pitts，1943）是脑功能的早期模；型。该线性模型通过检验函数f(x,w)的正负来识别两种不同类别的输；入。显然，模型的权重需要正确设置后才能使模型的输出对应于期望的", "keywords": "显然, 是脑功能的早期模, 的正负来识别两种不同类别的输, 神经元, 该线性模型通过检验函数", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "b7598a81-e0c4-441f-93f8-247344387167", "label": "摘要17", "info": "这些简单的学习算法大大影响了机器学习的现代景象。用于调节；ADALINE权重的训练算法是被称为随机梯度下降  （stochastic  gradient；descent）的一种特例。稍加改进后的随机梯度下降算法仍然是当今深度", "keywords": "稍加改进后的随机梯度下降算法仍然是当今深度, 用于调节, 的一种特例, 这些简单的学习算法大大影响了机器学习的现代景象, 权重的训练算法是被称为随机梯度下降", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "8fbedd07-d72b-414c-bf14-6af94ad541ae", "label": "摘要18", "info": "基于感知机和ADALINE中使用的函数f(x,w)的模型称为线性模型；（linear  model）。尽管在许多情况下，这些模型以不同于原始模型的方；式进行训练，但仍是目前最广泛使用的机器学习模型。", "keywords": "基于感知机和, 的模型称为线性模型, 中使用的函数, 但仍是目前最广泛使用的机器学习模型, 尽管在许多情况下", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e2bc4e4f-6249-451f-b93d-356285ace02b", "label": "摘要19", "info": "线性模型有很多局限性。最著名的是，它们无法学习异或（XOR）函；数，即f([0,1],w)=1和f([1,0],w)=1，但f([1,1],w)=0和f([0,0],w)=0。观察到；线性模型这个缺陷的批评者对受生物学启发的学习普遍地产生了抵触", "keywords": "线性模型这个缺陷的批评者对受生物学启发的学习普遍地产生了抵触, 最著名的是, 它们无法学习异或, 线性模型有很多局限性, 观察到", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "8f57a986-c5f4-445f-8cf0-fcded95ff494", "label": "摘要20", "info": "现在，神经科学被视为深度学习研究的一个重要灵感来源，但它已不再；是该领域的主要指导。", "keywords": "是该领域的主要指导, 现在, 神经科学被视为深度学习研究的一个重要灵感来源, 但它已不再", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c413759d-d8a2-4ffb-81c9-270ef6075e8d", "label": "摘要21", "info": "如今神经科学在深度学习研究中的作用被削弱，主要原因是我们根本没；有足够的关于大脑的信息来作为指导去使用它。要获得对被大脑实际使；用算法的深刻理解，我们需要有能力同时监测（至少是）数千相连神经", "keywords": "主要原因是我们根本没, 如今神经科学在深度学习研究中的作用被削弱, 我们需要有能力同时监测, 用算法的深刻理解, 至少是", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "06e0543b-37ea-4cb3-a221-5ab86ccc1811", "label": "摘要22", "info": "神经科学已经给了我们依靠单一深度学习算法解决许多不同任务的理；由。神经学家们发现，如果将雪貂的大脑重新连接，使视觉信号传送到；听觉区域，它们可以学会用大脑的听觉处理区域去“看”（Von  Melchner", "keywords": "神经科学已经给了我们依靠单一深度学习算法解决许多不同任务的理, 如果将雪貂的大脑重新连接, 它们可以学会用大脑的听觉处理区域去, 使视觉信号传送到, 听觉区域", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e4996a9f-a3d3-4031-b879-5312b19ce504", "label": "摘要23", "info": "linear", "keywords": "", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "9e994e70-54da-4b08-b9c7-7cf45d7bc2f5", "label": "摘要24", "info": "我们能够从神经科学得到一些粗略的指南。仅通过计算单元之间的相互；作用而变得智能的基本思想是受大脑启发的。新认知机（Fukushima，；1980）受哺乳动物视觉系统的结构启发，引入了一个处理图片的强大模", "keywords": "作用而变得智能的基本思想是受大脑启发的, 仅通过计算单元之间的相互, 引入了一个处理图片的强大模, 新认知机, 受哺乳动物视觉系统的结构启发", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "799ac7c1-6bb8-4d79-81ff-5d8bf46d6667", "label": "摘要25", "info": "媒体报道经常强调深度学习与大脑的相似性。的确，深度学习研究者比；其他机器学习领域（如核方法或贝叶斯统计）的研究者更可能地引用大；脑作为影响，但是大家不应该认为深度学习在尝试模拟大脑。现代深度", "keywords": "深度学习研究者比, 的研究者更可能地引用大, 其他机器学习领域, 脑作为影响, 媒体报道经常强调深度学习与大脑的相似性", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "36508314-3b12-40c4-ba91-c008ffe798e4", "label": "摘要26", "info": "值得注意的是，了解大脑是如何在算法层面上工作的尝试确实存在且发；展良好。这项尝试主要被称为“计算神经科学”，并且是独立于深度学习", "keywords": "并且是独立于深度学习, 计算神经科学, 这项尝试主要被称为, 值得注意的是, 展良好", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "65b23c5b-147f-4bc8-a233-afcfb9d7d7ea", "label": "摘要27", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的领域。研究人员在两个领域之间来回研究是很常见的。深度学习领域；主要关注如何构建计算机系统，从而成功解决需要智能才能解决的任", "keywords": "主要关注如何构建计算机系统, 的领域, 深度学习领域, 从而成功解决需要智能才能解决的任, 研究人员在两个领域之间来回研究是很常见的", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "4cde3f7b-d077-4a26-a6a3-b339a09f9dce", "label": "摘要28", "info": "20世纪80年代，神经网络研究的第二次浪潮在很大程度上是伴随一个被；称为联结主义  （connectionism）或并行分布处理  （parallel  distributed；processing）潮流而出现的（Rumelhart et  al.  ，1986d；McClelland  et  al.", "keywords": "称为联结主义, 神经网络研究的第二次浪潮在很大程度上是伴随一个被, 世纪, 年代, 或并行分布处理", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "91f4899a-431b-4ee4-850e-9dfe227d352f", "label": "摘要29", "info": "联结主义的中心思想是，当网络将大量简单的计算单元连接在一起时可；以实现智能行为。这种见解同样适用于生物神经系统中的神经元，因为；它和计算模型中隐藏单元起着类似的作用。", "keywords": "因为, 它和计算模型中隐藏单元起着类似的作用, 联结主义的中心思想是, 当网络将大量简单的计算单元连接在一起时可, 以实现智能行为", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c765b664-0578-4388-94d5-b3f2f7fa27bb", "label": "摘要30", "info": "在20世纪80年代的联结主义期间形成的几个关键概念在今天的深度学习；中仍然是非常重要的。", "keywords": "中仍然是非常重要的, 年代的联结主义期间形成的几个关键概念在今天的深度学习, 世纪", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "15141dcf-8b88-4b7d-a0cc-f61837a34e20", "label": "摘要31", "info": "其中一个概念是分布式表示  （distributed  representation）（Hinton  et  al.；，1986）。其思想是：系统的每一个输入都应该由多个特征表示，并且；每一个特征都应该参与到多个可能输入的表示。例如，假设我们有一个", "keywords": "每一个特征都应该参与到多个可能输入的表示, 假设我们有一个, 系统的每一个输入都应该由多个特征表示, 例如, 其中一个概念是分布式表示", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "2cb153f6-d1b4-4cca-aa07-0a774e4a524e", "label": "摘要32", "info": "联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度；神经网络中的成功使用以及反向传播算法的普及（Rumelhart  et  al.  ，；1986c；LeCun，1987）。这个算法虽然曾黯然失色且不再流行，但截至", "keywords": "但截至, 联结主义潮流的另一个重要成就是反向传播在训练具有内部表示的深度, 神经网络中的成功使用以及反向传播算法的普及, 这个算法虽然曾黯然失色且不再流行", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "581ddd1a-6d73-42c1-9e06-16dc0a1fc84b", "label": "摘要33", "info": "20世纪90年代，研究人员在使用神经网络进行序列建模的方面取得了重；要进展。Hochreiter（1991b）和Bengio  et  al.  （1994b）指出了对长序列；进行建模的一些根本性数学难题，这将在第10.7节中描述。Hochreiter和", "keywords": "世纪, 进行建模的一些根本性数学难题, 研究人员在使用神经网络进行序列建模的方面取得了重, 这将在第, 年代", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1ac46acc-d780-4f78-8ae7-14530392db8b", "label": "摘要34", "info": "神经网络研究的第二次浪潮一直持续到20世纪90年代中期。基于神经网；络和其他AI技术的创业公司开始寻求投资，其做法野心勃勃但不切实；际。当AI研究不能实现这些不合理的期望时，投资者感到失望。同时，", "keywords": "技术的创业公司开始寻求投资, 络和其他, 研究不能实现这些不合理的期望时, 同时, 世纪", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "3a607602-c493-4330-9871-5219ea3afc9f", "label": "摘要35", "info": "在此期间，神经网络继续在某些任务上获得令人印象深刻的表现；（LeCun  et  al.  ，1998c；Bengio  et  al.  ，2001a）。加拿大高级研究所；（CIFAR）通过其神经计算和自适应感知（NCAP）研究计划帮助维持", "keywords": "神经网络继续在某些任务上获得令人印象深刻的表现, 通过其神经计算和自适应感知, 加拿大高级研究所, 在此期间, 研究计划帮助维持", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "9592f74a-fb01-4654-abe8-7d5848162798", "label": "摘要36", "info": "在那个时候，人们普遍认为深度网络是难以训练的。现在我们知道，20；世纪80年代就存在的算法能工作得非常好，但是直到2006年前后都没有；体现出来。这可能仅仅由于其计算代价太高，而以当时可用的硬件难以", "keywords": "这可能仅仅由于其计算代价太高, 世纪, 而以当时可用的硬件难以, 但是直到, 年前后都没有", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "cd3f086f-1de7-4c46-b60b-7daceb43b3d9", "label": "摘要37", "info": "神经网络研究的第三次浪潮始于2006年的突破。Geoffrey  Hinton表明名；为“深度信念网络”的神经网络可以使用一种称为“贪婪逐层预训练”的策；略来有效地训练（Hinton  et  al.  ，2006a），我们将在第15.1节中更详细", "keywords": "年的突破, 表明名, 的神经网络可以使用一种称为, 我们将在第, 贪婪逐层预训练", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1fa97d9f-4814-4cd9-8ed0-3b68a264f173", "label": "摘要38", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；地描述。其他CIFAR附属研究小组很快表明，同样的策略可以被用来训；练许多其他类型的深度网络（Bengio  and  LeCun，2007a；Ranzato  et  al.", "keywords": "附属研究小组很快表明, 练许多其他类型的深度网络, 同样的策略可以被用来训, 地描述, 其他", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "2ef420c4-b687-4fa8-b315-012f3af45637", "label": "摘要39", "info": "1.2.2　与日俱增的数据量", "keywords": "与日俱增的数据量", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "0b9574c3-990c-4ab7-ba5c-e1ef2285648f", "label": "摘要40", "info": "人们可能想问，既然人工神经网络的第一个实验在20世纪50年代就完成；了，但为什么深度学习直到最近才被认为是关键技术？自20世纪90年代；以来，深度学习就已经成功用于商业应用，但通常被视为一种只有专家", "keywords": "但为什么深度学习直到最近才被认为是关键技术, 年代就完成, 世纪, 以来, 但通常被视为一种只有专家", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "59602c61-7554-4aed-8608-a934c25803b4", "label": "摘要41", "info": "的未标注样本。", "keywords": "的未标注样本", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "b7913c16-00d4-4260-b648-9b4d158b7f3f", "label": "摘要42", "info": "图1.8　与日俱增的数据量。20世纪初，统计学家使用数百或数千的手动制作的度量来研究数据；集（Garson，1900；Gosset，1908；Anderson，1935；Fisher，1936）。20世纪50年代到80年；代，受生物启发的机器学习开拓者通常使用小的合成数据集，如低分辨率的字母位图，设计为", "keywords": "设计为, 世纪, 统计学家使用数百或数千的手动制作的度量来研究数据, 如低分辨率的字母位图, 与日俱增的数据量", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "6192a0db-bc58-4be6-9ea9-45dacc0ad73a", "label": "摘要43", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图1.9　MNIST数据集的输入样例。“NIST”代表国家标准和技术研究所（National Institute of；Standards and Technology），是最初收集这些数据的机构。“M”代表“修改的（Modified）”，为", "keywords": "代表国家标准和技术研究所, 代表, 数据集的输入样例, 修改的, 是最初收集这些数据的机构", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "93774bc4-b5c5-4b56-b5df-932c2852f57c", "label": "摘要44", "info": "1.2.3　与日俱增的模型规模", "keywords": "与日俱增的模型规模", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "87e33993-6022-49b3-9e6e-998e417b0856", "label": "摘要45", "info": "20世纪80年代，神经网络只能取得相对较小的成功，而现在神经网络非；常成功的另一个重要原因是我们现在拥有的计算资源可以运行更大的模；型。联结主义的主要见解之一是，当动物的许多神经元一起工作时会变", "keywords": "常成功的另一个重要原因是我们现在拥有的计算资源可以运行更大的模, 世纪, 而现在神经网络非, 联结主义的主要见解之一是, 当动物的许多神经元一起工作时会变", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "4380ff7e-b360-4096-965e-94b0e5565792", "label": "摘要46", "info": "生物神经元不是特别稠密地连接在一起。如图1.10所示，几十年来，我；们的机器学习模型中每个神经元的连接数量已经与哺乳动物的大脑在同", "keywords": "所示, 们的机器学习模型中每个神经元的连接数量已经与哺乳动物的大脑在同, 生物神经元不是特别稠密地连接在一起, 如图, 几十年来", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "a8f3e005-0b13-411d-8d55-80eabdde9d7d", "label": "摘要47", "info": "一数量级上。", "keywords": "一数量级上", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "51364ad8-1950-4f50-a181-d8940cfd1b36", "label": "摘要48", "info": "图1.10　与日俱增的每个神经元的连接数。最初，人工神经网络中神经元之间的连接数受限于；硬件能力。而现在，神经元之间的连接数大多是出于设计考虑。一些人工神经网络中每个神经；元的连接数与猫一样多，并且对于其他神经网络来说，每个神经元的连接数与较小哺乳动物", "keywords": "与日俱增的每个神经元的连接数, 而现在, 人工神经网络中神经元之间的连接数受限于, 并且对于其他神经网络来说, 硬件能力", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "d664b6eb-25d6-4be9-ad51-cabebca280b1", "label": "摘要49", "info": "1．自适应线性单元（Widrow and Hoff，1960）；2．神经认知机（Fukushima，1980）；3．；GPU-加速卷积网络（Chellapilla et al. ，2006）；4．深度玻尔兹曼机（Salakhutdinov and；Hinton，2009a）；5．无监督卷积网络（Jarrett et al. ，2009b）；6．GPU-加速多层感知机", "keywords": "无监督卷积网络, 深度玻尔兹曼机, 自适应线性单元, 神经认知机, 加速卷积网络", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "dddac791-b25f-4f9a-b237-b9c3d05a1cf7", "label": "摘要50", "info": "如图1.11所示，就神经元的总数目而言，直到最近神经网络都是惊人的；小。自从隐藏单元引入以来，人工神经网络的规模大约每2.4年扩大一；倍。这种增长是由更大内存、更快的计算机和更大的可用数据集驱动", "keywords": "这种增长是由更大内存, 更快的计算机和更大的可用数据集驱动, 所示, 就神经元的总数目而言, 直到最近神经网络都是惊人的", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "3910a54c-8fb1-4bd8-bbc0-d0bd0607ccc0", "label": "摘要51", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图1.11　与日俱增的神经网络规模。自从引入隐藏单元，人工神经网络的规模大约每2.4年翻一；倍。生物神经网络规模来自Wikipedia（2015）", "keywords": "生物神经网络规模来自, 年翻一, 自从引入隐藏单元, 与日俱增的神经网络规模, 人工神经网络的规模大约每", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "714a6eab-9c1a-4f1e-acc0-06ad00220851", "label": "摘要52", "info": "1．感知机（Rosenblatt，1958，1962）；2.自适应线性单元（Widrow and Hoff，1960）；3.神经；认知机（Fukushima，1980）；4.早期后向传播网络（Rumelhart et al. ，1986b）；5.用于语音识；别的循环神经网络（Robinson and Fallside，1991）；6.用于语音识别的多层感知机（Bengio et al.", "keywords": "认知机, 感知机, 自适应线性单元, 用于语音识, 神经", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "7f290dca-874a-4a3a-bd10-7e0e4ac57247", "label": "摘要53", "info": "现在看来，神经元数量比一个水蛭还少的神经网络不能解决复杂的人工；智能问题，这是不足为奇的。即使现在的网络，从计算系统角度来看它；可能相当大，但实际上它比相对原始的脊椎动物（如青蛙）的神经系统", "keywords": "可能相当大, 但实际上它比相对原始的脊椎动物, 神经元数量比一个水蛭还少的神经网络不能解决复杂的人工, 从计算系统角度来看它, 的神经系统", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "978b7d12-f8d0-4475-8e32-24dd52273c04", "label": "摘要54", "info": "由于更快的CPU、通用GPU的出现（在第12.1.2节中讨论）、更快的网；络连接和更好的分布式计算的软件基础设施，模型规模随着时间的推移；不断增加是深度学习历史中最重要的趋势之一。人们普遍预计这种趋势", "keywords": "模型规模随着时间的推移, 不断增加是深度学习历史中最重要的趋势之一, 由于更快的, 的出现, 在第", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c765fb4e-a08e-479d-8d7c-1600aa75c024", "label": "摘要55", "info": "1.2.4　与日俱增的精度、复杂度和对现实世界的冲击", "keywords": "与日俱增的精度, 复杂度和对现实世界的冲击", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "bb1d5316-200b-4cab-b007-4c3e5248805f", "label": "摘要56", "info": "20世纪80年代以来，深度学习提供精确识别和预测的能力一直在提高。；而且，深度学习持续成功地应用于越来越广泛的实际问题中。", "keywords": "世纪, 而且, 年代以来, 深度学习提供精确识别和预测的能力一直在提高, 深度学习持续成功地应用于越来越广泛的实际问题中", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "34e8b362-72ba-421c-952f-de4f2a67c15a", "label": "摘要57", "info": "最早的深度模型被用来识别裁剪紧凑且非常小的图像中的单个对象；（Rumelhart  et  al.  ，1986d）。此后，神经网络可以处理的图像尺寸逐；渐增加。现代对象识别网络能处理丰富的高分辨率照片，并且不需要在", "keywords": "最早的深度模型被用来识别裁剪紧凑且非常小的图像中的单个对象, 渐增加, 并且不需要在, 现代对象识别网络能处理丰富的高分辨率照片, 此后", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "9c13419f-9dc5-4352-95b4-422f83cac674", "label": "摘要58", "info": "图1.12　日益降低的错误率。由于深度网络达到了在ImageNet大规模视觉识别挑战中竞争所必；需的规模，它们每年都能赢得胜利，并且产生越来越低的错误率。数据来源于Russakovsky et al.；（2014b）和He et al. （2015）", "keywords": "并且产生越来越低的错误率, 它们每年都能赢得胜利, 日益降低的错误率, 大规模视觉识别挑战中竞争所必, 由于深度网络达到了在", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "378f1b96-091e-482e-8714-62e9847b3f59", "label": "摘要59", "info": "深度学习也对语音识别产生了巨大影响。语音识别在20世纪90年代得到；提高后，直到约2000年都停滞不前。深度学习的引入（Dahl  et  al.  ，；2010；Deng et al. ，2010b；Seide et al. ，2011；Hinton et al. ，2012a）", "keywords": "语音识别在, 深度学习的引入, 年代得到, 直到约, 世纪", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "21441f7b-be7c-4d30-b9a0-a1592eb55836", "label": "摘要60", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；第12.3节更详细地探讨这个历史。", "keywords": "节更详细地探讨这个历史", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "adb885ca-1dc9-4d41-827e-cc90475f9b01", "label": "摘要61", "info": "深度网络在行人检测和图像分割中也取得了引人注目的成功（Sermanet；et al. ，2013；Fara-bet et al. ，2013；Couprie et al. ，2013），并且在交；通标志分类上取得了超越人类的表现（Ciresan et al. ，2012）。", "keywords": "通标志分类上取得了超越人类的表现, 深度网络在行人检测和图像分割中也取得了引人注目的成功, 并且在交", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "fbc980f3-450c-4333-bb75-2ea8ee8b9625", "label": "摘要62", "info": "在深度网络的规模和精度有所提高的同时，它们可以解决的任务也日益；复杂。Goodfellow et  al.  （2014d）表明，神经网络可以学习输出描述图；像的整个字符序列，而不是仅仅识别单个对象。此前，人们普遍认为，", "keywords": "神经网络可以学习输出描述图, 它们可以解决的任务也日益, 人们普遍认为, 像的整个字符序列, 而不是仅仅识别单个对象", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "fb6c336b-59a4-4c49-b1cd-03e73c711be9", "label": "摘要63", "info": "这种复杂性日益增加的趋势已将其推向逻辑结论，即神经图灵机；（Graves  et  al.  ，2014）的引入，它能学习读取存储单元和向存储单元；写入任意内容。这样的神经网络可以从期望行为的样本中学习简单的程", "keywords": "这种复杂性日益增加的趋势已将其推向逻辑结论, 它能学习读取存储单元和向存储单元, 的引入, 即神经图灵机, 这样的神经网络可以从期望行为的样本中学习简单的程", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "2af15641-ca1f-449f-86c0-bf070ee5b63d", "label": "摘要64", "info": "深度学习的另一个最大的成就是其在强化学习；learning）领域的扩展。在强化学习中，一个自主的智能体必须在没有；人类操作者指导的情况下，通过试错来学习执行任务。DeepMind表", "keywords": "深度学习的另一个最大的成就是其在强化学习, 一个自主的智能体必须在没有, 人类操作者指导的情况下, 通过试错来学习执行任务, 领域的扩展", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ba5cc02f-9165-4a80-9d9e-65f6d3bbd78f", "label": "摘要65", "info": "（reinforcement", "keywords": "", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ea225f54-d112-4328-8dfa-96d879443041", "label": "摘要66", "info": "许多深度学习应用都是高利润的。现在深度学习被许多顶级的技术公司；使用，包括Google、Microsoft、Facebook、IBM、Baidu、Apple、；Adobe、Netflix、NVIDIA和NEC等。", "keywords": "使用, 许多深度学习应用都是高利润的, 现在深度学习被许多顶级的技术公司, 包括", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "300de94c-3278-4ba8-a81d-ecd8b72b7747", "label": "摘要67", "info": "深度学习的进步也严重依赖于软件基础架构的进展。软件库如；et  al.  ，2012a）、；Theano（Bergstra", "keywords": "深度学习的进步也严重依赖于软件基础架构的进展, 软件库如", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "a012060c-962f-4c06-85b8-8cfcfe37ae1b", "label": "摘要68", "info": "et  al.  ，2010a；Bastien", "keywords": "", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e3176cc6-8ee2-45da-a200-10095ddd7e40", "label": "摘要69", "info": "MXNet（Chen et al. ，2015）和Tensor-Flow（Abadi et al. ，2015）都能；支持重要的研究项目或商业产品。", "keywords": "支持重要的研究项目或商业产品, 都能", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1b8e4d37-6322-4588-8fa3-4a1d1987ad17", "label": "摘要70", "info": "深度学习也为其他科学做出了贡献。用于对象识别的现代卷积网络为神；经科学家们提供了可以研究的视觉处理模型（DiCarlo，2013）。深度；学习也为处理海量数据以及在科学领域做出有效的预测提供了非常有用", "keywords": "深度学习也为其他科学做出了贡献, 学习也为处理海量数据以及在科学领域做出有效的预测提供了非常有用, 经科学家们提供了可以研究的视觉处理模型, 用于对象识别的现代卷积网络为神, 深度", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "148b35fa-d7ed-47c7-8eec-cb3460783add", "label": "摘要71", "info": "总之，深度学习是机器学习的一种方法。在过去几十年的发展中，它大；量借鉴了我们关于人脑、统计学和应用数学的知识。近年来，得益于更；强大的计算机、更大的数据集和能够训练更深网络的技术，深度学习的", "keywords": "它大, 深度学习是机器学习的一种方法, 得益于更, 在过去几十年的发展中, 近年来", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "dbc020fc-84cf-46a8-ae86-45ac6afb8d08", "label": "摘要72", "info": "第1部分　应用数学与机器学习基础", "keywords": "应用数学与机器学习基础, 部分", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "58399c68-8e89-4848-853b-808c4c66ebfa", "label": "摘要73", "info": "本书这一部分将介绍理解深度学习所需的基本数学概念。我们从应用数；学的一般概念开始，这能使我们定义拥有许多变量的函数，找到这些函；数的最高点和最低点，并量化信念度。", "keywords": "这能使我们定义拥有许多变量的函数, 并量化信念度, 学的一般概念开始, 本书这一部分将介绍理解深度学习所需的基本数学概念, 数的最高点和最低点", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "883e3e5c-fe1b-4cd2-b6bd-f5554c1bbdf7", "label": "摘要74", "info": "接着，我们描述机器学习的基本目标，并描述如何实现这些目标。我们；需要指定代表某些信念的模型、设计衡量这些信念与现实对应程度的代；价函数以及使用训练算法最小化这个代价函数。", "keywords": "我们描述机器学习的基本目标, 接着, 并描述如何实现这些目标, 我们, 需要指定代表某些信念的模型", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "61e0d1cb-3a1d-4a16-b659-222053487599", "label": "摘要75", "info": "这个基本框架是广泛多样的机器学习算法的基础，其中也包括非深度的；机器学习方法。在本书的后续章节，我们将在这个框架下开发深度学习；算法。", "keywords": "算法, 其中也包括非深度的, 这个基本框架是广泛多样的机器学习算法的基础, 我们将在这个框架下开发深度学习, 机器学习方法", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "64a4cf51-ffe3-4d8e-8698-0a0540633253", "label": "摘要76", "info": "1.2.1　神经网络的众多名称和命运变迁", "keywords": "神经网络的众多名称和命运变迁", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "f3ee2db6-489a-4c17-8e65-76da521d8252", "label": "摘要77", "info": "1.2.2　与日俱增的数据量", "keywords": "与日俱增的数据量", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "8fa08790-3267-4194-84d6-a8599bdef68f", "label": "摘要78", "info": "1.2.3　与日俱增的模型规模", "keywords": "与日俱增的模型规模", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "29c81824-b616-4500-8229-9abb600bc65f", "label": "摘要79", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；1.2.4　与日俱增的精度、复杂度和对现实世；界的冲击", "keywords": "与日俱增的精度, 复杂度和对现实世, 界的冲击", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "3182f8c3-a382-4716-87cb-68d79d1a9103", "label": "摘要80", "info": "第1部分　应用数学与机器学习基础", "keywords": "应用数学与机器学习基础, 部分", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "label": "20.15：结论", "level": 2, "group": "chapter-1", "type": "子章節"}, {"id": "5db66f2e-327f-4917-bce0-69d5b3cad422", "label": "摘要1", "info": "远在古希腊时期，发明家就梦想着创造能自主思考的机器。神话人物皮；格马利翁（Pygmalion）、代达罗斯（Daedalus）和赫淮斯托斯；（Hephaestus）可以被看作传说中的发明家，而加拉蒂亚（Galatea）、", "keywords": "远在古希腊时期, 和赫淮斯托斯, 可以被看作传说中的发明家, 代达罗斯, 格马利翁", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "add9305e-a66b-4ab9-a5c8-e971380d5150", "label": "摘要2", "info": "当人类第一次构思可编程计算机时，就已经在思考计算机能否变得智能；（尽管这距造出第一台计算机还有一百多年）（Lovelace，1842）。如；今，人工智能  （artificial  intelligence，AI）已经成为一个具有众多实际", "keywords": "就已经在思考计算机能否变得智能, 尽管这距造出第一台计算机还有一百多年, 当人类第一次构思可编程计算机时, 人工智能, 已经成为一个具有众多实际", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e129b177-6f94-4e24-a6a3-ed382c6ed575", "label": "摘要3", "info": "在人工智能的早期，那些对人类智力来说非常困难、但对计算机来说相；对简单的问题得到迅速解决，比如，那些可以通过一系列形式化的数学；规则来描述的问题。人工智能的真正挑战在于解决那些对人来说很容易", "keywords": "在人工智能的早期, 那些对人类智力来说非常困难, 但对计算机来说相, 比如, 人工智能的真正挑战在于解决那些对人来说很容易", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "869a0c7b-277b-4bfe-aa9e-0b51422541bc", "label": "摘要4", "info": "针对这些比较直观的问题，本书讨论一种解决方案。该方案可以让计算；机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念则；通过与某些相对简单的概念之间的关系来定义。让计算机从经验获取知", "keywords": "本书讨论一种解决方案, 该方案可以让计算, 机从经验中学习, 让计算机从经验获取知, 并根据层次化的概念体系来理解世界", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "b2de711e-7fca-438e-9f10-96df0c15bc48", "label": "摘要5", "info": "AI许多早期的成功发生在相对朴素且形式化的环境中，而且不要求计算；机具备很多关于世界的知识。例如，IBM的深蓝（Deep Blue）国际象棋；系统在1997年击败了世界冠军Garry  Kasparov（Hsu，2002）。显然国际", "keywords": "而且不要求计算, 国际象棋, 系统在, 机具备很多关于世界的知识, 例如", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "0f5f78a7-c17c-4126-8b0c-e756a10957a1", "label": "摘要6", "info": "具有讽刺意义的是，抽象和形式化的任务对人类而言是最困难的脑力任；务之一，但对计算机而言却属于最容易的。计算机早就能够打败人类最；好的国际象棋选手，但直到最近计算机才在识别对象或语音任务中达到", "keywords": "但直到最近计算机才在识别对象或语音任务中达到, 但对计算机而言却属于最容易的, 务之一, 抽象和形式化的任务对人类而言是最困难的脑力任, 计算机早就能够打败人类最", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "72272590-27bd-4206-a59c-96db000eaf6c", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；算机需要获取同样的知识才能表现出智能。人工智能的一个关键挑战就；是如何将这些非形式化的知识传达给计算机。", "keywords": "人工智能的一个关键挑战就, 算机需要获取同样的知识才能表现出智能, 是如何将这些非形式化的知识传达给计算机", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "571ff02c-90a6-4297-9bd5-d6bae7c298cf", "label": "摘要8", "info": "一些人工智能项目力求将关于世界的知识用形式化的语言进行硬编码；（hard-code）。计算机可以使用逻辑推理规则来自动地理解这些形式化；（knowledge", "keywords": "一些人工智能项目力求将关于世界的知识用形式化的语言进行硬编码, 计算机可以使用逻辑推理规则来自动地理解这些形式化", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c2306458-1b99-4239-ad42-c6ff54963a18", "label": "摘要9", "info": "依靠硬编码的知识体系面临的困难表明，AI系统需要具备自己获取知识；的能力，即从原始数据中提取模式的能力。这种能力称为机器学习（；machine  learning）。引入机器学习使计算机能够解决涉及现实世界知识", "keywords": "引入机器学习使计算机能够解决涉及现实世界知识, 依靠硬编码的知识体系面临的困难表明, 这种能力称为机器学习, 系统需要具备自己获取知识, 的能力", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "db270d6b-2c9f-4820-b573-2b70c4eab152", "label": "摘要10", "info": "这些简单的机器学习算法的性能在很大程度上依赖于给定数据的表示；（representation）。例如，当逻辑回归用于判断产妇是否适合剖腹产；时，AI系统不会直接检查患者。相反，医生需要告诉系统几条相关的信", "keywords": "系统不会直接检查患者, 例如, 这些简单的机器学习算法的性能在很大程度上依赖于给定数据的表示, 当逻辑回归用于判断产妇是否适合剖腹产, 医生需要告诉系统几条相关的信", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ef2f97d1-85af-46f8-a140-30ef0255cbdd", "label": "摘要11", "info": "在整个计算机科学乃至日常生活中，对表示的依赖都是一个普遍现象。；在计算机科学中，如果数据集合被精巧地结构化并被智能地索引，那么；诸如搜索之类的操作的处理速度就可以成指数级地加快。人们可以很容", "keywords": "诸如搜索之类的操作的处理速度就可以成指数级地加快, 对表示的依赖都是一个普遍现象, 人们可以很容, 那么, 在整个计算机科学乃至日常生活中", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "0282dff3-325d-4b68-9378-dfd83c77b0ad", "label": "摘要12", "info": "易地在阿拉伯数字的表示下进行算术运算，但在罗马数字的表示下，运；算会比较耗时。因此，毫不奇怪，表示的选择会对机器学习算法的性能；产生巨大的影响。图1.1展示了一个简单的可视化例子。", "keywords": "表示的选择会对机器学习算法的性能, 但在罗马数字的表示下, 展示了一个简单的可视化例子, 因此, 产生巨大的影响", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c482d277-723c-4bea-857c-d843acb47d5b", "label": "摘要13", "info": "图1.1　不同表示的例子：假设我们想在散点图中画一条线来分隔两类数据。在左图中，我们使；用笛卡儿坐标表示数据，这个任务是不可能的。在右图中，我们用极坐标表示数据，可以用垂；直线简单地解决这个任务（与David Warde-Farley合作绘制此图）", "keywords": "用笛卡儿坐标表示数据, 在左图中, 这个任务是不可能的, 假设我们想在散点图中画一条线来分隔两类数据, 可以用垂", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c36d5c5d-98a7-4042-a665-ad53af126631", "label": "摘要14", "info": "许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征；集，然后将这些特征提供给简单的机器学习算法。例如，对于通过声音；鉴别说话者的任务来说，一个有用的特征是对其声道大小的估计。这个", "keywords": "许多人工智能任务都可以通过以下方式解决, 鉴别说话者的任务来说, 一个有用的特征是对其声道大小的估计, 先提取一个合适的特征, 例如", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "fdb82484-65bd-4732-8010-c2682d277d25", "label": "摘要15", "info": "然而，对于许多任务来说，我们很难知道应该提取哪些特征。例如，假；设我们想编写一个程序来检测照片中的车。我们知道，汽车有轮子，所；以我们可能会想用车轮的存在与否作为特征。遗憾的是，我们难以准确", "keywords": "我们很难知道应该提取哪些特征, 以我们可能会想用车轮的存在与否作为特征, 然而, 对于许多任务来说, 例如", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "d6717944-382c-4972-a60b-183ded3dddaf", "label": "摘要16", "info": "解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把；表示映射到输出。这种方法我们称之为表示学习；（representation", "keywords": "解决这个问题的途径之一是使用机器学习来发掘表示本身, 而不仅仅把, 这种方法我们称之为表示学习, 表示映射到输出", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "7762a4e9-a4d8-415e-b56f-7c73982b9cd3", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；务则需要几小时到几个月。手动为一个复杂的任务设计特征需要耗费大；量的人工、时间和精力，甚至需要花费整个社群研究人员几十年的时", "keywords": "量的人工, 甚至需要花费整个社群研究人员几十年的时, 务则需要几小时到几个月, 手动为一个复杂的任务设计特征需要耗费大, 时间和精力", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "b8bb6233-5bc3-460d-a68c-444e3ee1d08b", "label": "摘要18", "info": "表示学习算法的典型例子是自编码器  （autoencoder）。自编码器由一；个编码器 （encoder）函数和一个解码器  （decoder）函数组合而成。编；码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新", "keywords": "而解码器函数则将这个新, 表示学习算法的典型例子是自编码器, 函数组合而成, 码器函数将输入数据转换为一种不同的表示, 函数和一个解码器", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "7e68f96e-30cc-4692-b265-232e58a8b183", "label": "摘要19", "info": "当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能；解释观察数据的变差因素  （factors  of  variation）。在此背景下，“因；素”这个词仅指代影响的不同来源；因素通常不是乘性组合。这些因素", "keywords": "这个词仅指代影响的不同来源, 解释观察数据的变差因素, 在此背景下, 我们的目标通常是分离出能, 当设计特征或设计用于学习特征的算法时", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ae6d9ac6-1923-4b90-8f66-e3147da435b8", "label": "摘要20", "info": "在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着；我们能够观察到的每一个数据。比如，在一张包含红色汽车的图片中，；其单个像素在夜间可能会非常接近黑色。汽车轮廓的形状取决于视角。", "keywords": "在一张包含红色汽车的图片中, 汽车轮廓的形状取决于视角, 困难主要源于多个变差因素同时影响着, 其单个像素在夜间可能会非常接近黑色, 比如", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1929e293-de44-4522-bf2c-c80245eb2ecd", "label": "摘要21", "info": "显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多；诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类；水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一", "keywords": "显然, 抽象的特征是非常困难的, 只能通过对数据进行复杂的, 许多, 水平的理解来辨识", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "1fd60ac0-053a-4fec-b1a2-ff5a7e6eb434", "label": "摘要22", "info": "深度学习  （deep  learning）通过其他较简单的表示来表达复杂表示，解；决了表示学习中的核心问题。", "keywords": "通过其他较简单的表示来表达复杂表示, 深度学习, 决了表示学习中的核心问题", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "4a233445-9e55-4d00-8963-73ad1b7db330", "label": "摘要23", "info": "深度学习让计算机通过较简单的概念构建复杂的概念。图1.2展示了深", "keywords": "深度学习让计算机通过较简单的概念构建复杂的概念, 展示了深", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "88326ec7-dfdb-442e-8197-e3cd5b031c03", "label": "摘要24", "info": "度学习系统如何通过组合较简单的概念（例如角和轮廓，它们反过来由；边线定义）来表示图像中人的概念。深度学习模型的典型例子是前馈深；度网络或或多层感知机 （multilayer perceptron，MLP）。多层感知机仅", "keywords": "多层感知机仅, 来表示图像中人的概念, 深度学习模型的典型例子是前馈深, 例如角和轮廓, 它们反过来由", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "ee2bab37-7e7c-44f9-8800-d2bbe5aa7400", "label": "摘要25", "info": "图1.2　深度学习模型的示意图。计算机难以理解原始感观输入数据的含义，如表示为像素值集；合的图像。将一组像素映射到对象标识的函数非常复杂。如果直接处理，学习或评估此映射似；乎是不可能的。深度学习将所需的复杂映射分解为一系列嵌套的简单映射（每个由模型的不同", "keywords": "如表示为像素值集, 如果直接处理, 学习或评估此映射似, 深度学习将所需的复杂映射分解为一系列嵌套的简单映射, 合的图像", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "f175e2b7-6a1e-4cc2-9744-b8295d8f8dc2", "label": "摘要26", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；学习数据的正确表示的想法是解释深度学习的一个视角。另一个视角是；深度促使计算机学习一个多步骤的计算机程序。每一层表示都可以被认", "keywords": "另一个视角是, 深度促使计算机学习一个多步骤的计算机程序, 学习数据的正确表示的想法是解释深度学习的一个视角, 每一层表示都可以被认", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "6290016f-8b41-4929-81a7-28dbbc53926e", "label": "摘要27", "info": "目前主要有两种度量模型深度的方式。一种方式是基于评估架构所需执；行的顺序指令的数目。假设我们将模型表示为给定输入后，计算对应输；出的流程图，则可以将这张流程图中的最长路径视为模型的深度。正如", "keywords": "一种方式是基于评估架构所需执, 出的流程图, 则可以将这张流程图中的最长路径视为模型的深度, 行的顺序指令的数目, 目前主要有两种度量模型深度的方式", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e4e0c8c0-23a0-4f13-91ce-b1242494d50e", "label": "摘要28", "info": "图1.3　将输入映射到输出的计算图表的示意图，其中每个节点执行一个操作。深度是从输入到；输出的最长路径的长度，但这取决于可能的计算步骤的定义。这些图中所示的计算是逻辑回归；模型的输出，σ(w T x)，其中σ是logistic sigmoid函数。如果使用加法、乘法和logistic sigmoid作", "keywords": "如果使用加法, 深度是从输入到, 输出的最长路径的长度, 乘法和, 将输入映射到输出的计算图表的示意图", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c5d8fff9-25bc-4125-a254-1509d626f61b", "label": "摘要29", "info": "另一种是在深度概率模型中使用的方法，它不是将计算图的深度视为模；型深度，而是将描述概念彼此如何关联的图的深度视为模型深度。在这；种情况下，计算每个概念表示的计算流程图的深度可能比概念本身的图", "keywords": "而是将描述概念彼此如何关联的图的深度视为模型深度, 计算每个概念表示的计算流程图的深度可能比概念本身的图, 在这, 型深度, 另一种是在深度概率模型中使用的方法", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "64724ae8-28d4-456d-8d36-dca59d3fdbec", "label": "摘要30", "info": "更深。这是因为系统对较简单概念的理解在给出更复杂概念的信息后可；以进一步精细化。例如，一个AI系统观察其中一只眼睛在阴影中的脸部；图像时，它最初可能只看到一只眼睛。但当检测到脸部的存在后，系统", "keywords": "以进一步精细化, 但当检测到脸部的存在后, 这是因为系统对较简单概念的理解在给出更复杂概念的信息后可, 例如, 系统观察其中一只眼睛在阴影中的脸部", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "e00d4de7-1455-4e52-aec4-fcc00ea5a6a5", "label": "摘要31", "info": "由于并不总是清楚计算图的深度和概率模型图的深度哪一个是最有意义；的，并且由于不同的人选择不同的最小元素集来构建相应的图，所以就；像计算机程序的长度不存在单一的正确值一样，架构的深度也不存在单", "keywords": "并且由于不同的人选择不同的最小元素集来构建相应的图, 像计算机程序的长度不存在单一的正确值一样, 所以就, 架构的深度也不存在单, 由于并不总是清楚计算图的深度和概率模型图的深度哪一个是最有意义", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "7e5d547e-01aa-47da-a992-6da3fc17156a", "label": "摘要32", "info": "总之，这本书的主题——深度学习是通向人工智能的途径之一。具体来；说，它是机器学习的一种，一种能够使计算机系统从经验和数据中得到；提高的技术。我们坚信机器学习可以构建出在复杂实际环境下运行的AI", "keywords": "具体来, 我们坚信机器学习可以构建出在复杂实际环境下运行的, 提高的技术, 一种能够使计算机系统从经验和数据中得到, 这本书的主题", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "c062870b-6f26-498f-ab44-b28a5c89cc92", "label": "摘要33", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图1.4　维恩图展示了深度学习既是一种表示学习，也是一种机器学习，可以用于许多（但不是；全部）AI方法。维恩图的每个部分包括一个AI技术的实例", "keywords": "全部, 也是一种机器学习, 维恩图展示了深度学习既是一种表示学习, 但不是, 技术的实例", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "58728449-f736-4561-ab61-e7a169c520f9", "label": "摘要34", "info": "图1.5　流程图展示了AI系统的不同部分如何在不同的AI学科中彼此相关。阴影框表示能从数据；中学习的组件", "keywords": "学科中彼此相关, 流程图展示了, 中学习的组件, 系统的不同部分如何在不同的, 阴影框表示能从数据", "level": 3, "group": "chapter-1", "type": "段落"}, {"id": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "label": "第2章：线性代数", "level": 1, "group": "chapter-2", "type": "章節"}, {"id": "3768fc32-968a-4054-95ef-af1754fb28f9", "label": "1.2：深度学习的历史趋势", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "afb0d559-0408-4760-94a5-99cc9864f8f7", "label": "摘要1", "info": "线性代数作为数学的一个分支，广泛应用于科学和工程中。然而，因为；线性代数主要是面向连续数学，而非离散数学，所以很多计算机科学家", "keywords": "因为, 而非离散数学, 然而, 线性代数作为数学的一个分支, 广泛应用于科学和工程中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "860131d0-b3d6-4b1a-b4c8-80d2a2bdd682", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；很少接触它。掌握好线性代数对于理解和从事机器学习算法相关工作是；很有必要的，尤其对于深度学习算法而言。因此，在开始介绍深度学习", "keywords": "掌握好线性代数对于理解和从事机器学习算法相关工作是, 因此, 尤其对于深度学习算法而言, 在开始介绍深度学习, 很有必要的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "05980e0b-4950-4028-9ced-1788448f44c8", "label": "摘要3", "info": "如果你已经很熟悉线性代数，那么可以轻松地跳过本章。如果你已经了；解这些概念，但是需要一份索引表来回顾一些重要公式，那么我们推；荐The Matrix Cookbook （Petersen and Pedersen，2006）。如果你没有接", "keywords": "那么可以轻松地跳过本章, 解这些概念, 但是需要一份索引表来回顾一些重要公式, 如果你已经了, 如果你没有接", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "label": "2.1：标量、向量、矩阵和张量", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "cbb80b98-a398-44b7-a48e-f50baf501920", "label": "摘要1", "info": "学习线性代数，会涉及以下几个数学概念：", "keywords": "学习线性代数, 会涉及以下几个数学概念", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "ff8430ed-a7cf-43f1-bbb3-519a7fd6d84a", "label": "摘要2", "info": "标量  （scalar）：一个标量就是一个单独的数，它不同于线性代数；中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表；示标量。标量通常被赋予小写的变量名称。在介绍标量时，我们会", "keywords": "标量, 我们用斜体表, 在介绍标量时, 通常是多个数的数组, 示标量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a9e5914d-d893-465e-9f62-09673386f4d0", "label": "摘要3", "info": "，并且该向量有n个元素，那么该向量属于实数集   的n次笛；。当需要明确表示向量中的元素", "keywords": "并且该向量有, 那么该向量属于实数集, 次笛, 个元素, 当需要明确表示向量中的元素", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "59aa8072-9b6c-4a78-9656-bf429d467787", "label": "摘要4", "info": "卡儿乘积构成的集合，记为；时，我们会将元素排列成一个方括号包围的纵列：", "keywords": "记为, 我们会将元素排列成一个方括号包围的纵列, 卡儿乘积构成的集合", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "0f0ec3cd-5027-458a-b786-234a1f6c58da", "label": "摘要5", "info": "我们可以把向量看作空间中的点，每个元素是不同坐标轴上的坐；标。", "keywords": "我们可以把向量看作空间中的点, 每个元素是不同坐标轴上的坐", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2da2b794-9a35-4841-acd8-36fd2baee14a", "label": "摘要6", "info": "有时我们需要索引向量中的一些元素。在这种情况下，我们定义一；个包含这些元素索引的集合，然后将该集合写在脚标处。比如，指；定x 1 、x 3 和x 6 ，我们定义集合S={1，3，6}，然后写作x  S  。我们", "keywords": "然后将该集合写在脚标处, 有时我们需要索引向量中的一些元素, 我们定义集合, 在这种情况下, 我们", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a8f39952-adec-46de-a883-7cc0d0f396ca", "label": "摘要7", "info": "有时我们需要矩阵值表达式的索引，而不是单个元素。在这种情况；下，我们在表达式后面接下标，但不必将矩阵的变量名称小写化。", "keywords": "在这种情况, 我们在表达式后面接下标, 而不是单个元素, 但不必将矩阵的变量名称小写化, 有时我们需要矩阵值表达式的索引", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f57eb52b-0c1c-42ea-8c00-3ff2583c2f3b", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；比如，f( A ) i,j 表示函数f作用在 A 上输出的矩阵的第i行第j列元素。；张量  （tensor）：在某些情况下，我们会讨论坐标超过两维的数", "keywords": "我们会讨论坐标超过两维的数, 列元素, 作用在, 张量, 上输出的矩阵的第", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "1c7d5a77-6635-401e-8880-961621348709", "label": "摘要9", "info": "转置 （transpose）是矩阵的重要操作之一。矩阵的转置是以对角线为轴；的镜像，这条从左上角到右下角的对角线被称为主对角线；（main", "keywords": "矩阵的转置是以对角线为轴, 这条从左上角到右下角的对角线被称为主对角线, 的镜像, 转置, 是矩阵的重要操作之一", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "9b5b300b-0e5c-47c3-a9d6-5fff15c01e30", "label": "摘要10", "info": "向量可以看作只有一列的矩阵。对应地，向量的转置可以看作只有一行；的矩阵。有时，我们通过将向量元素作为行矩阵写在文本行中，然后使；用转置操作将其变为标准的列向量，来定义一个向量，比如", "keywords": "对应地, 我们通过将向量元素作为行矩阵写在文本行中, 向量可以看作只有一列的矩阵, 然后使, 有时", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7c842841-0e27-450a-af3d-7da4f0f43da6", "label": "摘要11", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "04261eb7-43fc-4e26-92bb-5448f0d51c66", "label": "摘要12", "info": "图2.1　矩阵的转置可以看作以主对角线为轴的一个镜像", "keywords": "矩阵的转置可以看作以主对角线为轴的一个镜像", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "819f5bbd-2d31-4545-a654-2da3113305fb", "label": "摘要13", "info": "标量可以看作只有一个元素的矩阵。因此，标量的转置等于它本身，", "keywords": "标量的转置等于它本身, 因此, 标量可以看作只有一个元素的矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "401b69ed-1ba6-4fb5-95b6-7e92cc1249cf", "label": "摘要14", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "0f5ddf74-df7f-4884-bea9-6e55c366e792", "label": "摘要15", "info": "只要矩阵的形状一样，我们可以把两个矩阵相加。两个矩阵相加是指对；应位置的元素相加，比如 C = A ﹢ B ，其中C i,j =A i,j ﹢B i,j 。", "keywords": "我们可以把两个矩阵相加, 两个矩阵相加是指对, 应位置的元素相加, 其中, 比如", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "25226e66-94ae-4e6f-89c0-758e84f47ea2", "label": "摘要16", "info": "标量和矩阵相乘，或是和矩阵相加时，我们只需将其与矩阵的每个元素；相乘或相加，比如 D =a · B ﹢c ，其中 D i,j =a · B i,j ﹢c 。", "keywords": "我们只需将其与矩阵的每个元素, 其中, 比如, 标量和矩阵相乘, 或是和矩阵相加时", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "49eec879-a035-4528-85f3-442a77eabdbd", "label": "摘要17", "info": "在深度学习中，我们也使用一些不那么常规的符号。我们允许矩阵和向；量相加，产生另一个矩阵：  C = A ﹢ b ，其中 C  i,j  = A  i,j  ﹢ b  j  。换言；之，向量 b 和矩阵 A 的每一行相加。这个简写方法使我们无须在加法操", "keywords": "我们允许矩阵和向, 的每一行相加, 其中, 我们也使用一些不那么常规的符号, 量相加", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c62f821d-9ec8-4688-a3df-8007e86927b4", "label": "2.2：矩阵和向量相乘", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "ec736367-b1e4-4f6b-8c75-75a129ffca6e", "label": "摘要1", "info": "矩阵乘法是矩阵运算中最重要的操作之一。两个矩阵  A  和  B  的矩阵乘；积  （matrix  product）是第三个矩阵  C  。为了使乘法可被定义，矩阵  A；的列数必须和矩阵  B  的行数相等。如果矩阵  A  的形状是m×n，矩阵  B", "keywords": "两个矩阵, 的矩阵乘, 的形状是, 矩阵, 的行数相等", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "06e1a7bc-a464-49e4-a9a0-556b514d57b9", "label": "摘要2", "info": "具体地，该乘法操作定义为", "keywords": "该乘法操作定义为, 具体地", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "bbaff4f6-0eb8-4b16-bd1c-519d25fceeeb", "label": "摘要3", "info": "需要注意的是，两个矩阵的标准乘积不是指两个矩阵中对应元素的乘；积。不过，那样的矩阵操作确实是存在的，称为元素对应乘积；（element-wise product）或者Hadamard乘积 （Hadamard product），记", "keywords": "需要注意的是, 两个矩阵的标准乘积不是指两个矩阵中对应元素的乘, 不过, 称为元素对应乘积, 或者", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b34a1d7d-da54-4db2-bf5b-308620371b68", "label": "摘要4", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "8128d062-c150-426e-bf33-ac1aa448320b", "label": "摘要5", "info": "两个相同维数的向量  x  和  y  的点积  （dot  product）可看作矩阵乘积；。我们可以把矩阵乘积 C = AB 中计算C  i,j  的步骤看作 A 的第i行", "keywords": "的第, 的点积, 两个相同维数的向量, 的步骤看作, 我们可以把矩阵乘积", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f697610e-7b73-459b-9f88-1a4b4c2a04dc", "label": "摘要6", "info": "和 B 的第j列之间的点积。", "keywords": "的第, 列之间的点积", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f11ba6fc-7e45-415b-8b68-3468d4428dfa", "label": "摘要7", "info": "矩阵乘积运算有许多有用的性质，从而使矩阵的数学分析更加方便。比；如，矩阵乘积服从分配律：", "keywords": "矩阵乘积运算有许多有用的性质, 从而使矩阵的数学分析更加方便, 矩阵乘积服从分配律", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "aef847a8-6f96-4830-8aae-8b3a62b8503d", "label": "摘要8", "info": "矩阵乘积也服从结合律：", "keywords": "矩阵乘积也服从结合律", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c9abdc0f-3b4d-43ea-b5e3-72a1eb845220", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；不同于标量乘积，矩阵乘积并不满足交换律（  AB=BA  的情况并非总是；满足）。然而，两个向量的点积 满足交换律：", "keywords": "的情况并非总是, 满足交换律, 满足, 两个向量的点积, 然而", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "76af5e92-cc83-4c38-a3d6-04864ea4a4f4", "label": "摘要10", "info": "矩阵乘积的转置有着简单的形式：", "keywords": "矩阵乘积的转置有着简单的形式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c7fd73a9-1da4-4e5d-8587-0d21c9ffaf81", "label": "摘要11", "info": "利用两个向量点积的结果是标量、标量转置是自身的事实，我们可以证；明式（2.8）：", "keywords": "利用两个向量点积的结果是标量, 我们可以证, 标量转置是自身的事实, 明式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "43dfa9f3-7cf4-4a28-a9dd-d3f786c054c4", "label": "摘要12", "info": "由于本书的重点不是线性代数，我们并不想展示矩阵乘积的所有重要性；质，但读者应该知道矩阵乘积还有很多有用的性质。", "keywords": "我们并不想展示矩阵乘积的所有重要性, 由于本书的重点不是线性代数, 但读者应该知道矩阵乘积还有很多有用的性质", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e34b7c02-c643-486a-ac9c-600f4b912b85", "label": "摘要13", "info": "现在我们已经知道了足够多的线性代数符号，可以表达下列线性方程；组：", "keywords": "现在我们已经知道了足够多的线性代数符号, 可以表达下列线性方程", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c5b81e65-eed8-4adc-ae67-75a396923c76", "label": "摘要14", "info": "是一个已知矩阵，", "keywords": "是一个已知矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b77846b3-f11e-4c6e-8436-c908aa543197", "label": "摘要15", "info": "是一个已知向；其中；量，", "keywords": "是一个已知向, 其中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e1da67e3-02cf-439b-9942-0f23d0635939", "label": "摘要16", "info": "或者，更明确地，写作", "keywords": "写作, 更明确地, 或者", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d7437356-8b00-4de8-8193-6bcac71e7322", "label": "摘要17", "info": "矩阵向量乘积符号为这种形式的方程提供了更紧凑的表示。", "keywords": "矩阵向量乘积符号为这种形式的方程提供了更紧凑的表示", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "label": "2.3：单位矩阵和逆矩阵", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "50ccd227-1e72-4327-b5e2-54f7f3418a00", "label": "摘要1", "info": "线性代数提供了称为矩阵逆  （matrix  inversion）的强大工具。对于大多；数矩阵 A ，我们都能通过矩阵逆解析地求解式（2.11）。", "keywords": "数矩阵, 我们都能通过矩阵逆解析地求解式, 线性代数提供了称为矩阵逆, 对于大多, 的强大工具", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5633bd6e-0d0c-482b-badc-62c30b871736", "label": "摘要2", "info": "为了描述矩阵逆，我们首先需要定义单位矩阵  （identity  matrix）的概；念。任意向量和单位矩阵相乘，都不会改变。我们将保持n维向量不变；的单位矩阵记作 I n 。形式上，", "keywords": "我们首先需要定义单位矩阵, 我们将保持, 为了描述矩阵逆, 维向量不变, 任意向量和单位矩阵相乘", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b9a229a4-07ca-4e4f-8319-5e463c1a02a7", "label": "摘要3", "info": "，", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7b8d3339-d519-4728-82ce-1e289b220151", "label": "摘要4", "info": "单位矩阵的结构很简单：所有沿主对角线的元素都是1，而其他位置的；所有元素都是0，如图2.2所示。", "keywords": "而其他位置的, 所示, 所有元素都是, 单位矩阵的结构很简单, 如图", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f9ec413b-a64a-45ac-afbe-c75f02575418", "label": "摘要5", "info": "图2.2　单位矩阵的一个样例：这是 I 3", "keywords": "这是, 单位矩阵的一个样例", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "dfa0191d-ea3b-4dad-ba32-79638a7784e2", "label": "摘要6", "info": "矩阵 A 的矩阵逆 记作 A −1 ，其定义的矩阵满足如下条件：", "keywords": "记作, 矩阵, 的矩阵逆, 其定义的矩阵满足如下条件", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3f0d3751-144a-4abd-a764-ab223083980a", "label": "摘要7", "info": "现在我们可以通过以下步骤求解式（2.11）：", "keywords": "现在我们可以通过以下步骤求解式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6b4efab9-d1c3-4783-a4dc-d0b2ff3564b1", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；当然，这取决于我们能否找到一个逆矩阵 A −1 。在接下来的章节中，我；们会讨论逆矩阵 A −1 存在的条件。", "keywords": "存在的条件, 们会讨论逆矩阵, 在接下来的章节中, 这取决于我们能否找到一个逆矩阵, 当然", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e9067676-bf8d-471a-a41d-8417f0c55541", "label": "摘要9", "info": "当逆矩阵 A −1 存在时，有几种不同的算法都能找到它的闭解形式。理论；上，相同的逆矩阵可用于多次求解不同向量b的方程。然而，逆矩阵  A；−1  主要是作为理论工具使用的，并不会在大多数软件应用程序中实际使", "keywords": "相同的逆矩阵可用于多次求解不同向量, 存在时, 逆矩阵, 然而, 理论", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "label": "2.4：线性相关和生成子空间", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "61b36768-ede9-491b-9427-7f9b7fdb5ef1", "label": "摘要1", "info": "如果逆矩阵 A −1 存在，那么式（2.11）肯定对于每一个向量 b 恰好存在；一个解。但是，对于方程组而言，对于向量 b 的某些值，有可能不存在；解，或者存在无限多个解。存在多于一个解但是少于无限多个解的情况", "keywords": "如果逆矩阵, 那么式, 有可能不存在, 对于向量, 但是", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6da10c2d-3353-4e83-8dad-43eb817907f2", "label": "摘要2", "info": "（其中α取任意实数）也是该方程组的解。", "keywords": "取任意实数, 其中, 也是该方程组的解", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "292c0eff-f3aa-4202-94b1-5f6111ea9e9d", "label": "摘要3", "info": "为了分析方程有多少个解，我们可以将；（origin）（元素都是零的向量）出发的不同方向，确定有多少种方法；可以到达向量 b 。在这个观点下，向量 x 中的每个元素表示我们应该沿", "keywords": "为了分析方程有多少个解, 我们可以将, 出发的不同方向, 确定有多少种方法, 向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "dda87f09-e906-4f41-933b-5ed5d740d11e", "label": "摘要4", "info": "的列向量看作从原点", "keywords": "的列向量看作从原点", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "22372991-2a49-40a1-898f-f04412d1a587", "label": "摘要5", "info": "A", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "06bf814b-2704-4f61-b111-a3cd9b3043d3", "label": "摘要6", "info": "一般而言，这种操作称为线性组合  （linear  combination）。形式上，一；组向量的线性组合，是指每个向量乘以对应标量系数之后的和，即", "keywords": "是指每个向量乘以对应标量系数之后的和, 组向量的线性组合, 形式上, 一般而言, 这种操作称为线性组合", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b09c4cb4-086f-4e1a-80d4-8b028954f55b", "label": "摘要7", "info": "一组向量的生成子空间 （span）是原始向量线性组合后所能抵达的点的；集合。", "keywords": "集合, 是原始向量线性组合后所能抵达的点的, 一组向量的生成子空间", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "78c26023-3d9d-4007-82cb-25d21f2f9362", "label": "摘要8", "info": "确定 Ax=b 是否有解，相当于确定向量 b 是否在 A 列向量的生成子空间；中。这个特殊的生成子空间被称为 A 的列空间 （column space）或者 A；的值域 （range）。", "keywords": "是否在, 确定, 列向量的生成子空间, 是否有解, 这个特殊的生成子空间被称为", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "fd9b72a4-749d-4e49-b469-a36d73b2d024", "label": "摘要9", "info": "都存在解，我们要求  A；为了使方程  Ax=b  对于任意向量；中的某个点不在  A  的列空间", "keywords": "为了使方程, 都存在解, 我们要求, 对于任意向量, 的列空间", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "435191b9-57fc-49ae-b903-699c0efe1353", "label": "摘要10", "info": "的要求，意味着 A 至少有m列，即", "keywords": "至少有, 的要求, 意味着", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f94900ec-e8ce-479d-8d8f-1e815402e97b", "label": "摘要11", "info": "不等式；仅是方程对每一点都有解的必要条件。这不是一个；中的矩", "keywords": "仅是方程对每一点都有解的必要条件, 不等式, 这不是一个, 中的矩", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3fb4cbc7-e131-4745-8df9-70e75479958a", "label": "摘要12", "info": "正式地说，这种冗余称为线性相关  （linear  dependence）。如果一组向；量中的任意一个向量都不能表示成其他向量的线性组合，那么这组向量；称为线性无关  （linearly  independent）。如果某个向量是一组向量中某", "keywords": "这种冗余称为线性相关, 称为线性无关, 如果某个向量是一组向量中某, 如果一组向, 那么这组向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b5ddb78f-b811-4888-bebf-5db2b98774d4", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；要想使矩阵可逆，我们还需要保证式（2.11）对于每一个  b  值至多有一；个解。为此，我们需要确保该矩阵至多有m个列向量。否则，该方程会", "keywords": "个列向量, 值至多有一, 对于每一个, 否则, 我们还需要保证式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "71dad3df-c56a-449f-a5ed-1c1434733ea6", "label": "摘要14", "info": "综上所述，这意味着该矩阵必须是一个方阵  （square），即m=n，并且；所有列向量都是线性无关的。一个列向量线性相关的方阵被称为奇异的；（singular）。", "keywords": "综上所述, 一个列向量线性相关的方阵被称为奇异的, 并且, 这意味着该矩阵必须是一个方阵, 所有列向量都是线性无关的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3ac19ced-34f4-4776-b809-9461e7ec5e25", "label": "摘要15", "info": "如果矩阵  A  不是一个方阵或者是一个奇异的方阵，该方程仍然可能有；解。但是我们不能使用矩阵逆去求解。", "keywords": "不是一个方阵或者是一个奇异的方阵, 该方程仍然可能有, 如果矩阵, 但是我们不能使用矩阵逆去求解", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "064e5402-2932-46cd-af41-030f988a5b2d", "label": "摘要16", "info": "目前为止，我们已经讨论了逆矩阵左乘。我们也可以定义逆矩阵右乘：", "keywords": "我们已经讨论了逆矩阵左乘, 目前为止, 我们也可以定义逆矩阵右乘", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "99755dc8-4d85-433e-9014-9dadf9257ea5", "label": "摘要17", "info": "对于方阵而言，它的左逆和右逆是相等的。", "keywords": "它的左逆和右逆是相等的, 对于方阵而言", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "1d80402a-57b6-470e-af65-ef10c01291bd", "label": "2.5：范数", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "17532065-3a1b-4db4-bb52-eb51e164b444", "label": "摘要1", "info": "有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用称为；范数 （norm）的函数来衡量向量大小。形式上，L p 范数定义如下", "keywords": "我们经常使用称为, 在机器学习中, 的函数来衡量向量大小, 有时我们需要衡量一个向量的大小, 形式上", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "32a42634-f3c9-4db5-b2eb-cbd65830f327", "label": "摘要2", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "49f141a3-af02-4d7f-bde7-14ec9882aca1", "label": "摘要3", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d808c24b-8ead-44af-9fed-f7827c79b834", "label": "摘要4", "info": "范数（包括L  p  范数）是将向量映射到非负值的函数。直观上来说，向；量 x 的范数衡量从原点到点 x 的距离。更严格地说，范数是满足下列性；质的任意函数：", "keywords": "是将向量映射到非负值的函数, 的范数衡量从原点到点, 的距离, 更严格地说, 范数是满足下列性", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "05a4a6e2-70a2-45a0-8cf6-17d31853a778", "label": "摘要5", "info": "；", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2d60e995-7c50-48bc-97b9-bd8e81e4c28b", "label": "摘要6", "info": "（三角不等式  （triangle", "keywords": "三角不等式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6b05ae74-0ffc-4bad-b2fc-a720e279846d", "label": "摘要7", "info": "inequality））；", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f20df54c-d6cb-47c8-b3e4-00e4cad40ea7", "label": "摘要8", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3e567867-abd2-4542-a156-4136b221a7b6", "label": "摘要9", "info": "当p=2时，L  2  范数称为欧几里得范数  （Euclidean  norm）。它表示从原；点出发到向量  x  确定的点的欧几里得距离。L  2  范数在机器学习中出现；得十分频繁，经常简化表示为  ，略去了下标2。平方L 2 范数也经常", "keywords": "范数也经常, 范数在机器学习中出现, 它表示从原, 范数称为欧几里得范数, 略去了下标", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5e4c468e-2966-4803-818f-2bc6d92639df", "label": "摘要10", "info": "计算。", "keywords": "计算", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "91336e01-89d8-42a2-ab99-d02951a75d76", "label": "摘要11", "info": "平方L 2 范数在数学和计算上都比L 2 范数本身更方便。例如，平方L 2 范；数对  x  中每个元素的导数只取决于对应的元素，而L  2  范数对每个元素；的导数和整个向量相关。但是在很多情况下，平方L  2  范数也可能不受", "keywords": "的导数和整个向量相关, 例如, 中每个元素的导数只取决于对应的元素, 范数对每个元素, 但是在很多情况下", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "fe684702-4726-4521-9bc6-29f1d04539df", "label": "摘要12", "info": "当机器学习问题中零和非零元素之间的差异非常重要时，通常会使用L 1；范数。每当 x 中某个元素从0增加  ，对应的L 1 范数也会增加  。", "keywords": "对应的, 中某个元素从, 当机器学习问题中零和非零元素之间的差异非常重要时, 通常会使用, 范数也会增加", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "1d4d8ba2-0bc6-4233-aefc-a7cad7e8e320", "label": "摘要13", "info": "有时候我们会统计向量中非零元素的个数来衡量向量的大小。有些作者；将这种函数称为“L  0  范数”，但是这个术语在数学意义上是不对的。向；量的非零元素的数目不是范数，因为对向量缩放α倍不会改变该向量非", "keywords": "有些作者, 有时候我们会统计向量中非零元素的个数来衡量向量的大小, 但是这个术语在数学意义上是不对的, 量的非零元素的数目不是范数, 范数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "8987bf60-200a-4f13-bf12-cd98f865c33f", "label": "摘要14", "info": "1  范数经常作为表示非零元素数目的替代函", "keywords": "范数经常作为表示非零元素数目的替代函", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "12063177-dbbb-458e-944c-d84493c9fe0f", "label": "摘要15", "info": "另外一个经常在机器学习中出现的范数是L  ∞  范数，也被称为最大范数；（max norm）。这个范数表示向量中具有最大幅值的元素的绝对值：", "keywords": "这个范数表示向量中具有最大幅值的元素的绝对值, 另外一个经常在机器学习中出现的范数是, 也被称为最大范数, 范数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c2793f25-53a7-4446-928c-53144d969de5", "label": "摘要16", "info": "有时候我们可能也希望衡量矩阵的大小。在深度学习中，最常见的做法；是使用Frobenius范数 （Frobenius norm），即", "keywords": "有时候我们可能也希望衡量矩阵的大小, 最常见的做法, 是使用, 在深度学习中, 范数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f01bb23c-e27a-4a1d-88e0-ba0c0a5756cb", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其类似于向量的L 2 范数。", "keywords": "其类似于向量的, 范数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d5024a53-6149-4983-ab9a-7cf0c21d2697", "label": "摘要18", "info": "两个向量的点积 可以用范数来表示，具体如下", "keywords": "两个向量的点积, 可以用范数来表示, 具体如下", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "879b3bb3-dc20-426d-a732-33c346251340", "label": "摘要19", "info": "其中θ表示 x 和 y 之间的夹角。", "keywords": "表示, 之间的夹角, 其中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "043e5d74-b413-4c28-8400-edcb9675b6fa", "label": "2.6：特殊类型的矩阵和向量", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "dad39884-0005-4b45-aa7f-3cbc0d27b30a", "label": "摘要1", "info": "有些特殊类型的矩阵和向量是特别有用的。", "keywords": "有些特殊类型的矩阵和向量是特别有用的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6f5bac43-cbcc-422d-855f-91c3af08a4dd", "label": "摘要2", "info": "D", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5f7aacf6-77a2-435b-8942-bb17fa6adbd3", "label": "摘要3", "info": "对角矩阵  （diagonal  matrix）只在主对角线上含有非零元素，其他位置；是对角矩阵，当且仅当对于所有的；都是零。形式上，矩阵", "keywords": "是对角矩阵, 都是零, 当且仅当对于所有的, 矩阵, 只在主对角线上含有非零元素", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "1135e29f-a2f6-4770-af44-dd71392e22c2", "label": "摘要4", "info": "并非所有的对角矩阵都是方阵。长方形的矩阵也有可能是对角矩阵。非；方阵的对角矩阵没有逆矩阵，但我们仍然可以高效地计算它们的乘法。；对于一个长方形对角矩阵  D  而言，乘法  Dx  会涉及  x  中每个元素的缩", "keywords": "对于一个长方形对角矩阵, 乘法, 但我们仍然可以高效地计算它们的乘法, 并非所有的对角矩阵都是方阵, 而言", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6d481c05-4a89-41e3-b64d-db4ae4cd6bad", "label": "摘要5", "info": "对称 （symmetric）矩阵是转置和自己相等的矩阵，即", "keywords": "对称, 矩阵是转置和自己相等的矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5e9eea09-443d-4324-b033-5655f54f3e2d", "label": "摘要6", "info": "当某些不依赖参数顺序的双参数函数生成元素时，对称矩阵经常会出", "keywords": "当某些不依赖参数顺序的双参数函数生成元素时, 对称矩阵经常会出", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "0e04ea92-fe12-4a40-8f84-46c95b6d109c", "label": "摘要7", "info": "现。例如，如果 A 是一个距离度量矩阵， A  i,j  表示点i到点j的距离，那；么 A i,j = A j,i ，因为距离函数是对称的。", "keywords": "如果, 是一个距离度量矩阵, 例如, 的距离, 到点", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c12393c2-b4d8-44f6-9c0b-60915cda139e", "label": "摘要8", "info": "单位向量 （unit vector）是具有单位范数 （unit norm）的向量，即", "keywords": "的向量, 是具有单位范数, 单位向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7c450eb6-2d75-4680-956b-6d9f55ee95ab", "label": "摘要9", "info": "，那么向量 x 和向量 y 互相正交 （orthogonal）。如果", "keywords": "如果, 互相正交, 和向量, 那么向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3ace4ea1-d222-4fe5-ba9e-99d2737b9cad", "label": "摘要10", "info": "如果；两个向量都有非零范数，那么这两个向量之间的夹角是90◦。在；中，至多有n个范数非零向量互相正交。如果这些向量不但互相正交，", "keywords": "至多有, 如果, 那么这两个向量之间的夹角是, 个范数非零向量互相正交, 如果这些向量不但互相正交", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "07ba42da-19b8-4c2f-9e1d-2ba97c24feee", "label": "摘要11", "info": "正交矩阵  （orthogonal  matrix）指行向量和列向量是分别标准正交的方；阵，即", "keywords": "指行向量和列向量是分别标准正交的方, 正交矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "99e3c86f-9dc9-4d1c-8d3e-d2cf0c229e9a", "label": "摘要12", "info": "这意味着", "keywords": "这意味着", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "ccbd4288-d915-46be-9c6d-abde4c8b79f7", "label": "摘要13", "info": "正交矩阵受到关注是因为求逆计算代价小。我们需要注意正交矩阵的定；义。违反直觉的是，正交矩阵的行向量不仅是正交的，还是标准正交；的。对于行向量或列向量互相正交但不是标准正交的矩阵，没有对应的", "keywords": "正交矩阵受到关注是因为求逆计算代价小, 我们需要注意正交矩阵的定, 违反直觉的是, 还是标准正交, 没有对应的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "dffff6b3-6177-45f9-a1a0-af862c221f07", "label": "2.7：特征分解", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "eada462b-4f3e-495e-9e76-fec7a8581ce5", "label": "摘要1", "info": "许多数学对象可以通过将它们分解成多个组成部分或者找到它们的一些；属性来更好地理解。这些属性是通用的，而不是由我们选择表示它们的；方式所产生的。", "keywords": "这些属性是通用的, 属性来更好地理解, 许多数学对象可以通过将它们分解成多个组成部分或者找到它们的一些, 方式所产生的, 而不是由我们选择表示它们的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5e57f3e7-8f7f-4a15-b0b2-dc5f8a43dc92", "label": "摘要2", "info": "例如，整数可以分解为质因数。我们可以用十进制或二进制等不同方式；表示整数12，但是12=2×3×3永远是对的。从这个表示中我们可以获得一；些有用的信息，比如12不能被5整除，或者12的倍数可以被3整除。", "keywords": "整数可以分解为质因数, 但是, 例如, 从这个表示中我们可以获得一, 我们可以用十进制或二进制等不同方式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "9b852b7b-7c8a-4e50-8328-3f155584b791", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；正如我们可以通过分解质因数来发现整数的一些内在性质，我们也可以；通过分解矩阵来发现矩阵表示成数组元素时不明显的函数性质。", "keywords": "我们也可以, 通过分解矩阵来发现矩阵表示成数组元素时不明显的函数性质, 正如我们可以通过分解质因数来发现整数的一些内在性质", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "55833416-6a67-492a-99f2-c80c3ddce94a", "label": "摘要4", "info": "特征分解  （eigendecomposition）是使用最广的矩阵分解之一，即我们；将矩阵分解成一组特征向量和特征值。", "keywords": "即我们, 是使用最广的矩阵分解之一, 将矩阵分解成一组特征向量和特征值, 特征分解", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "4d7f80b6-2406-4319-8288-44f0de4c306d", "label": "摘要5", "info": "方阵  A  的特征向量  （eigenvector）是指与  A  相乘后相当于对该向量进；行缩放的非零向量ν：", "keywords": "相乘后相当于对该向量进, 方阵, 的特征向量, 是指与, 行缩放的非零向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a0a507ff-c6dd-40a4-b419-b1b85e39e97f", "label": "摘要6", "info": "其中标量λ称为这个特征向量对应的特征值 （eigenvalue）。（类似地，；，；我们也可以定义左特征向量  （left  eigenvector）", "keywords": "称为这个特征向量对应的特征值, 其中标量, 我们也可以定义左特征向量, 类似地", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3c943bff-8877-4997-bf1c-5a7c15b5de54", "label": "摘要7", "info": "如果", "keywords": "如果", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "81a00f00-9798-42e9-8a58-b0e541d0f646", "label": "摘要8", "info": "ν", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e583a43b-9e26-4fb5-9957-326d2c2acf01", "label": "摘要9", "info": "是", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "324be544-b64f-4dc6-946d-33fb909ba5eb", "label": "摘要10", "info": "的特征向量，那么任何缩放后的向量；A；也是 A 的特征向量。此外， sν 和 ν 有相同的", "keywords": "此外, 也是, 那么任何缩放后的向量, 的特征向量, 有相同的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "4fd863e5-7bf0-4ed7-ad18-697e4be2b76f", "label": "摘要11", "info": "特征值。基于这个原因，通常我们只考虑单位特征向量。", "keywords": "通常我们只考虑单位特征向量, 特征值, 基于这个原因", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "61de76da-990b-4d13-b756-bf68fd4d06d4", "label": "摘要12", "info": "假设矩阵  A  有n个线性无关的特征向量；征值；是一个特征向量：", "keywords": "个线性无关的特征向量, 假设矩阵, 是一个特征向量, 征值", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "52587fae-528f-49cb-8c82-f7611e200fca", "label": "摘要13", "info": "，对应着特；。我们将特征向量连接成一个矩阵，使得每一列；。类似地，我们也可以将特", "keywords": "使得每一列, 我们将特征向量连接成一个矩阵, 对应着特, 我们也可以将特, 类似地", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "972e3c32-12de-40ab-9d44-25476894437b", "label": "摘要14", "info": "我们已经看到了构建具有特定特征值和特征向量的矩阵，能够使我们在；目标方向上延伸空间。然而，我们也常常希望将矩阵分解；（decompose）成特征值和特征向量。这样可以帮助我们分析矩阵的特", "keywords": "成特征值和特征向量, 目标方向上延伸空间, 能够使我们在, 然而, 我们也常常希望将矩阵分解", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c299531d-cabe-4e87-8c27-016be3d5bf1e", "label": "摘要15", "info": "不是每一个矩阵都可以分解成特征值和特征向量。在某些情况下，特征；分解存在，但是会涉及复数而非实数。幸运的是，在本书中，我们通常；只需要分解一类有简单分解的矩阵。具体来讲，每个实对称矩阵都可以", "keywords": "但是会涉及复数而非实数, 具体来讲, 幸运的是, 在本书中, 我们通常", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d037669f-9eed-49fb-bc89-daab8a3d2d49", "label": "摘要16", "info": "其中 Q 是 A 的特征向量组成的正交矩阵， Λ 是对角矩阵。特征值Λ  i，i；对应的特征向量是矩阵 Q 的第i列，记作 Q ：，i 。因为 Q 是正交矩阵，；我们可以将 A 看作沿方向 ν (i) 延展λ i 倍的空间，如图2.3所示。", "keywords": "因为, 的第, 特征值, 是对角矩阵, 我们可以将", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "15a8ed99-b9ca-4ddb-9f04-7d0f534e5bdc", "label": "摘要17", "info": "图2.3　特征向量和特征值的作用效果。特征向量和特征值的作用效果的一个实例。在这里，矩；阵 A 有两个标准正交的特征向量，对应特征值为λ 1 的 ν (1) 以及对应特征值为λ 2 的 ν (2) 。；的集合，构成一个单位圆。（右）我们画出了所有", "keywords": "在这里, 对应特征值为, 特征向量和特征值的作用效果的一个实例, 特征向量和特征值的作用效果, 以及对应特征值为", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "8632ff0e-d48a-4f3a-9ae7-5923f07a81c4", "label": "摘要18", "info": "虽然任意一个实对称矩阵  A  都有特征分解，但是特征分解可能并不唯；一。如果两个或多个特征向量拥有相同的特征值，那么在由这些特征向；量产生的生成子空间中，任意一组正交向量都是该特征值对应的特征向", "keywords": "那么在由这些特征向, 如果两个或多个特征向量拥有相同的特征值, 量产生的生成子空间中, 但是特征分解可能并不唯, 任意一组正交向量都是该特征值对应的特征向", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6df0251b-cb71-48b7-aa48-f52de4abed1b", "label": "摘要19", "info": "矩阵的特征分解给了我们很多关于矩阵的有用信息。矩阵是奇异的，当；且仅当含有零特征值。实对称矩阵的特征分解也可以用于优化二次方程；。当 x 等于  A 的某个特征向", "keywords": "矩阵的特征分解给了我们很多关于矩阵的有用信息, 矩阵是奇异的, 实对称矩阵的特征分解也可以用于优化二次方程, 且仅当含有零特征值, 等于", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3d88a67e-80e6-4e50-bb27-ed86487f233f", "label": "摘要20", "info": "，其中限制", "keywords": "其中限制", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7daf6a3e-0e4f-4d39-a37f-061af1ea60da", "label": "摘要21", "info": "所有特征值都是正数的矩阵称为正定  （positive  definite）；所有特征值", "keywords": "所有特征值都是正数的矩阵称为正定, 所有特征值", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f7798f5f-fe1b-429e-8177-ad85a81a81f3", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；都是非负数的矩阵称为半正定  （positive  semidefinite）。同样地，所有；特征值都是负数的矩阵称为负定 （negative definite）；所有特征值都是", "keywords": "所有特征值都是, 同样地, 所有, 都是非负数的矩阵称为半正定, 特征值都是负数的矩阵称为负定", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d7d0b6ab-c4d0-45ea-a7f0-47391cd8cef6", "label": "摘要23", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "label": "2.8：奇异值分解", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "2dcf668d-e56a-471c-87af-36336987f879", "label": "摘要1", "info": "在第2.7节，我们探讨了如何将矩阵分解成特征向量和特征值。还有另；一种分解矩阵的方法，称为奇异值分解 （singular value decomposition，；vector）和奇异值", "keywords": "一种分解矩阵的方法, 称为奇异值分解, 和奇异值, 还有另, 在第", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "be744a9a-70f2-4431-9987-3c52ba781446", "label": "摘要2", "info": "回想一下，我们使用特征分解去分析矩阵 A 时，得到特征向量构成的矩；阵 V 和特征值构成的向量 λ ，我们可以重新将 A 写作", "keywords": "和特征值构成的向量, 写作, 我们可以重新将, 得到特征向量构成的矩, 回想一下", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "11a66b6d-5fb6-449a-9e78-7502a348e1f4", "label": "摘要3", "info": "奇异值分解是类似的，只不过这回我们将矩阵  A  分解成三个矩阵的乘；积：", "keywords": "只不过这回我们将矩阵, 奇异值分解是类似的, 分解成三个矩阵的乘", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "13dca31a-f23a-4c95-b69e-1e7f77f0398a", "label": "摘要4", "info": "假设 A 是一个m×n的矩阵，那么 U  是一个m×m的矩阵，  D  是一个m×n；的矩阵， V 是一个n×n矩阵。", "keywords": "的矩阵, 矩阵, 那么, 是一个, 假设", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c0cfffb7-a461-4a99-8e4a-479d8de8037f", "label": "摘要5", "info": "这些矩阵中的每一个经定义后都拥有特殊的结构。矩阵  U  和  V  都定义；为正交矩阵，而矩阵  D  定义为对角矩阵。注意，矩阵  D  不一定是方；阵。", "keywords": "定义为对角矩阵, 注意, 矩阵, 不一定是方, 为正交矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a6f1925c-ed78-48ea-849f-f81804787667", "label": "摘要6", "info": "对角矩阵 D  对角线上的元素称为矩阵  A  的奇异值  （singular  value）。；矩阵 U 的列向量称为左奇异向量 （left  singular  vector），矩阵  V  的列；向量称右奇异向量 （right singular vector）。", "keywords": "矩阵, 的列, 的奇异值, 对角线上的元素称为矩阵, 向量称右奇异向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e246d4e8-8555-4c15-be70-1949fdc95413", "label": "摘要7", "info": "事实上，我们可以用与  A  相关的特征分解去解释  A  的奇异值分解。  A；的左奇异向量 （left singular vector）是；的特征向量。 A 的右奇", "keywords": "我们可以用与, 事实上, 的奇异值分解, 相关的特征分解去解释, 的左奇异向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "d4d1d308-f6c0-4438-8015-66e3deec70d9", "label": "摘要8", "info": "特征值的平方根，同时也是", "keywords": "特征值的平方根, 同时也是", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "f509a854-a16b-4ffd-90e5-d76692a4893c", "label": "摘要9", "info": "SVD最有用的一个性质可能是拓展矩阵求逆到非方矩阵上。我们将在下；一节中探讨。", "keywords": "最有用的一个性质可能是拓展矩阵求逆到非方矩阵上, 一节中探讨, 我们将在下", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "label": "2.9：Moore-Penrose伪逆", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "afcf994e-fdc1-4914-a502-49776777256d", "label": "摘要1", "info": "对于非方矩阵而言，其逆矩阵没有定义。假设在下面的问题中，我们希；望通过矩阵 A 的左逆 B 来求解线性方程：", "keywords": "对于非方矩阵而言, 其逆矩阵没有定义, 来求解线性方程, 望通过矩阵, 的左逆", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5d75b7cd-3ab9-4b5e-9206-80d3c02abb31", "label": "摘要2", "info": "等式两边左乘左逆B后，我们得到", "keywords": "等式两边左乘左逆, 我们得到", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "21c97d56-40a3-4c43-89cb-1177440781bf", "label": "摘要3", "info": "取决于问题的形式，我们可能无法设计一个唯一的映射将  A  映射到  B；。", "keywords": "我们可能无法设计一个唯一的映射将, 映射到, 取决于问题的形式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6f97c8e3-44c0-4b05-834a-1116e6e7ec6a", "label": "摘要4", "info": "如果矩阵  A  的行数大于列数，那么上述方程可能没有解。如果矩阵  A；的行数小于列数，那么上述矩阵可能有多个解。", "keywords": "那么上述矩阵可能有多个解, 如果矩阵, 的行数小于列数, 那么上述方程可能没有解, 的行数大于列数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "fe1f9f35-ebeb-40af-a96b-5d9da0690636", "label": "摘要5", "info": "Moore-Penrose伪逆 （Moore-Penrose pseudoinverse）使我们在这类问题；上取得了一定的进展。矩阵 A 的伪逆定义为", "keywords": "上取得了一定的进展, 伪逆, 矩阵, 使我们在这类问题, 的伪逆定义为", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "bd293213-3b07-4baf-9152-e2e33d0e89f8", "label": "摘要6", "info": "计算伪逆的实际算法没有基于这个定义，而是使用下面的公式", "keywords": "计算伪逆的实际算法没有基于这个定义, 而是使用下面的公式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5c677835-4d6e-4dfc-9ea8-14d568c873ca", "label": "摘要7", "info": "其中，矩阵  U、D  和  V  是矩阵  A  奇异值分解后得到的矩阵。对角矩阵；D 的伪逆 D + 是其非零元素取倒数之后再转置得到的。", "keywords": "矩阵, 其中, 奇异值分解后得到的矩阵, 是其非零元素取倒数之后再转置得到的, 是矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "03dc3a27-3717-4f24-bff0-69a3760eda15", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；当矩阵 A 的列数多于行数时，使用伪逆求解线性方程是众多可能解法中；是方程所有可行解中欧几里得范数", "keywords": "当矩阵, 的列数多于行数时, 是方程所有可行解中欧几里得范数, 使用伪逆求解线性方程是众多可能解法中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "80c44071-1750-4135-ac4c-5c10d52537ee", "label": "摘要9", "info": "最小的一个。", "keywords": "最小的一个", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6d02fbe5-a974-486b-b275-a2c94953bb5b", "label": "摘要10", "info": "当矩阵 A 的行数多于列数时，可能没有解。在这种情况下，通过伪逆得；到的 x 使得 Ax 和 y 的欧几里得距离", "keywords": "可能没有解, 的欧几里得距离, 到的, 在这种情况下, 当矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "afdbb721-e9a7-4c32-8977-21722ca881d4", "label": "摘要11", "info": "最小。", "keywords": "最小", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "label": "2.10：迹运算", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "9202652b-de45-42be-b6ff-db3ef19e31bb", "label": "摘要1", "info": "迹运算返回的是矩阵对角元素的和：", "keywords": "迹运算返回的是矩阵对角元素的和", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "41225b05-7722-4430-9eaa-04e1c11a19c6", "label": "摘要2", "info": "迹运算因为很多原因而有用。若不使用求和符号，有些矩阵运算很难描；述，而通过矩阵乘法和迹运算符号可以清楚地表示。例如，迹运算提供；了另一种描述矩阵Frobenius范数的方式：", "keywords": "若不使用求和符号, 迹运算提供, 有些矩阵运算很难描, 了另一种描述矩阵, 例如", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2490a0ad-4f42-4f71-b75e-b8bf2a69d728", "label": "摘要3", "info": "用迹运算表示表达式，我们可以使用很多有用的等式巧妙地处理表达；式。例如，迹运算在转置运算下是不变的：", "keywords": "迹运算在转置运算下是不变的, 用迹运算表示表达式, 例如, 我们可以使用很多有用的等式巧妙地处理表达", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "ece56822-c910-417f-b68c-462190937e02", "label": "摘要4", "info": "多个矩阵相乘得到的方阵的迹，和将这些矩阵中的最后一个挪到最前面；之后相乘的迹是相同的。当然，我们需要考虑挪动之后矩阵乘积依然定；义良好：", "keywords": "之后相乘的迹是相同的, 义良好, 我们需要考虑挪动之后矩阵乘积依然定, 当然, 多个矩阵相乘得到的方阵的迹", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "329c9877-cc99-4ed2-8782-e489cce4dab7", "label": "摘要5", "info": "或者更一般地，", "keywords": "或者更一般地", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "43dab182-ad88-4ea2-b47e-40760426a1a1", "label": "摘要6", "info": "即使循环置换后矩阵乘积得到的矩阵形状变了，迹运算的结果依然不", "keywords": "迹运算的结果依然不, 即使循环置换后矩阵乘积得到的矩阵形状变了", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "dd5dd22e-1709-4b88-afba-c98a0b7d0294", "label": "摘要7", "info": "变。例如，假设矩阵；们可以得到", "keywords": "们可以得到, 假设矩阵, 例如", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "cb1393a0-ca80-40bb-8a62-743e24019322", "label": "摘要8", "info": "，矩阵", "keywords": "矩阵", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "41dc3f55-3594-4a26-91d9-5166b058a8b7", "label": "摘要9", "info": "，我", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e716fdb5-e0a5-45cf-a69a-fe88563149ec", "label": "摘要10", "info": "尽管", "keywords": "尽管", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "6d4f6481-2d58-4511-8ed0-5391622a8807", "label": "摘要11", "info": "。", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "047b7325-631b-4665-9abb-175d6d84ee99", "label": "摘要12", "info": "另一个有用的事实是标量在迹运算后仍然是它自己：a=Tr(a)。", "keywords": "另一个有用的事实是标量在迹运算后仍然是它自己", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2ebb834a-ba70-4caf-99f2-538a478af600", "label": "2.11：行列式", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "69cfa5fc-0824-4f45-a7ba-fa8fecb064fd", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；2.12　实例：主成分分析", "keywords": "主成分分析, 实例", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "730c01f8-fcdc-43e4-8c8b-184572cf0c8e", "label": "摘要2", "info": "行列式，记作det(  A  )，是一个将方阵  A  映射到实数的函数。行列式等；于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法；后空间扩大或者缩小了多少。如果行列式是0，那么空间至少沿着某一", "keywords": "行列式, 于矩阵特征值的乘积, 记作, 后空间扩大或者缩小了多少, 映射到实数的函数", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "label": "2.12：实例：主成分分析", "level": 2, "group": "chapter-2", "type": "子章節"}, {"id": "4d06c647-3b84-4c2c-81b1-23cda1581fd9", "label": "摘要1", "info": "主成分分析 （principal components analysis，PC A ）是一个简单的机器；学习算法，可以通过基础的线性代数知识推导。", "keywords": "主成分分析, 可以通过基础的线性代数知识推导, 学习算法, 是一个简单的机器", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "fe8bded0-3716-4d7e-935e-0c3461899b33", "label": "摘要2", "info": "空间中有m个点", "keywords": "个点, 空间中有", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "35b13a67-b78f-4b97-bbf3-06887b8a2712", "label": "摘要3", "info": "，我们希望对这些点；假设在；进行有损压缩。有损压缩表示我们使用更少的内存，但损失一些精度去", "keywords": "假设在, 但损失一些精度去, 我们希望对这些点, 进行有损压缩, 有损压缩表示我们使用更少的内存", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "60d306b2-546e-4f7d-a6ba-c629595ad904", "label": "摘要4", "info": "，会有；编码这些点的一种方式是用低维表示。对于每个点；。如果l比n小，那么我们便使用了更", "keywords": "如果, 对于每个点, 会有, 那么我们便使用了更, 编码这些点的一种方式是用低维表示", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7bd9620a-afe2-4e35-8e70-5c36b81f8012", "label": "摘要5", "info": "PCA由我们选择的解码函数而定。具体来讲，为了简化解码器，我们使；是；用矩阵乘法将编码映射回", "keywords": "为了简化解码器, 由我们选择的解码函数而定, 具体来讲, 用矩阵乘法将编码映射回, 我们使", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c216aa51-8c40-44d2-8c30-657cc07a20e9", "label": "摘要6", "info": "，即g (c )=Dc ，其中", "keywords": "其中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b418c39b-df42-4e63-b24f-315ebb460b4b", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；到目前为止，所描述的问题可能会有多个解。因为如果我们按比例地缩；小所有点对应的编码向量c i ，那么只需按比例放大 D :,i ，即可保持结果", "keywords": "小所有点对应的编码向量, 即可保持结果, 那么只需按比例放大, 因为如果我们按比例地缩, 所描述的问题可能会有多个解", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a1e66262-26c7-4ee4-b96e-d2cbab29bd0f", "label": "摘要8", "info": "计算这个解码器的最优编码可能是一个困难的问题。为了使编码问题简；单一些，PCA限制  D  的列向量彼此正交（注意，除非l=n，否则严格意；义上 D 不是一个正交矩阵）。", "keywords": "除非, 义上, 不是一个正交矩阵, 的列向量彼此正交, 注意", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "bb4399b9-8773-48ba-8706-681227649279", "label": "摘要9", "info": "为了将这个基本想法变为我们能够实现的算法，首先我们需要明确如何；根据每一个输入 x 得到一个最优编码c ∗ 。一种方法是最小化原始输入向；量  x  和重构向量g(c  ∗  )之间的距离。我们使用范数来衡量它们之间的距", "keywords": "得到一个最优编码, 和重构向量, 我们使用范数来衡量它们之间的距, 一种方法是最小化原始输入向, 为了将这个基本想法变为我们能够实现的算法", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e35fea74-8f72-4a43-b823-c5b8fe69b5b1", "label": "摘要10", "info": "我们可以用平方L 2 范数替代L 2 范数，因为两者在相同的值c上取得最小；值。这是因为L  2  范数是非负的，并且平方运算在非负值上是单调递增；的。", "keywords": "这是因为, 我们可以用平方, 上取得最小, 范数是非负的, 并且平方运算在非负值上是单调递增", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "ba246938-0346-491f-9263-2e5197323cc9", "label": "摘要11", "info": "该最小化函数可以简化成", "keywords": "该最小化函数可以简化成", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c0c3b973-bbf0-40f6-94e9-e050545e3136", "label": "摘要12", "info": "（式（2.30）中L 2 范数的定义）", "keywords": "范数的定义", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "fb08780c-2e87-4215-a5cb-c50bf5637d32", "label": "摘要13", "info": "（分配律）", "keywords": "分配律", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7cff5273-5c41-4998-8f01-8d6c5fd1376c", "label": "摘要14", "info": "（因为标量", "keywords": "因为标量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "22130431-ec91-420b-8833-151dc724cf37", "label": "摘要15", "info": "的转置等于自己）。", "keywords": "的转置等于自己", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "38139c87-c345-4482-bb2b-8f95c40a8ca4", "label": "摘要16", "info": "因为第一项", "keywords": "因为第一项", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "68e08954-70ce-41f6-969d-ab034ed925d2", "label": "摘要17", "info": "不依赖于c，所以我们可以忽略它，得到如下的优化", "keywords": "不依赖于, 所以我们可以忽略它, 得到如下的优化", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "12f63830-f83b-450a-8e2b-2374c797381f", "label": "摘要18", "info": "目标：", "keywords": "目标", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "342c16b6-262e-4d3c-9d1f-57f8852b6db5", "label": "摘要19", "info": "更进一步，代入g(c)的定义：", "keywords": "的定义, 更进一步, 代入", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "8182e4d1-7f58-4ac1-8866-2c27654fafef", "label": "摘要20", "info": "（矩阵 D 的正交性和单位范数约束）", "keywords": "矩阵, 的正交性和单位范数约束", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "78dc5fd1-1774-46f4-9077-f1f46bb3793f", "label": "摘要21", "info": "我们可以通过向量微积分来求解这个最优化问题（如果你不清楚怎么；做，请参考第4.3节）。", "keywords": "请参考第, 我们可以通过向量微积分来求解这个最优化问题, 如果你不清楚怎么", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "0f36df21-d663-406b-8c4d-e62e322f64d5", "label": "摘要22", "info": "这使得算法很高效：最优编码  x  只需要一个矩阵-向量乘法操作。为了；编码向量，我们使用编码函数", "keywords": "最优编码, 只需要一个矩阵, 为了, 编码向量, 向量乘法操作", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "894f2d70-ff1e-41a5-99b6-cf1a109ba18f", "label": "摘要23", "info": "进一步使用矩阵乘法，我们也可以定义PCA重构操作：", "keywords": "重构操作, 进一步使用矩阵乘法, 我们也可以定义", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "89725635-0e4d-47c4-b18e-1f313a968452", "label": "摘要24", "info": "接下来，我们需要挑选编码矩阵  D  。要做到这一点，先来回顾最小化；输入和重构之间L  2  距离的这个想法。因为用相同的矩阵  D  对所有点进；行解码，我们不能再孤立地看待每个点。反之，我们必须最小化所有维", "keywords": "接下来, 先来回顾最小化, 因为用相同的矩阵, 反之, 对所有点进", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c35002f0-ab96-43a4-90aa-ad0d2a4018f7", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；为了推导用于寻求  D  ∗  的算法，我们首先考虑l=1的情况。在这种情况；下， D 是一个单一向量 d 。将式（2.67）代入式（2.68），简化 D 为 d", "keywords": "在这种情况, 简化, 的情况, 的算法, 为了推导用于寻求", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "2e7f75e2-c21f-4d42-96ba-de6c06a291af", "label": "摘要26", "info": "上述公式是直接代入得到的，但不是表述上最美观的方式。在上述公式；中，我们将标量；放在向量  d  的右边。将该标量放在左边的写", "keywords": "我们将标量, 将该标量放在左边的写, 上述公式是直接代入得到的, 但不是表述上最美观的方式, 在上述公式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "85cb58a1-8d6b-4a24-993c-1f5874e45932", "label": "摘要27", "info": "或者，考虑到标量的转置和自身相等，我们也可以写作", "keywords": "我们也可以写作, 或者, 考虑到标量的转置和自身相等", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "634c67b5-6d98-4f40-8478-bfae78fec2dd", "label": "摘要28", "info": "读者应该对这些重排写法慢慢熟悉起来。", "keywords": "读者应该对这些重排写法慢慢熟悉起来", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "69a2de50-418f-4adf-af68-06960c718455", "label": "摘要29", "info": "此时，使用单一矩阵来重述问题，比将问题写成求和形式更有帮助。这；有助于我们使用更紧凑的符号。将表示各点的向量堆叠成一个矩阵，记；为", "keywords": "将表示各点的向量堆叠成一个矩阵, 有助于我们使用更紧凑的符号, 比将问题写成求和形式更有帮助, 此时, 使用单一矩阵来重述问题", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "b6a75168-661b-4279-920b-7380fd2472db", "label": "摘要30", "info": "。原问题可以重新表述为", "keywords": "原问题可以重新表述为", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "4c940a40-5ead-4b20-a8d5-00bbd8dae544", "label": "摘要31", "info": "，其中", "keywords": "其中", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "5efc8ca7-057d-4c07-b7e1-831c4f0b250b", "label": "摘要32", "info": "暂时不考虑约束，我们可以将Frobenius范数简化成下面的形式：", "keywords": "范数简化成下面的形式, 暂时不考虑约束, 我们可以将", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "c729d245-91eb-43f1-a5e0-ebd8c42aaa5a", "label": "摘要33", "info": "（式（2.49））", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "72f11dc9-52c0-4c12-9793-cae20f0e5076", "label": "摘要34", "info": "（因为与d无关的项不影响arg min）", "keywords": "因为与, 无关的项不影响", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "701883d6-4d70-4dbb-be92-0144915de760", "label": "摘要35", "info": "（因为循环改变迹运算中相乘矩阵的顺序不影响结果，如式（2.52）所；示）", "keywords": "因为循环改变迹运算中相乘矩阵的顺序不影响结果, 如式", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "33628547-e5e4-47ff-8fae-321924672714", "label": "摘要36", "info": "（再次使用上述性质）。", "keywords": "再次使用上述性质", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "e0ab27b1-5822-435e-8a3d-2f5f48cf8b8b", "label": "摘要37", "info": "此时，我们再来考虑约束条件", "keywords": "我们再来考虑约束条件, 此时", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "aa231a64-833a-455f-9d0c-1d6e559b8892", "label": "摘要38", "info": "（因为约束条件）", "keywords": "因为约束条件", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "79198185-13d2-431b-bdfb-3885fed1bc65", "label": "摘要39", "info": "这个优化问题可以通过特征分解来求解。具体来讲，最优的", "keywords": "具体来讲, 这个优化问题可以通过特征分解来求解, 最优的", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "9d5eb376-252f-44dc-967b-13710e6019d1", "label": "摘要40", "info": "d  是", "keywords": "", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "bd5cd98d-e98f-41fd-b0ff-0194e79407ad", "label": "摘要41", "info": "最大特征值对应的特征向量。", "keywords": "最大特征值对应的特征向量", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "1b68fb30-8ec8-4fd6-84df-c64bbc5fdcac", "label": "摘要42", "info": "以上推导特定于l=1的情况，仅得到了第一个主成分。更一般地，当我；们希望得到主成分的基时，矩阵  D  由前l个最大的特征值对应的特征向；量组成。这个结论可以通过归纳法证明，我们建议将此证明作为练习。", "keywords": "当我, 仅得到了第一个主成分, 以上推导特定于, 们希望得到主成分的基时, 个最大的特征值对应的特征向", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "a77a5d53-5a5d-42eb-8eef-2af8798c4db6", "label": "摘要43", "info": "线性代数是理解深度学习所必须掌握的基础数学学科之一。另一门在机", "keywords": "线性代数是理解深度学习所必须掌握的基础数学学科之一, 另一门在机", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "90b113cb-1b1d-4f14-941d-8d850de21594", "label": "摘要44", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；器学习中无处不在的重要数学学科是概率论，我们将在下一章探讨。", "keywords": "器学习中无处不在的重要数学学科是概率论, 我们将在下一章探讨", "level": 3, "group": "chapter-2", "type": "段落"}, {"id": "7045c527-0004-4c88-aeae-8b10e6134b82", "label": "第3章：概率与信息论", "level": 1, "group": "chapter-3", "type": "章節"}, {"id": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "label": "2.12：实例：主成分分析", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "a5dda387-9131-44a0-b592-1c901adb776f", "label": "摘要1", "info": "本章讨论概率论和信息论。", "keywords": "本章讨论概率论和信息论", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5dbb78ad-797a-4822-8d98-7791a87273e9", "label": "摘要2", "info": "概率论是用于表示不确定性声明的数学框架。它不仅提供了量化不确定；性的方法，也提供了用于导出新的不确定性声明 （statement）的公理。；在人工智能领域，概率论主要有两种用途：首先，概率法则告诉我们AI", "keywords": "在人工智能领域, 也提供了用于导出新的不确定性声明, 的公理, 概率论主要有两种用途, 性的方法", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "874ad328-2517-451e-b2f5-70b3f640c1ae", "label": "摘要3", "info": "概率论是众多科学学科和工程学科的基本工具。之所以讲述这章的内；容，是为了确保那些背景偏软件工程而较少接触概率论的读者也可以理；解本书的内容。", "keywords": "概率论是众多科学学科和工程学科的基本工具, 是为了确保那些背景偏软件工程而较少接触概率论的读者也可以理, 之所以讲述这章的内, 解本书的内容", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ed1bac3b-1217-4ad1-aa53-f268615b8045", "label": "摘要4", "info": "概率论使我们能够提出不确定的声明以及在不确定性存在的情况下进行；推理，而信息论使我们能够量化概率分布中的不确定性总量。", "keywords": "推理, 而信息论使我们能够量化概率分布中的不确定性总量, 概率论使我们能够提出不确定的声明以及在不确定性存在的情况下进行", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "24b0a1dd-6ef4-45b4-a0ec-7b7f0cd34485", "label": "摘要5", "info": "如果你已经对概率论和信息论很熟悉了，那么除了第3.14节，本章其余；内容你都可以跳过。而在第3.14节中，我们会介绍用来描述机器学习中；结构化概率模型的图。即使你对这些主题没有任何的先验知识，本章对", "keywords": "我们会介绍用来描述机器学习中, 内容你都可以跳过, 本章其余, 而在第, 节中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "label": "3.1：为什么要使用概率", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "55158685-0df9-4c25-ad0e-06f3e54dfa86", "label": "摘要1", "info": "计算机科学的许多分支处理的实体大部分都是完全确定且必然的。程序；员通常可以安全地假定CPU将完美地执行每条机器指令。虽然硬件错误；确实会发生，但它们非常罕见，以至于大部分软件应用在设计时并不需", "keywords": "虽然硬件错误, 员通常可以安全地假定, 计算机科学的许多分支处理的实体大部分都是完全确定且必然的, 但它们非常罕见, 程序", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "52d1f30e-bda9-4a13-9a52-ad45fa398eaf", "label": "摘要2", "info": "这是因为机器学习通常必须处理不确定量，有时也可能需要处理随机", "keywords": "有时也可能需要处理随机, 这是因为机器学习通常必须处理不确定量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6c5cd387-f3a1-4f30-a0b4-66f022e03fde", "label": "摘要3", "info": "（非确定性的）量。不确定性和随机性可能来自多个方面。至少从20世；纪80年代开始，研究人员就对使用概率论来量化不确定性提出了令人信；服的论据。这里给出的许多论据都是根据Pearl（1988）的工作总结或启", "keywords": "的工作总结或启, 这里给出的许多论据都是根据, 非确定性的, 年代开始, 不确定性和随机性可能来自多个方面", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "77e4d67c-1fdb-4962-8496-e00447ad6c98", "label": "摘要4", "info": "几乎所有活动都需要一些在不确定性存在的情况下进行推理的能力。事；实上，除了那些被定义为真的数学声明，我们很难认定某个命题是千真；万确的或者确保某件事一定会发生。", "keywords": "几乎所有活动都需要一些在不确定性存在的情况下进行推理的能力, 除了那些被定义为真的数学声明, 实上, 万确的或者确保某件事一定会发生, 我们很难认定某个命题是千真", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e21c0e45-1c50-4e12-8e9e-e807c2f044b2", "label": "摘要5", "info": "不确定性有3种可能的来源：", "keywords": "不确定性有, 种可能的来源", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9ada1768-551b-421a-8884-2498af2d39bc", "label": "摘要6", "info": "（1）被建模系统内在的随机性。例如，大多数量子力学的解释，都将；亚原子粒子的动力学描述为概率的。我们还可以创建一些假设具有随机；动态的理论情境，例如一个假想的纸牌游戏，在这个游戏中，我们假设", "keywords": "大多数量子力学的解释, 动态的理论情境, 亚原子粒子的动力学描述为概率的, 例如一个假想的纸牌游戏, 例如", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "97f69696-8150-4af7-8088-fe673c33c457", "label": "摘要7", "info": "（2）不完全观测。即使是确定的系统，当我们不能观测到所有驱动系；统行为的变量时，该系统也会呈现随机性。例如，在Monty；中，一个游戏节目的参与者被要求在3个门之间选择，并且会赢得放置", "keywords": "统行为的变量时, 该系统也会呈现随机性, 即使是确定的系统, 不完全观测, 当我们不能观测到所有驱动系", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9981d7b4-7b00-490f-86c0-a6ed17a45a25", "label": "摘要8", "info": "Hall问题", "keywords": "问题", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f6a70b26-c1f3-4ebb-a00b-af99fdeca3dc", "label": "摘要9", "info": "（3）不完全建模。当我们使用一些必须舍弃某些观测信息的模型时，；舍弃的信息会导致模型的预测出现不确定性。例如，假设我们制作了一；个机器人，它可以准确地观察周围每一个对象的位置。在对这些对象将", "keywords": "它可以准确地观察周围每一个对象的位置, 舍弃的信息会导致模型的预测出现不确定性, 例如, 个机器人, 当我们使用一些必须舍弃某些观测信息的模型时", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8d53c76c-9f98-41bb-b5c6-60d52d78362c", "label": "摘要10", "info": "在很多情况下，使用一些简单而不确定的规则要比复杂而确定的规则更；为实用，即使真正的规则是确定的并且我们建模的系统可以足够精确地；容纳复杂的规则。例如，“多数鸟儿都会飞”这个简单的规则描述起来很", "keywords": "这个简单的规则描述起来很, 容纳复杂的规则, 为实用, 例如, 即使真正的规则是确定的并且我们建模的系统可以足够精确地", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b0d23491-add4-4c75-a55a-133b0c884269", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；即使经过这么多的努力，这个规则还是很脆弱而且容易失效。", "keywords": "即使经过这么多的努力, 这个规则还是很脆弱而且容易失效", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e41825cb-e358-46c2-9a59-23579f200e5e", "label": "摘要12", "info": "尽管我们的确需要一种用以对不确定性进行表示和推理的方法，但是概；率论并不能明显地提供我们在人工智能领域需要的所有工具。概率论最；初的发展是为了分析事件发生的频率。我们可以很容易地看出概率论，", "keywords": "我们可以很容易地看出概率论, 但是概, 概率论最, 率论并不能明显地提供我们在人工智能领域需要的所有工具, 初的发展是为了分析事件发生的频率", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "1662a3cb-99df-4743-b083-9fb6dd8aa2e1", "label": "摘要13", "info": "关于不确定性的常识推理，如果我们已经列出了若干条期望它具有的性；质，那么满足这些性质的唯一一种方法就是将贝叶斯概率和频率派概率；视为等同的。例如，如果我们要在扑克牌游戏中根据玩家手上的牌计算", "keywords": "关于不确定性的常识推理, 如果我们已经列出了若干条期望它具有的性, 那么满足这些性质的唯一一种方法就是将贝叶斯概率和频率派概率, 例如, 视为等同的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b392fa61-624f-45cc-898a-5003c7f8afd2", "label": "摘要14", "info": "概率可以被看作用于处理不确定性的逻辑扩展。逻辑提供了一套形式化；的规则，可以在给定某些命题是真或假的假设下，判断另外一些命题是；真的还是假的。概率论提供了一套形式化的规则，可以在给定一些命题", "keywords": "概率可以被看作用于处理不确定性的逻辑扩展, 的规则, 判断另外一些命题是, 可以在给定一些命题, 概率论提供了一套形式化的规则", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "53a44cbb-09ed-4f0c-9a10-640f1ea344a3", "label": "3.2：随机变量", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "be155ce7-f6b3-4d72-a6db-1c99d6d581d2", "label": "摘要1", "info": "随机变量  （random  variable）是可以随机地取不同值的变量。我们通常；用无格式字体（plain  typeface）中的小写字母来表示随机变量本身，而；用手写体中的小写字母来表示随机变量能够取到的值。例如，x  1  和x  2", "keywords": "中的小写字母来表示随机变量本身, 是可以随机地取不同值的变量, 用无格式字体, 例如, 我们通常", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "93dfb729-ffb4-466d-a5fb-99bb4e8ca3da", "label": "摘要2", "info": "都是随机变量x可能的取值。对于向量值变量，我们会将随机变量写成x；，它的一个可能取值为 x  。就其本身而言，一个随机变量只是对可能的；状态的描述；它必须伴随着一个概率分布来指定每个状态的可能性。", "keywords": "就其本身而言, 我们会将随机变量写成, 都是随机变量, 对于向量值变量, 一个随机变量只是对可能的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3184c6f8-814d-4136-97d6-ceafa6330195", "label": "摘要3", "info": "随机变量可以是离散的或者连续的。离散随机变量拥有有限或者可数无；限多的状态。注意：这些状态不一定非要是整数，它们也可能只是一些；被命名的状态而没有数值。连续随机变量伴随着实数值。", "keywords": "这些状态不一定非要是整数, 随机变量可以是离散的或者连续的, 注意, 被命名的状态而没有数值, 它们也可能只是一些", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "label": "3.3：概率分布", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "01eaaf48-d477-4b0a-8829-c7ab44c8ca01", "label": "摘要1", "info": "3.3.1　离散型变量和概率质量函数", "keywords": "离散型变量和概率质量函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0ab68bc0-103b-4a0d-ba42-2fa603addb2a", "label": "摘要2", "info": "3.3.2　连续型变量和概率密度函数", "keywords": "连续型变量和概率密度函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "cfadc1a2-3b88-48f1-8699-4e97a6f00c56", "label": "摘要3", "info": "概率分布  （probability  distribution）用来描述随机变量或一簇随机变量；在每一个可能取到的状态的可能性大小。我们描述概率分布的方式取决；于随机变量是离散的还是连续的。", "keywords": "于随机变量是离散的还是连续的, 在每一个可能取到的状态的可能性大小, 用来描述随机变量或一簇随机变量, 概率分布, 我们描述概率分布的方式取决", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c6935ed5-439e-42ec-82a0-91d5c7f9bb3d", "label": "摘要4", "info": "3.3.1　离散型变量和概率质量函数", "keywords": "离散型变量和概率质量函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "cda58efd-328e-4cd4-89f6-e88747453720", "label": "摘要5", "info": "离散型变量的概率分布可以用概率质量函数；mass；function，PMF）", "keywords": "离散型变量的概率分布可以用概率质量函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "170b3368-2a9e-452b-b913-69c6b7d93292", "label": "摘要6", "info": "（probability", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3b1c2a60-d73e-4d07-9bb4-2c7318e62f69", "label": "摘要7", "info": "概率质量函数将随机变量能够取得的每个状态映射到随机变量取得该状；态的概率。x=x的概率用P(x)来表示，概率为1表示x=x是确定的，概率；为0表示x=x是不可能发生的。有时为了使得PMF的使用不相互混淆，我", "keywords": "表示, 的概率用, 有时为了使得, 是不可能发生的, 态的概率", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5b59bbfa-0504-48fd-8229-4015331eed0f", "label": "摘要8", "info": "概率质量函数可以同时作用于多个随机变量。这种多个变量的概率分布；被称为联合概率分布  （joint  probability  distribution）。P(x=x,y=y)表示；x=x和y=y同时发生的概率。我们也可以简写为P(x,y)。", "keywords": "表示, 这种多个变量的概率分布, 我们也可以简写为, 被称为联合概率分布, 概率质量函数可以同时作用于多个随机变量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b309f670-b9da-45f9-9312-604494aef47a", "label": "摘要9", "info": "如果一个函数P是随机变量x的PMF，必须满足下面这几个条件：", "keywords": "必须满足下面这几个条件, 如果一个函数, 是随机变量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c418e165-81c8-4716-9c44-64bd73d3ab80", "label": "摘要10", "info": "P的定义域必须是x所有可能状态的集合。", "keywords": "的定义域必须是, 所有可能状态的集合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "fb418ff4-854e-4f88-b226-37481110b327", "label": "摘要11", "info": "。不可能发生的事件概率为0，并且", "keywords": "并且, 不可能发生的事件概率为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "34f2e78c-76c4-4adf-96db-db3d4bb502e0", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；不存在比这概率更低的状态。类似地，能够确保一定发生的事件概；率为1，而且不存在比这概率更高的状态。", "keywords": "率为, 不存在比这概率更低的状态, 能够确保一定发生的事件概, 而且不存在比这概率更高的状态, 类似地", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a4c0d33f-39ea-4aec-8eb4-0974d8daa0f2", "label": "摘要13", "info": "。我们把这条性质称之为归一化的", "keywords": "我们把这条性质称之为归一化的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "d28b18da-f90f-456f-8f86-85eef07efc93", "label": "摘要14", "info": "（normalized）。如果没有这条性质，当我们计算很多事件其中之；一发生的概率时，可能会得到大于1的概率。", "keywords": "如果没有这条性质, 一发生的概率时, 当我们计算很多事件其中之, 可能会得到大于, 的概率", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "79bf1fe5-0f6e-4790-8211-cdb71d3ff93b", "label": "摘要15", "info": "例如，考虑一个离散型随机变量x有k个不同的状态。我们可以假设x是；均匀分布  （uniform  distribution）的（也就是将它的每个状态视为等可；能的），通过将它的PMF设为", "keywords": "也就是将它的每个状态视为等可, 均匀分布, 个不同的状态, 考虑一个离散型随机变量, 能的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "276be3f5-f23c-4773-b43d-7585baf6259b", "label": "摘要16", "info": "对于所有的i都成立。我们可以看出这满足上述成为概率质量函数的条", "keywords": "对于所有的, 都成立, 我们可以看出这满足上述成为概率质量函数的条", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f2432701-be2e-4fbe-9e06-1cacac4b3b70", "label": "摘要17", "info": "件。因为k是一个正整数，所以  是正的。我们也可以看出", "keywords": "因为, 是一个正整数, 是正的, 所以, 我们也可以看出", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "778026f7-ebce-4c8a-af9e-ef3f0dd759eb", "label": "摘要18", "info": "因此分布也满足归一化条件。", "keywords": "因此分布也满足归一化条件", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b502f299-822b-40ff-a9b5-92379a8729a1", "label": "摘要19", "info": "3.3.2　连续型变量和概率密度函数", "keywords": "连续型变量和概率密度函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6fa1cf3f-b1ae-460f-98df-0111b58188e9", "label": "摘要20", "info": "当研究的对象是连续型随机变量时，我们用概率密度函数  （probability；density  function，P D  F）而不是概率质量函数来描述它的概率分布。如；果一个函数p是概率密度函数，必须满足下面这几个条件：", "keywords": "当研究的对象是连续型随机变量时, 必须满足下面这几个条件, 我们用概率密度函数, 而不是概率质量函数来描述它的概率分布, 是概率密度函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "25ebe544-de97-4eb1-925f-60105c1a851e", "label": "摘要21", "info": "p的定义域必须是x所有可能状态的集合。", "keywords": "的定义域必须是, 所有可能状态的集合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b5f4a576-0a96-4f17-8231-a4354562e7c9", "label": "摘要22", "info": "。注意，我们并不要求", "keywords": "注意, 我们并不要求", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4bf974c2-a8cd-4f6e-b137-394e9e82a915", "label": "摘要23", "info": "。", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "85cf4d1a-27cb-4c53-9056-fe0b1719f637", "label": "摘要24", "info": "。", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f929dd43-a191-4e6b-934b-c3fb26177373", "label": "摘要25", "info": "概率密度函数P(x)并没有直接对特定的状态给出概率，相对的，它给出；了落在面积为δx的无限小的区域内的概率为P(x)δx。", "keywords": "了落在面积为, 它给出, 的无限小的区域内的概率为, 并没有直接对特定的状态给出概率, 相对的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "860f4d01-6336-467d-a064-a3fea221c120", "label": "摘要26", "info": "我们可以对概率密度函数求积分来获得点集的真实概率质量。特别是，", "keywords": "我们可以对概率密度函数求积分来获得点集的真实概率质量, 特别是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "68be7291-cde1-42b6-867e-c092d0f09f5c", "label": "摘要27", "info": "x落在集合   中的概率可以通过P(x)对这个集合求积分来得到。在单变；量的例子中，x落在区间［a，b］的概率是", "keywords": "落在区间, 落在集合, 中的概率可以通过, 的概率是, 量的例子中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "08fbc10e-3828-4780-af2f-4b489fdebb0f", "label": "摘要28", "info": "。", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8afe2901-4819-436f-8941-0d54f22923d7", "label": "摘要29", "info": "为了给出一个连续型随机变量的PDF的例子，我们可以考虑实数区间上；的均匀分布。我们可以使用函数u(x;a,b)，其中a和b是区间的端点且满足；b＞a。符号“；”表示“以什么为参数”；我们把x作为函数的自变量，a和b", "keywords": "表示, 我们可以考虑实数区间上, 符号, 其中, 是区间的端点且满足", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ac7aaebd-c851-42d5-82de-97c3ea04a235", "label": "摘要30", "info": "。在［a，b］内，有", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0563b6c1-95cb-4838-aba5-1d354b97b2b0", "label": "摘要31", "info": "。可以看出，任何一点都非负。另", "keywords": "可以看出, 任何一点都非负", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6a48ea37-a8ad-4d86-b8c2-0c51ebd2cc6b", "label": "摘要32", "info": "外，它的积分为1。我们通常用x∼U(a,b)表示x在［a，b］上是均匀分布；的。", "keywords": "表示, 它的积分为, 我们通常用, 上是均匀分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ef700de7-294a-4c4e-b022-61e38e35c004", "label": "摘要33", "info": "3.3.1　离散型变量和概率；质量函数", "keywords": "离散型变量和概率, 质量函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ed504886-18fc-45b2-9737-ef35761d4bc6", "label": "摘要34", "info": "3.3.2　连续型变量和概率；密度函数", "keywords": "连续型变量和概率, 密度函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "218712a1-80b8-467d-b2cf-4136a13efb36", "label": "3.4：边缘概率", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "bc5efd42-891b-4d07-9a57-f49af79aaed6", "label": "摘要1", "info": "有时，我们知道了一组变量的联合概率分布，但想要了解其中一个子集；的概率分布。这种定义在子集上的概率分布被称为边缘概率分布；（marginal probability distribution）。", "keywords": "的概率分布, 有时, 但想要了解其中一个子集, 这种定义在子集上的概率分布被称为边缘概率分布, 我们知道了一组变量的联合概率分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "fb407bd7-e288-4261-9c38-2f802c26c261", "label": "摘要2", "info": "例如，假设有离散型随机变量x和y，并且我们知道P(x,y)。可以依据下；面的求和法则 （sum rule）来计算P(x)：", "keywords": "可以依据下, 并且我们知道, 来计算, 例如, 假设有离散型随机变量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c4f925d8-b97b-423b-9d17-777f1b0f926b", "label": "摘要3", "info": "“边缘概率”的名称来源于手算边缘概率的计算过程。当P(x,y)的每个值；被写在由每行表示不同的x值、每列表示不同的y值形成的网格中时，对；网格中的每行求和是很自然的事情，然后将求和的结果P(x)写在每行右", "keywords": "的每个值, 值形成的网格中时, 然后将求和的结果, 边缘概率, 每列表示不同的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a48d8121-f3bb-4816-9e35-5124bcf26b5b", "label": "摘要4", "info": "对于连续型变量，我们需要用积分替代求和：", "keywords": "对于连续型变量, 我们需要用积分替代求和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8e629ffe-3ff2-4f83-aa65-caf8ed9a0edb", "label": "3.5：条件概率", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "6cf143ca-4045-4149-a38a-f0228f0454ac", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在很多情况下，我们感兴趣的是某个事件在给定其他事件发生时出现的；概率。这种概率叫作条件概率。我们将给定x=x，y=y发生的条件概率记", "keywords": "发生的条件概率记, 这种概率叫作条件概率, 概率, 在很多情况下, 我们感兴趣的是某个事件在给定其他事件发生时出现的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c60fb3f4-d123-4cc2-8076-17ec217bf261", "label": "摘要2", "info": "条件概率只在P(x=x)＞0时有定义。我们不能计算给定在永远不会发生；的事件上的条件概率。", "keywords": "的事件上的条件概率, 时有定义, 我们不能计算给定在永远不会发生, 条件概率只在", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "cae183da-5053-4ee1-b140-240852fe9ab4", "label": "摘要3", "info": "这里需要注意的是，不要把条件概率和计算当采用某个动作后会发生什；么相混淆。假定某个人说德语，那么他是德国人的条件概率是非常高；的，但是如果随机选择的一个人会说德语，他的国籍不会因此而改变。", "keywords": "但是如果随机选择的一个人会说德语, 他的国籍不会因此而改变, 那么他是德国人的条件概率是非常高, 这里需要注意的是, 假定某个人说德语", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "48c39bc6-e735-4afe-8bbc-c6dd2f3c52c4", "label": "3.6：条件概率的链式法则", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "b817a606-8bef-41b5-a06e-e14e7d9e68bd", "label": "摘要1", "info": "任何多维随机变量的联合概率分布，都可以分解成只有一个变量的条件；概率相乘的形式：", "keywords": "概率相乘的形式, 任何多维随机变量的联合概率分布, 都可以分解成只有一个变量的条件", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5aaa8135-a75c-4a78-aa76-2531bdbbf3d4", "label": "摘要2", "info": "这个规则被称为概率的链式法则  （chain  rule）或者乘法法则  （product；rule）。它可以直接从式（3.5）条件概率的定义中得到。例如，使用两；次定义可以得到", "keywords": "使用两, 它可以直接从式, 例如, 这个规则被称为概率的链式法则, 或者乘法法则", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "86b8602c-b84a-4813-bd1f-586f252114da", "label": "3.7：独立性和条件独立性", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "c93461d0-ee7a-42ab-8d67-89d0a9685402", "label": "摘要1", "info": "两个随机变量x和y，如果它们的概率分布可以表示成两个因子的乘积形", "keywords": "两个随机变量, 如果它们的概率分布可以表示成两个因子的乘积形", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9f3f9e8e-c714-4406-8cca-f55aeb3cde7c", "label": "摘要2", "info": "式，并且一个因子只包含x，另一个因子只包含y，我们就称这两个随机；变量是相互独立的 （independent）：", "keywords": "我们就称这两个随机, 变量是相互独立的, 并且一个因子只包含, 另一个因子只包含", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9b0eb60f-7458-4549-937a-1c220474ddd1", "label": "摘要3", "info": "如果关于x和y的条件概率分布对于z的每一个值都可以写成乘积的形；式，那么这两个随机变量x和y在给定随机变量z时是条件独立的；（conditionally independent）：", "keywords": "的条件概率分布对于, 时是条件独立的, 那么这两个随机变量, 的每一个值都可以写成乘积的形, 如果关于", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0c6be5e5-4ee7-4667-9ca1-89be2f6758e3", "label": "摘要4", "info": "我们可以采用一种简化形式来表示独立性和条件独立性：x⊥y表示x和y；相互独立，x⊥y｜z表示x和y在给定z时条件独立。", "keywords": "表示, 时条件独立, 我们可以采用一种简化形式来表示独立性和条件独立性, 在给定, 相互独立", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "label": "3.8：期望、方差和协方差", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "46ea7816-2ce7-4942-b0b3-a5495b443992", "label": "摘要1", "info": "函数f(  x  )关于某分布P(x)的期望  （expectation）或者期望值  （expected；value）是指，当x由P产生，f作用于x时，f( x )的平均值。对于离散型随；机变量，这可以通过求和得到", "keywords": "的平均值, 对于离散型随, 函数, 是指, 产生", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "060a54bb-ed7f-43fc-9cbf-f48f8175dd02", "label": "摘要2", "info": "对于连续型随机变量，可以通过求积分得到", "keywords": "对于连续型随机变量, 可以通过求积分得到", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ab31991a-a7a0-4706-ae86-12f6a46fae72", "label": "摘要3", "info": "当概率分布在上下文中指明时，我们可以只写出期望作用的随机变量的；名称来进行简化，例如；。如果期望作用的随机变量也很明", "keywords": "当概率分布在上下文中指明时, 如果期望作用的随机变量也很明, 例如, 名称来进行简化, 我们可以只写出期望作用的随机变量的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "80439a20-3673-486a-86e8-d3352997dfce", "label": "摘要4", "info": "。默认地，我们假设", "keywords": "我们假设, 默认地", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "60a6cb34-54f6-4131-ae01-dceb01233f99", "label": "摘要5", "info": "期望是线性的，例如，", "keywords": "例如, 期望是线性的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4ebe519c-7063-4b9d-b957-6c31f162c548", "label": "摘要6", "info": "其中α和β不依赖于x。", "keywords": "不依赖于, 其中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0b78a6ae-9ace-46b0-9a13-0042f10cf3c6", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；方差 （variance）衡量的是当我们对x依据它的概率分布进行采样时，随；机变量x的函数值会呈现多大的差异：", "keywords": "衡量的是当我们对, 依据它的概率分布进行采样时, 方差, 机变量, 的函数值会呈现多大的差异", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b1b2cf12-76fb-429c-b8da-5d1b4324b0d6", "label": "摘要8", "info": "当方差很小时，f( x  )的值形成的簇比较接近它们的期望值。方差的平方；根被称为标准差 （standard deviation）。", "keywords": "当方差很小时, 方差的平方, 根被称为标准差, 的值形成的簇比较接近它们的期望值", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a081c8d8-c98f-45fd-8871-d3135bba02c9", "label": "摘要9", "info": "协方差  （covariance）在某种意义上给出了两个变量线性相关性的强度；以及这些变量的尺度：", "keywords": "以及这些变量的尺度, 协方差, 在某种意义上给出了两个变量线性相关性的强度", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4c3e480e-b603-4e30-a1b4-83f774934a92", "label": "摘要10", "info": "协方差的绝对值如果很大，则意味着变量值变化很大，并且它们同时距；离各自的均值很远。如果协方差是正的，那么两个变量都倾向于同时取；得相对较大的值。如果协方差是负的，那么其中一个变量倾向于取得相", "keywords": "并且它们同时距, 则意味着变量值变化很大, 协方差的绝对值如果很大, 那么两个变量都倾向于同时取, 得相对较大的值", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6a30f54f-3f56-4b83-a796-eaac68f4c2e9", "label": "摘要11", "info": "协方差和相关性是有联系的，但实际上是不同的概念。它们是有联系；的：如果两个变量相互独立，那么它们的协方差为零；如果两个变量的；协方差不为零，那么它们一定是相关的。然而，独立性又是和协方差完", "keywords": "它们是有联系, 如果两个变量相互独立, 如果两个变量的, 协方差不为零, 那么它们的协方差为零", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a3c54fc1-5f3f-43f7-b5fb-e0e4f5fbe787", "label": "摘要12", "info": "机变量s进行采样。s以   的概率值为1，否则为−1。我们可以通过令", "keywords": "进行采样, 否则为, 我们可以通过令, 机变量, 的概率值为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "78ace56f-9b9c-4d6a-b422-ddf4a9b35048", "label": "摘要13", "info": "y=sx来生成一个随机变量y。显然，x和y不是相互独立的，因为x完全决；定了y的尺度。然而，Cov(x,y)=0。", "keywords": "显然, 因为, 的尺度, 不是相互独立的, 定了", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "44d98696-2871-4f0e-9cdd-9147f5d5b9fb", "label": "摘要14", "info": "随机向量；矩阵，并且满足", "keywords": "并且满足, 矩阵, 随机向量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "84a9d0c0-9249-499d-a9df-c2e9c5186200", "label": "摘要15", "info": "的协方差矩阵 （covariance matrix）是一个n×n的", "keywords": "是一个, 的协方差矩阵", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a0e67463-366f-43b6-a453-f74271f24441", "label": "摘要16", "info": "协方差矩阵的对角元是方差：", "keywords": "协方差矩阵的对角元是方差", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "63770936-0a6f-452e-ae13-d0194f12f4cc", "label": "3.9：常用概率分布", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "c9f859a0-a364-42d7-bb20-6e8ef6c7416c", "label": "摘要1", "info": "3.9.1　Bernoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "87cb0d1f-ac0e-438f-8177-8c01b82f419f", "label": "摘要2", "info": "3.9.2　Multinoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e729d44a-09ff-4f8f-8bca-45f49c5fc93f", "label": "摘要3", "info": "3.9.3　高斯分布", "keywords": "高斯分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c5399cff-249c-4fa5-959b-d86a6f369b56", "label": "摘要4", "info": "3.9.4　指数分布和Laplace分布", "keywords": "分布, 指数分布和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "52e4198a-34ef-4253-8825-ab993a4153cb", "label": "摘要5", "info": "3.9.5　Dirac分布和经验分布", "keywords": "分布和经验分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "63a48710-9337-4d4f-bb03-e29133ba498d", "label": "摘要6", "info": "3.9.6　分布的混合", "keywords": "分布的混合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "84767f4d-9df4-401f-a900-ecb2e9e84390", "label": "摘要7", "info": "许多简单的概率分布在机器学习的众多领域中都是有用的。", "keywords": "许多简单的概率分布在机器学习的众多领域中都是有用的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a64b14a0-b0f2-4180-a667-2282c716919c", "label": "摘要8", "info": "3.9.1　Bernoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9fc84c1a-6013-44da-bb7e-f62b878d5e80", "label": "摘要9", "info": "Bernoulli分布 （Bernoulli  distribution）是单个二值随机变量的分布。它；由单个参数φ∈［0，1］控制，φ给出了随机变量等于1的概率。它具有；如下的一些性质。", "keywords": "它具有, 如下的一些性质, 控制, 是单个二值随机变量的分布, 分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "1dde8a98-0140-4771-b54a-53f33f8c09fd", "label": "摘要10", "info": "3.9.2　Multinoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f85a6089-58f5-4d7d-8fb5-1d927ecd2e3e", "label": "摘要11", "info": "Multinoulli分布  （multinoulli  distribution）或者范畴分布  （categorical；distribution）是指在具有k个不同状态的单个离散型随机变量上的分布，；其中k是一个有限值。 (2) Multinoulli分布由向量p∈［0，1］ k−1 参数化，", "keywords": "参数化, 或者范畴分布, 是一个有限值, 其中, 个不同状态的单个离散型随机变量上的分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3f4486cc-7ea0-4ec9-b2c3-fa056cfd8036", "label": "摘要12", "info": "给出。注意我们必须限制", "keywords": "注意我们必须限制, 给出", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e2c7c9f0-9ecf-41eb-80ed-4a0f9baf87f3", "label": "摘要13", "info": "Bernoulli分布和Multinoulli分布足够用来描述在它们领域内的任意分；布。它们能够描述这些分布，不是因为它们特别强大，而是因为它们的；领域很简单。它们可以对那些能够将所有的状态进行枚举的离散型随机", "keywords": "分布足够用来描述在它们领域内的任意分, 不是因为它们特别强大, 领域很简单, 而是因为它们的, 它们可以对那些能够将所有的状态进行枚举的离散型随机", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9f677498-d32d-46da-980f-cde431166c87", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；变量进行建模。当处理的是连续型随机变量时，会有不可数无限多的状；态，所以任何通过少量参数描述的概率分布都必须在分布上加以严格的", "keywords": "变量进行建模, 会有不可数无限多的状, 所以任何通过少量参数描述的概率分布都必须在分布上加以严格的, 当处理的是连续型随机变量时", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c5efdca1-9f68-4c60-a6e2-460b24ebf3b0", "label": "摘要15", "info": "3.9.3　高斯分布", "keywords": "高斯分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "54c05310-d3dc-40b3-9c9b-0552295c0257", "label": "摘要16", "info": "实数上最常用的分布就是正态分布 （normal distribution），也称为高斯；分布 （Gaussian dis-tribution）：", "keywords": "也称为高斯, 分布, 实数上最常用的分布就是正态分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8f1d95f8-fe02-42f4-851c-59d9b44c6b14", "label": "摘要17", "info": "图3.1画出了正态分布的概率密度函数。", "keywords": "画出了正态分布的概率密度函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6dd53651-dc92-4a6f-922c-b5ba09ff8d4b", "label": "摘要18", "info": "图3.1　正态分布。正态分布；由µ给出，峰的宽度受σ控制。在这个示例中，我们展示的是 标准正态分布 （standard normal；distribution），其中µ=0，σ=1", "keywords": "正态分布, 其中, 控制, 我们展示的是, 峰的宽度受", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a3ade592-3611-45bd-ad7e-b1f9ef2c1983", "label": "摘要19", "info": "呈现经典的“钟形曲线”的形状，其中中心峰的x坐标", "keywords": "的形状, 坐标, 呈现经典的, 其中中心峰的, 钟形曲线", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a3dd6eeb-7a99-4e7b-90aa-9c8a82c82e36", "label": "摘要20", "info": "正态分布由两个参数控制，；心峰值的坐标，这也是分布的均值：；示，方差用σ 2 表示。", "keywords": "表示, 正态分布由两个参数控制, 方差用, 这也是分布的均值, 心峰值的坐标", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8218945a-245c-420b-98e3-e734a3a89a8d", "label": "摘要21", "info": "。参数µ给出了中；。分布的标准差用σ表", "keywords": "分布的标准差用, 参数, 给出了中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3daafca7-e85f-4a33-9ea3-739320d5b813", "label": "摘要22", "info": "当我们要对概率密度函数求值时，需要对σ平方并且取倒数。当我们需；要经常对不同参数下的概率密度函数求值时，一种更高效的参数化分布；的方式是使用参数β∈(0,∞)来控制分布的精度  （precision）（或方差的", "keywords": "当我们需, 来控制分布的精度, 的方式是使用参数, 一种更高效的参数化分布, 当我们要对概率密度函数求值时", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "45b35c8c-be1c-4274-b360-f197772a393f", "label": "摘要23", "info": "采用正态分布在很多应用中都是一个明智的选择。当我们由于缺乏关于；某个实数上分布的先验知识而不知道该选择怎样的形式时，正态分布是；默认的比较好的选择，其中有两个原因。", "keywords": "正态分布是, 当我们由于缺乏关于, 采用正态分布在很多应用中都是一个明智的选择, 其中有两个原因, 默认的比较好的选择", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0571319b-e335-4d45-994b-09fe216c4e7c", "label": "摘要24", "info": "第一，我们想要建模的很多分布的真实情况是比较接近正态分布的。中；心极限定理  （central  limit  theorem）说明很多独立随机变量的和近似服；从正态分布。这意味着在实际中，很多复杂系统都可以被成功地建模成", "keywords": "这意味着在实际中, 说明很多独立随机变量的和近似服, 第一, 心极限定理, 很多复杂系统都可以被成功地建模成", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "38df95cd-2b7c-4172-8968-b5ae12d5e37c", "label": "摘要25", "info": "第二，在具有相同方差的所有可能的概率分布中，正态分布在实数上具；有最大的不确定性。因此，我们可以认为正态分布是对模型加入的先验；知识量最少的分布。充分利用和证明这个想法需要更多的数学工具，我", "keywords": "充分利用和证明这个想法需要更多的数学工具, 我们可以认为正态分布是对模型加入的先验, 在具有相同方差的所有可能的概率分布中, 有最大的不确定性, 因此", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "491a9b9a-5f83-4281-a0b2-4d36fb5466d3", "label": "摘要26", "info": "空间，这种情况下被称为多维正态分布；正态分布可以推广到；（multivariate normal dis-tribution）。它的参数是一个正定对称矩阵Σ：", "keywords": "正态分布可以推广到, 它的参数是一个正定对称矩阵, 空间, 这种情况下被称为多维正态分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b34a4624-b240-4bcc-b8c3-aa1f84e6c569", "label": "摘要27", "info": "参数µ仍然表示分布的均值，只不过现在是向量值。参数Σ给出了分布的；协方差矩阵。和单变量的情况类似，当我们希望对很多不同参数下的概；率密度函数多次求值时，协方差矩阵并不是一个很高效的参数化分布的", "keywords": "只不过现在是向量值, 参数, 和单变量的情况类似, 给出了分布的, 仍然表示分布的均值", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "206560ee-8eed-4940-b162-8b9a0ad39b86", "label": "摘要28", "info": "我们常常把协方差矩阵固定成一个对角阵。一个更简单的版本是各向同；性 （isotropic）高斯分布，它的协方差矩阵是一个标量乘以单位阵。", "keywords": "它的协方差矩阵是一个标量乘以单位阵, 我们常常把协方差矩阵固定成一个对角阵, 高斯分布, 一个更简单的版本是各向同", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "77f91416-bb91-42d3-a84a-4bfc985b7f06", "label": "摘要29", "info": "3.9.4　指数分布和Laplace分布", "keywords": "分布, 指数分布和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "22512835-d2ba-4f3b-9ec7-3bc2eca7bf57", "label": "摘要30", "info": "在深度学习中，我们经常会需要一个在x=0点处取得边界点（sharp", "keywords": "我们经常会需要一个在, 在深度学习中, 点处取得边界点", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9f421fce-b105-426c-b180-5ccfd12cf3b5", "label": "摘要31", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；point）的分布。为了实现这一目的，我们可以使用指数分布；（exponential distribution）：", "keywords": "的分布, 为了实现这一目的, 我们可以使用指数分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4a6b9871-7d56-485a-b2ad-be8cb7412414", "label": "摘要32", "info": "指数分布用指示函数（indicator  function）；概率为零。", "keywords": "概率为零, 指数分布用指示函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e7e8bf24-1a25-4eb9-aaca-eb29de598a48", "label": "摘要33", "info": "来使得当x取负值时的", "keywords": "取负值时的, 来使得当", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6004ab67-a18b-4a18-96b7-856bf7da3982", "label": "摘要34", "info": "一个联系紧密的概率分布是Laplace分布  （Laplace  distribution），它允；许我们在任意一点µ处设置概率质量的峰值：", "keywords": "处设置概率质量的峰值, 许我们在任意一点, 一个联系紧密的概率分布是, 它允, 分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "74f084b8-6a83-4df6-ac7d-145ea23cf534", "label": "摘要35", "info": "3.9.5　Dirac分布和经验分布", "keywords": "分布和经验分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b074e0aa-a670-4f81-9311-d04ddc45169f", "label": "摘要36", "info": "在一些情况下，我们希望概率分布中的所有质量都集中在一个点上。这；可以通过Dirac  delta函数 （Dirac  delta  function）δ(x)定义概率密度函数；来实现：", "keywords": "定义概率密度函数, 函数, 我们希望概率分布中的所有质量都集中在一个点上, 来实现, 可以通过", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "db1cefa2-182b-4f17-838f-64310b1a331c", "label": "摘要37", "info": "Dirac  delta函数被定义成在除了0以外的所有点的值都为0，但是积分为；1。Dirac  delta函数不像普通函数一样对x的每一个值都有一个实数值的；输出，它是一种不同类型的数学对象，被称为广义函数  （generalized", "keywords": "以外的所有点的值都为, 被称为广义函数, 函数不像普通函数一样对, 但是积分为, 的每一个值都有一个实数值的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6aecf157-44cd-4d3e-82c0-4ebba06d804c", "label": "摘要38", "info": "通过把P(x)定义成δ函数左移−µ个单位，我们得到了一个在x=µ处具有无；限窄也无限高的峰值的概率质量。", "keywords": "我们得到了一个在, 定义成, 处具有无, 通过把, 函数左移", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "182a4ecc-a546-40c5-9a9a-b4ea6fce42ed", "label": "摘要39", "info": "Dirac分布经常作为经验分布 （empirical distribution）的一个组成部分出；现：", "keywords": "分布经常作为经验分布, 的一个组成部分出", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "896613ad-e081-464d-85aa-30724bd600c2", "label": "摘要40", "info": "经验分布将概率密度   赋给m个点", "keywords": "经验分布将概率密度, 个点, 赋给", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "fab7a6c6-2834-48ca-8339-422d5eb36992", "label": "摘要41", "info": "中的每一个，这", "keywords": "中的每一个", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "d02181a8-e15e-4449-9b0d-e9502911c2c2", "label": "摘要42", "info": "些点是给定的数据集或者采样的集合。只有在定义连续型随机变量的经；验分布时，Dirac  delta函数才是必要的。对于离散型随机变量，情况更；加简单：经验分布可以被定义成一个Multinoulli分布，对于每一个可能", "keywords": "对于离散型随机变量, 加简单, 只有在定义连续型随机变量的经, 经验分布可以被定义成一个, 函数才是必要的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "70abb7d3-ab83-4ef5-b809-6eb838e3dbc4", "label": "摘要43", "info": "当我们在训练集上训练模型时，可以认为从这个训练集上得到的经验分；布指明了采样来源的分布。关于经验分布另外一种重要的观点是，它是；训练数据的似然最大的那个概率密度函数（见第5.5节）。", "keywords": "可以认为从这个训练集上得到的经验分, 关于经验分布另外一种重要的观点是, 当我们在训练集上训练模型时, 训练数据的似然最大的那个概率密度函数, 见第", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "cd3b1ecc-8730-466c-8ff5-2f8a5f784475", "label": "摘要44", "info": "3.9.6　分布的混合", "keywords": "分布的混合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "657f10f5-ec84-4399-a225-fadf53ee75a8", "label": "摘要45", "info": "通过组合一些简单的概率分布来定义新的概率分布也是很常见的。一种；通用的组合方法是构造混合分布  （mixture  distribution）。混合分布由；一些组件（component）分布构成。每次实验，样本是由哪个组件分布", "keywords": "一些组件, 分布构成, 通用的组合方法是构造混合分布, 混合分布由, 样本是由哪个组件分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "84c16956-04fa-4d8f-88c6-053441c06a83", "label": "摘要46", "info": "这里P(c)是对各组件的一个Multinoulli分布。", "keywords": "这里, 分布, 是对各组件的一个", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "83ca5f37-c988-4078-bc6c-cf112c4ffe32", "label": "摘要47", "info": "我们已经看过一个混合分布的例子了：实值变量的经验分布对于每一个；训练实例来说，就是以Dirac分布为组件的混合分布。", "keywords": "训练实例来说, 就是以, 实值变量的经验分布对于每一个, 我们已经看过一个混合分布的例子了, 分布为组件的混合分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4601d909-d33f-440b-8c96-8425d751334d", "label": "摘要48", "info": "混合模型是组合简单概率分布来生成更丰富的分布的一种简单策略。在；第16章中，我们更加详细地探讨从简单概率分布构建复杂模型的技术。", "keywords": "章中, 我们更加详细地探讨从简单概率分布构建复杂模型的技术, 混合模型是组合简单概率分布来生成更丰富的分布的一种简单策略", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8718948d-6a37-48ec-b676-895483e5fedd", "label": "摘要49", "info": "混合模型使我们能够一瞥以后会用到的一个非常重要的概念——潜变量；（latent  variable）。潜变量是我们不能直接观测到的随机变量。混合模；型的组件标识变量c就是其中一个例子。潜变量在联合分布中可能和x有", "keywords": "潜变量, 混合模型使我们能够一瞥以后会用到的一个非常重要的概念, 型的组件标识变量, 就是其中一个例子, 潜变量在联合分布中可能和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5481889f-03fa-437f-954e-71ad2f6ee803", "label": "摘要50", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；一个非常强大且常见的混合模型是高斯混合模型  （Gaussian  Mixture；Model），它的组件p(x｜c=i)是高斯分布。每个组件都有各自的参数，", "keywords": "是高斯分布, 一个非常强大且常见的混合模型是高斯混合模型, 每个组件都有各自的参数, 它的组件", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "bbeae2a9-2661-438a-bf0c-ac663266171e", "label": "摘要51", "info": "除了均值和协方差以外，高斯混合模型的参数指明了给每个组件i的先；验概率  （prior  probability）α  i  =P(c=i)。“先验”一词表明了在观测到x之；前传递给模型关于c的信念。作为对比，P(c｜x)是后验概率  （posterior", "keywords": "一词表明了在观测到, 前传递给模型关于, 是后验概率, 验概率, 的信念", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "2ec2a0db-66c4-44a2-bd05-629c22c08d63", "label": "摘要52", "info": "图3.2展示了某个高斯混合模型生成的样本。", "keywords": "展示了某个高斯混合模型生成的样本", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3e2fc096-3818-46d5-ab3d-7d3f6fbfb72e", "label": "摘要53", "info": "图3.2　来自高斯混合模型的样本。在这个示例中，有3个组件。从左到右，第1个组件具有各向", "keywords": "来自高斯混合模型的样本, 个组件, 个组件具有各向, 在这个示例中, 从左到右", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9423e57e-0d60-4db5-8965-c4d4fe459848", "label": "摘要54", "info": "同性的协方差矩阵，这意味着它在每个方向上具有相同的方差。第2个组件具有对角的协方差矩；阵，这意味着它可以沿着每个轴的对齐方向单独控制方差。该示例中，沿着x 2 轴的方差要比沿；着x 1 轴的方差大。第3个组件具有满秩的协方差矩阵，使它能够沿着任意基的方向单独地控制", "keywords": "同性的协方差矩阵, 个组件具有对角的协方差矩, 轴的方差要比沿, 使它能够沿着任意基的方向单独地控制, 沿着", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a78406c0-8baa-4359-a500-9596ceb8a327", "label": "摘要55", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；3.10　常用函数的有用性质", "keywords": "常用函数的有用性质", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f5a3b93c-0ba3-4478-8f67-b363af51ccc7", "label": "摘要56", "info": "某些函数在处理概率分布时经常会出现，尤其是深度学习的模型中用到；的概率分布。", "keywords": "的概率分布, 某些函数在处理概率分布时经常会出现, 尤其是深度学习的模型中用到", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a2419d86-83e6-4526-878c-bc4bdb83c106", "label": "摘要57", "info": "其中一个函数是logistic sigmoid函数：", "keywords": "函数, 其中一个函数是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "716fefb9-9624-4de6-aebf-91abaa43747e", "label": "摘要58", "info": "logistic  sigmoid函数通常用来产生Bernoulli分布中的参数φ，因为它的范；围是（0,1），处在φ的有效取值范围内。图3.3给出了sigmoid函数的图；示。sigmoid函数在变量取绝对值非常大的正值或负值时会出现饱和", "keywords": "分布中的参数, 函数通常用来产生, 函数的图, 因为它的范, 围是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e8071a28-a1bf-4d7f-9efa-81d47c7da8a7", "label": "摘要59", "info": "图3.3　logistic sigmoid函数", "keywords": "函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "2adfbae2-2570-4a31-a303-00413a84d818", "label": "摘要60", "info": "另外一个经常遇到的函数是softplus函数 （softplus function）（Dugas et；al. ，2001）：", "keywords": "函数, 另外一个经常遇到的函数是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "bbcdaedd-98db-4a28-aafd-7e529d3b53bc", "label": "摘要61", "info": "softplus函数可以用来产生正态分布的β和σ参数，因为它的范围是；（0,∞）。当处理包含sigmoid函数的表达式时，它也经常出现。softplus；函数名来源于它是另外一个函数的平滑（或“软化”）形式，这个函数是", "keywords": "形式, 参数, 当处理包含, 因为它的范围是, 函数可以用来产生正态分布的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "7a2ab0f7-1ba0-4fdc-9b12-102c90acc658", "label": "摘要62", "info": "图3.4给出了softplus函数的图示。", "keywords": "函数的图示, 给出了", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "01711602-2123-4030-864e-06425f800a3d", "label": "摘要63", "info": "下面一些性质非常有用，你可能要记下来。", "keywords": "你可能要记下来, 下面一些性质非常有用", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3ef892e7-f747-444f-871d-3c32c8f8e133", "label": "摘要64", "info": "图3.4　softplus函数", "keywords": "函数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5ba5e718-6833-4047-a356-1df0accea2c7", "label": "摘要65", "info": "函数σ −1 (x)在统计学中被称为分对数 （logit），但这个函数在机器学习；中很少用到。", "keywords": "函数, 中很少用到, 但这个函数在机器学习, 在统计学中被称为分对数", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "35b03065-f095-4426-809c-95dc63df4960", "label": "摘要66", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；+", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ac80bb00-3a9c-4fb7-89b0-19b75a7908c3", "label": "摘要67", "info": "式（3.41）为函数名“softplus”提供了其他的正当理由。softplus函数被设；计成正部函数 （positive part function）的平滑版本，这个正部函数是指；x", "keywords": "的平滑版本, 函数被设, 计成正部函数, 提供了其他的正当理由, 这个正部函数是指", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9d676e77-af17-43aa-9ea4-c6073befca66", "label": "摘要68", "info": "3.9.1　Bernoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "1c07e131-12b3-4637-a5e6-f3ed1d160921", "label": "摘要69", "info": "3.9.2　Multinoulli分布", "keywords": "分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f74b81ca-2eaf-43b0-8146-8162cc03bbe7", "label": "摘要70", "info": "3.9.3　高斯分布", "keywords": "高斯分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "23dc956d-e09f-4ad5-b249-85bf351f1ef9", "label": "摘要71", "info": "3.9.4　指数分布和Laplace；分布", "keywords": "分布, 指数分布和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "d717b6ae-11eb-4f00-83ee-3db9671cc53f", "label": "摘要72", "info": "3.9.5　Dirac分布和经验；分布", "keywords": "分布和经验, 分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "332e7d16-0b4a-4815-b22d-8bb8c94aac21", "label": "摘要73", "info": "3.9.6　分布的混合", "keywords": "分布的混合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "label": "3.11：贝叶斯规则", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "7ac6e88f-ecbc-4b2b-8e61-f2be39d3a316", "label": "摘要1", "info": "我们经常会需要在已知P(y｜x)时计算P(x｜y)。幸运的是，如果还知道；P(x)，我们可以用贝叶斯规则 （Bayes' rule）来实现这一目的：", "keywords": "我们经常会需要在已知, 我们可以用贝叶斯规则, 幸运的是, 来实现这一目的, 时计算", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ffa3929e-98d0-4727-a3ce-8087ef93b907", "label": "摘要2", "info": "注意到P(y)出现在上面的公式中，它通常使用", "keywords": "注意到, 它通常使用, 出现在上面的公式中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "629ef581-932c-4516-add2-c753f9b5654e", "label": "摘要3", "info": "来计算，所以我们并不需要事先知道", "keywords": "来计算, 所以我们并不需要事先知道", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "229ab6f4-a246-49cc-91fd-28ee3863e437", "label": "摘要4", "info": "P(y)的信息。", "keywords": "的信息", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "5ccbab0b-83ad-4f41-8b56-25024dee4a3c", "label": "摘要5", "info": "贝叶斯规则可以从条件概率的定义直接推导得出，但我们最好记住这个；公式的名字，因为很多文献通过名字来引用这个公式。这个公式是以牧；师Thomas  Bayes的名字来命名的，他是第一个发现这个公式特例的人。", "keywords": "贝叶斯规则可以从条件概率的定义直接推导得出, 这个公式是以牧, 但我们最好记住这个, 的名字来命名的, 因为很多文献通过名字来引用这个公式", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "356926b4-c684-4884-86eb-a03b7cce74dc", "label": "3.12：连续型变量的技术细节", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "add044ac-08d0-4672-ade3-5b7e2c0dab33", "label": "摘要1", "info": "连续型随机变量和概率密度函数的深入理解需要用到数学分支测度论；（measure；畴，但我们可以简要介绍一些测度论用来解决的问题。", "keywords": "但我们可以简要介绍一些测度论用来解决的问题, 连续型随机变量和概率密度函数的深入理解需要用到数学分支测度论", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a8d9b458-f574-4280-9592-3966175d78a5", "label": "摘要2", "info": "theory）的相关内容来扩展概率论。测度论超出了本书的范", "keywords": "测度论超出了本书的范, 的相关内容来扩展概率论", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "337979d0-1778-4d3a-af9d-6d5981a2a7de", "label": "摘要3", "info": "在第3.3.2节中，我们已经看到连续型向量值随机变量x  落在某个集合；中的概率是通过p( x )对集合  积分得到的。对于集合  的一些选择可；使得", "keywords": "的一些选择可, 对集合, 积分得到的, 对于集合, 节中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c313d5aa-b12d-423b-b75e-1eb88cbefc00", "label": "摘要4", "info": "并且", "keywords": "并且", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4e5cb232-ffc3-4b37-bb29-edb746f1662d", "label": "摘要5", "info": "和", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "1e5b4051-7eea-4a01-9bda-0df7c8ed4763", "label": "摘要6", "info": "的。这些集合通常是大量使用了实数的无限精度来构造的，例如通过构；造分形形状（fractal-shaped）的集合或者是通过有理数相关集合的变换；定义的集合。 (3) 测度论的一个重要贡献就是提供了一些集合的特征，使", "keywords": "的集合或者是通过有理数相关集合的变换, 测度论的一个重要贡献就是提供了一些集合的特征, 定义的集合, 造分形形状, 这些集合通常是大量使用了实数的无限精度来构造的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "65a74f72-fda1-4957-93e6-b0c1c7d90254", "label": "摘要7", "info": "对于我们的目的，测度论更多的是用来描述那些适用于；上的大多；数点，却不适用于一些边界情况的定理。测度论提供了一种严格的方式", "keywords": "却不适用于一些边界情况的定理, 对于我们的目的, 数点, 测度论提供了一种严格的方式, 测度论更多的是用来描述那些适用于", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "69b72292-32bb-40b4-9716-03e3176c601d", "label": "摘要8", "info": "另外一个有用的测度论中的术语是“几乎处处  （almost  everywhere）”。；某个性质如果是几乎处处都成立的，那么它在整个空间中除了一个测度；为零的集合以外都是成立的。因为这些例外只在空间中占有极其微小的", "keywords": "那么它在整个空间中除了一个测度, 几乎处处, 另外一个有用的测度论中的术语是, 为零的集合以外都是成立的, 某个性质如果是几乎处处都成立的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c969c946-2860-4747-880b-113835d5e77a", "label": "摘要9", "info": "连续型随机变量的另一技术细节涉及处理那种相互之间有确定性函数关；系的连续型变量。假设有两个随机变量x 和y 满足 y =g( x )，其中g是可；逆的、连续可微的函数。可能有人会想", "keywords": "是可, 系的连续型变量, 满足, 连续型随机变量的另一技术细节涉及处理那种相互之间有确定性函数关, 假设有两个随机变量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "2ed6e943-a4bc-418d-964d-a4d618e2e446", "label": "摘要10", "info": "举一个简单的例子，假设有两个标量值随机变量x和y，并且满足", "keywords": "并且满足, 假设有两个标量值随机变量, 举一个简单的例子", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "a77303f2-575e-4bef-8a64-905661dcd10b", "label": "摘要11", "info": "以及x∼U(0,1)。如果我们使用p  y  (y)=p  x  (2y)，那么p  y  除", "keywords": "那么, 如果我们使用, 以及", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "19bf87c3-41b1-427c-90e5-d093158315b0", "label": "摘要12", "info": "了区间", "keywords": "了区间", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "2eebbb24-373d-43aa-a7ba-6aea31b3c0d4", "label": "摘要13", "info": "以外都为0，并且在这个区间上的值为1。这意味着", "keywords": "并且在这个区间上的值为, 这意味着, 以外都为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "05e597f8-d79f-4e70-a131-e3cbb47d4183", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；而这违背了概率密度的定义（积分为1）。这个常见错误之所以错，是；因为它没有考虑到引入函数g后造成的空间变形。回忆一下，  x  落在无", "keywords": "回忆一下, 而这违背了概率密度的定义, 这个常见错误之所以错, 因为它没有考虑到引入函数, 积分为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e29e77bc-922f-4e16-b6e8-abe31341fcf4", "label": "摘要15", "info": "为了看出如何改正这个问题，我们回到标量值的情况。我们需要保持下；面这个性质：", "keywords": "面这个性质, 我们回到标量值的情况, 为了看出如何改正这个问题, 我们需要保持下", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4d26bf4a-615d-4cf6-bfa2-25e2dc0602ea", "label": "摘要16", "info": "求解上式，我们得到", "keywords": "我们得到, 求解上式", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "2ce96c33-d4ac-4e05-aab8-d44a1776a865", "label": "摘要17", "info": "或者等价地，", "keywords": "或者等价地", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "640906ca-70f1-4eda-b0d3-d5b04b60ed53", "label": "摘要18", "info": "在高维空间中，微分运算扩展为Jacobian矩阵  （Jacobian  matrix）的行", "keywords": "矩阵, 在高维空间中, 的行, 微分运算扩展为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "daaf8b8e-caa9-4042-ac53-8dceb55cb7ea", "label": "摘要19", "info": "列式——矩阵的每个元素为", "keywords": "列式, 矩阵的每个元素为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0974bdae-5d38-479c-821d-7f98862747f3", "label": "摘要20", "info": "。因此，对于实值向量  x", "keywords": "因此, 对于实值向量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6c1a6eee-71a7-4753-bcbb-6de7175a2076", "label": "摘要21", "info": "和 y ，", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "dab39d12-64bf-4f93-aea5-a46fb977913d", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；3.13　信息论", "keywords": "信息论", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ac959196-2190-40e3-a722-e4722d929cd8", "label": "3.13：信息论", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "1c2392dc-babf-4b3e-8ece-4cdb0d047210", "label": "摘要1", "info": "信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多；少进行量化。它最初被发明是用来研究在一个含有噪声的信道上用离散；的字母表来发送消息，例如通过无线电传输来通信。在这种情况下，信", "keywords": "少进行量化, 主要研究的是对一个信号包含信息的多, 例如通过无线电传输来通信, 在这种情况下, 信息论是应用数学的一个分支", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f7a84694-a99f-4fb6-aa0a-7ddd805be33f", "label": "摘要2", "info": "的解释不再适用。信息论是电子工程和计算机科学中许多领域的基础。；在本书中，我们主要使用信息论的一些关键思想来描述概率分布或者量；化概率分布之间的相似性。有关信息论的更多细节，参见Cover", "keywords": "参见, 的解释不再适用, 信息论是电子工程和计算机科学中许多领域的基础, 我们主要使用信息论的一些关键思想来描述概率分布或者量, 在本书中", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f5385f9b-462a-4d3d-be57-f5fdd321335f", "label": "摘要3", "info": "信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可；能的事件发生，能提供更多的信息。消息说：“今天早上太阳升起”，信；息量是如此之少，以至于没有必要发送；但一条消息说：“今天早上有", "keywords": "息量是如此之少, 能的事件发生, 今天早上太阳升起, 能提供更多的信息, 要比一个非常可", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "97104ea2-cf8b-4344-b3e0-96b1ea72e12a", "label": "摘要4", "info": "我们想要通过这种基本想法来量化信息。特别是：", "keywords": "我们想要通过这种基本想法来量化信息, 特别是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "36e6e657-79dc-45b9-81b3-5dfaa6943ccf", "label": "摘要5", "info": "非常可能发生的事件信息量要比较少，并且极端情况下，确保能够；发生的事件应该没有信息量。；较不可能发生的事件具有更高的信息量。", "keywords": "并且极端情况下, 确保能够, 非常可能发生的事件信息量要比较少, 较不可能发生的事件具有更高的信息量, 发生的事件应该没有信息量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "daf5dcdd-c09c-481a-aa69-a730344b5a04", "label": "摘要6", "info": "为了满足上述3个性质，我们定义一个事件x=x  的自信息  （self-；information）为", "keywords": "为了满足上述, 我们定义一个事件, 个性质, 的自信息", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "cd92b3b2-caaa-41c3-a715-c09546598770", "label": "摘要7", "info": "在本书中，我们总是用log来表示自然对数，其底数为e。因此我们定义", "keywords": "其底数为, 在本书中, 我们总是用, 来表示自然对数, 因此我们定义", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "959b83a9-9d29-471e-8ae3-789988cadfa0", "label": "摘要8", "info": "的I(x)单位是奈特  （nats）。一奈特是以   的概率观测到一个事件时获", "keywords": "一奈特是以, 单位是奈特, 的概率观测到一个事件时获", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "14c9f7bc-da77-41d7-8575-5c82652b6b3d", "label": "摘要9", "info": "得的信息量。其他的材料中使用底数为2的对数，单位是比特  （bit）或；者香农  （shannons）；通过比特度量的信息只是通过奈特度量信息的常；数倍。", "keywords": "得的信息量, 的对数, 数倍, 通过比特度量的信息只是通过奈特度量信息的常, 其他的材料中使用底数为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "66b545c0-d808-47eb-80e3-f37cd619c181", "label": "摘要10", "info": "当x是连续的，我们使用类似的关于信息的定义，但有些来源于离散形；式的性质就丢失了。例如，一个具有单位密度的事件信息量仍然为0，；但是不能保证它一定发生。", "keywords": "一个具有单位密度的事件信息量仍然为, 我们使用类似的关于信息的定义, 但有些来源于离散形, 是连续的, 例如", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "27c5eca0-9670-488e-a17d-05b63863fbd7", "label": "摘要11", "info": "自信息只处理单个的输出。我们可以用香农熵 （Shannon entropy）来对；整个概率分布中的不确定性总量进行量化：", "keywords": "我们可以用香农熵, 整个概率分布中的不确定性总量进行量化, 来对, 自信息只处理单个的输出", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "07f26626-f2d1-44da-b128-839f7af19682", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；也记作H(P)。换言之，一个分布的香农熵是指遵循这个分布的事件所产；生的期望信息总量。它给出了对依据概率分布P生成的符号进行编码所", "keywords": "生成的符号进行编码所, 换言之, 一个分布的香农熵是指遵循这个分布的事件所产, 也记作, 生的期望信息总量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4f43140b-77a3-4c55-9a3a-e11d75e09128", "label": "摘要13", "info": "图3.5　二值随机变量的香农熵。该图说明了更接近确定性的分布是如何具有较低的香农熵，而；更接近均匀分布的分布是如何具有较高的香农熵。水平轴是p，表示二值随机变量等于1的概；率。熵由(p−1)log(1−p)−p log p给出。当p接近0时，分布几乎是确定的，因为随机变量几乎总是", "keywords": "熵由, 水平轴是, 因为随机变量几乎总是, 表示二值随机变量等于, 分布几乎是确定的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8230cf26-e3f3-45db-b1f1-6db42661e79d", "label": "摘要14", "info": "如果对于同一个随机变量x有两个单独的概率分布P(x)和Q(x)，可以使用；KL散度  （Kullback-Leibler（KL）divergence）来衡量这两个分布的差；异：", "keywords": "如果对于同一个随机变量, 可以使用, 散度, 来衡量这两个分布的差, 有两个单独的概率分布", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "fc272bd1-9884-42cb-8bae-61086e549503", "label": "摘要15", "info": "在离散型变量的情况下，KL散度衡量的是，当我们使用一种被设计成；能够使得概率分布Q产生的消息的长度最小的编码，发送包含由概率分；布P产生的符号的消息时，所需要的额外信息量（如果我们使用底数为2", "keywords": "能够使得概率分布, 当我们使用一种被设计成, 所需要的额外信息量, 发送包含由概率分, 在离散型变量的情况下", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e8d0cd63-be81-4eea-b147-e1c0483afa75", "label": "摘要16", "info": "。为了说明每种选择的效果，我们", "keywords": "为了说明每种选择的效果, 我们", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c12c86d5-080b-4cb6-a867-7145269e4713", "label": "摘要17", "info": "或最小化", "keywords": "或最小化", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "25182d73-5992-45c2-adac-bcd81bb28b68", "label": "摘要18", "info": "图3.6　KL散度是不对称的。假设我们有一个分布P(x)，并且希望用另一个分布q(x)来近似它。；我们可以选择最小化；令p是两个高斯分布的混合，令q为单个高斯分布。选择使用KL散度的哪个方向是取决于问题", "keywords": "为单个高斯分布, 来近似它, 散度的哪个方向是取决于问题, 散度是不对称的, 是两个高斯分布的混合", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "23cab896-e012-4ea5-89d7-354fb0ad750e", "label": "摘要19", "info": "KL散度有很多有用的性质，最重要的是，它是非负的。KL散度为0，当；且仅当P和Q在离散型变量的情况下是相同的分布，或者在连续型变量；的情况下是“几乎处处”相同的。因为KL散度是非负的并且衡量的是两", "keywords": "因为, 散度有很多有用的性质, 散度是非负的并且衡量的是两, 散度为, 几乎处处", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3b04691c-3d50-4cf8-9d49-acd8a1d5ed8a", "label": "摘要20", "info": "。这种非对称性意味着选择；影响很大。更多细节可以看图3.6。", "keywords": "影响很大, 这种非对称性意味着选择, 更多细节可以看图", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "674ef669-4f87-404c-9af0-e01fc52eba1d", "label": "摘要21", "info": "还是", "keywords": "还是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c92901d1-54ee-4c7e-9522-42b02e76369b", "label": "摘要22", "info": "一个和KL散度密切联系的量是交叉熵", "keywords": "一个和, 散度密切联系的量是交叉熵", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "08d4a724-fe05-4d10-91b0-54c878ad2549", "label": "摘要23", "info": "（cross-entropy），即；，它和KL散度很像，但是缺", "keywords": "散度很像, 但是缺, 它和", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f65d619f-24f7-416c-9083-18dac8521973", "label": "摘要24", "info": "少左边一项：", "keywords": "少左边一项", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8d76ff78-44e7-4fb7-8789-33dca54c80eb", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；针对Q最小化交叉熵等价于最小化KL散度，因为Q并不参与被省略的那；一项。", "keywords": "因为, 针对, 散度, 一项, 最小化交叉熵等价于最小化", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "4a1117e2-88b8-4198-9797-28f8e1d072f0", "label": "摘要26", "info": "当我们计算这些量时，经常会遇到0  log  0这个表达式。按照惯例，在信；息论中，我们将这个表达式处理为lim x→0 x log x=0。", "keywords": "息论中, 当我们计算这些量时, 这个表达式, 在信, 我们将这个表达式处理为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "label": "3.14：结构化概率模型", "level": 2, "group": "chapter-3", "type": "子章節"}, {"id": "485a9dc5-a515-4909-b09d-fa43054ac0e4", "label": "摘要1", "info": "机器学习的算法经常会涉及在非常多的随机变量上的概率分布。通常，；这些概率分布涉及的直接相互作用都是介于非常少的变量之间的。使用；单个函数来描述整个联合概率分布是非常低效的（无论是计算上还是统", "keywords": "通常, 机器学习的算法经常会涉及在非常多的随机变量上的概率分布, 无论是计算上还是统, 这些概率分布涉及的直接相互作用都是介于非常少的变量之间的, 单个函数来描述整个联合概率分布是非常低效的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "17b66602-1769-449b-9cfb-4ac080b4bac2", "label": "摘要2", "info": "我们可以把概率分布分解成许多因子的乘积形式，而不是使用单一的函；数来表示概率分布。例如，假设我们有3个随机变量a、b和c，并且a影；响b的取值，b影响c的取值，但是a和c在给定b时是条件独立的。我们可", "keywords": "时是条件独立的, 的取值, 而不是使用单一的函, 影响, 但是", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "968a3cfa-e2c6-4871-95fa-fb1b7084e940", "label": "摘要3", "info": "这种分解可以极大地减少用来描述一个分布的参数数量。每个因子使用；的参数数目是其变量数目的指数倍。这意味着，如果我们能够找到一种；使每个因子分布具有更少变量的分解方法，就能极大地降低表示联合分", "keywords": "如果我们能够找到一种, 每个因子使用, 的参数数目是其变量数目的指数倍, 这种分解可以极大地减少用来描述一个分布的参数数量, 使每个因子分布具有更少变量的分解方法", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "40273434-b037-4ae4-8587-8d384fc58028", "label": "摘要4", "info": "可以用图来描述这种分解。这里我们使用的是图论中的“图”的概念：由；一些可以通过边互相连接的顶点的集合构成。当用图来表示这种概率分；布的分解时，我们把它称为结构化概率模型  （structured  probabilistic", "keywords": "布的分解时, 可以用图来描述这种分解, 当用图来表示这种概率分, 我们把它称为结构化概率模型, 这里我们使用的是图论中的", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0a0f3e94-3f16-4c7e-ac52-e50bbfeb11ee", "label": "摘要5", "info": "有两种主要的结构化概率模型：有向的和无向的。两种图模型都使用图；，其中图的每个节点对应着一个随机变量，连接两个随机变量的边意", "keywords": "两种图模型都使用图, 连接两个随机变量的边意, 有两种主要的结构化概率模型, 有向的和无向的, 其中图的每个节点对应着一个随机变量", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "791d3bcb-1ed7-47d9-b1fd-dca51ba06549", "label": "摘要6", "info": "味着概率分布可以表示成这两个随机变量之间的直接作用。", "keywords": "味着概率分布可以表示成这两个随机变量之间的直接作用", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f1fb282e-a4d2-4dee-b77e-d93006e01393", "label": "摘要7", "info": "有向  （directed）模型使用带有有向边的图，它们用条件概率分布来表", "keywords": "有向, 模型使用带有有向边的图, 它们用条件概率分布来表", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "0bb5fa90-3ea9-42e8-a17e-ddcbf4d9ae65", "label": "摘要8", "info": "示分解，就像上面的例子。特别地，有向模型对于分布中的每一个随机；变量x i 都包含着一个影响因子，这个组成x i 条件概率的影响因子被称为；x i 的父节点，记为", "keywords": "有向模型对于分布中的每一个随机, 记为, 这个组成, 特别地, 就像上面的例子", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "e42ab872-a834-4470-8ced-9b974389de10", "label": "摘要9", "info": "。", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "396ff3b1-a60a-40c4-b411-92730bf7cc23", "label": "摘要10", "info": "图3.7给出了一个有向图的例子以及它表示的概率分布的分解。", "keywords": "给出了一个有向图的例子以及它表示的概率分布的分解", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "8e7a2e16-dd12-4343-a4fb-2b4886754007", "label": "摘要11", "info": "图3.7　关于随机变量a、b、c、d和e的有向图模型。这幅图对应的概率分布可以分解为", "keywords": "的有向图模型, 关于随机变量, 这幅图对应的概率分布可以分解为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "16059016-fe09-430a-ae81-baf432918a64", "label": "摘要12", "info": "该图模型使我们能够快速看出此分布的一些性质。例如，a和c直接相互；影响，但a和e只有通过c间接相互影响", "keywords": "直接相互, 影响, 例如, 该图模型使我们能够快速看出此分布的一些性质, 间接相互影响", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "079fd5a6-23a9-4d84-867b-0462392559c1", "label": "摘要13", "info": "无向  （undirected）模型使用带有无向边的图，它们将分解表示成一组；函数：不像有向模型那样，这些函数通常不是任何类型的概率分布。；中任何满足两两之间有边连接的顶点的集合被称为团。无向模型中的每", "keywords": "无向模型中的每, 模型使用带有无向边的图, 函数, 这些函数通常不是任何类型的概率分布, 中任何满足两两之间有边连接的顶点的集合被称为团", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "17c6b45f-f02e-4d1b-b203-0d3d16edef98", "label": "摘要14", "info": "都伴随着一个因子", "keywords": "都伴随着一个因子", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f5275367-e4f3-453d-9ff8-17a2f40e5678", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；中那样要求因子的和或者积分为1。", "keywords": "中那样要求因子的和或者积分为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "ce7826a7-91b0-4336-821f-ae63afff0fe1", "label": "摘要16", "info": "随机变量的联合概率与所有这些因子的乘积成比例  （proportional）；——这意味着因子的值越大，则可能性越大。当然，不能保证这种乘积；的求和为1。所以我们需要除以一个归一化常数Z来得到归一化的概率分", "keywords": "所以我们需要除以一个归一化常数, 的求和为, 不能保证这种乘积, 随机变量的联合概率与所有这些因子的乘积成比例, 则可能性越大", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "3001566c-7240-4a7e-a772-ddd92d44842b", "label": "摘要17", "info": "图3.8给出了一个无向图的例子以及它表示的概率分布的分解。", "keywords": "给出了一个无向图的例子以及它表示的概率分布的分解", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c8d8b40d-d18f-47df-9934-84a52993545a", "label": "摘要18", "info": "图3.8　关于随机变量a、b、c、d和e的无向图模型。这幅图对应的概率分布可以分解为", "keywords": "关于随机变量, 这幅图对应的概率分布可以分解为, 的无向图模型", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "83dac0ba-591c-47d9-8fe7-4698a66dc3ce", "label": "摘要19", "info": "该图模型使我们能够快速看出此分布的一些性质。例如，a和c直接相互；影响，但a和e只有通过c间接相互影响", "keywords": "直接相互, 影响, 例如, 该图模型使我们能够快速看出此分布的一些性质, 间接相互影响", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "b7f88cf5-54f0-42dc-b13d-d356f3997cc7", "label": "摘要20", "info": "请记住，这些图模型表示的分解仅仅是描述概率分布的一种语言。它们", "keywords": "这些图模型表示的分解仅仅是描述概率分布的一种语言, 请记住, 它们", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "570ee7e2-6aba-4537-b2bd-e67e6d5c299e", "label": "摘要21", "info": "不是互相排斥的概率分布族。有向或者无向不是概率分布的特性；它是；概率分布的一种特殊描述  （description）所具有的特性，而任何概率分；布都可以用这两种方式进行描述。", "keywords": "布都可以用这两种方式进行描述, 概率分布的一种特殊描述, 有向或者无向不是概率分布的特性, 所具有的特性, 而任何概率分", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "c7b46a7f-5196-4aec-9372-f74402540d26", "label": "摘要22", "info": "在本书第1部分和第2部分中，我们仅仅将结构化概率模型视作一门语；言，来描述不同的机器学习算法选择表示的直接的概率关系。在讨论研；究课题之前，读者不需要更深入地理解结构化概率模型。在第3部分的", "keywords": "在讨论研, 部分和第, 究课题之前, 在本书第, 我们仅仅将结构化概率模型视作一门语", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "237bbcc0-d629-4af9-b7b9-3fdf95fc0c46", "label": "摘要23", "info": "本章复习了概率论中与深度学习最为相关的一些基本概念。我们还剩下；一些基本的数学工具需要讨论：数值计算。", "keywords": "一些基本的数学工具需要讨论, 我们还剩下, 本章复习了概率论中与深度学习最为相关的一些基本概念, 数值计算", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "af1e1459-b3bb-4659-a0b8-de355d839859", "label": "摘要24", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "f1220093-8a0c-4f17-9a11-b95c220cd990", "label": "摘要25", "info": "(1)  译者注：国内有些教材也将PMF翻译成概率分布律。", "keywords": "翻译成概率分布律, 译者注, 国内有些教材也将", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "932816f4-b62b-44e3-889d-29af2c3bbaf3", "label": "摘要26", "info": "“multinoulli”这个术语是最近被Gustavo", "keywords": "这个术语是最近被", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "9d4c09fa-01b3-4345-91a4-0234cf6bd02d", "label": "摘要27", "info": "(2)；Lacerdo发明、被Murphy（2012）推广的。；Multinoulli分布是 多项式分布 （multinomial distribution）的一个特例。多项式分布是{0，···，n}", "keywords": "推广的, 的一个特例, 分布是, 多项式分布, 发明", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "13688be7-9bc7-49f9-805f-bd3d11742c99", "label": "摘要28", "info": "(3)；Banach-Tarski定理给出了这类集合的一个有趣的例子。译者注：我们这里把“the  set  of；rational  numbers”翻译成“有理数相关集合”，理解为“一些有理数组成的集合”，如果直接用后面", "keywords": "翻译成, 定理给出了这类集合的一个有趣的例子, 有理数相关集合, 译者注, 理解为", "level": 3, "group": "chapter-3", "type": "段落"}, {"id": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "label": "第4章：数值计算", "level": 1, "group": "chapter-4", "type": "章節"}, {"id": "2f790937-6f45-4d08-9503-225f8640651c", "label": "3.14：结构化概率模型", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "9acfc2fe-fca5-432a-8e69-04c7847a8f33", "label": "摘要1", "info": "机器学习算法通常需要大量的数值计算。这通常是指通过迭代过程更新；解的估计值来解决数学问题的算法，而不是通过解析过程推导出公式来；提供正确解的方法。常见的操作包括优化（找到最小化或最大化函数值", "keywords": "找到最小化或最大化函数值, 机器学习算法通常需要大量的数值计算, 提供正确解的方法, 解的估计值来解决数学问题的算法, 常见的操作包括优化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "615c0846-de67-43a1-9b80-0b104d15c105", "label": "4.1：上溢和下溢", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "c3a44142-43ee-4386-83cb-9d0de6589eec", "label": "摘要1", "info": "连续数学在数字计算机上的根本困难是，我们需要通过有限数量的位模", "keywords": "我们需要通过有限数量的位模, 连续数学在数字计算机上的根本困难是", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "08cb40d5-15e9-4de1-878b-af21e1efa58a", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；式来表示无限多的实数。这意味着我们在计算机中表示实数时，几乎总；会引入一些近似误差。在许多情况下，这仅仅是舍入误差。舍入误差会", "keywords": "会引入一些近似误差, 在许多情况下, 式来表示无限多的实数, 几乎总, 这仅仅是舍入误差", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "13861071-0749-4499-867f-f6b6539d10ba", "label": "摘要3", "info": "一种极具毁灭性的舍入误差是下溢  （underflow）。当接近零的数被四；舍五入为零时发生下溢。许多函数在其参数为零而不是一个很小的正数；时才会表现出质的不同。例如，我们通常要避免被零除（一些软件环境", "keywords": "我们通常要避免被零除, 例如, 许多函数在其参数为零而不是一个很小的正数, 当接近零的数被四, 一些软件环境", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "620af10a-19f8-484d-8878-df37b22d75e3", "label": "摘要4", "info": "另一个极具破坏力的数值错误形式是上溢  （overflow）。当大量级的数；被近似为∞或−∞时发生上溢。进一步的运算通常会导致这些无限值变为；非数字。", "keywords": "进一步的运算通常会导致这些无限值变为, 当大量级的数, 非数字, 时发生上溢, 另一个极具破坏力的数值错误形式是上溢", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "8b83faca-b080-4847-8567-de09456fdd16", "label": "摘要5", "info": "必须对上溢和下溢进行数值稳定的一个例子是softmax函数  （softmax；function）。softmax函数经常用于预测与Multinoulli分布相关联的概率，；定义为", "keywords": "分布相关联的概率, 必须对上溢和下溢进行数值稳定的一个例子是, 定义为, 函数, 函数经常用于预测与", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4efefb04-1b67-4e99-8970-3b2631b72b3c", "label": "摘要6", "info": "考虑一下当所有x  i  都等于某个常数c时会发生什么。从理论分析上说，", "keywords": "从理论分析上说, 都等于某个常数, 时会发生什么, 考虑一下当所有", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "af98b822-3e36-4534-a14d-d52eaa12a40f", "label": "摘要7", "info": "我们可以发现所有的输出都应该为   。从数值计算上说，当c量级很大", "keywords": "量级很大, 从数值计算上说, 我们可以发现所有的输出都应该为", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a20c47ee-5fba-44d8-91bb-8475adef315a", "label": "摘要8", "info": "时，这可能不会发生。如果c是很小的负数，exp(c)就会下溢。这意味着；softmax函数的分母会变成0，所以最后的结果是未定义的。当c是非常大；的正数时，exp(c)的上溢再次导致整个表达式未定义。这两个困难能通", "keywords": "如果, 这两个困难能通, 函数的分母会变成, 就会下溢, 的上溢再次导致整个表达式未定义", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "9dbdfa5d-5e73-4a3f-ac4d-605d4f4acb7b", "label": "摘要9", "info": "i  导致exp的最大参数为0，这排除了上溢的可能性。同样", "keywords": "这排除了上溢的可能性, 同样, 的最大参数为, 导致", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "56dc860e-dce7-43be-b308-91fea7a0a8c7", "label": "摘要10", "info": "i  x", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f7c9b08b-1517-4dad-a97d-4357a7deff74", "label": "摘要11", "info": "还有一个小问题。分子中的下溢仍可以导致整体表达式被计算为零。这；意味着，如果我们在计算log  softmax(  x  )时，先计算softmax再把结果传；给log函数，会错误地得到−∞。相反，我们必须实现一个单独的函数，", "keywords": "会错误地得到, 如果我们在计算, 函数, 还有一个小问题, 再把结果传", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f2b781c9-631f-4896-9099-ecc45384ee77", "label": "摘要12", "info": "在大多数情况下，我们没有明确地对本书描述的各种算法所涉及的数值；考虑进行详细说明。在实现深度学习算法时，底层库的开发者应该牢记；数值问题。本书的大多数读者可以简单地依赖保证数值稳定的底层库。", "keywords": "在大多数情况下, 在实现深度学习算法时, 底层库的开发者应该牢记, 我们没有明确地对本书描述的各种算法所涉及的数值, 本书的大多数读者可以简单地依赖保证数值稳定的底层库", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "15148bc6-f768-494d-9ea6-359e60de35ba", "label": "4.2：病态条件", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "5dc6f6be-f43f-41bf-a4fa-cbb21b4af3e2", "label": "摘要1", "info": "条件数指的是函数相对于输入的微小变化而变化的快慢程度。输入被轻；微扰动而迅速改变的函数对于科学计算来说可能是有问题的，因为输入；中的舍入误差可能导致输出的巨大变化。", "keywords": "因为输入, 中的舍入误差可能导致输出的巨大变化, 条件数指的是函数相对于输入的微小变化而变化的快慢程度, 输入被轻, 微扰动而迅速改变的函数对于科学计算来说可能是有问题的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "baeb7777-6891-494e-b040-4d113a2a5307", "label": "摘要2", "info": "考虑函数；其条件数为", "keywords": "考虑函数, 其条件数为", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "deb2ed87-f10f-4b23-b866-b0349cddb864", "label": "摘要3", "info": "。当", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "d3ba9c2c-7960-4a1f-8e15-b8ddaf052e76", "label": "摘要4", "info": "具有特征值分解时，", "keywords": "具有特征值分解时", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "fc2ae307-85c5-4f26-a3ad-f63c7089feac", "label": "摘要5", "info": "这是最大和最小特征值的模之比 (1) 。当该数很大时，矩阵求逆对输入的；误差特别敏感。", "keywords": "这是最大和最小特征值的模之比, 误差特别敏感, 当该数很大时, 矩阵求逆对输入的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "e7a561a5-3a36-4c4d-97e8-51d554d8953c", "label": "摘要6", "info": "这种敏感性是矩阵本身的固有特性，而不是矩阵求逆期间舍入误差的结；果。即使我们乘以完全正确的矩阵逆，病态条件的矩阵也会放大预先存；在的误差。在实践中，该错误将与求逆过程本身的数值误差进一步复", "keywords": "病态条件的矩阵也会放大预先存, 即使我们乘以完全正确的矩阵逆, 而不是矩阵求逆期间舍入误差的结, 该错误将与求逆过程本身的数值误差进一步复, 在的误差", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "label": "4.3：基于梯度的优化方法", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "fdd043cd-d2b7-41c2-ac47-39e4cd525e7b", "label": "摘要1", "info": "4.3.1　梯度之上：Jacobian和Hessian矩阵", "keywords": "矩阵, 梯度之上", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "e453067f-b605-40fa-b687-f330811fcb06", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；大多数深度学习算法都涉及某种形式的优化。优化指的是改变 x 以最小；化或最大化某个函数f( x )的任务。我们通常以最小化f( x )指代大多数最", "keywords": "的任务, 以最小, 化或最大化某个函数, 优化指的是改变, 大多数深度学习算法都涉及某种形式的优化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "64257ec1-6ea9-46a5-9ff6-1a96d18ca6d9", "label": "摘要3", "info": "我们把要最小化或最大化的函数称为目标函数  （objective  function）或；准则  （criterion）。当我们对其进行最小化时，也把它称为代价函数；（cost", "keywords": "当我们对其进行最小化时, 准则, 我们把要最小化或最大化的函数称为目标函数, 也把它称为代价函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a417eedb-200a-4051-a043-522bc649bd1e", "label": "摘要4", "info": "function）、损失函数  （loss", "keywords": "损失函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "87773dce-19e3-4f43-8267-e99800bf5eab", "label": "摘要5", "info": "我们通常使用一个上标∗表示最小化或最大化函数的 x 值，如记 x ∗ =arg；min f( x )。", "keywords": "我们通常使用一个上标, 如记, 表示最小化或最大化函数的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c280483a-1995-43ee-82ee-a5082e69ab41", "label": "摘要6", "info": "我们假设读者已经熟悉微积分，这里简要回顾微积分概念如何与优化联；系。", "keywords": "我们假设读者已经熟悉微积分, 这里简要回顾微积分概念如何与优化联", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "669afdcb-4b6e-4285-b8cf-8b23d62daa08", "label": "摘要7", "info": "假设有一个函数y=f(", "keywords": "假设有一个函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5ff506e8-e6a4-4db6-b864-9c6f96bc3f4d", "label": "摘要8", "info": "x", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "eca3c47b-9d08-4587-aa3b-ae39c178d239", "label": "摘要9", "info": ")，其中x和y是实数。这个函数的导数", "keywords": "这个函数的导数, 其中, 是实数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a9531542-1b22-478a-b4db-8901ee5598bc", "label": "摘要10", "info": "（derivative）记为f ′( x )或  。导数f ′( x )代表f( x )在点x处的斜率。", "keywords": "记为, 导数, 在点, 代表, 处的斜率", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "ae5affb9-66e3-48dd-b08f-2ab489f8d3b2", "label": "摘要11", "info": "换句话说，它表明如何缩放输入的小变化才能在输出获得相应的变化：；。", "keywords": "换句话说, 它表明如何缩放输入的小变化才能在输出获得相应的变化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4ab25c62-f8cc-4589-a4a4-3568d87e8a26", "label": "摘要12", "info": "因此导数对于最小化一个函数很有用，因为它告诉我们如何更改x来略；微地改善y。例如，我们知道对于足够小的   来说，f(x−sign（f  ′(  x  )))；是比f( x )小的。因此我们可以将x往导数的反方向移动一小步来减小f( x", "keywords": "微地改善, 是比, 来略, 小的, 例如", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "0a59754c-6bbc-4222-809c-fe44032a7810", "label": "摘要13", "info": "图4.1　梯度下降。梯度下降算法如何使用函数导数的示意图，即沿着函数的下坡方向（导数反；方向）直到最小", "keywords": "直到最小, 即沿着函数的下坡方向, 梯度下降算法如何使用函数导数的示意图, 方向, 梯度下降", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1350f8f8-e1a3-47cc-ac76-16bb2e9b4f83", "label": "摘要14", "info": "当f ′( x )=0时，导数无法提供往哪个方向移动的信息。f ′( x )=0的点称为；临界点  （critical  point）或驻点  （stationary  point）。一个局部极小点；（local minimum）意味着这个点的f( x )小于所有邻近点，因此不可能通", "keywords": "的点称为, 一个局部极小点, 意味着这个点的, 因此不可能通, 或驻点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "74aabd27-3e37-4b65-88a6-b918531ab943", "label": "摘要15", "info": "图4.2　临界点的类型。一维情况下，3种临界点的示例。临界点是斜率为零的点。这样的点可；以是： 局部极小点 （local minimum），其值低于相邻点； 局部极大点 （local maximum），其；值高于相邻点；鞍点，同时存在更高和更低的相邻点", "keywords": "临界点的类型, 一维情况下, 种临界点的示例, 其值低于相邻点, 鞍点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f4abbbc2-5d11-4492-be99-e099628defb0", "label": "摘要16", "info": "使f(", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f991c445-68a3-49b1-9a23-7394622354a6", "label": "摘要17", "info": "x", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5c464486-30c7-402b-b712-87476094f5d0", "label": "摘要18", "info": ")取得绝对的最小值（相对所有其他值）的点是全局最小点", "keywords": "相对所有其他值, 取得绝对的最小值, 的点是全局最小点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "876c06cf-0935-41dd-a685-6322d8cc6fd5", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（global  minimum）。函数可能只有一个全局最小点或存在多个全局最；小点，还可能存在不是全局最优的全局极小点。在深度学习的背景下，", "keywords": "函数可能只有一个全局最小点或存在多个全局最, 还可能存在不是全局最优的全局极小点, 小点, 在深度学习的背景下", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "bd3f6a90-61bf-4602-b94f-875265eaa32a", "label": "摘要20", "info": "图4.3　近似最小化。当存在多个全局极小点或平坦区域时，优化算法可能无法找到全局最小；点。在深度学习的背景下，即使找到的解不是真正最小的，但只要它们对应于代价函数显著低；的值，我们通常就能接受这样的解", "keywords": "我们通常就能接受这样的解, 近似最小化, 的值, 优化算法可能无法找到全局最小, 即使找到的解不是真正最小的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b1469aef-15d1-451d-a13f-fa9b2ba3650d", "label": "摘要21", "info": "我们经常最小化具有多维输入的函数：；小化”的概念有意义，输出必须是一维的（标量）。", "keywords": "小化, 标量, 的概念有意义, 输出必须是一维的, 我们经常最小化具有多维输入的函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c0b45df5-50f8-439d-947b-b2bbb317e769", "label": "摘要22", "info": "。为了使“最", "keywords": "为了使", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "37a02009-b9fd-4c73-9cba-8dd29975ca0d", "label": "摘要23", "info": "针对具有多维输入的函数，我们需要用到偏导数 （partial derivative）的", "keywords": "针对具有多维输入的函数, 我们需要用到偏导数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "2ab868c5-336d-4b2e-86fa-0b248a6b6e5c", "label": "摘要24", "info": "概念。偏导数", "keywords": "偏导数, 概念", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "6f5f9495-e8fe-4c05-a5ff-307515752ac4", "label": "摘要25", "info": "衡量点 x 处只有x i 增加时f( x )如何变化。", "keywords": "处只有, 如何变化, 衡量点, 增加时", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "09ca4e61-b286-464f-97dc-c3dff19b1668", "label": "摘要26", "info": "梯度  （gradient）是相对一个向量求导的导数：f的导数是包含所有偏导；数的向量，记为；。梯度的第i个元素是f关于x  i  的偏导数。在", "keywords": "梯度, 的导数是包含所有偏导, 记为, 是相对一个向量求导的导数, 数的向量", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "cefc96d2-54cb-456e-88a9-8e424a173b5b", "label": "摘要27", "info": "在 u （单位向量）方向的方向导数 （directional derivative）是函数f在 u；关于α的导数；方向的斜率。换句话说，方向导数是函数", "keywords": "方向导数是函数, 单位向量, 是函数, 方向的方向导数, 方向的斜率", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5fb7cc6d-7b7e-4382-9833-5fa39134c2e5", "label": "摘要28", "info": "为了最小化f，我们希望找到使f下降得最快的方向。计算方向导数：", "keywords": "计算方向导数, 下降得最快的方向, 我们希望找到使, 为了最小化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "27d95f30-3c93-45e8-9686-84070240c500", "label": "摘要29", "info": "。", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "805b60a1-8975-417b-80cc-e237bfe1d95e", "label": "摘要30", "info": "其中θ是  u  与梯度的夹角。将", "keywords": "与梯度的夹角, 其中", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f93febad-7c43-44a4-85cc-7448ae2d8f06", "label": "摘要31", "info": "代入，并忽略与  u  无关的", "keywords": "并忽略与, 无关的, 代入", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "98712501-4d8c-4981-8956-b95f909de99a", "label": "摘要32", "info": "项，就能简化得到", "keywords": "就能简化得到", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "18e440ef-d503-4490-9ad7-987defb0acef", "label": "摘要33", "info": "这在  u  与梯度方向相反时取得最", "keywords": "这在, 与梯度方向相反时取得最", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "cae30be1-718c-4b17-86ec-63a08efff18b", "label": "摘要34", "info": "小。换句话说，梯度向量指向上坡，负梯度向量指向下坡。我们在负梯；度方向上移动可以减小f。这被称为最速下降法  （method  of  steepest；descent）或梯度下降 （gradient descent）。", "keywords": "这被称为最速下降法, 我们在负梯, 梯度向量指向上坡, 度方向上移动可以减小, 或梯度下降", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "9f30ae50-d877-4743-8059-7ba873470c42", "label": "摘要35", "info": "最速下降建议新的点为", "keywords": "最速下降建议新的点为", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "fecd02d5-4528-495f-9db8-c7a14f71c603", "label": "摘要36", "info": "其中  为学习率  （learning  rate），是一个确定步长大小的正标量。我；们可以通过几种不同的方式选择   。普遍的方式是选择一个小常数。；有时我们通过计算，选择使方向导数消失的步长。还有一种方法是根据", "keywords": "们可以通过几种不同的方式选择, 是一个确定步长大小的正标量, 普遍的方式是选择一个小常数, 其中, 还有一种方法是根据", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "3070b318-a3e3-473a-a20f-f7f5c88e3907", "label": "摘要37", "info": "最速下降在梯度的每一个元素为零时收敛（或在实践中，很接近零；时）。在某些情况下，我们也许能够避免运行该迭代算法，并通过解方；程", "keywords": "最速下降在梯度的每一个元素为零时收敛, 或在实践中, 我们也许能够避免运行该迭代算法, 很接近零, 在某些情况下", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "d943f304-778b-47e3-9076-3ee8a7dbb2ce", "label": "摘要38", "info": "直接跳到临界点。", "keywords": "直接跳到临界点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c9314075-abfd-4c28-b92a-65dda9580d24", "label": "摘要39", "info": "虽然梯度下降被限制在连续空间中的优化问题，但不断向更好的情况移；动一小步（即近似最佳的小移动）的一般概念可以推广到离散空间。递；增带有离散参数的目标函数称为爬山 （hill  climbing）算法（Russel  and", "keywords": "的一般概念可以推广到离散空间, 算法, 即近似最佳的小移动, 增带有离散参数的目标函数称为爬山, 但不断向更好的情况移", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "9488e2b6-a48c-4d97-8487-18a58a876929", "label": "摘要40", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；4.3.1　梯度之上：Jacobian和Hessian矩阵", "keywords": "矩阵, 梯度之上", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "fa06002e-6ffe-4624-8cee-0a9810a60606", "label": "摘要41", "info": "有时我们需要计算输入和输出都为向量的函数的所有偏导数。包含所有；这样的偏导数的矩阵被称为Jacobian 矩阵。具体来说，如果我们有一个；定义为", "keywords": "定义为, 这样的偏导数的矩阵被称为, 矩阵, 包含所有, 具体来说", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "8779f531-9b4c-454e-981d-7723f306aae9", "label": "摘要42", "info": "。", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c8923764-e53d-45c0-9d50-332a716ec11f", "label": "摘要43", "info": "有时，我们也对导数的导数感兴趣，即二阶导数；derivative）。例如，有一个函数", "keywords": "有一个函数, 即二阶导数, 有时, 例如, 我们也对导数的导数感兴趣", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "29c19681-a5ce-4465-8d53-58124ecb7e7e", "label": "摘要44", "info": "（second；，f的一阶导数（关", "keywords": "的一阶导数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "9da6fb5d-6877-4786-aa65-40bbbff29305", "label": "摘要45", "info": "于x  j  ）关于x  i  的导数记为", "keywords": "的导数记为, 关于", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "cff349a5-48dc-47ad-96d4-7d36216d0f18", "label": "摘要46", "info": "。在一维情况下，我们可以将", "keywords": "在一维情况下, 我们可以将", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "3917e1b2-6f3f-4671-90fc-9dbd89009276", "label": "摘要47", "info": "。二阶导数告诉我们，一阶导数将如何随", "keywords": "二阶导数告诉我们, 一阶导数将如何随", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "eb124b99-095a-4b64-a488-7e1ce0675eea", "label": "摘要48", "info": "着输入的变化而改变。它表示只基于梯度信息的梯度下降步骤是否会产；生如我们预期的那样大的改善，因此它是重要的。我们可以认为，二阶；导数是对曲率的衡量。假设我们有一个二次函数（虽然很多实践中的函", "keywords": "虽然很多实践中的函, 因此它是重要的, 它表示只基于梯度信息的梯度下降步骤是否会产, 二阶, 假设我们有一个二次函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "80a4e1e2-150e-47dd-8c4f-827f2619c76c", "label": "摘要49", "info": "图4.4　二阶导数确定函数的曲率。这里我们展示具有各种曲率的二次函数。虚线表示我们仅根；据梯度信息进行梯度下降后预期的代价函数值。对于负曲率，代价函数实际上比梯度预测下降；得更快。没有曲率时，梯度正确预测下降值。对于正曲率，代价函数比预期下降得更慢，并且", "keywords": "代价函数实际上比梯度预测下降, 对于负曲率, 据梯度信息进行梯度下降后预期的代价函数值, 没有曲率时, 虚线表示我们仅根", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c705778f-d84d-45e6-8cd9-7b8ad4e7a1e5", "label": "摘要50", "info": "当我们的函数具有多维输入时，二阶导数也有很多。我们可以将这些导；数合并成一个矩阵，称为Hessian  矩阵。Hessian矩阵；定义", "keywords": "称为, 定义, 矩阵, 当我们的函数具有多维输入时, 二阶导数也有很多", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "0b83c62e-a827-41c0-b8cf-ef20edf43609", "label": "摘要51", "info": "Hessian等价于梯度的Jacobian矩阵。", "keywords": "等价于梯度的, 矩阵", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "ae8361de-70cb-4233-a6e0-f2934f638c81", "label": "摘要52", "info": "微分算子在任何二阶偏导连续的点处可交换，也就是它们的顺序可以互；换：", "keywords": "也就是它们的顺序可以互, 微分算子在任何二阶偏导连续的点处可交换", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "53d720e9-507a-49c9-b5d3-e4b9f9b25424", "label": "摘要53", "info": "这意味着H i,j =H j,i ，因此Hessian矩阵在这些点上是对称的。在深度学习；背景下，我们遇到的大多数函数的Hessian几乎处处都是对称的。因为；Hessian矩阵是实对称的，我们可以将其分解成一组实特征值和一组特征", "keywords": "几乎处处都是对称的, 因为, 因此, 矩阵是实对称的, 矩阵在这些点上是对称的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "869bc397-1986-43a7-b79b-e9416aa4331f", "label": "摘要54", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；于其他的方向 d  ，方向二阶导数是所有特征值的加权平均，权重在0和1；之间，且与 d 夹角越小的特征向量的权重越大。最大特征值确定最大二", "keywords": "方向二阶导数是所有特征值的加权平均, 之间, 于其他的方向, 最大特征值确定最大二, 夹角越小的特征向量的权重越大", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b58abdc1-3271-4a4a-80b0-559833bc5d26", "label": "摘要55", "info": "我们可以通过（方向）二阶导数预期一个梯度下降步骤能表现得多好。；我们在当前点 x (0) 处做函数f ( x )的近似二阶泰勒级数：", "keywords": "处做函数, 二阶导数预期一个梯度下降步骤能表现得多好, 我们可以通过, 方向, 我们在当前点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "bd95eaaf-0b80-4f20-b860-22ec50e6436f", "label": "摘要56", "info": "其中 g 是梯度， H 是 x (0) 点的Hessian。如果我们使用学习率  ，那么；新的点 x 将会是", "keywords": "是梯度, 其中, 将会是, 那么, 如果我们使用学习率", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "faba72bb-486f-4376-b068-25c59873f9ec", "label": "摘要57", "info": "。代入上述的近似，可得", "keywords": "代入上述的近似, 可得", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a980a3c4-4955-4a31-a3cf-96c3ea18f7d6", "label": "摘要58", "info": "其中有3项：函数的原始值、函数斜率导致的预期改善和函数曲率导致；的校正。当最后一项太大时，梯度下降实际上是可能向上移动的。当", "keywords": "函数斜率导致的预期改善和函数曲率导致, 其中有, 函数的原始值, 的校正, 当最后一项太大时", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "3e42208d-a7fa-4727-be92-d0cad4e1d678", "label": "摘要59", "info": "为零或负时，近似的泰勒级数表明增加   将永远使f下降。在；实践中，泰勒级数不会在   大的时候也保持准确，因此在这种情况下；为正时，通过计算可得，", "keywords": "为正时, 大的时候也保持准确, 因此在这种情况下, 通过计算可得, 下降", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "86da56e5-db8e-41f7-ab46-c28024917bec", "label": "摘要60", "info": "最坏的情况下， g 与  H  最大特征值λ  max  对应的特征向量对齐，则最优", "keywords": "最坏的情况下, 对应的特征向量对齐, 最大特征值, 则最优", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "44199f0f-a9a3-46d4-af39-b2fadf64155a", "label": "摘要61", "info": "步长是", "keywords": "步长是", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1f91323b-a3ed-4672-bf1d-d409b521eb3f", "label": "摘要62", "info": "。当我们要最小化的函数能用二次函数很好地近似的情", "keywords": "当我们要最小化的函数能用二次函数很好地近似的情", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "bb145d70-24a9-43ed-8a9e-5f3312d2e383", "label": "摘要63", "info": "况下，Hessian的特征值决定了学习率的量级。", "keywords": "况下, 的特征值决定了学习率的量级", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f00d5522-2695-40b4-bdc8-a332841745b2", "label": "摘要64", "info": "二阶导数还可以用于确定一个临界点是否是局部极大点、全局极小点或；鞍点。回想一下，在临界点处f ′( x )=0。而f ″( x )>0意味着f ′( x )会随着；我们移向右边而增加，移向左边而减小，也就是f ′( x -ε)<0和f ′( x +ε)>0", "keywords": "也就是, 全局极小点或, 会随着, 二阶导数还可以用于确定一个临界点是否是局部极大点, 鞍点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "16b1e1ef-2c5a-4ef2-b1dc-2c155af390c0", "label": "摘要65", "info": "论，当f ′( x )=0且f ″( x )>0时， x 是一个全局极小点。同理，当f ′( x )=0；且f  ″(  x  )<0时，  x  是一个局部极大点。这就是所谓的二阶导数测试；（second  derivative  test）。不幸的是，当f  ″(  x  )=0时，测试是不确定", "keywords": "同理, 测试是不确定, 这就是所谓的二阶导数测试, 是一个全局极小点, 不幸的是", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "09916e7c-6a1c-448e-8196-859ff370f148", "label": "摘要66", "info": "在多维情况下，我们需要检测函数的所有二阶导数。利用Hessian的特征；值分解，我们可以将二阶导数测试扩展到多维情况。在临界点处", "keywords": "我们可以将二阶导数测试扩展到多维情况, 的特征, 在多维情况下, 我们需要检测函数的所有二阶导数, 值分解", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "937cdc5a-8dfa-4da5-b053-dca876bf8f42", "label": "摘要67", "info": "，我们通过检测Hessian的特征值来判断该临界点是；一个局部极大点、全局极小点还是鞍点。当Hessian是正定的（所有特征；值都是正的），则该临界点是全局极小点。因为方向二阶导数在任意方", "keywords": "则该临界点是全局极小点, 因为方向二阶导数在任意方, 的特征值来判断该临界点是, 是正定的, 全局极小点还是鞍点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "7af5cd91-25cc-48d3-9fd7-e743aa71342b", "label": "摘要68", "info": "图4.5　既有正曲率又有负曲率的鞍点。示例中的函数是；上弯曲。x 1 轴是Hessian的一个特征向量，并且具有正特征值。函数沿x 2 轴向下弯曲。该方向；对应于Hessian负特征值的特征向量。名称“鞍点”源自该处函数的鞍状形状。这是具有鞍点函数", "keywords": "并且具有正特征值, 这是具有鞍点函数, 鞍点, 函数沿, 既有正曲率又有负曲率的鞍点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5478e927-35eb-47fd-a0d1-b0a1ea46e4f6", "label": "摘要69", "info": "。函数沿x 1 轴向", "keywords": "轴向, 函数沿", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c8701475-f24e-4ef0-a970-6064795f5a65", "label": "摘要70", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；个横截面内是全局极小点", "keywords": "个横截面内是全局极小点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "08ff49a7-1727-4f62-a1bd-919c182218d8", "label": "摘要71", "info": "多维情况下，单个点处每个方向上的二阶导数是不同的。Hessian的条件；数衡量这些二阶导数的变化范围。当Hessian的条件数很差时，梯度下降；法也会表现得很差。这是因为一个方向上的导数增加得很快，而在另一", "keywords": "的条件数很差时, 的条件, 单个点处每个方向上的二阶导数是不同的, 数衡量这些二阶导数的变化范围, 多维情况下", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5073053f-6c64-4e3f-a9fe-f915d92a3846", "label": "摘要72", "info": "我们可以使用Hessian矩阵的信息来指导搜索，以解决这个问题。其中最；简单的方法是牛顿法  （Newton's  method）。牛顿法基于一个二阶泰勒；展开来近似 x (0) 附近的f( x )：", "keywords": "展开来近似, 我们可以使用, 以解决这个问题, 矩阵的信息来指导搜索, 附近的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "e0a71a71-9561-4f3b-ac99-7486bbc8d5a3", "label": "摘要73", "info": "接着通过计算，我们可以得到这个函数的临界点：", "keywords": "接着通过计算, 我们可以得到这个函数的临界点", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "e4d66724-8c5a-4152-82a9-ed0a5e068fbd", "label": "摘要74", "info": "如果f是一个正定二次函数，牛顿法只要应用一次式（4.12）就能直接跳；到函数的最小点。如果f不是一个真正二次但能在局部近似为正定二；次，牛顿法则需要多次迭代应用式（4.12）。迭代地更新近似函数和跳", "keywords": "如果, 迭代地更新近似函数和跳, 牛顿法只要应用一次式, 到函数的最小点, 不是一个真正二次但能在局部近似为正定二", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4f13b442-a14c-42ed-a8cf-863d72f2321e", "label": "摘要75", "info": "图4.6　梯度下降无法利用包含在Hessian矩阵中的曲率信息。这里我们使用梯度下降来最小化；Hessian矩阵条件数为5的二次函数f( x )。这意味着最大曲率方向具有比最小曲率方向多5倍的曲；率。在这种情况下，最大曲率在", "keywords": "矩阵条件数为, 梯度下降无法利用包含在, 矩阵中的曲率信息, 在这种情况下, 最大曲率在", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "fd707d3f-fc9b-4b3f-a36c-a76def73a1ea", "label": "摘要76", "info": "方向上，最小曲率在", "keywords": "方向上, 最小曲率在", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "8a1714ad-779f-4ca1-8475-0be308e51f79", "label": "摘要77", "info": "方向上。红线表示梯度", "keywords": "红线表示梯度, 方向上", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b57c760c-6ebf-4dd4-aa27-7c9a0d91115a", "label": "摘要78", "info": "仅使用梯度信息的优化算法称为一阶优化算法  （first-order  optimization；algorithms），如梯度下降。使用Hessian矩阵的优化算法称为二阶最优；化算法 （second-order optimization algo-rithms）（Nocedal and Wright，", "keywords": "矩阵的优化算法称为二阶最优, 化算法, 使用, 如梯度下降, 仅使用梯度信息的优化算法称为一阶优化算法", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "425c2459-3d1a-4739-a09a-2deaa27a7413", "label": "摘要79", "info": "本书大多数上下文中使用的优化算法适用于各种各样的函数，但几乎都；没有理论保证。因为在深度学习中使用的函数族是相当复杂的，所以深；度学习算法往往缺乏理论保证。在许多其他领域，优化的主要方法是为", "keywords": "但几乎都, 因为在深度学习中使用的函数族是相当复杂的, 没有理论保证, 本书大多数上下文中使用的优化算法适用于各种各样的函数, 在许多其他领域", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "161637f6-c237-4383-8206-69b3ba8f0913", "label": "摘要80", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；有限的函数族设计优化算法。", "keywords": "有限的函数族设计优化算法", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "265b2855-d6fa-48d7-97ae-5d9da3f6b88f", "label": "摘要81", "info": "在深度学习的背景下，限制函数满足Lipschitz连续；（Lipschitz；continuous）或其导数Lip-schitz连续可以获得一些保证。Lipschitz连续函", "keywords": "连续, 或其导数, 限制函数满足, 连续可以获得一些保证, 连续函", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "fbdf2186-9b6e-4f77-a90b-d896cb669bd7", "label": "摘要82", "info": "这个属性允许我们量化自己的假设——梯度下降等算法导致的输入的微；小变化将使输出只产生微小变化，因此是很有用的。Lipschitz连续性也；是相当弱的约束，并且深度学习中很多优化问题经过相对较小的修改后", "keywords": "并且深度学习中很多优化问题经过相对较小的修改后, 梯度下降等算法导致的输入的微, 连续性也, 这个属性允许我们量化自己的假设, 因此是很有用的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f56c9b14-ab82-40c7-a98b-ebc97e1b73f6", "label": "摘要83", "info": "最成功的特定优化领域或许是凸优化  （Convex  optimization）。凸优化；通过更强的限制提供更多的保证。凸优化算法只对凸函数适用，即；Hessian处处半正定的函数。因为这些函数没有鞍点而且其所有全局极小", "keywords": "处处半正定的函数, 通过更强的限制提供更多的保证, 最成功的特定优化领域或许是凸优化, 凸优化算法只对凸函数适用, 因为这些函数没有鞍点而且其所有全局极小", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a6a01c35-b7ec-4e2e-ac2b-bc6f74bd6de0", "label": "摘要84", "info": "4.3.1　梯度之上：；Jacobian和Hessian矩阵", "keywords": "矩阵, 梯度之上", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "label": "4.4：约束优化", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "40c515fa-8a35-404f-8a6d-9d7635e7aada", "label": "摘要1", "info": "有时候，在  x  的所有可能值下最大化或最小化一个函数f(x)不是我们所；希望的。相反，我们可能希望在  x  的某些集合   中找f(  x  )的最大值或；最小值。这称为约束优化  （constrained  optimization）。在约束优化术", "keywords": "的某些集合, 这称为约束优化, 在约束优化术, 我们可能希望在, 最小值", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "356ec497-bf93-4f22-97d9-b42e7e5837f8", "label": "摘要2", "info": "我们常常希望找到在某种意义上小的解。针对这种情况下的常见方法是；。；强加一个范数约束，如", "keywords": "针对这种情况下的常见方法是, 强加一个范数约束, 我们常常希望找到在某种意义上小的解", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "602dffeb-ff1e-41cf-b8e7-488bba93594e", "label": "摘要3", "info": "约束优化的一个简单方法是将约束考虑在内后简单地对梯度下降进行修；改。如果使用一个小的恒定步长   ，我们可以先取梯度下降的单步结；果，然后将结果投影回   。如果使用线搜索，我们只能在步长为   范", "keywords": "如果使用线搜索, 我们可以先取梯度下降的单步结, 我们只能在步长为, 然后将结果投影回, 约束优化的一个简单方法是将约束考虑在内后简单地对梯度下降进行修", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "217a36b1-e5f1-49fd-8fcd-dec995ae8643", "label": "摘要4", "info": "围内搜索可行的新 x  点，或者可以将线上的每个点投影到约束区域。如；果可能，在梯度下降或线搜索前将梯度投影到可行域的切空间会更高效；（Rosen，1960）。", "keywords": "或者可以将线上的每个点投影到约束区域, 围内搜索可行的新, 果可能, 在梯度下降或线搜索前将梯度投影到可行域的切空间会更高效", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "2e58764c-b1e2-4052-8da7-1be4a882b2d8", "label": "摘要5", "info": ")，其中", "keywords": "其中", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1867f03b-d5fc-425a-9785-99a92a3134de", "label": "摘要6", "info": "一个更复杂的方法是设计一个不同的、无约束的优化问题，其解可以转；中最小化f(  x；化成原始约束优化问题的解。例如，我们要在", "keywords": "一个更复杂的方法是设计一个不同的, 无约束的优化问题, 我们要在, 例如, 中最小化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "449b9638-2466-41cc-87c0-9d96611c5cc4", "label": "摘要7", "info": "Karush-Kuhn-Tucker （KKT）方法 (2) 是针对约束优化非常通用的解决；方案。为介绍KKT方法，我们引入一个称为广义Lagrangian；（generalized  Lagrangian）或广义Lagrange函数  （generalized  Lagrange", "keywords": "我们引入一个称为广义, 函数, 或广义, 是针对约束优化非常通用的解决, 方案", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c9333f27-8aab-4de0-88a6-141bd72127d0", "label": "摘要8", "info": "为了定义Lagrangian，我们先要通过等式和不等式的形式描述   。我们；(j)  描述   ，那么   可以表示为；希望通过m个函数g", "keywords": "我们, 希望通过, 那么, 描述, 我们先要通过等式和不等式的形式描述", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "bdd65124-4f2f-4e97-b75b-bb0de7886f63", "label": "摘要9", "info": "(i)  和n个函数h", "keywords": "个函数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "759368ac-5ae4-4a5c-9b3d-64cc3d591cf0", "label": "摘要10", "info": "。其中涉及g", "keywords": "其中涉及", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "ce75f645-52ed-4da8-92a8-281bcc32b2c7", "label": "摘要11", "info": "的等式称为等式约束  （equality  constraint），涉及h  (j)  的不等式称为不；等式约束 （inequality constraint）。", "keywords": "的等式称为等式约束, 涉及, 的不等式称为不, 等式约束", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "89114c32-659b-4246-a135-a29158080cf5", "label": "摘要12", "info": "我们为每个约束引入新的变量λ  i  和α  j  ，这些新变量被称为KKT乘子。；广义Lagrangian可以定义为", "keywords": "我们为每个约束引入新的变量, 广义, 乘子, 这些新变量被称为, 可以定义为", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "515de9c0-e583-4d33-a9ce-5a41cc481236", "label": "摘要13", "info": "现在，我们可以通过优化无约束的广义Lagrangian解决约束最小化问；题。只要存在至少一个可行点且f( x )不允许取∞，那么", "keywords": "只要存在至少一个可行点且, 我们可以通过优化无约束的广义, 那么, 解决约束最小化问, 不允许取", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "d4cb0e1a-e48f-4b6a-9df9-3309544e2dd0", "label": "摘要14", "info": "与如下函数有相同的最优目标函数值和最优点集 x", "keywords": "与如下函数有相同的最优目标函数值和最优点集", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "08aee597-847a-48ab-9e08-73488406c3c1", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；这是因为当约束满足时，", "keywords": "这是因为当约束满足时", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "eb0ea772-12dd-4f6d-8a9b-e0733b1d7f8b", "label": "摘要16", "info": "而违反任意约束时，", "keywords": "而违反任意约束时", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1d64314f-c893-45ec-8a50-6bb42a281522", "label": "摘要17", "info": "这些性质保证不可行点不会是最佳的，并且可行点范围内的最优点不；变。", "keywords": "这些性质保证不可行点不会是最佳的, 并且可行点范围内的最优点不", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5866f5a1-104d-438b-9fff-139efc127d8c", "label": "摘要18", "info": "要解决约束最大化问题，我们可以构造−f(  x  )的广义Lagrange函数，从；而导致以下优化问题：", "keywords": "而导致以下优化问题, 函数, 的广义, 要解决约束最大化问题, 我们可以构造", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "eeded39a-6db7-4382-9760-0b4e86aedba9", "label": "摘要19", "info": "我们也可将其转换为在外层最大化的问题：", "keywords": "我们也可将其转换为在外层最大化的问题", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "88d2b5c0-acfc-424e-a809-559c666078ba", "label": "摘要20", "info": "等式约束对应项的符号并不重要，因为优化可以自由选择每个λ；号，我们可以随意将其定义为加法或减法。", "keywords": "因为优化可以自由选择每个, 我们可以随意将其定义为加法或减法, 等式约束对应项的符号并不重要", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1f64b106-e4d5-4796-a046-29e61fec4c75", "label": "摘要21", "info": "i  的符", "keywords": "的符", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "5dbee0cc-9cb2-4450-afab-86da245ec78b", "label": "摘要22", "info": "，我们就说说这个约束h  (i)  (；不等式约束特别有趣。如果；x  )是活跃  （active）的。如果约束不是活跃的，则有该约束的问题的解", "keywords": "是活跃, 如果, 如果约束不是活跃的, 不等式约束特别有趣, 我们就说说这个约束", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "78ef57c4-a331-4fb6-847a-afa4329d9d0c", "label": "摘要23", "info": "(i)", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a57bc292-3ffe-47ae-89d5-75c95201bc55", "label": "摘要24", "info": "中的α  i  =0。因此，我们", "keywords": "因此, 中的, 我们", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "27b442f8-969d-4a52-b6d6-806683a0bd11", "label": "摘要25", "info": "可以观察到在该解中", "keywords": "可以观察到在该解中", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "37953da2-654a-4be8-8827-1ef1fcfc9db3", "label": "摘要26", "info": "或", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4da87067-c54c-44fa-8c84-d66041e8e21e", "label": "摘要27", "info": "。换句话说，对于所有的；在收敛时必有一个是活跃的。为了获得", "keywords": "为了获得, 对于所有的, 换句话说, 在收敛时必有一个是活跃的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a73ef2c1-4a61-4295-a838-e382e10ed6ab", "label": "摘要28", "info": "关于这个想法的一些直观解释，我们可以说这个解是由不等式强加的边；界，我们必须通过对应的KKT乘子影响 x 的解，或者不等式对解没有影；响，我们则归零KKT乘子。", "keywords": "或者不等式对解没有影, 乘子影响, 的解, 乘子, 我们必须通过对应的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "d858538c-8744-47d1-a02f-50a8769d785b", "label": "摘要29", "info": "我们可以使用一组简单的性质来描述约束优化问题的最优点。这些性质；称为Karush-Kuhn-Tucker  （KKT）条件（Karush，1939；Kuhn  and；Tucker，1951）。这些是确定一个点是最优点的必要条件，但不一定是", "keywords": "称为, 这些是确定一个点是最优点的必要条件, 我们可以使用一组简单的性质来描述约束优化问题的最优点, 这些性质, 但不一定是", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "374fc1da-22bc-48fe-bdaa-e9aba9505402", "label": "摘要30", "info": "广义Lagrangian的梯度为零。；所有关于 x 和KKT乘子的约束都满足。；不等式约束显示的“互补松弛性”：", "keywords": "所有关于, 的梯度为零, 广义, 乘子的约束都满足, 不等式约束显示的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "425fcea2-8c27-4cb5-9508-cceff0739fb7", "label": "摘要31", "info": "。", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "6f1d357e-df79-4b1d-945d-c9968690a8b1", "label": "摘要32", "info": "有关KKT方法的详细信息，请参阅Nocedal and Wright（2006）。", "keywords": "有关, 请参阅, 方法的详细信息", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "label": "4.5：实例：线性最小二乘", "level": 2, "group": "chapter-4", "type": "子章節"}, {"id": "582e162d-2c4c-4fcf-90ac-ca1ad4d69b0c", "label": "摘要1", "info": "假设我们希望找到最小化下式的 x 值", "keywords": "假设我们希望找到最小化下式的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "693b4d2b-4402-4414-aeee-a5acf335724c", "label": "摘要2", "info": "存在专门的线性代数算法能够高效地解决这个问题，但是我们也可以探；索如何使用基于梯度的优化来解决这个问题，这可以作为这些技术是如；何工作的一个简单例子。", "keywords": "但是我们也可以探, 何工作的一个简单例子, 这可以作为这些技术是如, 索如何使用基于梯度的优化来解决这个问题, 存在专门的线性代数算法能够高效地解决这个问题", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "a4e12cce-6d60-4521-9226-e3e63524c149", "label": "摘要3", "info": "首先，我们计算梯度", "keywords": "首先, 我们计算梯度", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "3f29d764-0473-474f-8fc1-1f2c5953ee98", "label": "摘要4", "info": "然后，我们可以采用小的步长，并按照这个梯度下降，见算法4.1中的；详细信息。", "keywords": "我们可以采用小的步长, 并按照这个梯度下降, 见算法, 详细信息, 中的", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "32f566e1-a97a-4c83-b797-6c615ed41dba", "label": "摘要5", "info": "算法4.1  　从任意点", "keywords": "从任意点, 算法", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b007c0d7-4cfb-460f-bf6e-0a5f5abdb606", "label": "摘要6", "info": "x  开始，使用梯度下降关于", "keywords": "使用梯度下降关于, 开始", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "cf7bd105-bc37-4941-a800-831969a63293", "label": "摘要7", "info": "x  最小化", "keywords": "最小化", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b5e6f254-7810-4e09-af43-46328c8541df", "label": "摘要8", "info": "的算法。", "keywords": "的算法", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4ce4126d-2acd-4ab1-a1e6-c0f0b4ab199b", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；将步长（  ）和容差（δ）设为小的正数。", "keywords": "将步长, 和容差, 设为小的正数", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "e34a19ac-a9a4-4da5-a387-473a181ec656", "label": "摘要10", "info": "end while", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "c813f934-c9fb-4db9-a1e4-58fa7a61ee57", "label": "摘要11", "info": "我们也可以使用牛顿法解决这个问题。因为在这个情况下，真实函数是；二次的，牛顿法所用的二次近似是精确的，该算法会在一步后收敛到全；局最小点。", "keywords": "真实函数是, 局最小点, 二次的, 牛顿法所用的二次近似是精确的, 因为在这个情况下", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "8a43844c-67ab-4984-a90a-122a91b67ff2", "label": "摘要12", "info": "现在假设我们希望最小化同样的函数，但受；到这一点，我们引入Lagrangian", "keywords": "但受, 到这一点, 现在假设我们希望最小化同样的函数, 我们引入", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "2f97350a-bca1-4f9d-a338-a044fb386ce8", "label": "摘要13", "info": "的约束。要做", "keywords": "的约束, 要做", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "d29d0ada-4ad3-4c80-a3db-064d6ac5bae6", "label": "摘要14", "info": "现在，我们解决以下问题", "keywords": "现在, 我们解决以下问题", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4feda145-4379-4f35-aee8-dc3a96123d5b", "label": "摘要15", "info": "找到无约束最小二乘问；我们可以用Moore-Penrose伪逆：；题的最小范数解。如果这一点是可行的，那么这也是约束问题的解。否", "keywords": "题的最小范数解, 那么这也是约束问题的解, 找到无约束最小二乘问, 如果这一点是可行的, 伪逆", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "b405b6d2-9fd9-4035-bc2f-28424dccd390", "label": "摘要16", "info": "这就告诉我们，该解的形式将会是", "keywords": "这就告诉我们, 该解的形式将会是", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "6d0bf4cf-d756-4260-8134-433dddabc233", "label": "摘要17", "info": "λ的选择必须使结果服从约束。我们可以关于λ进行梯度上升找到这个；值。为了做到这一点，观察", "keywords": "进行梯度上升找到这个, 为了做到这一点, 的选择必须使结果服从约束, 观察, 我们可以关于", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "4a81a0d4-5670-42ec-a7c2-05c75b23ef65", "label": "摘要18", "info": "当 x 的范数超过1时，该导数是正的，所以为了跟随导数上坡并相对λ增；的惩罚系数增加了，求解；加Lagrangian，我们需要增加λ。因为", "keywords": "因为, 该导数是正的, 的范数超过, 所以为了跟随导数上坡并相对, 我们需要增加", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "71ef96b6-242b-46a9-bfb4-76be2eedf0cb", "label": "摘要19", "info": "本章总结了开发机器学习算法所需的数学基础。现在，我们已经为建立；和分析一些成熟的学习系统做好了准备。", "keywords": "本章总结了开发机器学习算法所需的数学基础, 我们已经为建立, 现在, 和分析一些成熟的学习系统做好了准备", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "34d9b2cd-6c21-4722-ba61-4984d5393d53", "label": "摘要20", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "8661101b-f304-48a2-80b1-030d9e5ab576", "label": "摘要21", "info": "(1)  译者注：与通常的条件数定义有所不同。", "keywords": "与通常的条件数定义有所不同, 译者注", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "bc201f14-7365-4f95-82f1-711a668e8589", "label": "摘要22", "info": "(2)  KKT方法是 Lagrange乘子法 （只允许等式约束）的推广。", "keywords": "乘子法, 方法是, 只允许等式约束, 的推广", "level": 3, "group": "chapter-4", "type": "段落"}, {"id": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "label": "第5章：机器学习基础", "level": 1, "group": "chapter-5", "type": "章節"}, {"id": "8a59087b-6c40-4544-a338-b8ff054ca094", "label": "4.5：实例：线性最小二乘", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "1afc5dd0-7231-471f-898e-163b66994977", "label": "摘要1", "info": "深度学习是机器学习的一个特定分支。我们要想充分理解深度学习，必；须对机器学习的基本原理有深刻的理解。本章将探讨贯穿本书其余部分；的一些机器学习的重要原理。我们建议新手读者或是希望更全面了解的", "keywords": "本章将探讨贯穿本书其余部分, 我们要想充分理解深度学习, 深度学习是机器学习的一个特定分支, 的一些机器学习的重要原理, 须对机器学习的基本原理有深刻的理解", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c3a3aa31-14f0-40eb-83a3-c2c95bad6358", "label": "摘要2", "info": "首先，我们将介绍学习算法的定义，并介绍一个简单的示例：线性回归；算法。接下来，我们会探讨拟合训练数据与寻找能够泛化到新数据的模；式存在哪些不同的挑战。大部分机器学习算法都有超参数（必须在学习", "keywords": "接下来, 算法, 我们将介绍学习算法的定义, 我们会探讨拟合训练数据与寻找能够泛化到新数据的模, 并介绍一个简单的示例", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3fa3bbee-7bb6-4e7e-ad0e-9bd48b2d41ac", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；法。最后在第5.11节，我们会介绍一些限制传统机器学习泛化能力的因；素。这些挑战促进了解决这些问题的深度学习算法的发展。", "keywords": "我们会介绍一些限制传统机器学习泛化能力的因, 最后在第, 这些挑战促进了解决这些问题的深度学习算法的发展", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "label": "5.1：学习算法", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "1feea8c2-86c9-40e0-8238-512b9f838ac3", "label": "摘要1", "info": "5.1.1　任务T", "keywords": "任务", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "93b6049a-11ff-4324-83d6-677e1796fdd8", "label": "摘要2", "info": "5.1.2　性能度量P", "keywords": "性能度量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "aea5fa9b-c0c3-496c-89c6-e49e60301e5f", "label": "摘要3", "info": "5.1.3　经验E", "keywords": "经验", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3443ce02-2fbc-4bbc-ad9a-f1791975236e", "label": "摘要4", "info": "5.1.4　示例：线性回归", "keywords": "示例, 线性回归", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "788ed1da-9177-46bc-b235-2875a9416199", "label": "摘要5", "info": "机器学习算法是一种能够从数据中学习的算法。然而，我们所谓的“学；习”是什么意思呢？Mitchell（1997）提供了一个简洁的定义：“对于某；类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是", "keywords": "一个计算机程序被认为可以从经验, 是什么意思呢, 和性能度量, 提供了一个简洁的定义, 然而", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e7b62fab-bdd9-4bbc-822b-67276c539a04", "label": "摘要6", "info": "5.1.1　任务T", "keywords": "任务", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f8ca9504-40a2-4069-808b-72fc72c8084b", "label": "摘要7", "info": "机器学习可以让我们解决一些人为设计和使用确定性程序很难解决的问；题。从科学和哲学的角度来看，机器学习之所以受到关注，是因为提高；我们对机器学习的认识需要提高我们自身对智能背后原理的理解。", "keywords": "机器学习可以让我们解决一些人为设计和使用确定性程序很难解决的问, 我们对机器学习的认识需要提高我们自身对智能背后原理的理解, 是因为提高, 机器学习之所以受到关注, 从科学和哲学的角度来看", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cccf52d2-d168-419a-8ef1-23b770ea2023", "label": "摘要8", "info": "从“任务”的相对正式的定义上说，学习过程本身不能算是任务。学习是；我们所谓的获取完成任务的能力。例如，我们的目标是使机器人能够行；走，那么行走便是任务。我们可以编程让机器人学会如何行走，或者可", "keywords": "任务, 我们可以编程让机器人学会如何行走, 我们的目标是使机器人能够行, 学习是, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8e062e79-0bf6-4f0b-ad18-43e9f9b5f605", "label": "摘要9", "info": "通常机器学习任务定义为机器学习系统应该如何处理样本；（example）。样本是指我们从某些希望机器学习系统处理的对象或事；件中收集到的已经量化的特征 （feature）的集合。我们通常会将样本表", "keywords": "件中收集到的已经量化的特征, 通常机器学习任务定义为机器学习系统应该如何处理样本, 的集合, 我们通常会将样本表, 样本是指我们从某些希望机器学习系统处理的对象或事", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1240be14-7d74-4b63-ab6d-8ed633635997", "label": "摘要10", "info": "机器学习可以解决很多类型的任务。一些非常常见的机器学习任务列举；如下。", "keywords": "如下, 一些非常常见的机器学习任务列举, 机器学习可以解决很多类型的任务", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0a138425-8d4d-411c-8690-84472bd6c735", "label": "摘要11", "info": "分类：  在这类任务中，计算机程序需要指定某些输入属于k类中的；哪一类。为了完成这个任务，学习算法通常会返回一个函数", "keywords": "在这类任务中, 学习算法通常会返回一个函数, 类中的, 计算机程序需要指定某些输入属于, 为了完成这个任务", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "37231f52-4095-475e-924a-19955f6a3a8b", "label": "摘要12", "info": "。当y=f( x )时，模型将向量 x 所代表", "keywords": "模型将向量, 所代表", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a1524643-8f93-4231-8691-ac7bd6a32076", "label": "摘要13", "info": "的输入分类到数字码y所代表的类别。还有一些其他的分类问题，；例如，f输出的是不同类别的概率分布。分类任务中有一个任务是；对象识别，其中输入是图片（通常由一组像素亮度值表示），输出", "keywords": "输出的是不同类别的概率分布, 通常由一组像素亮度值表示, 其中输入是图片, 对象识别, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "77472101-4086-4ce9-baa9-672429479645", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的编码。深度学习是现代语音识别系统的重要组成部分，被各大公；司广泛使用，包括微软、IBM和谷歌（Hinton et al. ，2012b）。", "keywords": "深度学习是现代语音识别系统的重要组成部分, 的编码, 包括微软, 和谷歌, 被各大公", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6c9aad24-efe9-48e1-a547-0d01c0e42572", "label": "摘要15", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6d5e16ab-21b3-4a5f-8140-67f4bed9b5fc", "label": "摘要16", "info": "去噪：", "keywords": "去噪", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "61ec6945-33af-4320-8cd4-f7a83250bae0", "label": "摘要17", "info": "经过未知损坏过程后得到的损坏样本", "keywords": "经过未知损坏过程后得到的损坏样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9760e559-c4f5-40e7-9e71-130bdd10c120", "label": "摘要18", "info": "入并非只有一个正确输出的条件，并且我们明确希望输出有很多变；化，这可以使结果看上去更加自然和真实。；缺失值填补：", "keywords": "入并非只有一个正确输出的条件, 缺失值填补, 并且我们明确希望输出有很多变, 这可以使结果看上去更加自然和真实", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6a5e4110-137a-4bc0-b8c5-d036dea600b9", "label": "摘要19", "info": "在这类任务中，机器学习算法给定一个新样本；， x 中某些元素x i 缺失。算法必须填补这些缺失值。；在这类任务中，机器学习算法的输入是，干净样本", "keywords": "在这类任务中, 机器学习算法的输入是, 算法必须填补这些缺失值, 缺失, 机器学习算法给定一个新样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0da45cc6-d92f-4e25-ad0c-4efbd7bb96c5", "label": "摘要20", "info": "当然，还有很多其他同类型或其他类型的任务。这里我们列举的任务类；型只是用来介绍机器学习可以做哪些任务，并非严格地定义机器学习任；务分类。", "keywords": "并非严格地定义机器学习任, 型只是用来介绍机器学习可以做哪些任务, 还有很多其他同类型或其他类型的任务, 这里我们列举的任务类, 当然", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0245a122-c396-495c-b048-fa2aaf09b73d", "label": "摘要21", "info": "5.1.2　性能度量P", "keywords": "性能度量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "04d5866c-0cd0-4e15-bba7-0ae5755fe195", "label": "摘要22", "info": "为了评估机器学习算法的能力，我们必须设计其性能的定量度量。通常；性能度量P是特定于系统执行的任务T而言的。", "keywords": "通常, 性能度量, 是特定于系统执行的任务, 为了评估机器学习算法的能力, 而言的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1ca0317f-ffda-4ca8-9fdd-75ce698ec5a3", "label": "摘要23", "info": "对于诸如分类、缺失输入分类和转录任务，我们通常度量模型的准确率；（accuracy）。准确率是指该模型输出正确结果的样本比率。我们也可；以通过错误率  （errorrate）得到相同的信息。错误率是指该模型输出错", "keywords": "缺失输入分类和转录任务, 准确率是指该模型输出正确结果的样本比率, 得到相同的信息, 我们通常度量模型的准确率, 我们也可", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "978d12e3-f4ee-42c3-99b8-e60efb95e2e7", "label": "摘要24", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；误结果的样本比率。我们通常把错误率称为0−1损失的期望。在一个特；定的样本上，如果结果是对的，那么0−1损失是0；否则是1。但是对于", "keywords": "定的样本上, 但是对于, 如果结果是对的, 那么, 误结果的样本比率", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4ddcd579-1614-4fdb-8104-8bd1f91136fd", "label": "摘要25", "info": "通常，我们会更加关注机器学习算法在未观测数据上的性能如何，因为；这将决定其在实际应用中的性能。因此，我们使用测试集 （test set）数；据来评估系统性能，将其与训练机器学习系统的训练集数据分开。", "keywords": "因为, 通常, 据来评估系统性能, 我们会更加关注机器学习算法在未观测数据上的性能如何, 因此", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b991137f-be6c-4e0b-8d9a-287ef5b0a0cf", "label": "摘要26", "info": "性能度量的选择或许看上去简单且客观，但是选择一个与系统理想表现；对应的性能度量通常是很难的。", "keywords": "对应的性能度量通常是很难的, 但是选择一个与系统理想表现, 性能度量的选择或许看上去简单且客观", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4bf774f4-ea2a-4bb9-a3ef-b080db921b95", "label": "摘要27", "info": "在某些情况下，这是因为很难确定应该度量什么。例如，在执行转录任；务时，我们是应该度量系统转录整个序列的准确率，还是应该用一个更；细粒度的指标，对序列中正确的部分元素以正面评价？在执行回归任务", "keywords": "这是因为很难确定应该度量什么, 在执行转录任, 细粒度的指标, 例如, 我们是应该度量系统转录整个序列的准确率", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "60307d4d-ea40-4766-899e-80d17ee61123", "label": "摘要28", "info": "还有一些情况，我们知道应该度量哪些数值，但是度量它们不太现实。；这种情况经常出现在密度估计中。很多最好的概率模型只能隐式地表示；概率分布。在许多这类模型中，计算空间中特定点的概率是不可行的。", "keywords": "在许多这类模型中, 很多最好的概率模型只能隐式地表示, 我们知道应该度量哪些数值, 还有一些情况, 概率分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b7a3718a-3cea-4fea-a522-4d439c31c0b8", "label": "摘要29", "info": "5.1.3　经验E", "keywords": "经验", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a8a83afd-8d65-439b-8cbf-e6747627e842", "label": "摘要30", "info": "根据学习过程中的不同经验，机器学习算法可以大致分类为无监督；（unsupervised）算法和监督 （supervised）算法。", "keywords": "算法和监督, 机器学习算法可以大致分类为无监督, 根据学习过程中的不同经验, 算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8e3b20c2-fb8d-4ec6-ae9c-7fa4165fffb9", "label": "摘要31", "info": "本书中的大部分学习算法可以被理解为在整个数据集 （dataset）上获取；经验。数据集是指很多样本组成的集合，如第5.1.1节所定义的。有时我；们也将样本称为数据点 （data point）。", "keywords": "们也将样本称为数据点, 有时我, 上获取, 经验, 数据集是指很多样本组成的集合", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d8afde95-765f-44d5-8e38-3eea329eaf52", "label": "摘要32", "info": "Iris（鸢尾花卉）数据集（Fisher，1936）是统计学家和机器学习研究者；使用了很久的数据集。它是150个鸢尾花卉植物不同部分测量结果的集", "keywords": "使用了很久的数据集, 鸢尾花卉, 是统计学家和机器学习研究者, 个鸢尾花卉植物不同部分测量结果的集, 数据集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "74043dc8-4707-40e7-b9d7-66a338c58002", "label": "摘要33", "info": "合。每个单独的植物对应一个样本。每个样本的特征是该植物不同部分；的测量结果：萼片长度、萼片宽度、花瓣长度和花瓣宽度。这个数据集；也记录了每个植物属于什么品种，其中共有3个不同的品种。", "keywords": "个不同的品种, 萼片长度, 每个样本的特征是该植物不同部分, 这个数据集, 也记录了每个植物属于什么品种", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4f72fb26-4253-4e22-8ac1-07ef61a6c8c5", "label": "摘要34", "info": "无监督学习算法  （unsupervised  learning  algorithm）训练含有很多特征；的数据集，然后学习出这个数据集上有用的结构性质。在深度学习中，；我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，", "keywords": "然后学习出这个数据集上有用的结构性质, 比如密度估计, 我们通常要学习生成数据集的整个概率分布, 在深度学习中, 无监督学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e563bee3-7feb-48eb-9e05-b6dde06a256f", "label": "摘要35", "info": "监督学习算法  （supervised  learning  algorithm）训练含有很多特征的数；据集，不过数据集中的样本都有一个标签  （label）或目标  （target）。；例如，Iris数据集注明了每个鸢尾花卉样本属于什么品种。监督学习算", "keywords": "数据集注明了每个鸢尾花卉样本属于什么品种, 不过数据集中的样本都有一个标签, 例如, 监督学习算, 或目标", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "25434239-daef-46d1-94d0-da1a946319f3", "label": "摘要36", "info": "大致说来，无监督学习涉及观察随机向量x  的好几个样本，试图显式或；隐式地学习出概率分布p（x  ），或者是该分布一些有意思的性质；而；监督学习包含观察随机向量x  及其相关联的值或向量y  ，然后从x  预测y", "keywords": "无监督学习涉及观察随机向量, 或者是该分布一些有意思的性质, 试图显式或, 隐式地学习出概率分布, 然后从", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d6db9e3d-12d2-4063-b9d0-4d584d8cc9bb", "label": "摘要37", "info": "无监督学习和监督学习不是严格定义的术语。它们之间界线通常是模糊；的。很多机器学习技术可以用于这两个任务。例如，概率的链式法则表；明对于随机向量", "keywords": "无监督学习和监督学习不是严格定义的术语, 它们之间界线通常是模糊, 例如, 很多机器学习技术可以用于这两个任务, 概率的链式法则表", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "67f19f78-cb31-412d-ae87-8e457e135015", "label": "摘要38", "info": "，联合分布可以分解成", "keywords": "联合分布可以分解成", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "48033914-f004-4b53-b64a-7d4c2540f41f", "label": "摘要39", "info": "该分解意味着我们可以将其拆分成n个监督学习问题，来解决表面上的；无监督学习p(  x  )。另外，我们求解监督学习问题p(y｜x  )时，也可以使；用传统的无监督学习策略学习联合分布p(x ,y)，然后推断", "keywords": "也可以使, 来解决表面上的, 然后推断, 我们求解监督学习问题, 用传统的无监督学习策略学习联合分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "aee31e0e-b18e-4997-b0f1-d2de9ba26bf0", "label": "摘要40", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；尽管无监督学习和监督学习并非完全没有交集的正式概念，它们确实有；助于粗略分类我们研究机器学习算法时遇到的问题。传统上，人们将回", "keywords": "它们确实有, 尽管无监督学习和监督学习并非完全没有交集的正式概念, 人们将回, 传统上, 助于粗略分类我们研究机器学习算法时遇到的问题", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b64cb134-ce48-46ee-877f-b9f0221726ca", "label": "摘要41", "info": "学习范式的其他变种也是有可能的。例如，半监督学习中，一些样本有；监督目标，但其他样本没有。在多实例学习中，样本的整个集合被标记；为含有或者不含有该类的样本，但是集合中单独的样本是没有标记的。", "keywords": "一些样本有, 学习范式的其他变种也是有可能的, 监督目标, 在多实例学习中, 为含有或者不含有该类的样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a793171a-2048-4038-ad94-68bb27994cc8", "label": "摘要42", "info": "有些机器学习算法并不是训练于一个固定的数据集上。例如，强化学习；（reinforcement learning）算法会和环境进行交互，所以学习系统和它的；训练过程会有反馈回路。这类算法超出了本书的范畴。请参考Sutton", "keywords": "算法会和环境进行交互, 请参考, 所以学习系统和它的, 这类算法超出了本书的范畴, 有些机器学习算法并不是训练于一个固定的数据集上", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9ad1bd48-5e02-42a7-b259-9a73cbe8fd7f", "label": "摘要43", "info": "大部分机器学习算法简单地训练于一个数据集上。数据集可以用很多不；同方式来表示。在所有的情况下，数据集都是样本的集合，而样本是特；征的集合。", "keywords": "征的集合, 数据集都是样本的集合, 数据集可以用很多不, 同方式来表示, 而样本是特", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "76330a8c-e37e-4f2f-ad19-f7b27d65c088", "label": "摘要44", "info": "表示数据集的常用方法是设计矩阵  （design  matrix）。设计矩阵的每一；行包含一个不同的样本。每一列对应不同的特征。例如，Iris数据集包；含150个样本，每个样本有4个特征。这意味着我们可以将该数据集表示", "keywords": "行包含一个不同的样本, 每一列对应不同的特征, 设计矩阵的每一, 数据集包, 个样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0ba42787-8a63-416f-8cc7-72d8bf4b8601", "label": "摘要45", "info": "当然，每一个样本都能表示成向量，并且这些向量的维度相同，才能将；一个数据集表示成设计矩阵。这一点并非永远可能。例如，你有不同宽；度和高度的照片的集合，那么不同的照片将会包含不同数量的像素。因", "keywords": "那么不同的照片将会包含不同数量的像素, 这一点并非永远可能, 你有不同宽, 例如, 每一个样本都能表示成向量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "837132dc-98fb-4094-88be-0f4e0592a30e", "label": "摘要46", "info": "在监督学习中，样本包含一个标签或目标和一组特征。例如，我们希望；使用学习算法从照片中识别对象。我们需要明确哪些对象会出现在每张；照片中。我们或许会用数字编码表示，如0表示人、1表示车、2表示猫", "keywords": "我们或许会用数字编码表示, 表示猫, 使用学习算法从照片中识别对象, 例如, 在监督学习中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "86e4c5b1-c476-4d99-9294-d261119dce33", "label": "摘要47", "info": "当然，有时标签可能不止一个数。例如，如果我们想要训练语音模型转；录整个句子，那么每个句子样本的标签是一个单词序列。", "keywords": "录整个句子, 例如, 那么每个句子样本的标签是一个单词序列, 有时标签可能不止一个数, 当然", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a858347c-2638-4654-896a-f68424440c76", "label": "摘要48", "info": "正如监督学习和无监督学习没有正式的定义，数据集或者经验也没有严；格的区分。这里介绍的结构涵盖了大多数情况，但始终有可能为新的应；用设计出新的结构。", "keywords": "正如监督学习和无监督学习没有正式的定义, 数据集或者经验也没有严, 这里介绍的结构涵盖了大多数情况, 但始终有可能为新的应, 用设计出新的结构", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "89701bc7-1405-41f7-a9f1-af89c06edd00", "label": "摘要49", "info": "5.1.4　示例：线性回归", "keywords": "示例, 线性回归", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e26be0d6-3228-4fef-8de0-c7c4a4987956", "label": "摘要50", "info": "我们将机器学习算法定义为：通过经验以提高计算机程序在某些任务上；性能的算法。这个定义有点抽象。为了使这个定义更具体点，我们展示；一个简单的机器学习示例：线性回归 （linear regression）。当我们介绍", "keywords": "为了使这个定义更具体点, 通过经验以提高计算机程序在某些任务上, 这个定义有点抽象, 我们展示, 性能的算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1da4db56-91e6-4190-9c28-cfd3677b1470", "label": "摘要51", "info": "顾名思义，线性回归解决回归问题。换言之，我们的目标是建立一个系；统，将向量；作为输出。线性", "keywords": "线性回归解决回归问题, 我们的目标是建立一个系, 将向量, 换言之, 作为输出", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bf6bc0a5-02e0-4c2b-90a0-029e0c995f09", "label": "摘要52", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9fc19783-28f1-4012-8320-b9a248d1078d", "label": "摘要53", "info": "是参数 （parameter）向量。", "keywords": "是参数, 向量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eecec0c5-7df3-4c00-b391-375366a356e3", "label": "摘要54", "info": "参数是控制系统行为的值。在这种情况下，w  i  是系数，会和特征x  i  相；乘之后全部相加起来。我们可以将 w 看作一组决定每个特征如何影响预；测的权重  （weight）。如果特征x  i  对应的权重w  i  是正的，那么特征的", "keywords": "那么特征的, 看作一组决定每个特征如何影响预, 参数是控制系统行为的值, 如果特征, 对应的权重", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c8fa9d94-8a68-4bef-ab7c-5b640bda0540", "label": "摘要55", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；对预测没有影响。", "keywords": "对预测没有影响", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "45520a25-95cb-455b-945c-dc4a316bcfb6", "label": "摘要56", "info": "因此，我们可以定义任务T：通过输出；来我们需要定义性能度量——P。", "keywords": "通过输出, 因此, 我们可以定义任务, 来我们需要定义性能度量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "507fe883-8b8d-4061-a1f1-dbf87f26091b", "label": "摘要57", "info": "预测y。接下", "keywords": "接下, 预测", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "dba99d3e-420f-418f-8060-6ca6b20a9197", "label": "摘要58", "info": "假设我们有m个输入样本组成的设计矩阵，不用它来训练模型，而是评；估模型性能如何。我们也有每个样本对应的正确值y组成的回归目标向；量。因为这个数据集只是用来评估性能，我们称之为测试集", "keywords": "我们也有每个样本对应的正确值, 我们称之为测试集, 估模型性能如何, 而是评, 不用它来训练模型", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "17b87aab-0206-45e0-a727-3b43e4809af2", "label": "摘要59", "info": "度量模型性能的一种方法是计算模型在测试集上的均方误差  （mean；squared  error）。如果；表示模型在测试集上的预测值，那么均方", "keywords": "如果, 表示模型在测试集上的预测值, 度量模型性能的一种方法是计算模型在测试集上的均方误差, 那么均方", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "378516e0-c839-4b7e-a0f7-b07b2610ab39", "label": "摘要60", "info": "直观上，当；看到", "keywords": "直观上, 看到", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "40fe57d0-3b4d-45f0-b31f-4758abd0d274", "label": "摘要61", "info": "时，我们会发现误差降为0。我们也可以", "keywords": "我们也可以, 我们会发现误差降为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f01f99d3-bc4d-4bd9-8b2c-e2759c48d361", "label": "摘要62", "info": "所以当预测值和目标值之间的欧几里得距离增加时，误差也会增加。", "keywords": "误差也会增加, 所以当预测值和目标值之间的欧几里得距离增加时", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4cb2a37d-a709-457b-9cef-ca8a061d30ff", "label": "摘要63", "info": "为了构建一个机器学习算法，我们需要设计一个算法，通过观察训练集；获得经验，减少MSE  test 以改进权重  w  。一种直观；方式（我们将在后续的第5.5.1节说明其合法性）是最小化训练集上的均", "keywords": "方式, 获得经验, 减少, 是最小化训练集上的均, 通过观察训练集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7e103ee8-fdcc-4ad3-9951-cfbb2c4ada75", "label": "摘要64", "info": "最小化MSE train ，我们可以简单地求解其导数为0的情况：", "keywords": "最小化, 的情况, 我们可以简单地求解其导数为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c24ad2b2-17b1-438b-aad5-a0e4646c4024", "label": "摘要65", "info": "通过式（5.12）给出解的系统方程被称为正规方程；equation）。计算式（5.12）构成了一个简单的机器学习算法。图5.1展；示了线性回归算法的使用示例。", "keywords": "给出解的系统方程被称为正规方程, 构成了一个简单的机器学习算法, 计算式, 示了线性回归算法的使用示例, 通过式", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7d7f6c8a-e3e7-4fdc-b62b-dca42a92e4ba", "label": "摘要66", "info": "（normal", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7669d313-5383-4d5a-a5a5-1d64c196ae24", "label": "摘要67", "info": "图5.1　一个线性回归问题，其中训练集包括10个数据点，每个数据点包含一个特征。因为只有；一个特征，权重向量 w 也只有一个要学习的参数w 1 。（左）我们可以观察到线性回归学习w 1；，从而使得直线y=w 1 x能够尽量接近穿过所有的训练点。（右）标注的点表示由正规方程学习", "keywords": "也只有一个要学习的参数, 因为只有, 从而使得直线, 权重向量, 个数据点", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6ed8613e-e1db-403b-8dab-08c37153741f", "label": "摘要68", "info": "值得注意的是，术语线性回归 （linear regression）通常用来指稍微复杂；一些，附加额外参数（截距项b）的模型。在这个模型中，", "keywords": "一些, 截距项, 通常用来指稍微复杂, 的模型, 值得注意的是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9d68abca-6838-4fe9-b31d-cf8adb9d10e2", "label": "摘要69", "info": "因此从参数到预测的映射仍是一个线性函数，而从特征到预测的映射是；一个仿射函数。如此扩展到仿射函数意味着模型预测的曲线仍然看起来；像是一条直线，只是这条直线没必要经过原点。除了通过添加偏置参数", "keywords": "一个仿射函数, 而从特征到预测的映射是, 只是这条直线没必要经过原点, 如此扩展到仿射函数意味着模型预测的曲线仍然看起来, 除了通过添加偏置参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2c297147-40b3-4fde-b2aa-78bfd39e5e9c", "label": "摘要70", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；b，我们还可以使用仅含权重的模型，但是 x 需要增加一项永远为1的元；素。对应于额外1的权重起到了偏置参数的作用。当我们在本书中提到", "keywords": "但是, 我们还可以使用仅含权重的模型, 的元, 对应于额外, 当我们在本书中提到", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "99e93cac-4df7-4c63-b187-f7b00d4d18a7", "label": "摘要71", "info": "截距项b通常被称为仿射变换的偏置  （bias）参数。这个术语的命名源；自该变换的输出在没有任何输入时会偏移b。它和统计偏差中指代统计；估计算法的某个量的期望估计偏离真实值的意思是不一样的。", "keywords": "参数, 截距项, 估计算法的某个量的期望估计偏离真实值的意思是不一样的, 通常被称为仿射变换的偏置, 自该变换的输出在没有任何输入时会偏移", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b15c80b2-bb25-4f2d-a886-61551ea2897e", "label": "摘要72", "info": "线性回归当然是一个极其简单且有局限的学习算法，但是它提供了一个；说明学习算法如何工作的例子。在接下来的章节中，我们将会介绍一些；设计学习算法的基本原则，并说明如何使用这些原则来构建更复杂的学", "keywords": "并说明如何使用这些原则来构建更复杂的学, 线性回归当然是一个极其简单且有局限的学习算法, 我们将会介绍一些, 说明学习算法如何工作的例子, 在接下来的章节中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b8e86b11-888f-4a3c-95f6-0b13e27645ee", "label": "摘要73", "info": "5.1.1　任务T", "keywords": "任务", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "62d1899b-5354-41d5-932a-a4ade215a393", "label": "摘要74", "info": "5.1.2　性能度量P", "keywords": "性能度量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "12dd54d4-9ba5-44bb-9b40-89e7d91869cb", "label": "摘要75", "info": "5.1.3　经验E", "keywords": "经验", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ca1f70b0-925e-4d3f-9c76-d775d5a79109", "label": "摘要76", "info": "5.1.4　示例：线性回归", "keywords": "示例, 线性回归", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "label": "5.2：容量、过拟合和欠拟合", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "c3f50562-6d2f-42e3-84b7-4ec18d880d52", "label": "摘要1", "info": "5.2.1　没有免费午餐定理", "keywords": "没有免费午餐定理", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7798d47d-aaa3-48cd-8d0c-6959ee7beefc", "label": "摘要2", "info": "5.2.2　正则化", "keywords": "正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "47e8bdac-d8fd-4501-b5f3-af6d9002719d", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；5.3　超参数和验证集", "keywords": "超参数和验证集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "468664b3-d8f0-4692-a469-5c3e7ab65211", "label": "摘要4", "info": "5.3.1　交叉验证", "keywords": "交叉验证", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b4f2768d-de82-4f37-b07c-040ca6703535", "label": "摘要5", "info": "机器学习的主要挑战是我们的算法必须能够在先前未观测到的新输入上；表现良好，而不只是在训练集上表现良好。在先前未观测到的输入上表；现良好的能力被称为泛化 （generaliza-tion）。", "keywords": "现良好的能力被称为泛化, 在先前未观测到的输入上表, 表现良好, 机器学习的主要挑战是我们的算法必须能够在先前未观测到的新输入上, 而不只是在训练集上表现良好", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "08b06164-2233-423f-a803-23c3bb9cf203", "label": "摘要6", "info": "通常情况下，训练机器学习模型时，我们可以使用某个训练集，在训练；集上计算一些被称为训练误差  （training  error）的度量误差，目标是降；低训练误差。到目前为止，我们讨论的是一个简单的优化问题。机器学", "keywords": "通常情况下, 目标是降, 我们讨论的是一个简单的优化问题, 低训练误差, 在训练", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1fc7d301-fa8f-431e-8499-e27bfed13d60", "label": "摘要7", "info": "通常，我们度量模型在训练集中分出来的测试集 （test set）样本上的性；能，来评估机器学习模型的泛化误差。", "keywords": "我们度量模型在训练集中分出来的测试集, 通常, 样本上的性, 来评估机器学习模型的泛化误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c1b4e672-f936-4637-a6b6-bb4aeb1e7f8c", "label": "摘要8", "info": "在我们的线性回归示例中，通过最小化训练误差来训练模型，", "keywords": "通过最小化训练误差来训练模型, 在我们的线性回归示例中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ae00c426-6d67-4ddc-a737-1702e78c97ab", "label": "摘要9", "info": "但是我们真正关注的是测试误差", "keywords": "但是我们真正关注的是测试误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8026c164-06bd-4e7d-85cd-4cc53e91bd76", "label": "摘要10", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d456c6c1-5691-4adb-a8b5-d96231882688", "label": "摘要11", "info": "当我们只能观测到训练集时，如何才能影响测试集的性能呢？统计学习；理论  （statistical  learning  theory）提供了一些答案。如果训练集和测试；集的数据是任意收集的，那么我们能够做的确实很有限。如果可以对训", "keywords": "当我们只能观测到训练集时, 集的数据是任意收集的, 如何才能影响测试集的性能呢, 理论, 提供了一些答案", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4bd06cbd-bfa8-4e91-9a31-1383592b19d3", "label": "摘要12", "info": "训练集和测试集数据通过数据集上被称为数据生成过程；（data；generating  process）的概率分布生成。通常，我们会做一系列被统称为", "keywords": "通常, 我们会做一系列被统称为, 训练集和测试集数据通过数据集上被称为数据生成过程, 的概率分布生成", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f7cd467c-d54e-4f09-b0d4-da3a43db9b8b", "label": "摘要13", "info": "我们能观察到训练误差和测试误差之间的直接联系是，随机模型训练误；差的期望和该模型测试误差的期望是一样的。假设我们有概率分布p（；x  ，y），从中重复采样生成训练集和测试集。对于某个固定的  w  ，训", "keywords": "假设我们有概率分布, 我们能观察到训练误差和测试误差之间的直接联系是, 差的期望和该模型测试误差的期望是一样的, 从中重复采样生成训练集和测试集, 对于某个固定的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "47715a69-3f3a-4382-a16a-af2bbc7bf7ee", "label": "摘要14", "info": "当然，在使用机器学习算法时，我们不会提前固定参数，然后采样得到；两个数据集。我们采样得到训练集，然后挑选参数去降低训练集误差，；然后采样得到测试集。在这个过程中，测试误差期望会大于或等于训练", "keywords": "然后采样得到测试集, 我们采样得到训练集, 在这个过程中, 测试误差期望会大于或等于训练, 然后采样得到", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c22ee86a-db2b-4868-9e90-611bd52f7bb4", "label": "摘要15", "info": "（1）降低训练误差。", "keywords": "降低训练误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f33efad2-360e-4565-b57a-8f1d417bb91b", "label": "摘要16", "info": "（2）缩小训练误差和测试误差的差距。", "keywords": "缩小训练误差和测试误差的差距", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3ede5480-773f-43fd-9f4b-339b375f89ef", "label": "摘要17", "info": "这两个因素对应机器学习的两个主要挑战：欠拟合  （underfitting）和过；拟合  （overfitting）。欠拟合是指模型不能在训练集上获得足够低的误；差，而过拟合是指训练误差和测试误差之间的差距太大。", "keywords": "这两个因素对应机器学习的两个主要挑战, 而过拟合是指训练误差和测试误差之间的差距太大, 和过, 欠拟合是指模型不能在训练集上获得足够低的误, 欠拟合", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5848f47b-20cc-4fe3-b8c4-f20a70683010", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；通过调整模型的容量  （capacity），我们可以控制模型是否偏向于过拟；合或者欠拟合。通俗来讲，模型的容量是指其拟合各种函数的能力。容", "keywords": "通过调整模型的容量, 模型的容量是指其拟合各种函数的能力, 我们可以控制模型是否偏向于过拟, 通俗来讲, 合或者欠拟合", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7f93c8a9-bb5c-422f-af87-4befd885dfa6", "label": "摘要19", "info": "一种控制训练算法容量的方法是选择假设空间 （hypothesis space），即；学习算法可以选择为解决方案的函数集。例如，线性回归函数将关于其；输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项", "keywords": "一种控制训练算法容量的方法是选择假设空间, 学习算法可以选择为解决方案的函数集, 线性回归函数将关于其, 例如, 广义线性回归的假设空间包括多项", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "81713b78-586a-4e5a-b2da-70302a00f837", "label": "摘要20", "info": "一次多项式提供了我们已经熟悉的线性回归模型，其预测如下", "keywords": "其预测如下, 一次多项式提供了我们已经熟悉的线性回归模型", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "79685f38-9c39-4514-b9d1-4398f3702184", "label": "摘要21", "info": "通过引入x  2  作为线性回归模型的另一个特征，我们能够学习关于x的二；次函数模型：", "keywords": "作为线性回归模型的另一个特征, 我们能够学习关于, 的二, 通过引入, 次函数模型", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0177ffda-342b-4dee-96d6-095a9ed8e5c6", "label": "摘要22", "info": "尽管该模型是输入的二次函数，但输出仍是参数的线性函数，因此我们；仍然可以用正规方程得到模型的闭解。我们可以继续添加x的更高幂作；为额外特征，例如下面的9次多项式：", "keywords": "为额外特征, 因此我们, 仍然可以用正规方程得到模型的闭解, 次多项式, 例如下面的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ef6327b4-e728-4a5c-b1cf-b3cb811eb274", "label": "摘要23", "info": "当机器学习算法的容量适合于所执行任务的复杂度和所提供训练数据的；数量时，算法效果通常会最佳。容量不足的模型不能解决复杂任务。容；量高的模型能够解决复杂的任务，但是当其容量高于任务所需时，有可", "keywords": "容量不足的模型不能解决复杂任务, 有可, 算法效果通常会最佳, 当机器学习算法的容量适合于所执行任务的复杂度和所提供训练数据的, 数量时", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "397d96e6-e8a5-4daf-8f56-29d609be3fad", "label": "摘要24", "info": "图5.2展示了这个原理的使用情况。我们比较了线性、二次和9次预测器；拟合真实二次函数的效果。线性函数无法刻画真实函数的曲率，所以欠；拟合。9次函数能够表示正确的函数，但是因为训练参数比训练样本还", "keywords": "展示了这个原理的使用情况, 所以欠, 次预测器, 但是因为训练参数比训练样本还, 二次和", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6c805dd9-4814-44e8-b88f-4348a46bd187", "label": "摘要25", "info": "据上。", "keywords": "据上", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "99a7c393-36e9-466d-b26e-2a4217681ede", "label": "摘要26", "info": "图5.2　我们用3个模型拟合了这个训练集的样本。训练数据是通过随机抽取x然后用二次函数确；定性地生成y来合成的。（左）用一个线性函数拟合数据会导致欠拟合——它无法捕捉数据中的；曲率信息。（中）用二次函数拟合数据在未观察到的点上泛化得很好，这并不会导致明显的欠", "keywords": "来合成的, 这并不会导致明显的欠, 用一个线性函数拟合数据会导致欠拟合, 它无法捕捉数据中的, 个模型拟合了这个训练集的样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d249caf9-a206-425f-9e8e-96e178242afc", "label": "摘要27", "info": "到目前为止，我们探讨了通过改变输入特征的数目和加入这些特征对应；的参数，改变模型的容量。事实上，还有很多方法可以改变模型的容；量。容量不仅取决于模型的选择。模型规定了调整参数降低训练目标", "keywords": "改变模型的容量, 的参数, 事实上, 我们探讨了通过改变输入特征的数目和加入这些特征对应, 到目前为止", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1c57669e-6cf9-40f3-b06e-72050f048e9f", "label": "摘要28", "info": "提高机器学习模型泛化的现代思想可以追溯到早在托勒密时期的哲学家；的思想。许多早期的学者提出一个简约原则，现在广泛被称为奥卡姆剃；刀  （Occam's  razor）（c．1287-1387）。该原则指出，在同样能够解释", "keywords": "的思想, 现在广泛被称为奥卡姆剃, 该原则指出, 提高机器学习模型泛化的现代思想可以追溯到早在托勒密时期的哲学家, 许多早期的学者提出一个简约原则", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "29e1b47c-aed7-4f33-b793-0cc009275328", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；统计学习理论提供了量化模型容量的不同方法。在这些方法中，最有名；的是Vapnik-Chervonenkis维度  （Vapnik-Chervonenkis", "keywords": "的是, 最有名, 在这些方法中, 维度, 统计学习理论提供了量化模型容量的不同方法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "744ab4df-7d6b-408f-a2c8-b64532a8b99d", "label": "摘要30", "info": "量化模型的容量使得统计学习理论可以进行量化预测。统计学习理论中；最重要的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量；增长而增长，但随着训练样本增多而下降（Vapnik  and  Chervonenkis，", "keywords": "统计学习理论中, 增长而增长, 最重要的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量, 量化模型的容量使得统计学习理论可以进行量化预测, 但随着训练样本增多而下降", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "79a93ccd-9f1c-499e-b661-ecc5c44d7da2", "label": "摘要31", "info": "我们必须记住虽然更简单的函数更可能泛化（训练误差和测试误差的差；距小），但我们仍然需要选择一个充分复杂的假设以达到低的训练误；差。通常，当模型容量上升时，训练误差会下降，直到其渐近最小可能", "keywords": "通常, 训练误差和测试误差的差, 训练误差会下降, 但我们仍然需要选择一个充分复杂的假设以达到低的训练误, 我们必须记住虽然更简单的函数更可能泛化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d79b8e3a-4d21-42ee-be2a-0588a9bae9e6", "label": "摘要32", "info": "图5.3　容量和误差之间的典型关系。训练误差和测试误差表现得非常不同。在图的左端，训练；误差和泛化误差都非常高，这是 欠拟合机制 （underfitting regime）。当我们增加容量时，训练；误差减小，但是训练误差和泛化误差之间的间距却不断扩大。最终，这个间距的大小超过了训", "keywords": "训练, 但是训练误差和泛化误差之间的间距却不断扩大, 误差和泛化误差都非常高, 这是, 欠拟合机制", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8b857748-994a-46d9-b333-17bf004f7814", "label": "摘要33", "info": "练误差的下降，我们进入到了 过拟合机制 （overfitting regime），其中容量过大，超过了 最优；容量 （optimal capacity）", "keywords": "最优, 练误差的下降, 超过了, 容量, 过拟合机制", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b5f2e9d1-fa0a-4b7c-b608-b8eb2890fe11", "label": "摘要34", "info": "为考虑容量任意高的极端情况，我们介绍非参数  （non-parametric）模；型的概念。至此，我们只探讨过参数模型，例如线性回归。参数模型学；习的函数在观测到新数据前，参数向量的分量个数是有限且固定的。非", "keywords": "我们介绍非参数, 参数向量的分量个数是有限且固定的, 习的函数在观测到新数据前, 我们只探讨过参数模型, 型的概念", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c42762f5-40f7-46a6-8f97-5e9d045d6001", "label": "摘要35", "info": "有时，非参数模型仅是一些不能实际实现的理论抽象（比如搜索所有可；能概率分布的算法）。然而，我们也可以设计一些实用的非参数模型，；使它们的复杂度和训练集大小有关。这种算法的一个示例是最近邻回归", "keywords": "我们也可以设计一些实用的非参数模型, 有时, 然而, 比如搜索所有可, 非参数模型仅是一些不能实际实现的理论抽象", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b7290eeb-9999-4b57-91eb-26d89ee623d6", "label": "摘要36", "info": "最后，我们也可以将参数学习算法嵌入另一个增加参数数目的算法来创；建非参数学习算法。例如，我们可以想象这样一个算法，外层循环调整；多项式的次数，内层循环通过线性回归学习模型。", "keywords": "我们可以想象这样一个算法, 多项式的次数, 建非参数学习算法, 例如, 内层循环通过线性回归学习模型", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ea6052b2-309e-46bf-be77-16a257746b91", "label": "摘要37", "info": "理想模型假设我们能够预先知道生成数据的真实概率分布。然而这样的；模型仍然会在很多问题上发生一些错误，因为分布中仍然会有一些噪；声。在监督学习中，从 x  到y的映射可能内在是随机的，或者y可能是其", "keywords": "可能是其, 的映射可能内在是随机的, 因为分布中仍然会有一些噪, 在监督学习中, 然而这样的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "09543f48-2e54-48d4-afe3-dc72bd9c4480", "label": "摘要38", "info": "训练误差和泛化误差会随训练集的大小发生变化。泛化误差的期望从不；会因训练样本数目的增加而增加。对于非参数模型而言，更多的数据会；得到更好的泛化能力，直到达到最佳可能的泛化误差。任何模型容量小", "keywords": "泛化误差的期望从不, 得到更好的泛化能力, 更多的数据会, 任何模型容量小, 直到达到最佳可能的泛化误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9b7cb458-cb97-4e02-9c47-9c13f6709817", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；和泛化误差之间存在很大的差距。在这种情况下，我们可以通过收集更；多的训练样本来缩小差距。", "keywords": "我们可以通过收集更, 和泛化误差之间存在很大的差距, 在这种情况下, 多的训练样本来缩小差距", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "111c7461-8ffd-43ca-8085-8648acde5415", "label": "摘要40", "info": "图5.4　训练集大小对训练误差、测试误差以及最优容量的影响。通过给一个5阶多项式添加适；当大小的噪声，我们构造了一个合成的回归问题，生成单个测试集，然后生成一些不同尺寸的；训练集。为了描述95％置信区间的误差条，对于每一个尺寸，我们生成了40个不同的训练集。", "keywords": "训练集, 置信区间的误差条, 我们生成了, 测试误差以及最优容量的影响, 当大小的噪声", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e5b02be6-2f77-4723-a4c2-a624551bc861", "label": "摘要41", "info": "5.2.1　没有免费午餐定理", "keywords": "没有免费午餐定理", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d5bc7827-e827-42f0-9036-7e2e29980d22", "label": "摘要42", "info": "学习理论表明机器学习算法能够在有限个训练集样本中很好地泛化。这；似乎违背一些基本的逻辑原则。归纳推理，或是从一组有限的样本中推", "keywords": "学习理论表明机器学习算法能够在有限个训练集样本中很好地泛化, 或是从一组有限的样本中推, 归纳推理, 似乎违背一些基本的逻辑原则", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0f143a28-eefb-4ab9-a071-400eb8dc4a52", "label": "摘要43", "info": "断一般的规则，在逻辑上不是很有效。为了逻辑地推断一个规则去描述；集合中的元素，我们必须具有集合中每个元素的信息。", "keywords": "断一般的规则, 集合中的元素, 为了逻辑地推断一个规则去描述, 在逻辑上不是很有效, 我们必须具有集合中每个元素的信息", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d29466a3-0e57-41ea-b446-e9b5bb5a3b54", "label": "摘要44", "info": "在一定程度上，机器学习仅通过概率法则就可以避免这个问题，而无须；使用纯逻辑推理整个确定性法则。机器学习保证找到一个在所关注的大；多数样本上可能正确的规则。", "keywords": "在一定程度上, 机器学习仅通过概率法则就可以避免这个问题, 多数样本上可能正确的规则, 使用纯逻辑推理整个确定性法则, 而无须", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e918ecb6-b230-41f6-aec7-3c53b3428c92", "label": "摘要45", "info": "可惜，即使这样也不能解决整个问题。机器学习的没有免费午餐定理；（no free lunch theorem）表明（Wolpert，1996），在所有可能的数据生；成分布上平均之后，每一个分类算法在未事先观测的点上都有相同的错", "keywords": "成分布上平均之后, 每一个分类算法在未事先观测的点上都有相同的错, 机器学习的没有免费午餐定理, 在所有可能的数据生, 表明", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "44bcb745-7e18-458b-9cdd-5a15bfef35a5", "label": "摘要46", "info": "幸运的是，这些结论仅在我们考虑所有可能的数据生成分布时才成立。；在真实世界应用中，如果我们对遇到的概率分布进行假设，那么可以设；计在这些分布上效果良好的学习算法。", "keywords": "在真实世界应用中, 幸运的是, 如果我们对遇到的概率分布进行假设, 那么可以设, 计在这些分布上效果良好的学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "af30dac6-bea4-4885-89f3-5b4533f02d5d", "label": "摘要47", "info": "这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的；学习算法，而是理解什么样的分布与人工智能获取经验的“真实世界”相；关，以及什么样的学习算法在我们关注的数据生成分布上效果最好。", "keywords": "这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的, 真实世界, 学习算法, 以及什么样的学习算法在我们关注的数据生成分布上效果最好, 而是理解什么样的分布与人工智能获取经验的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b2af6275-814d-4ae2-aab1-ab7bc60b353e", "label": "摘要48", "info": "5.2.2　正则化", "keywords": "正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5ab3dd5b-36bd-4bb6-9b4a-f579114bca19", "label": "摘要49", "info": "没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习；算法。我们建立一组学习算法的偏好来达到这个要求。当这些偏好和我；们希望算法解决的学习问题相吻合时，性能会更好。", "keywords": "算法, 当这些偏好和我, 们希望算法解决的学习问题相吻合时, 没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习, 我们建立一组学习算法的偏好来达到这个要求", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b054d260-8f76-4439-8b59-6c9d2c8b905a", "label": "摘要50", "info": "至此，我们具体讨论修改学习算法的方法，只有通过增加或减少学习算；法可选假设空间的函数来增加或减少模型的容量。所列举的一个具体示；例是线性回归增加或减少多项式的次数。到目前为止讨论的观点都是过", "keywords": "我们具体讨论修改学习算法的方法, 到目前为止讨论的观点都是过, 只有通过增加或减少学习算, 法可选假设空间的函数来增加或减少模型的容量, 所列举的一个具体示", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a1db578f-57a8-4398-ab6f-9cbc5aaef3bc", "label": "摘要51", "info": "算法的效果不仅很大程度上受影响于假设空间的函数数量，也取决于这；些函数的具体形式。我们已经讨论的学习算法（线性回归）具有包含其；输入的线性函数集的假设空间。对于输入和输出确实接近线性相关的问", "keywords": "我们已经讨论的学习算法, 输入的线性函数集的假设空间, 具有包含其, 些函数的具体形式, 也取决于这", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3df19a52-316f-477b-8674-c6b19a04de68", "label": "摘要52", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；例如，我们用线性回归，从x预测sin(x)，效果不会好。因此我们可以通；过两种方式控制算法的性能，一是允许使用的函数种类，二是这些函数", "keywords": "过两种方式控制算法的性能, 因此我们可以通, 例如, 我们用线性回归, 二是这些函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f38a7929-96b0-4285-b704-0cad731d7d35", "label": "摘要53", "info": "在假设空间中，相比于某一个学习算法，我们可能更偏好另一个学习算；法。这意味着两个函数都是符合条件的，但是我们更偏好其中一个。只；有非偏好函数比偏好函数在训练数据集上效果明显好很多时，我们才会", "keywords": "有非偏好函数比偏好函数在训练数据集上效果明显好很多时, 但是我们更偏好其中一个, 我们可能更偏好另一个学习算, 这意味着两个函数都是符合条件的, 我们才会", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "00c31610-60bf-47ed-9bd3-e26fe6f617fe", "label": "摘要54", "info": "例如，可以加入权重衰减  （weight  decay）来修改线性回归的训练标；准。带权重衰减的线性回归最小化训练集上的均方误差和正则项的和；J（ w ），其偏好于平方L 2 范数较小的权重。具体如下", "keywords": "具体如下, 其偏好于平方, 范数较小的权重, 可以加入权重衰减, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cfad2660-d6aa-4e0a-9549-1c6d45e14fcf", "label": "摘要55", "info": "其中λ是提前挑选的值，控制我们偏好小范数权重的程度。当λ=0时，我；们没有任何偏好。越大的λ偏好范数越小的权重。最小化J（ w ）可以看；作拟合训练数据和偏好小权重范数之间的权衡。这会使得解决方案的斜", "keywords": "们没有任何偏好, 作拟合训练数据和偏好小权重范数之间的权衡, 其中, 偏好范数越小的权重, 这会使得解决方案的斜", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1afef863-8343-49b9-901e-5a414d3d4602", "label": "摘要56", "info": "图5.5　我们使用高阶多项式回归模型来拟合图5.2中的训练样本。真实函数是二次的，但是在这；里只使用9阶多项式。我们通过改变权重衰减的量来避免高阶模型的过拟合问题。（左）当λ非；常大时，我们可以强迫模型学习到一个没有斜率的函数。由于它只能表示一个常数函数，所以", "keywords": "但是在这, 真实函数是二次的, 我们可以强迫模型学习到一个没有斜率的函数, 我们使用高阶多项式回归模型来拟合图, 我们通过改变权重衰减的量来避免高阶模型的过拟合问题", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d2a5ed11-9069-4e4f-887a-b251cbb9d836", "label": "摘要57", "info": "问题）时，这个9阶多项式会导致严重的过拟合，这和我们在图5.2中看到的一样", "keywords": "中看到的一样, 这和我们在图, 问题, 阶多项式会导致严重的过拟合, 这个", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "62886cfa-bf90-47a9-8d4b-3a1bc2122fb5", "label": "摘要58", "info": "更一般地，正则化一个学习函数 f（x；θ）  的模型，我们可以给代价函；数添加被称为正则化项  （regularizer）的惩罚。在权重衰减的例子中，；正则化是", "keywords": "我们可以给代价函, 更一般地, 的模型, 在权重衰减的例子中, 正则化是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a1227c3f-6ba9-487d-99e8-6c4294835842", "label": "摘要59", "info": "表示对函数的偏好是比增减假设空间的成员函数更一般地控制模型容量；的方法。我们可以将去掉假设空间中的某个函数看作对不赞成这个函数；的无限偏好。", "keywords": "的方法, 表示对函数的偏好是比增减假设空间的成员函数更一般地控制模型容量, 我们可以将去掉假设空间中的某个函数看作对不赞成这个函数, 的无限偏好", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cbe6d743-c055-41b5-b3b5-59cf91089600", "label": "摘要60", "info": "在权重衰减的示例中，通过在最小化的目标中额外增加一项，我们明确；地表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示；对不同解的偏好。总而言之，这些不同的方法都被称为正则化", "keywords": "总而言之, 地表示了偏好权重较小的线性函数, 对不同解的偏好, 在权重衰减的示例中, 有很多其他方法隐式或显式地表示", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7d317fc5-8820-42f2-8b3f-ad1f7231792f", "label": "摘要61", "info": "没有免费午餐定理已经清楚地阐述了没有最优的学习算法，特别是没有；最优的正则化形式。反之，我们必须挑选一个非常适合于我们所要解决；的任务的正则形式。深度学习中普遍的（特别是本书中的）理念是大量", "keywords": "的任务的正则形式, 深度学习中普遍的, 我们必须挑选一个非常适合于我们所要解决, 特别是没有, 没有免费午餐定理已经清楚地阐述了没有最优的学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6e04c4d1-fdd6-4a3f-88d1-faf73c2a57a7", "label": "摘要62", "info": "5.2.1　没有免费午餐定理", "keywords": "没有免费午餐定理", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c7c6cd32-0363-41fd-ae2a-8221cd621fd6", "label": "摘要63", "info": "5.2.2　正则化", "keywords": "正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "label": "5.3：超参数和验证集", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "9a3b4f2e-ffaa-484f-bbb5-c9c318574abe", "label": "摘要1", "info": "大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的；值不是通过学习算法本身学习出来的（尽管我们可以设计一个嵌套的学；习过程，一个学习算法为另一个学习算法学出最优超参数）。", "keywords": "可以设置来控制算法行为, 一个学习算法为另一个学习算法学出最优超参数, 超参数的, 大多数机器学习算法都有超参数, 尽管我们可以设计一个嵌套的学", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "17b85f71-2c3b-4800-aa0b-f602e73b19fa", "label": "摘要2", "info": "在图5.2所示的多项式回归示例中，有一个超参数，即多项式的次数，；作为容量 超参数。控制权重衰减程度的λ是另一个超参数。", "keywords": "在图, 即多项式的次数, 有一个超参数, 控制权重衰减程度的, 作为容量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "76c76ae6-8bdf-424e-bcb2-06b85e0db3bc", "label": "摘要3", "info": "有时一个选项被设为学习算法不用学习的超参数，是因为它太难优化；了。更多的情况是，该选项必须是超参数，因为它不适合在训练集上学；习。这适用于控制模型容量的所有超参数。如果在训练集上学习超参", "keywords": "是因为它太难优化, 该选项必须是超参数, 有时一个选项被设为学习算法不用学习的超参数, 这适用于控制模型容量的所有超参数, 因为它不适合在训练集上学", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f92104b0-9797-4dd9-be0e-1f74301eeabd", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；数，这些超参数总是趋向于最大可能的模型容量，导致过拟合（见图；5.3）。例如，相比低次多项式和正的权重衰减设定，更高次的多项式", "keywords": "更高次的多项式, 相比低次多项式和正的权重衰减设定, 例如, 见图, 这些超参数总是趋向于最大可能的模型容量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a6124eb4-7f73-4d75-8552-f0fc9041fe5d", "label": "摘要5", "info": "为了解决这个问题，我们需要一个训练算法观测不到的验证集；（validation set）样本。", "keywords": "为了解决这个问题, 我们需要一个训练算法观测不到的验证集, 样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ee967b76-2790-4152-89e1-a86fd5a53fc9", "label": "摘要6", "info": "早先我们讨论过和训练数据相同分布的样本组成的测试集，它可以用来；估计学习过程完成之后的学习器的泛化误差。其重点在于测试样本不能；以任何形式参与到模型的选择中，包括设定超参数。基于这个原因，测", "keywords": "基于这个原因, 以任何形式参与到模型的选择中, 它可以用来, 其重点在于测试样本不能, 估计学习过程完成之后的学习器的泛化误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7cc0283a-5d10-4853-9cf3-8a05d4e0c74b", "label": "摘要7", "info": "在实际中，当相同的测试集已在很多年中重复地用于评估不同算法的性；能，并且考虑学术界在该测试集上的各种尝试，我们最后可能也会对测；试集有着乐观的估计。基准会因之变得陈旧，而不能反映系统的真实性", "keywords": "在实际中, 我们最后可能也会对测, 基准会因之变得陈旧, 试集有着乐观的估计, 而不能反映系统的真实性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1ddca7a0-0bb0-4955-a7b5-76af9ae86b61", "label": "摘要8", "info": "5.3.1　交叉验证", "keywords": "交叉验证", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a3a419de-9afd-4a25-a7a0-be108a311cc7", "label": "摘要9", "info": "将数据集分成固定的训练集和固定的测试集后，若测试集的误差很小，；这将是有问题的。一个小规模的测试集意味着平均测试误差估计的统计；不确定性，使得很难判断算法A是否比算法B在给定的任务上做得更", "keywords": "不确定性, 若测试集的误差很小, 将数据集分成固定的训练集和固定的测试集后, 一个小规模的测试集意味着平均测试误差估计的统计, 是否比算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "51e12282-6afa-4c16-b555-e7dda8aee501", "label": "摘要10", "info": "当数据集有十万计或者更多的样本时，这不会是一个严重的问题。当数；据集太小时，也有替代方法允许我们使用所有的样本估计平均测试误；差，代价是增加了计算量。这些过程是基于在原始数据上随机采样或分", "keywords": "当数, 这不会是一个严重的问题, 这些过程是基于在原始数据上随机采样或分, 当数据集有十万计或者更多的样本时, 据集太小时", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c12d7451-6618-49b6-98f3-6c17e23ef34a", "label": "摘要11", "info": "离出的不同数据集上重复训练和测试的想法。最常见的是k-折交叉验证；过程，如算法5.1所示，将数据集分成k个不重合的子集。测试误差可以；估计为k次计算后的平均测试误差。在第i次测试时，数据的第i个子集用", "keywords": "个不重合的子集, 估计为, 最常见的是, 离出的不同数据集上重复训练和测试的想法, 折交叉验证", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e19dbb5e-eb99-4328-9b37-bdbcb92636bd", "label": "摘要12", "info": "算法5.1  　k-折交叉验证算法。当给定数据集   对于简单的训练/测试；或训练/验证分割而言太小难以产生泛化误差的准确估计时（因为在小；的测试集上，L可能具有过高的方差），k-折交叉验证算法可以用于估", "keywords": "折交叉验证算法可以用于估, 当给定数据集, 算法, 验证分割而言太小难以产生泛化误差的准确估计时, 对于简单的训练", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5d4f9523-9e94-4cf3-a5e3-8e0268006a73", "label": "摘要13", "info": "Define KFoldXV(", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "12832579-5e23-4b08-b52d-c3c249f876da", "label": "摘要14", "info": ",A,L,k)：", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6684f816-afff-449a-9344-95ee6907d20b", "label": "摘要15", "info": "Require：", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "11e4e5fc-ecf1-4c6c-a0f5-c485993ad02d", "label": "摘要16", "info": "为给定数据集，其中元素为z (i)", "keywords": "其中元素为, 为给定数据集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "07db2df9-71d1-40b5-9819-90ddb3c114f9", "label": "摘要17", "info": "Require：  A为学习算法，可视为一个函数（使用数据集作为输入，输；出一个学好的函数）", "keywords": "为学习算法, 可视为一个函数, 出一个学好的函数, 使用数据集作为输入", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4b49678c-858e-4788-8140-9f1d5aca7e1f", "label": "摘要18", "info": "Require：  L为损失函数，可视为来自学好的函数f，将样本；映射到  中标量的函数", "keywords": "将样本, 为损失函数, 中标量的函数, 映射到, 可视为来自学好的函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f1b27146-b477-4a54-a75c-a9e0ddacb8d6", "label": "摘要19", "info": "Require： k为折数", "keywords": "为折数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "305f1dc4-fd86-484e-8bc8-9dbd8d558fc1", "label": "摘要20", "info": "将  分为k个互斥子集  i ，它们的并集为", "keywords": "个互斥子集, 它们的并集为, 分为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e1b9c998-fa78-479c-b1c6-04409b4d004f", "label": "摘要21", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；for i from 1 to k do", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b12c3097-fd75-4dba-916a-11dcd05a1635", "label": "摘要22", "info": "for z (j) in", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "32ed0b43-6ad7-4866-b89e-ec5910f58475", "label": "摘要23", "info": "i do", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5b15ca3b-c5e7-4732-b342-199f59f112a9", "label": "摘要24", "info": "end for", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b24e58e9-9c06-44ed-acb3-bead70a814b2", "label": "摘要25", "info": "end for", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c2f75dee-887b-4357-99bf-7d87e568ad75", "label": "摘要26", "info": "Return e", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8961a51a-3d93-49e9-bfb4-6e285d9fe56a", "label": "摘要27", "info": "5.3.1　交叉验证", "keywords": "交叉验证", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8d08d757-0265-4364-8244-ee368e489de4", "label": "5.4：估计、偏差和方差", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "5f655528-52e4-4d26-bbc8-ea2e7d7854a2", "label": "摘要1", "info": "5.4.1　点估计", "keywords": "点估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a9a770d8-3bdd-45c3-962d-54625782db68", "label": "摘要2", "info": "5.4.2　偏差", "keywords": "偏差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2d24c8b3-a96f-415c-86ed-ef88a8a8f349", "label": "摘要3", "info": "5.4.3　方差和标准差", "keywords": "方差和标准差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c979434a-5dae-488b-9e69-9f5c4c97d4b4", "label": "摘要4", "info": "5.4.4　权衡偏差和方差以最小化均方误差", "keywords": "权衡偏差和方差以最小化均方误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d6adb17d-8146-4b10-aa38-c96baebff097", "label": "摘要5", "info": "5.4.5　一致性", "keywords": "一致性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "095feebc-4811-4f7e-9b7a-ceaa6212fc45", "label": "摘要6", "info": "统计领域为我们提供了很多工具来实现机器学习目标，不仅可以解决训；练集上的任务，还可以泛化。基本的概念，例如参数估计、偏差和方；差，对于正式地刻画泛化、欠拟合和过拟合都非常有帮助。", "keywords": "不仅可以解决训, 欠拟合和过拟合都非常有帮助, 例如参数估计, 基本的概念, 统计领域为我们提供了很多工具来实现机器学习目标", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fc342d43-7dd3-45cc-8992-7a7d2a78c9b8", "label": "摘要7", "info": "5.4.1　点估计", "keywords": "点估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a09c04dd-e9d9-455d-ab38-30d3a1559e79", "label": "摘要8", "info": "点估计试图为一些感兴趣的量提供单个“最优”预测。一般地，感兴趣的；量可以是单个参数，或是某些参数模型中的一个向量参数，例如第5.1.4；节线性回归中的权重，但是也有可能是整个函数。", "keywords": "最优, 感兴趣的, 节线性回归中的权重, 但是也有可能是整个函数, 一般地", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "561ed393-cc3f-4ac7-a610-5f11145895d6", "label": "摘要9", "info": "为了区分参数估计和真实值，我们习惯将参数 θ 的点估计表示为  。", "keywords": "为了区分参数估计和真实值, 的点估计表示为, 我们习惯将参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cd958be6-75e8-4f84-8841-f7e76eced64e", "label": "摘要10", "info": "令；（point estimator）或统计量 （statistics）是这些数据的任意函数：", "keywords": "是这些数据的任意函数, 或统计量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9fab7c7c-8900-4f11-b239-173fe7c3113a", "label": "摘要11", "info": "是m个独立同分布（i.i.d.）的数据点。点估计", "keywords": "点估计, 的数据点, 个独立同分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "40246fd2-074d-4a7b-ae59-02244d58b58c", "label": "摘要12", "info": "这个定义不要求g返回一个接近真实 θ 的值，或者g的值域恰好是 θ 的允；许取值范围。点估计的定义非常宽泛，给了估计量的设计者极大的灵活", "keywords": "许取值范围, 的值域恰好是, 这个定义不要求, 返回一个接近真实, 或者", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4901ae8e-9299-4d7f-ab36-999f04c49553", "label": "摘要13", "info": "性。虽然几乎所有的函数都可以称为估计量，但是一个良好的估计量的；输出会接近生成训练数据的真实参数 θ 。", "keywords": "但是一个良好的估计量的, 输出会接近生成训练数据的真实参数, 虽然几乎所有的函数都可以称为估计量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a00c328b-3c9a-4b73-8c40-5ca86933781d", "label": "摘要14", "info": "现在，我们采取频率派在统计上的观点。换言之，我们假设真实参数  θ；是固定但未知的，而点估计   是数据的函数。由于数据是随机过程采样；出来的，数据的任何函数都是随机的，因此  是一个随机变量。", "keywords": "是一个随机变量, 我们假设真实参数, 出来的, 因此, 换言之", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "82fa38f6-3c4a-49b4-bb78-4411099fe3b1", "label": "摘要15", "info": "点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点；估计称为函数估计。", "keywords": "我们将这种类型的点, 估计称为函数估计, 点估计也可以指输入和目标变量之间关系的估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8299d2e3-c807-4d8b-837a-693740d9336a", "label": "摘要16", "info": "函数估计  　有时我们会关注函数估计（或函数近似）。这时我们试图；从输入向量 x 预测变量 y 。假设有一个函数f( x )表示 y 和 x 之间的近似；关系。例如，我们可能假设", "keywords": "有时我们会关注函数估计, 表示, 之间的近似, 从输入向量, 函数估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "484591de-f717-448d-8702-51a8225517fd", "label": "摘要17", "info": "现在我们回顾点估计最常研究的性质，并探讨这些性质说明了估计的哪；些特点。", "keywords": "现在我们回顾点估计最常研究的性质, 些特点, 并探讨这些性质说明了估计的哪", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d660c839-32b0-450a-8e42-2c804df1e97b", "label": "摘要18", "info": "5.4.2　偏差", "keywords": "偏差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2e286e5f-b3d8-42c2-8d9d-6eb700318f21", "label": "摘要19", "info": "估计的偏差被定义为", "keywords": "估计的偏差被定义为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9895656f-0cad-45e2-9f49-643ebc0db1a2", "label": "摘要20", "info": "其中期望作用在所有数据（看作从随机变量采样得到的）上， θ 是用于；，那么估计量；定义数据生成分布的  θ  的真实值。如果", "keywords": "如果, 看作从随机变量采样得到的, 定义数据生成分布的, 其中期望作用在所有数据, 的真实值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1ed05ec7-4eaf-47fd-aef8-a78a2bb639e6", "label": "摘要21", "info": "被称为是无偏  （unbiased），这意味着", "keywords": "这意味着, 被称为是无偏", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1810add9-154c-41e9-adc0-b24120a248df", "label": "摘要22", "info": "，那么估计量   被称为是渐近无偏", "keywords": "被称为是渐近无偏, 那么估计量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5b18eab9-15bc-4d2f-8dda-109d785946b4", "label": "摘要23", "info": "（asymptotically unbiased），这意味着", "keywords": "这意味着", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5cd19ab9-960f-476c-be52-42623a8ea7f4", "label": "摘要24", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4166e511-ef6d-40ad-b097-7f4d62de909e", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；示例：伯努利分布  　考虑一组服从均值为θ的伯努利分布的独立同分布；的样本", "keywords": "考虑一组服从均值为, 伯努利分布, 的伯努利分布的独立同分布, 示例, 的样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f8e25844-f1da-4b96-879f-ee37bf43f76c", "label": "摘要26", "info": "：", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5038228d-74ee-4ba7-8a72-9a209cfb24ed", "label": "摘要27", "info": "这个分布中参数θ的常用估计量是训练样本的均值：", "keywords": "这个分布中参数, 的常用估计量是训练样本的均值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4f845365-b9b9-4fb6-a256-3b072da46421", "label": "摘要28", "info": "判断这个估计量是否有偏，我们将式（5.22）代入式（5.20）：", "keywords": "代入式, 我们将式, 判断这个估计量是否有偏", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "85c641d5-e36c-4a42-8219-c6c610d996c6", "label": "摘要29", "info": "因为bias(", "keywords": "因为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0f5367d7-5ae0-4744-b3d7-d3e563584778", "label": "摘要30", "info": ")=0，我们称估计  是无偏的。", "keywords": "我们称估计, 是无偏的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "062f76cd-d509-4c37-bb4c-816e2fc4fd03", "label": "摘要31", "info": "示例：均值的高斯分布估计", "keywords": "示例, 均值的高斯分布估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0d02fa23-f61f-4b64-867c-eb2d0ae262b8", "label": "摘要32", "info": "现在，考虑一组独立同分布的样本；，其中", "keywords": "现在, 其中, 考虑一组独立同分布的样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5474d8e8-9c1f-43c2-98b4-d58a0e96122c", "label": "摘要33", "info": "服从高斯分布；。回顾高斯概率密度函数如下：", "keywords": "服从高斯分布, 回顾高斯概率密度函数如下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eae7c655-1da5-4354-8c8d-73d225580548", "label": "摘要34", "info": "高斯均值参数的常用估计量被称为样本均值 （sample mean）：", "keywords": "高斯均值参数的常用估计量被称为样本均值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e81bea30-f10a-4b0e-b487-814b2e7361e6", "label": "摘要35", "info": "判断样本均值是否有偏，我们再次计算它的期望：", "keywords": "我们再次计算它的期望, 判断样本均值是否有偏", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ad77fde6-4cc2-4d5b-91df-b702a415d6d5", "label": "摘要36", "info": "因此我们发现样本均值是高斯均值参数的无偏估计量。", "keywords": "因此我们发现样本均值是高斯均值参数的无偏估计量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1ba6bec3-c3d6-4f73-b216-667498478c1b", "label": "摘要37", "info": "示例：高斯分布方差估计 　本例中，我们比较高斯分布方差参数σ  2  的；两个不同估计。我们探讨是否有一个是有偏的。", "keywords": "示例, 本例中, 我们探讨是否有一个是有偏的, 高斯分布方差估计, 两个不同估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7e8a72e9-acd6-48f9-b4d2-37fd962f009e", "label": "摘要38", "info": "我们考虑的第一个方差估计被称为样本方差 （sample variance）：", "keywords": "我们考虑的第一个方差估计被称为样本方差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8bcdc83b-71ee-4f1d-b345-b0d7e174c46a", "label": "摘要39", "info": "其中  是样本均值。更形式化地，我们对计算感兴趣", "keywords": "是样本均值, 我们对计算感兴趣, 更形式化地, 其中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bbd4e1b3-48ae-4768-b8d5-229ec1d49931", "label": "摘要40", "info": "我们首先估计项", "keywords": "我们首先估计项", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "68fabf2a-b762-4c49-bf3e-29d1279e1278", "label": "摘要41", "info": "：", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "63f7fd8e-37ee-4616-9f81-d30f1eea6254", "label": "摘要42", "info": "回到式（5.37），我们可以得出   的偏差是", "keywords": "我们可以得出, 回到式, 的偏差是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6d39aea2-5600-4b7e-830c-d40a1263d864", "label": "摘要43", "info": "。因此样本方差", "keywords": "因此样本方差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "51017097-9e6d-4d59-95ee-657c7f089085", "label": "摘要44", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；是有偏估计。", "keywords": "是有偏估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "79ec6287-a19a-40c3-b067-b82123c1b4d9", "label": "摘要45", "info": "无偏样本方差 （unbiased sample variance）估计：", "keywords": "估计, 无偏样本方差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8e640147-3489-4d1a-bb58-87982c8ac563", "label": "摘要46", "info": "提供了另一种可选方法。正如名字所言，这个估计是无偏的。换言之，；我们会发现", "keywords": "我们会发现, 换言之, 这个估计是无偏的, 提供了另一种可选方法, 正如名字所言", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d6e794ff-467a-4686-bcbd-567fa1ce92a2", "label": "摘要47", "info": "：", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0373a355-9ea6-4d6c-91a7-bc214f7f1295", "label": "摘要48", "info": "我们有两个估计量：一个是有偏的，另一个是无偏的。尽管无偏估计显；然是令人满意的，但它并不总是“最好”的估计。我们将看到，经常会使；用其他具有重要性质的有偏估计。", "keywords": "的估计, 用其他具有重要性质的有偏估计, 我们将看到, 经常会使, 但它并不总是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cb181de3-4dce-4c3c-8d8c-30068d070dd5", "label": "摘要49", "info": "5.4.3　方差和标准差", "keywords": "方差和标准差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "63b4731f-99ab-40fe-88a1-15067025fdd1", "label": "摘要50", "info": "我们有时会考虑估计量的另一个性质是它作为数据样本的函数，期望的；变化程度是多少。正如我们可以计算估计量的期望来决定它的偏差，我；们也可以计算它的方差。估计量的方差 （variance）就是一个方差：", "keywords": "变化程度是多少, 正如我们可以计算估计量的期望来决定它的偏差, 期望的, 估计量的方差, 我们有时会考虑估计量的另一个性质是它作为数据样本的函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2c3ae533-f681-412e-8e75-b92e432e80ff", "label": "摘要51", "info": "其中随机变量是训练集。另外，方差的平方根被称为标准差  （standard；error），记作SE（  ）。", "keywords": "其中随机变量是训练集, 记作, 另外, 方差的平方根被称为标准差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1033ab6d-37ad-4e01-9123-0a9cdc2d5d0a", "label": "摘要52", "info": "估计量的方差或标准差告诉我们，当独立地从潜在的数据生成过程中重；采样数据集时，如何期望估计的变化。正如我们希望估计的偏差较小，；我们也希望其方差较小。", "keywords": "我们也希望其方差较小, 正如我们希望估计的偏差较小, 采样数据集时, 当独立地从潜在的数据生成过程中重, 如何期望估计的变化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "04b663f5-0d31-48e8-96ba-459cdc71328a", "label": "摘要53", "info": "当我们使用有限的样本计算任何统计量时，真实参数的估计都是不确定；的，在这个意义下，从相同的分布得到其他样本时，它们的统计量也会；不一样。任何方差估计量的期望程度是我们想量化的误差的来源。", "keywords": "它们的统计量也会, 任何方差估计量的期望程度是我们想量化的误差的来源, 不一样, 在这个意义下, 真实参数的估计都是不确定", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f325e522-677d-4a1b-85ea-bf3cc9ee99ae", "label": "摘要54", "info": "均值的标准差被记作", "keywords": "均值的标准差被记作", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "29cd7b55-dfec-4c67-a123-1ce1af78f651", "label": "摘要55", "info": "其中σ  2  是样本 x  (i) 的真实方差。标准差通常被记作σ。可惜，样本方差；的平方根和方差无偏估计的平方根都不是标准差的无偏估计。这两种计；算方法都倾向于低估真实的标准差，但仍用于实际中。相较而言，方差", "keywords": "是样本, 的真实方差, 标准差通常被记作, 相较而言, 但仍用于实际中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9edb89c9-5636-471f-8d47-9de3eaf972d3", "label": "摘要56", "info": "均值的标准差在机器学习实验中非常有用。我们通常用测试集样本的误；差均值来估计泛化误差。测试集中样本的数量决定了这个估计的精确；度。中心极限定理告诉我们均值会接近一个高斯分布，我们可以用标准", "keywords": "中心极限定理告诉我们均值会接近一个高斯分布, 我们可以用标准, 均值的标准差在机器学习实验中非常有用, 差均值来估计泛化误差, 我们通常用测试集样本的误", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fa9f3c7e-b8d6-451a-af48-4d99e2d929d1", "label": "摘要57", "info": "的高斯分布。在机器学习；以上区间是基于均值   和方差；实验中，我们通常说算法A比算法B好，是指算法A的误差的95％置信区", "keywords": "和方差, 比算法, 实验中, 的误差的, 置信区", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "899a9f26-203e-43a5-9c24-775d64db06f8", "label": "摘要58", "info": "示例：伯努利分布", "keywords": "示例, 伯努利分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "437901b7-4488-4720-b976-fa40aa5d52ef", "label": "摘要59", "info": "我们再次考虑从伯努利分布（回顾；中独立同分布采样出来的一组样本", "keywords": "回顾, 中独立同分布采样出来的一组样本, 我们再次考虑从伯努利分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "073825ac-fc93-4d67-8169-3b366ddc0631", "label": "摘要60", "info": "。这次我们关注估计", "keywords": "这次我们关注估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "90d9aea0-4db2-4c1e-974b-892da43b1b6e", "label": "摘要61", "info": "的方差：", "keywords": "的方差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d62cc73c-8a8e-46d2-883c-a94b8f136e3a", "label": "摘要62", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；估计量方差的下降速率是关于数据集样本数目m的函数。这是常见估计；量的普遍性质，在探讨一致性（参见第5.4.5节）时，我们会继续讨论。", "keywords": "这是常见估计, 的函数, 参见第, 估计量方差的下降速率是关于数据集样本数目, 在探讨一致性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "477fc92e-18db-44c9-bff9-dd8193178560", "label": "摘要63", "info": "5.4.4　权衡偏差和方差以最小化均方误差", "keywords": "权衡偏差和方差以最小化均方误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ab2f1627-b809-4c56-b9e0-6fefb1c706e2", "label": "摘要64", "info": "偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函；数或参数的误差期望，而方差度量着数据上任意特定采样可能导致的估；计期望的偏差。", "keywords": "数或参数的误差期望, 计期望的偏差, 偏差和方差度量着估计量的两个不同误差来源, 而方差度量着数据上任意特定采样可能导致的估, 偏差度量着偏离真实函", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "972781dd-fb54-451d-91e4-3e4b7819c34f", "label": "摘要65", "info": "当我们可以在一个偏差更大的估计和一个方差更大的估计中进行选择；时，会发生什么呢？我们该如何选择？例如，想象我们希望近似图5.2；中的函数，如果只可以选择一个偏差较大的估计或一个方差较大的估", "keywords": "我们该如何选择, 例如, 如果只可以选择一个偏差较大的估计或一个方差较大的估, 中的函数, 想象我们希望近似图", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a0904ef4-0d7f-4f8d-a5d4-28973677e2d2", "label": "摘要66", "info": "判断这种权衡最常用的方法是交叉验证。经验上，交叉验证在真实世界；的许多任务中都非常成功。另外，我们也可以比较这些估计的均方误差；（mean squared error，MSE）：", "keywords": "经验上, 的许多任务中都非常成功, 我们也可以比较这些估计的均方误差, 判断这种权衡最常用的方法是交叉验证, 交叉验证在真实世界", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "381917d2-a6cc-4158-87ac-ca96b8afd0ee", "label": "摘要67", "info": "MSE度量着估计和真实参数θ之间平方误差的总体期望偏差。如式；（5.54）所示，MSE估计包含了偏差和方差。理想的估计具有较小的；MSE或是在检查中会稍微约束它们的偏差和方差。", "keywords": "之间平方误差的总体期望偏差, 度量着估计和真实参数, 如式, 估计包含了偏差和方差, 或是在检查中会稍微约束它们的偏差和方差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cc7f1605-52eb-446d-b564-84f8a450a49c", "label": "摘要68", "info": "偏差和方差的关系与机器学习容量、欠拟合和过拟合的概念紧密相联。；用MSE度量泛化误差（偏差和方差对于泛化误差都是有意义的）时，增；加容量会增加方差，降低偏差。如图5.6所示，我们再次在关于容量的", "keywords": "欠拟合和过拟合的概念紧密相联, 加容量会增加方差, 偏差和方差的关系与机器学习容量, 我们再次在关于容量的, 所示", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a74fb4b6-9988-4753-b7f4-3ac11dd75592", "label": "摘要69", "info": "图5.6　当容量增大（x轴）时，偏差（用点表示）随之减小，而方差（虚线）随之增大，使得；泛化误差（加粗曲线）产生了另一种U形。如果我们沿着轴改变容量，会发现最佳容量，当容；量小于最佳容量会呈现欠拟合，大于时导致过拟合。这种关系与第5.2节以及图5.3中讨论的容", "keywords": "泛化误差, 量小于最佳容量会呈现欠拟合, 随之减小, 中讨论的容, 当容", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5c7dd41f-bb3e-4f32-8c4c-abab7fc1cd70", "label": "摘要70", "info": "5.4.5　一致性", "keywords": "一致性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "913f2da3-18ec-453d-9931-484c69c6f639", "label": "摘要71", "info": "目前我们已经探讨了固定大小训练集下不同估计量的性质。通常，我们；也会关注训练数据增多后估计量的效果。特别地，我们希望当数据集中；数据点的数量m增加时，点估计会收敛到对应参数的真实值。更形式化", "keywords": "通常, 我们希望当数据集中, 特别地, 增加时, 我们", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "aa0c404a-fc95-4000-acb5-2029e1cf8b7a", "label": "摘要72", "info": "符号plim表示依概率收敛，即对于任意的", "keywords": "表示依概率收敛, 符号, 即对于任意的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9469db13-dc02-4fa5-9c1d-6ba8dc98904e", "label": "摘要73", "info": "＞0，当m→∞时，有；。式（5.55）表示的条件被称为一致性", "keywords": "表示的条件被称为一致性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "61f39357-b0cb-4ab5-b201-81eb15029fc2", "label": "摘要74", "info": "（consistency）。有时它是指弱一致性，强一致性是指几乎必然；（almost；sure）从   收敛到θ。几乎必然收敛  （almost", "keywords": "有时它是指弱一致性, 几乎必然收敛, 收敛到, 强一致性是指几乎必然", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6c0675fa-6a65-4d30-8592-454219197546", "label": "摘要75", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；一致性保证了估计量的偏差会随数据样本数目的增多而减少。然而，反；过来是不正确的——渐近无偏并不意味着一致性。例如，考虑用包含m", "keywords": "过来是不正确的, 然而, 例如, 一致性保证了估计量的偏差会随数据样本数目的增多而减少, 考虑用包含", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d31cca04-694a-4d11-b00c-69e6ffaa68a4", "label": "摘要76", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "14d33529-9c94-42e0-a7cc-3f2a0657351a", "label": "摘要77", "info": "5.4.1　点估计", "keywords": "点估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c71f8fe5-4158-4e4f-a175-1c1bfa4ddb08", "label": "摘要78", "info": "5.4.2　偏差", "keywords": "偏差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f9897146-836f-4bfa-b2c6-fb1a9ebf6203", "label": "摘要79", "info": "5.4.3　方差和标准差", "keywords": "方差和标准差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "33429f72-c3ff-4b1e-b4de-f5f40b6d00ef", "label": "摘要80", "info": "5.4.4　权衡偏差和方差以；最小化均方误差", "keywords": "最小化均方误差, 权衡偏差和方差以", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "895dc9c0-d527-4e58-a89f-6fe33b6e686b", "label": "摘要81", "info": "5.4.5　一致性", "keywords": "一致性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "label": "5.5：最大似然估计", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "4640bd0f-17cd-4304-879b-a9e3d125f8ad", "label": "摘要1", "info": "5.5.1　条件对数似然和均方误差", "keywords": "条件对数似然和均方误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a7a46163-67b0-4fe3-b09b-f296fb2dcdeb", "label": "摘要2", "info": "5.5.2　最大似然的性质", "keywords": "最大似然的性质", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "dd1bfa67-6961-4016-848f-dc7a4dee9401", "label": "摘要3", "info": "之前，我们已经看过常用估计的定义，并分析了它们的性质。但是这些；估计是从哪里来的呢？我们希望有些准则可以让我们从不同模型中得到；特定函数作为好的估计，而不是猜测某些函数可能是好的估计，然后分", "keywords": "而不是猜测某些函数可能是好的估计, 然后分, 但是这些, 我们已经看过常用估计的定义, 特定函数作为好的估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7a00e2cc-f7ca-4a98-b33d-0e3594b01d75", "label": "摘要4", "info": "最常用的准则是最大似然估计。", "keywords": "最常用的准则是最大似然估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5d405183-4a10-4e69-839a-8a5469fcdf6a", "label": "摘要5", "info": "考虑一组含有m个样本的数据集；未知的真实数据生成分布p data (x)生成。", "keywords": "未知的真实数据生成分布, 考虑一组含有, 生成, 个样本的数据集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "21d0b57c-6ece-44a2-a57d-ceb29b674d29", "label": "摘要6", "info": "，独立地由", "keywords": "独立地由", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6b9b516b-c93c-4d9e-b56f-3fa613400034", "label": "摘要7", "info": "令p model (x ； θ  )是一族由 θ 确定在相同空间上的概率分布。换言之，p；model ( x ; θ )将任意输入 x 映射到实数来估计真实概率p data ( x )。", "keywords": "将任意输入, 确定在相同空间上的概率分布, 换言之, 映射到实数来估计真实概率, 是一族由", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f9db6a80-0963-4dbe-8b0d-2e1f460fc85a", "label": "摘要8", "info": "对 θ 的最大似然估计被定义为", "keywords": "的最大似然估计被定义为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "200a7fd1-2399-426e-8379-ff1178263056", "label": "摘要9", "info": "多个概率的乘积会因很多原因不便于计算。例如，计算中很可能会出现；数值下溢。为了得到一个便于计算的等价优化问题，我们观察到似然对；数不会改变其arg max，但是将乘积转化成了便于计算的求和形式：", "keywords": "多个概率的乘积会因很多原因不便于计算, 但是将乘积转化成了便于计算的求和形式, 计算中很可能会出现, 为了得到一个便于计算的等价优化问题, 数值下溢", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "64e89a97-08ee-4eba-8379-89476892143f", "label": "摘要10", "info": "因为当重新缩放代价函数时arg  max不会改变，我们可以除以m得到和训；练数据经验分布ˆp data 相关的期望作为准则：", "keywords": "因为当重新缩放代价函数时, 得到和训, 相关的期望作为准则, 我们可以除以, 不会改变", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a8c7f027-61c7-4b87-9cb8-8145c49e3826", "label": "摘要11", "info": "一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布ˆp；data  和模型分布之间的差异，两者之间的差异程度可以通过KL散度度；量。KL散度被定义为", "keywords": "两者之间的差异程度可以通过, 一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布, 散度被定义为, 和模型分布之间的差异, 散度度", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c911d4a5-f8bc-49f1-9000-e5ba178ed3f7", "label": "摘要12", "info": "左边一项仅涉及数据生成过程，和模型无关。这意味着当训练模型最小；化KL散度时，我们只需要最小化", "keywords": "我们只需要最小化, 左边一项仅涉及数据生成过程, 和模型无关, 散度时, 这意味着当训练模型最小", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "81bd073c-4bf5-40c5-b117-b92c65e3e4ae", "label": "摘要13", "info": "当然，这和式（5.59）中最大化是相同的。", "keywords": "当然, 中最大化是相同的, 这和式", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f6b5590c-ce8e-4e5c-b698-a5917e307dfd", "label": "摘要14", "info": "最小化KL散度其实就是在最小化分布之间的交叉熵。许多作者使用术；语“交叉熵”特定表示伯努利或softmax分布的负对数似然，但那是用词不；当的。任何一个由负对数似然组成的损失都是定义在训练集上的经验分", "keywords": "交叉熵, 散度其实就是在最小化分布之间的交叉熵, 分布的负对数似然, 许多作者使用术, 当的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "680fcd7b-f145-4532-9caa-3f6648d3457b", "label": "摘要15", "info": "我们可以将最大似然看作使模型分布尽可能地和经验分布ˆp  data  相匹配；的尝试。理想情况下，我们希望匹配真实的数据生成分布p  data  ，但我；们无法直接知道这个分布。", "keywords": "但我, 我们可以将最大似然看作使模型分布尽可能地和经验分布, 相匹配, 们无法直接知道这个分布, 我们希望匹配真实的数据生成分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "cc8b0c53-e97d-4654-bed8-2e043558bdb3", "label": "摘要16", "info": "虽然最优  θ  在最大化似然或是最小化KL散度时是相同的，但目标函数；值是不一样的。在软件中，我们通常将两者都称为最小化代价函数。因；此最大化似然变成了最小化负对数似然（NLL），或者等价的是最小化", "keywords": "或者等价的是最小化, 值是不一样的, 在软件中, 在最大化似然或是最小化, 我们通常将两者都称为最小化代价函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eae6c89d-76dd-492f-93d0-0754a1684610", "label": "摘要17", "info": "5.5.1　条件对数似然和均方误差", "keywords": "条件对数似然和均方误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9ccc1652-3bb5-4f74-87b5-370fe1db0573", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最大似然估计很容易扩展到估计条件概率P (y |x  ;θ  )，从而给定x  预测y；。实际上这是最常见的情况，因为这构成了大多数监督学习的基础。如", "keywords": "最大似然估计很容易扩展到估计条件概率, 从而给定, 预测, 实际上这是最常见的情况, 因为这构成了大多数监督学习的基础", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fe957801-a6fc-40b1-8822-5279616a3e15", "label": "摘要19", "info": "如果假设样本是独立同分布的，那么式（5.62）可以分解成", "keywords": "那么式, 可以分解成, 如果假设样本是独立同分布的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "60f779d1-6db2-4dc4-b2fa-404986694303", "label": "摘要20", "info": "示例：线性回归作为最大似然  　第5.1.4节介绍的线性回归，可以被看；作最大似然过程。之前，我们将线性回归作为学习从输入 x 映射到输出；的算法。从x到   的映射选自最小化均方误差（我们或多或少介绍的", "keywords": "可以被看, 作最大似然过程, 的映射选自最小化均方误差, 的算法, 节介绍的线性回归", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fb033b12-c97c-4c3d-acd0-019be3f410ea", "label": "摘要21", "info": "。函数", "keywords": "函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d650084b-5988-4c82-8fd0-13d19782b74a", "label": "摘要22", "info": "其中  是线性回归在第i个输入 x  (i)  上的输出，m是训练样本的数目。；对比均方误差和对数似然，", "keywords": "上的输出, 是线性回归在第, 其中, 个输入, 对比均方误差和对数似然", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2f6a01df-4f2e-4c94-a7bd-63fa537cbf00", "label": "摘要23", "info": "我们立刻可以看出，最大化关于 w 的对数似然和最小化均方误差会得到；相同的参数估计  w  。但是对于相同的最优  w  ，这两个准则有着不同的；值。这验证了MSE可以用于最大似然估计。正如我们将看到的，最大似", "keywords": "正如我们将看到的, 相同的参数估计, 可以用于最大似然估计, 的对数似然和最小化均方误差会得到, 但是对于相同的最优", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3d06037e-f389-46d2-a36e-220bdeef0faf", "label": "摘要24", "info": "5.5.2　最大似然的性质", "keywords": "最大似然的性质", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "59214e42-ac36-49f8-b75d-efd40acb1ac2", "label": "摘要25", "info": "最大似然估计最吸引人的地方在于，它被证明当样本数目m→∞时，就；收敛率而言是最好的渐近估计。", "keywords": "收敛率而言是最好的渐近估计, 最大似然估计最吸引人的地方在于, 它被证明当样本数目", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "48c449ab-a93b-47ec-9c14-d3493821d5f6", "label": "摘要26", "info": "在合适的条件下，最大似然估计具有一致性（参考第5.4.5节），意味着；训练样本数目趋向于无穷大时，参数的最大似然估计会收敛到参数的真；实值。这些条件是：", "keywords": "在合适的条件下, 参数的最大似然估计会收敛到参数的真, 参考第, 意味着, 实值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4a7033b2-dace-4ff9-bf7f-21ac09a82498", "label": "摘要27", "info": "真实分布p  data  必须在模型族p  model  (·;  θ  )中。否则，没有估计可以；还原p data 。；真实分布p  data  必须刚好对应一个  θ  值。否则，最大似然估计恢复", "keywords": "最大似然估计恢复, 否则, 必须刚好对应一个, 还原, 没有估计可以", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e85b34e4-c5c5-4993-88c8-0f1382504397", "label": "摘要28", "info": "除了最大似然估计，还有其他的归纳准则，其中许多共享一致估计的性；质。然而，一致估计的统计效率  （statistic  efficiency）可能区别很大。；某些一致估计可能会在固定数目的样本上获得一个较低的泛化误差，或", "keywords": "某些一致估计可能会在固定数目的样本上获得一个较低的泛化误差, 然而, 其中许多共享一致估计的性, 可能区别很大, 还有其他的归纳准则", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a3715061-2a90-46d1-8f0e-a2dac6a19608", "label": "摘要29", "info": "统计效率通常用于有参情况  （parametric  case）的研究中（例如线性回；归）。在有参情况中，我们的目标是估计参数值（假设有可能确定真实；参数），而不是函数值。一种度量和真实参数相差多少的方法是计算均", "keywords": "参数, 假设有可能确定真实, 我们的目标是估计参数值, 在有参情况中, 一种度量和真实参数相差多少的方法是计算均", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b79036cb-9d00-4036-ac4f-0df911bf7428", "label": "摘要30", "info": "因为这些原因（一致性和统计效率），最大似然通常是机器学习中的首；选估计方法。当样本数目小到会发生过拟合时，正则化策略如权重衰减；可用于获得训练数据有限时方差较小的最大似然有偏版本。", "keywords": "选估计方法, 正则化策略如权重衰减, 最大似然通常是机器学习中的首, 当样本数目小到会发生过拟合时, 因为这些原因", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a720895b-7282-48e2-be98-8c57343e94c3", "label": "摘要31", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；5.6　贝叶斯统计", "keywords": "贝叶斯统计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "034cd175-fddc-4fc2-9d70-2434a415f0bc", "label": "摘要32", "info": "至此我们已经讨论了频率派统计  （frequentist  statistics）方法和基于估；计单一值 θ 的方法，然后基于该估计作所有的预测。另一种方法是在做；预测时会考虑所有可能的", "keywords": "至此我们已经讨论了频率派统计, 另一种方法是在做, 然后基于该估计作所有的预测, 预测时会考虑所有可能的, 的方法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "988f4a3a-1000-4fa6-af16-373c0c726efc", "label": "摘要33", "info": "正如第5.4.1节中讨论的，频率派的视角是真实参数 θ 是未知的定值，而；点估计  是考虑数据集上函数（可以看作随机的）的随机变量。", "keywords": "可以看作随机的, 正如第, 点估计, 是未知的定值, 节中讨论的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c3d26534-84b5-4342-8e7b-a432625ed418", "label": "摘要34", "info": "贝叶斯统计的视角完全不同。贝叶斯统计用概率反映知识状态的确定性；程度。数据集能够被直接观测到，因此不是随机的。另一方面，真实参；数 θ 是未知或不确定的，因此可以表示成随机变量。", "keywords": "是未知或不确定的, 贝叶斯统计用概率反映知识状态的确定性, 数据集能够被直接观测到, 因此可以表示成随机变量, 另一方面", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "617d108e-e175-42c0-957a-5993c4b8603c", "label": "摘要35", "info": "在观察到数据前，我们将；θ  的已知知识表示成先验概率分布（prior；probability  distribu-tion），p(  θ  )（有时简单地称为“先验”）。一般而", "keywords": "的已知知识表示成先验概率分布, 一般而, 我们将, 在观察到数据前, 先验", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "97239ed9-c59b-429e-a20d-dd0ca6cf2be1", "label": "摘要36", "info": "现在假设我们有一组数据样本；，通过贝叶斯规则结；合数据似然p(x (1) ，···，x (m) ｜ θ )和先验，可以恢复数据对我们关于 θ", "keywords": "合数据似然, 和先验, 通过贝叶斯规则结, 现在假设我们有一组数据样本, 可以恢复数据对我们关于", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "25660551-6ba3-49a6-a1a1-06da4a8d3794", "label": "摘要37", "info": "在贝叶斯估计常用的情景下，先验开始是相对均匀的分布或高熵的高斯；分布，观测数据通常会使后验的熵下降，并集中在参数的几个可能性很；高的值。", "keywords": "高的值, 先验开始是相对均匀的分布或高熵的高斯, 并集中在参数的几个可能性很, 观测数据通常会使后验的熵下降, 分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6079c9f0-8760-47ba-a7dd-cd288f1ca930", "label": "摘要38", "info": "相对于最大似然估计，贝叶斯估计有两个重要区别。第一，不像最大似；然方法预测时使用 θ 的点估计，贝叶斯方法使用 θ 的全分布。例如，在；观测到m个样本后，下一个数据样本x (m+1) 的预测分布如下：", "keywords": "贝叶斯方法使用, 第一, 不像最大似, 观测到, 的预测分布如下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "90db7358-5f16-4dbd-a409-b0a10717b966", "label": "摘要39", "info": "这里，每个具有正概率密度的 θ  的值有助于下一个样本的预测，其中贡；献由后验密度本身加权。在观测到数据集{x (1) ,···,x (m) }之后，如果我们；仍然非常不确定 θ 的值，那么这个不确定性会直接包含在我们所做的任", "keywords": "的值有助于下一个样本的预测, 之后, 其中贡, 如果我们, 在观测到数据集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bc771ac9-53df-4df2-a11a-8efc8faa8621", "label": "摘要40", "info": "在第5.4节中，我们已经探讨频率派方法解决给定点估计  θ  的不确定性；的方法是评估方差，估计的方差评估了观测数据重新从观测数据中采样；后，估计可能如何变化。对于如何处理估计不确定性的这个问题，贝叶", "keywords": "估计的方差评估了观测数据重新从观测数据中采样, 的不确定性, 的方法是评估方差, 节中, 贝叶", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "478b191d-9735-469a-bba3-8c949e0b03fb", "label": "摘要41", "info": "贝叶斯方法和最大似然方法的第二个最大区别是由贝叶斯先验分布造成；的。先验能够影响概率质量密度朝参数空间中偏好先验的区域偏移。实；践中，先验通常表现为偏好更简单或更光滑的模型。对贝叶斯方法的批", "keywords": "对贝叶斯方法的批, 先验能够影响概率质量密度朝参数空间中偏好先验的区域偏移, 践中, 贝叶斯方法和最大似然方法的第二个最大区别是由贝叶斯先验分布造成, 先验通常表现为偏好更简单或更光滑的模型", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e77cfd67-1173-4a20-865f-4c56f365c83f", "label": "摘要42", "info": "当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数；目很大时，通常会有很大的计算代价。", "keywords": "通常会有很大的计算代价, 贝叶斯方法通常泛化得更好, 当训练数据很有限时, 目很大时, 但是当训练样本数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "20480933-c6a3-49c5-9921-7edf33171e1c", "label": "摘要43", "info": "示例：贝叶斯线性回归  　我们使用贝叶斯估计方法学习线性回归的参；预测标量；数。在线性回归中，我们学习从输入向量", "keywords": "在线性回归中, 预测标量, 我们学习从输入向量, 我们使用贝叶斯估计方法学习线性回归的参, 示例", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "00bee20e-0742-41ca-ad31-8cc20df494e7", "label": "摘要44", "info": "的线性映射。该预测由向量", "keywords": "的线性映射, 该预测由向量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9c7e8ff6-fbe5-4c2c-a458-422fcd6af8e6", "label": "摘要45", "info": "参数化：", "keywords": "参数化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6f1235cd-abe5-4889-802f-125d46c943d0", "label": "摘要46", "info": "给定一组m个训练样本（ X （train） ， y （train） ），我们可以表示整个训；练集对y的预测：", "keywords": "我们可以表示整个训, 练集对, 个训练样本, 给定一组, 的预测", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f8b8e8a4-0ece-4f2c-9d2d-4af903be34f3", "label": "摘要47", "info": "表示为 y （train） 上的高斯条件分布，我们得到", "keywords": "上的高斯条件分布, 表示为, 我们得到", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3c15ab36-4e02-4dde-9753-45acd54e0f08", "label": "摘要48", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其中，我们根据标准的MSE公式假设y上的高斯方差为1。在下文中，为；减少符号负担，我们将（  X  （train）  ，  y  （train）  ）简单表示为（  X，y", "keywords": "上的高斯方差为, 我们将, 其中, 公式假设, 简单表示为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "303989d1-381a-4ae0-8659-38cbbbbce82b", "label": "摘要49", "info": "为确定模型参数向量 w 的后验分布，我们首先需要指定一个先验分布。；先验应该反映我们对这些参数取值的信念。虽然有时将我们的先验信念；表示为模型的参数很难或很不自然，但在实践中我们通常假设一个相当", "keywords": "我们首先需要指定一个先验分布, 为确定模型参数向量, 先验应该反映我们对这些参数取值的信念, 虽然有时将我们的先验信念, 的后验分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "07a82008-78bb-40d7-94a0-78488d9e6167", "label": "摘要50", "info": "其中， µ 0 和Λ 0 分别是先验分布的均值向量和协方差矩阵。 (1)", "keywords": "分别是先验分布的均值向量和协方差矩阵, 其中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5e54841b-3681-44b6-98eb-9a84245ebcdd", "label": "摘要51", "info": "确定好先验后，我们现在可以继续确定模型参数的后验 分布。", "keywords": "确定好先验后, 我们现在可以继续确定模型参数的后验, 分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8928a5bb-ecbc-43c1-8c69-d1904365dc5a", "label": "摘要52", "info": "现在我们定义", "keywords": "现在我们定义", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7ced4303-7726-4d72-abe4-841d26a32dd1", "label": "摘要53", "info": "这些新的变量，我们发现后验可改写为高斯分布：", "keywords": "我们发现后验可改写为高斯分布, 这些新的变量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "98148375-888c-460b-b14d-8849f97efdee", "label": "摘要54", "info": "。使用", "keywords": "使用", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8e536514-cfc8-443f-812f-8df20551edf1", "label": "摘要55", "info": "分布的积分必须归一这个事实意味着要删去所有不包括参数向量w的；项。式（3.23）显示了如何标准化多元高斯分布。", "keywords": "分布的积分必须归一这个事实意味着要删去所有不包括参数向量, 显示了如何标准化多元高斯分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c2f7c7e2-bc06-417f-a8ce-14ebc19475fc", "label": "摘要56", "info": "检查此后验分布可以让我们获得贝叶斯推断效果的一些直觉。大多数情", "keywords": "大多数情, 检查此后验分布可以让我们获得贝叶斯推断效果的一些直觉", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "abec4b5c-6dd7-4cc1-9d8e-e47827cebebb", "label": "摘要57", "info": "况下，我们设置 µ 0 =0。如果我们设置", "keywords": "我们设置, 如果我们设置, 况下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ef852be7-e2a3-461f-9ac7-131b2d36d2ca", "label": "摘要58", "info": "，那么µ  m", "keywords": "那么", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6e72f28a-926c-4971-a865-44098d53def2", "label": "摘要59", "info": "的线性回归的估计是；对 w 的估计就和频率派带权重衰减惩罚；一样的。一个区别是若α设为0，则贝叶斯估计是未定义的——我们不能", "keywords": "一个区别是若, 一样的, 的估计就和频率派带权重衰减惩罚, 则贝叶斯估计是未定义的, 设为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "434a4bc4-654a-4689-a07b-c14ba25b45ec", "label": "摘要60", "info": "5.6.1　最大后验（MAP）估计", "keywords": "最大后验, 估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f8c2e453-35ea-4b48-9901-b76cfc9b448c", "label": "摘要61", "info": "原则上，我们应该使用参数 θ  的完整贝叶斯后验分布进行预测，但单点；估计常常也是需要的。希望使用点估计的一个常见原因是，对于大多数；有意义的模型而言，大多数涉及贝叶斯后验的计算是非常棘手的，点估", "keywords": "但单点, 有意义的模型而言, 点估, 希望使用点估计的一个常见原因是, 我们应该使用参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0d61a946-3338-4930-8bb1-c606e8463a32", "label": "摘要62", "info": "我们可以认出式（5.79）右边的log  p(  x  ｜  θ  )对应着标准的对数似然；项，log p( θ )对应着先验分布。", "keywords": "对应着标准的对数似然, 我们可以认出式, 对应着先验分布, 右边的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0b810174-c821-40cf-b4c8-c6368f12fa65", "label": "摘要63", "info": "例如，考虑具有高斯先验权重", "keywords": "考虑具有高斯先验权重, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0d6bd43e-bcfa-4c6f-a531-4a250d0fa1cf", "label": "摘要64", "info": "w", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a13b2ff5-f466-40d5-a246-c31d04b12cc2", "label": "摘要65", "info": "的线性回归模型。如果先验是", "keywords": "的线性回归模型, 如果先验是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0c4979d1-2495-4c21-8452-c417b71e63cf", "label": "摘要66", "info": "，那么式（5.79）的对数先验项正比于", "keywords": "那么式, 的对数先验项正比于", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "48da7657-b641-4e32-8e6a-79b5b0cfb56e", "label": "摘要67", "info": "熟悉的权重衰减惩罚；过程的项。因此，具有高斯先验权重的MAP贝叶斯推断对应着权重衰；减。", "keywords": "贝叶斯推断对应着权重衰, 因此, 熟悉的权重衰减惩罚, 具有高斯先验权重的, 过程的项", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8b767bd3-5592-4aff-837d-aa3dbc9ac896", "label": "摘要68", "info": "，加上一个不依赖于 w 也不会影响学习", "keywords": "加上一个不依赖于, 也不会影响学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b35bc84a-37ae-4711-9c5b-1a6e1ed626cf", "label": "摘要69", "info": "正如全贝叶斯推断，MAP贝叶斯推断的优势是能够利用来自先验的信；息，这些信息无法从训练数据中获得。该附加信息有助于减少最大后验；点估计的方差（相比于ML估计）。然而，这个优点的代价是增加了偏", "keywords": "估计, 正如全贝叶斯推断, 这些信息无法从训练数据中获得, 该附加信息有助于减少最大后验, 这个优点的代价是增加了偏", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7a08600a-a58e-44e4-81c4-b65bd7c871ec", "label": "摘要70", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；许多正规化估计方法，例如权重衰减正则化的最大似然学习，可以被解；释为贝叶斯推断的MAP近似。这个适应于正则化时加到目标函数的附加", "keywords": "许多正规化估计方法, 可以被解, 释为贝叶斯推断的, 例如权重衰减正则化的最大似然学习, 这个适应于正则化时加到目标函数的附加", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "92eb194c-7e8a-4be1-afb6-65f4dafd7e72", "label": "摘要71", "info": "MAP贝叶斯推断提供了一个直观的方法来设计复杂但可解释的正则化。；例如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一；个单独的高斯分布（Nowlan and Hinton，1992）。", "keywords": "更复杂的惩罚项可以通过混合高斯分布作为先验得到, 例如, 贝叶斯推断提供了一个直观的方法来设计复杂但可解释的正则化, 而不是一, 个单独的高斯分布", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bdecf7bb-547c-4650-b20a-ba28681113f9", "label": "摘要72", "info": "5.5.1　条件对数似然和均；方误差", "keywords": "条件对数似然和均, 方误差", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "330e5861-32c7-40b8-ac37-40b6bf4373b0", "label": "摘要73", "info": "5.5.2　最大似然的性质", "keywords": "最大似然的性质", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f2a34f8d-1535-4ce7-b56b-1f6f25a565af", "label": "5.6：贝叶斯统计", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "261e01d0-8150-4280-af2c-9dac0148ceca", "label": "摘要1", "info": "5.6.1　最大后验（MAP）估计", "keywords": "最大后验, 估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0801cb0e-7f94-44c1-97d6-73110b74c440", "label": "摘要2", "info": "5.6.1　最大后验（MAP）；估计", "keywords": "最大后验, 估计", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "06c45e7f-2b0f-445a-9524-1a53f085f668", "label": "5.7：监督学习算法", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "7aafad76-98d7-41f4-b02e-4403cd5d4d15", "label": "摘要1", "info": "5.7.1　概率监督学习", "keywords": "概率监督学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6f48b6a0-1ac9-40ff-b7f4-19181dcb0bf8", "label": "摘要2", "info": "5.7.2　支持向量机", "keywords": "支持向量机", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "94d05379-8468-4827-a28e-2be64963daf8", "label": "摘要3", "info": "5.7.3　其他简单的监督学习算法", "keywords": "其他简单的监督学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e104aaa0-f5e1-40ab-a37a-eb7dfb4c5a61", "label": "摘要4", "info": "回顾第5.1.3节，粗略地说，监督学习算法是给定一组输入x和输出y的训；练集，学习如何关联输入和输出。在许多情况下，输出y很难自动收；集，必须由人来提供“监督”，不过该术语仍然适用于训练集目标可以被", "keywords": "输出, 的训, 在许多情况下, 回顾第, 不过该术语仍然适用于训练集目标可以被", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b15c6252-1ccd-457c-b57b-1280d40ae902", "label": "摘要5", "info": "5.7.1　概率监督学习", "keywords": "概率监督学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e4ef17de-154e-4699-81e7-8ed3cb8188a1", "label": "摘要6", "info": "本书的大部分监督学习算法都是基于估计概率分布p(y｜  x  )的。我们可；以使用最大似然估计找到对于有参分布族p(y｜ x ; θ )最好的参数向量 θ；。", "keywords": "以使用最大似然估计找到对于有参分布族, 本书的大部分监督学习算法都是基于估计概率分布, 我们可, 最好的参数向量", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8909cc3e-01ea-465d-af1b-505221ed9b48", "label": "摘要7", "info": "我们已经看到，线性回归对应于分布族", "keywords": "线性回归对应于分布族, 我们已经看到", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c1fae477-3f33-43ee-9dbd-e2b0c1e97f7e", "label": "摘要8", "info": "通过定义一族不同的概率分布，我们可以将线性回归扩展到分类情况；中。如果我们有两个类，类0和类1，那么只需要指定这两类之一的概；率。类1的概率决定了类0的概率，因为这两个值加起来必须等于1。", "keywords": "通过定义一族不同的概率分布, 那么只需要指定这两类之一的概, 的概率决定了类, 和类, 的概率", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7c7622b8-5fe3-463b-a805-a5083d5174b4", "label": "摘要9", "info": "我们用于线性回归的实数正态分布是用均值参数化的。我们提供这个均；值的任何值都是有效的。二元变量上的的分布稍微复杂些，因为它的均；值必须始终在0和1之间。解决这个问题的一种方法是使用logistic", "keywords": "值的任何值都是有效的, 我们用于线性回归的实数正态分布是用均值参数化的, 解决这个问题的一种方法是使用, 我们提供这个均, 因为它的均", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "53b91ced-5cde-449d-902f-e52dc3e13431", "label": "摘要10", "info": "这个方法被称为逻辑回归  （logistic  regression），这个名字有点奇怪，；因为该模型用于分类而非回归。", "keywords": "这个方法被称为逻辑回归, 因为该模型用于分类而非回归, 这个名字有点奇怪", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7ca16bc7-f3ef-4180-aea4-38e0099d0d60", "label": "摘要11", "info": "线性回归中，我们能够通过求解正规方程以找到最佳权重。相比而言，；逻辑回归会更困难些。其最佳权重没有闭解。反之，我们必须最大化对；数似然来搜索最优解。我们可以通过梯度下降算法最小化负对数似然来", "keywords": "相比而言, 反之, 我们可以通过梯度下降算法最小化负对数似然来, 线性回归中, 其最佳权重没有闭解", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "169fded6-6867-4e04-8a4b-cc55b67fd2f9", "label": "摘要12", "info": "通过确定正确的输入和输出变量上的有参条件概率分布族，相同的策略；基本上可以用于任何监督学习问题。", "keywords": "通过确定正确的输入和输出变量上的有参条件概率分布族, 相同的策略, 基本上可以用于任何监督学习问题", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a0ad7ef0-d10a-4134-88f3-05e7a2d92897", "label": "摘要13", "info": "5.7.2　支持向量机", "keywords": "支持向量机", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "83c598b8-d887-4aef-887e-e8c5a150cfb3", "label": "摘要14", "info": "支持向量机 （support vector machine，SVM）是监督学习中最有影响力；的方法之一（Boser  et  al.  ，1992；Cortes  and  Vapnik，1995）。类似于；的。不同于逻辑回", "keywords": "不同于逻辑回, 是监督学习中最有影响力, 支持向量机, 类似于, 的方法之一", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7b069158-b80c-438c-856e-c19c9bf2d98f", "label": "摘要15", "info": "支持向量机的一个重要创新是核技巧  （kernel  trick）。核技巧观察到许；多机器学习算法都可以写成样本间点积的形式。例如，支持向量机中的；线性函数可以重写为", "keywords": "支持向量机的一个重要创新是核技巧, 核技巧观察到许, 多机器学习算法都可以写成样本间点积的形式, 例如, 支持向量机中的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6849077d-df61-46bd-b731-776f1a466808", "label": "摘要16", "info": "其中， x (i) 是训练样本， α  是系数向量。学习算法重写为这种形式允许；我们将  x  替换为特征函数φ(  x；)的输出，点积替换为被称为核函数", "keywords": "是系数向量, 的输出, 我们将, 其中, 学习算法重写为这种形式允许", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e1ba6aa6-3505-436e-adab-88f839b8c7b3", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；使用核估计替换点积之后，我们可以使用如下函数进行预测", "keywords": "使用核估计替换点积之后, 我们可以使用如下函数进行预测", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0f7d3c61-1a90-4bdf-99e0-d11426d82fe4", "label": "摘要18", "info": "这个函数关于 x  是非线性的，关于φ( x )是线性的。 α  和f(  x  )之间的关；系也是线性的。核函数完全等价于用φ(  x  )预处理所有的输入，然后在；新的转换空间学习线性模型。", "keywords": "核函数完全等价于用, 之间的关, 系也是线性的, 是非线性的, 然后在", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "60af9883-7d6c-40df-84e5-d1a26cf75400", "label": "摘要19", "info": "核技巧十分强大有两个原因：其一，它使我们能够使用保证有效收敛的；凸优化技术来学习非线性模型（关于 x 的函数）。这是可能的，因为我；们可以认为φ是固定的，仅优化α，即优化算法可以将决策函数视为不同", "keywords": "们可以认为, 是固定的, 即优化算法可以将决策函数视为不同, 凸优化技术来学习非线性模型, 的函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "86c15d1e-0996-48bd-b9ac-ab0f31ddea5f", "label": "摘要20", "info": ")甚至可以是无限维的，对于普通的显式方法而；在某些情况下，φ(  x；言，这将是无限的计算代价。在很多情况下，即使φ( x )是难算的，k(  x", "keywords": "甚至可以是无限维的, 这将是无限的计算代价, 对于普通的显式方法而, 即使, 在某些情况下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4865f250-14e9-4911-b807-d6d25ef05f5b", "label": "摘要21", "info": "最常用的核函数是高斯核 （Gaussian kernel），", "keywords": "最常用的核函数是高斯核", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "861228e7-42e2-481b-99a3-967502eb9c93", "label": "摘要22", "info": "是标准正态密度。这个核也被称为径向基函数；其中；（radial basis function，RBF）核，因为其值沿 ν 中从 u 向外辐射的方向", "keywords": "中从, 是标准正态密度, 其中, 向外辐射的方向, 因为其值沿", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "30a02490-8b7f-4e32-8296-ebb29d9f9945", "label": "摘要23", "info": "我们可以认为高斯核在执行一种模板匹配  （template  matching）。训练；标签y相关的训练样本  x  变成了类别y的模板。当测试点  x/  到  x  的欧几；里得距离很小，对应的高斯核响应很大时，表明  x'  和模板  x  非常相", "keywords": "训练, 对应的高斯核响应很大时, 里得距离很小, 当测试点, 和模板", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "70e9db68-23b3-4211-8eb0-6e71106ee7da", "label": "摘要24", "info": "支持向量机不是唯一可以使用核技巧来增强的算法。许多其他的线性模；型也可以通过这种方式来增强。使用核技巧的算法类别被称为核机器；（kernel  machine）或核方法  （kernel  method）（Williams", "keywords": "许多其他的线性模, 支持向量机不是唯一可以使用核技巧来增强的算法, 或核方法, 型也可以通过这种方式来增强, 使用核技巧的算法类别被称为核机器", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "54cd6c4e-0578-419e-a384-3feda5f995ac", "label": "摘要25", "info": "and", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "21ee9440-2f9a-42b5-b221-a8e14de29ca8", "label": "摘要26", "info": "核机器的一个主要缺点是计算决策函数的成本关于训练样本的数目是线；性的。因为第i个样本贡献α i k( x , x  (i)  )到决策函数。支持向量机能够通；过学习主要包含零的向量 α ，以缓和这个缺点。那么判断新样本的类别", "keywords": "核机器的一个主要缺点是计算决策函数的成本关于训练样本的数目是线, 那么判断新样本的类别, 过学习主要包含零的向量, 性的, 个样本贡献", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e6f57719-9dd2-4a1c-b7eb-be4177f26296", "label": "摘要27", "info": "当数据集很大时，核机器的计算量也会很大。我们将会在第5.9节回顾；这个想法。带通用核的核机器致力于泛化得更好。我们将在第5.11节解；释原因。现代深度学习的设计旨在克服核机器的这些限制。当前深度学", "keywords": "释原因, 节回顾, 节解, 现代深度学习的设计旨在克服核机器的这些限制, 当前深度学", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e9c73820-8388-4647-848d-8124f8275e26", "label": "摘要28", "info": "5.7.3　其他简单的监督学习算法", "keywords": "其他简单的监督学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c92f721d-5fef-4f7e-ab8f-cb327bc87912", "label": "摘要29", "info": "我们已经简要介绍过另一个非概率监督学习算法，最近邻回归。通常，；k-最近邻是一类可用于分类或回归的技术。作为一个非参数学习算法，；k-最近邻并不局限于固定数目的参数。我们通常认为k-最近邻算法没有", "keywords": "通常, 我们已经简要介绍过另一个非概率监督学习算法, 最近邻是一类可用于分类或回归的技术, 作为一个非参数学习算法, 最近邻并不局限于固定数目的参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b8741686-aab3-4736-b26a-3ce4f1fc4272", "label": "摘要30", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；高容量使其在训练样本数目大时能够获取较高的精度。然而，它的计算；成本很高，另外在训练集较小时泛化能力很差。k-最近邻的一个弱点是", "keywords": "最近邻的一个弱点是, 成本很高, 另外在训练集较小时泛化能力很差, 然而, 高容量使其在训练样本数目大时能够获取较高的精度", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f5c19905-c654-4be9-8ba3-7e867a036f4c", "label": "摘要31", "info": "决策树  （decision；tree）及其变种是另一类将输入空间分成不同的区；域，每个区域有独立参数的算法（Breiman  et  al.  ，1984）。如图5.7所", "keywords": "每个区域有独立参数的算法, 决策树, 如图, 及其变种是另一类将输入空间分成不同的区", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "274dff5d-1bf8-4e7e-817f-0e668b4308e5", "label": "摘要32", "info": "图5.7　描述一个决策树如何工作的示意图。（上）树中每个节点都选择将输入样本送到左子节；点（0）或者右子节点（1）。内部的节点用圆圈表示，叶节点用方块表示。每一个节点可以用；一个二值的字符串识别并对应树中的位置，这个字符串是通过给起父亲节点的字符串添加一个", "keywords": "内部的节点用圆圈表示, 叶节点用方块表示, 或者右子节点, 树中每个节点都选择将输入样本送到左子节, 这个字符串是通过给起父亲节点的字符串添加一个", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e7b8f8d7-ea17-4106-911d-ef3ab3ab603b", "label": "摘要33", "info": "。这个平面中画出了树的节点，每个内部点穿过分割线", "keywords": "每个内部点穿过分割线, 这个平面中画出了树的节点", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "47ed1138-62ff-4667-84e4-4ea3c7d44187", "label": "摘要34", "info": "正如我们已经看到的，最近邻预测和决策树都有很多的局限性。尽管如", "keywords": "尽管如, 正如我们已经看到的, 最近邻预测和决策树都有很多的局限性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6261aac1-32d8-4c5f-9275-9c6b81c8663d", "label": "摘要35", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；此，在计算资源受限制时，它们都是很有用的学习算法。通过思考复杂；算法和k-最近邻或决策树之间的相似性和差异，我们可以建立对更复杂", "keywords": "通过思考复杂, 它们都是很有用的学习算法, 我们可以建立对更复杂, 最近邻或决策树之间的相似性和差异, 算法和", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "766d47c3-7700-44e8-a472-9a103893881f", "label": "摘要36", "info": "读者可以参考Murphy（2012）；Bishop（2006）；Hastie et al. （2001）；或其他机器学习教科书了解更多的传统监督学习算法。", "keywords": "或其他机器学习教科书了解更多的传统监督学习算法, 读者可以参考", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d0662837-3bee-424a-9bf2-4831b865e1cd", "label": "摘要37", "info": "5.7.1　概率监督学习", "keywords": "概率监督学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2c872967-e2b3-49ab-9167-f56c3b54a029", "label": "摘要38", "info": "5.7.2　支持向量机", "keywords": "支持向量机", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a83fe325-5eec-43e6-b1ef-26d1aae187f8", "label": "摘要39", "info": "5.7.3　其他简单的监督学；习算法", "keywords": "其他简单的监督学, 习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "label": "5.8：无监督学习算法", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "1cc5a203-9292-4012-8400-a9a6b920de73", "label": "摘要1", "info": "5.8.1　主成分分析", "keywords": "主成分分析", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "da3c9d11-64ce-4185-82ba-222f8073a9f4", "label": "摘要2", "info": "5.8.2　k-均值聚类", "keywords": "均值聚类", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9294f3eb-d800-4cbd-b8ab-63c0943f5141", "label": "摘要3", "info": "回顾第5.1.3节，无监督算法只处理“特征”，不操作监督信号。监督和无；监督算法之间的区别没有规范严格的定义，因为没有客观的判断来区分；监督者提供的值是特征还是目标。通俗地说，无监督学习的大多数尝试", "keywords": "监督和无, 通俗地说, 回顾第, 监督者提供的值是特征还是目标, 监督算法之间的区别没有规范严格的定义", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9919d91c-905b-4e8d-a0a7-f9de360a0704", "label": "摘要4", "info": "一个经典的无监督学习任务是找到数据的“最佳”表示。“最佳”可以是不；同的表示，但是一般来说，是指该表示在比本身表示的信息更简单或更；易访问而受到一些惩罚或限制的情况下，尽可能地保存关于 x 更多的信", "keywords": "表示, 最佳, 是指该表示在比本身表示的信息更简单或更, 可以是不, 易访问而受到一些惩罚或限制的情况下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "af615571-1a16-4740-b358-30c7d9db4195", "label": "摘要5", "info": "有很多方式定义较简单的表示。最常见的3种包括低维表示、稀疏表示；和独立表示。低维表示尝试将 x 中的信息尽可能压缩在一个较小的表示；中。稀疏表示将数据集嵌入到输入项大多数为零的表示中（Barlow，", "keywords": "最常见的, 低维表示尝试将, 稀疏表示将数据集嵌入到输入项大多数为零的表示中, 有很多方式定义较简单的表示, 稀疏表示", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "af0aa4fb-4d04-481d-9d30-5753f8e47602", "label": "摘要6", "info": "当然，这3个标准并非相互排斥的。低维表示通常会产生比原始的高维；数据具有较少或较弱依赖关系的元素。这是因为减少表示大小的一种方；式是找到并消除冗余。识别并去除更多的冗余使得降维算法在丢失更少", "keywords": "这是因为减少表示大小的一种方, 式是找到并消除冗余, 低维表示通常会产生比原始的高维, 识别并去除更多的冗余使得降维算法在丢失更少, 当然", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2fcb4b82-ce1f-43bf-935e-cc738f144bcd", "label": "摘要7", "info": "表示的概念是深度学习核心主题之一，因此也是本书的核心主题之一。", "keywords": "因此也是本书的核心主题之一, 表示的概念是深度学习核心主题之一", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "494b96ac-703f-4ce6-a392-6247f82d2de3", "label": "摘要8", "info": "本节会介绍表示学习算法中的一些简单示例。总的来说，这些示例算法；会说明如何实施上面的3个标准。剩余的大部分章节会介绍额外的表示；学习算法，它们以不同方式处理这3个标准或是引入其他标准。", "keywords": "剩余的大部分章节会介绍额外的表示, 个标准或是引入其他标准, 学习算法, 这些示例算法, 个标准", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "378b64de-c655-4761-8022-94b08df668b7", "label": "摘要9", "info": "5.8.1　主成分分析", "keywords": "主成分分析", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1e52114c-c6d7-4e2a-b7eb-b39c37a31264", "label": "摘要10", "info": "在第2.12节中，我们看到PCA算法提供了一种压缩数据的方式。我们也；可以将PCA视为学习数据表示的无监督学习算法。这种表示基于上述简；单表示的两个标准。PCA学习一种比原始输入维数更低的表示。它也学", "keywords": "单表示的两个标准, 它也学, 可以将, 学习一种比原始输入维数更低的表示, 节中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "60eb3261-fba2-4408-b7ad-48d04e1608ff", "label": "摘要11", "info": "如图5.8所示，PCA将输入 x 投影表示成 z ，学习数据的正交线性变换。；在第2.12节中，我们看到了如何学习重建原始数据的最佳一维表示（就；均方误差而言），这种表示其实对应着数据的第一个主要成分。因此，", "keywords": "学习数据的正交线性变换, 投影表示成, 所示, 这种表示其实对应着数据的第一个主要成分, 因此", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a950a5d0-5576-4b73-9383-dc1584058c0b", "label": "摘要12", "info": "图5.8　PCA学习一种线性投影，使最大方差的方向和新空间的轴对齐。（左）原始数据包含了；x 的样本。在这个空间中，方差的方向与轴的方向并不是对齐的。（右）变换过的数据；在轴z 1 的方向上有最大的变化。第二大变化方差的方向沿着轴z 2", "keywords": "使最大方差的方向和新空间的轴对齐, 原始数据包含了, 学习一种线性投影, 第二大变化方差的方向沿着轴, 的方向上有最大的变化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fbb8a9b1-b83f-4665-845f-8030ed4af3eb", "label": "摘要13", "info": "假设有一个m×n的设计矩阵 X  ，数据的均值为零，；如此，通过预处理步骤使所有样本减去均值，数据可以很容易地中心；化。", "keywords": "如此, 数据的均值为零, 的设计矩阵, 通过预处理步骤使所有样本减去均值, 数据可以很容易地中心", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b1ba8b0c-ccf9-45d0-b85a-c887f96ca8b8", "label": "摘要14", "info": "。若非", "keywords": "若非", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a9217984-a988-48b3-9f3f-922071d23580", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；X 对应的无偏样本协方差矩阵给定如下", "keywords": "对应的无偏样本协方差矩阵给定如下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3bd28b98-0f3c-4f48-a621-fe4c75229369", "label": "摘要16", "info": "PCA通过线性变换找到一个Var［ z  ］是对角矩阵的表示；。", "keywords": "是对角矩阵的表示, 通过线性变换找到一个", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9d16898a-cec8-443e-96cf-851e2c18a652", "label": "摘要17", "info": "在第2.12节，我们已知设计矩阵  X  的主成分由；定。从这个角度，我们有", "keywords": "我们有, 从这个角度, 的主成分由, 在第, 我们已知设计矩阵", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eea8acd9-bc66-4754-be70-cefac4167f7d", "label": "摘要18", "info": "的特征向量给", "keywords": "的特征向量给", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c13e138b-d61c-4b1c-8a1a-97ccebcce215", "label": "摘要19", "info": "本节中，我们会探索主成分的另一种推导。主成分也可以通过奇异值分；解（SVD）得到。具体来说，它们是 X 的右奇异向量。为了说明这点，；假设 W 是奇异值分解", "keywords": "本节中, 它们是, 是奇异值分解, 得到, 具体来说", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9b2fdc27-0554-465f-80a9-96c11b976b42", "label": "摘要20", "info": "SVD有助于说明PCA后的Var［  z  ］是对角的。使用  X  的SVD分解，  X；的方差可以表示为", "keywords": "有助于说明, 后的, 分解, 是对角的, 的方差可以表示为", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8af8914f-8a95-439f-8ec9-f307605bebf3", "label": "摘要21", "info": "其中，我们使用；的。这表明 z 的协方差满足对角的要求：", "keywords": "的协方差满足对角的要求, 这表明, 其中, 我们使用", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "fae01717-2de0-4000-933d-f759bf29b09b", "label": "摘要22", "info": "，因为根据奇异值的定义矩阵 U 是正交", "keywords": "是正交, 因为根据奇异值的定义矩阵", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6cee61ff-5807-4262-a408-e228a3e45c98", "label": "摘要23", "info": "其中，再次使用SVD的定义有", "keywords": "的定义有, 其中, 再次使用", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "38ad840c-98f6-4d9b-a4cd-ee340c2a872d", "label": "摘要24", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "77efb4df-ce93-4c7a-abf0-13fefe443e7f", "label": "摘要25", "info": "以上分析指明当我们通过线性变换  W  将数据  x  投影到  z  时，得到的数；据表示的协方差矩阵是对角的（即Σ  2  ），立刻可得  z  中的元素是彼此；无关的。", "keywords": "无关的, 中的元素是彼此, 得到的数, 据表示的协方差矩阵是对角的, 立刻可得", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "48dfac7a-9387-43c2-ad6f-70f2601e847d", "label": "摘要26", "info": "PCA这种将数据变换为元素之间彼此不相关表示的能力是PCA的一个重；要性质。它是消除数据中未知变化因素的简单表示示例。在PCA中，这；个消除是通过寻找输入空间的一个旋转（由  W  确定），使得方差的主", "keywords": "它是消除数据中未知变化因素的简单表示示例, 使得方差的主, 这种将数据变换为元素之间彼此不相关表示的能力是, 确定, 要性质", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7dcd21a7-59a6-4361-96a1-25aaf8b3df9b", "label": "摘要27", "info": "虽然相关性是数据元素间依赖关系的一个重要范畴，但我们对于能够消；除更复杂形式的特征依赖的表示学习也很感兴趣。对此，我们需要比简；单线性变换更强的工具。", "keywords": "虽然相关性是数据元素间依赖关系的一个重要范畴, 单线性变换更强的工具, 我们需要比简, 除更复杂形式的特征依赖的表示学习也很感兴趣, 对此", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d9df4b0d-95ea-4515-94b2-3a8a75b31097", "label": "摘要28", "info": "5.8.2　k-均值聚类", "keywords": "均值聚类", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f182bf51-4299-44b1-b75c-091193383d72", "label": "摘要29", "info": "另外一个简单的表示学习算法是k-均值聚类。k-均值聚类算法将训练集；分成k个靠近彼此的不同样本聚类。因此我们可以认为该算法提供了k-；维的one-hot编码向量h以表示输入  x 。当 x 属于聚类i时，有h  i  =1，h的", "keywords": "另外一个简单的表示学习算法是, 均值聚类, 因此我们可以认为该算法提供了, 个靠近彼此的不同样本聚类, 分成", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6fc36433-884e-4f3b-9697-afb499cd94a6", "label": "摘要30", "info": "k-均值聚类提供的one-hot编码也是一种稀疏表示，因为每个输入的表示；中大部分元素为零。之后，我们会介绍能够学习更灵活的稀疏表示的一；些其他算法（表示中每个输入 x 不只一个非零项）。one-hot编码是稀疏", "keywords": "之后, 编码是稀疏, 中大部分元素为零, 不只一个非零项, 些其他算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8845e81b-f12e-4956-a4df-3fc9180851ff", "label": "摘要31", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；k-均值聚类初始化k个不同的中心点{µ (1) ,...,µ (k) }，然后迭代交换两个不；同的步骤直到收敛。步骤一，每个训练样本分配到最近的中心点µ  (i)  所", "keywords": "步骤一, 个不同的中心点, 每个训练样本分配到最近的中心点, 同的步骤直到收敛, 均值聚类初始化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c739c0b8-a990-499a-9cd9-15ed2109acd9", "label": "摘要32", "info": "关于聚类的一个问题是，聚类问题本身是病态的。这是说没有单一的标；准去度量聚类的数据在真实世界中效果如何。我们可以度量聚类的性；质，例如类中元素到类中心点的欧几里得距离的均值。这使我们可以判", "keywords": "准去度量聚类的数据在真实世界中效果如何, 关于聚类的一个问题是, 聚类问题本身是病态的, 这使我们可以判, 例如类中元素到类中心点的欧几里得距离的均值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e18b0ee2-a7b6-43b9-87cb-b400142d0eb2", "label": "摘要33", "info": "这些问题说明了一些我们可能更偏好于分布式表示（相对于one-hot表示；而言）的原因。分布式表示可以对每个车辆赋予两个属性——一个表示；它的颜色，一个表示它是汽车还是卡车。目前仍然不清楚什么是最优的", "keywords": "表示, 的原因, 相对于, 而言, 它的颜色", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ad285520-dd16-4c79-ac04-c43310520f83", "label": "摘要34", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；5.8.1　主成分分析", "keywords": "主成分分析", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "300a5041-0caf-4054-b124-9af09996d03d", "label": "摘要35", "info": "5.8.2　k-均值聚类", "keywords": "均值聚类", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9a00340a-9072-4c58-9a5f-98e204b02b37", "label": "5.9：随机梯度下降", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "53d417fd-4603-4e07-91ca-cf4c67099723", "label": "摘要1", "info": "几乎所有的深度学习算法都用到了一个非常重要的算法：随机梯度下降；（stochastic  gradi-ent  descent，SGD）。随机梯度下降是第4.3节介绍的；梯度下降算法的一个扩展。", "keywords": "节介绍的, 梯度下降算法的一个扩展, 随机梯度下降是第, 随机梯度下降, 几乎所有的深度学习算法都用到了一个非常重要的算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "21e158d9-86b1-42ca-98cd-6e774cce8fbd", "label": "摘要2", "info": "机器学习中反复出现的一个问题是好的泛化需要大的训练集，但大的训；练集的计算代价也更大。", "keywords": "但大的训, 练集的计算代价也更大, 机器学习中反复出现的一个问题是好的泛化需要大的训练集", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e43ead4f-67bc-44aa-9c3f-8d5bb90d3b4f", "label": "摘要3", "info": "机器学习算法中的代价函数通常可以分解成每个样本的代价函数的总；和。例如，训练数据的负条件对数似然可以写成", "keywords": "机器学习算法中的代价函数通常可以分解成每个样本的代价函数的总, 例如, 训练数据的负条件对数似然可以写成", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4bf886e9-e95a-4128-b8b1-6ddff59edfb1", "label": "摘要4", "info": "其中L是每个样本的损失", "keywords": "是每个样本的损失, 其中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f3aaeb4f-c0a5-4942-9922-11483c99c8e9", "label": "摘要5", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4671ea2d-ad53-4a36-821d-bb9b3ac70a2a", "label": "摘要6", "info": "对于这些相加的代价函数，梯度下降需要计算", "keywords": "对于这些相加的代价函数, 梯度下降需要计算", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d54b6589-4f23-48e8-96c6-9392cb332864", "label": "摘要7", "info": "这个运算的计算代价是O(m)。随着训练集规模增长为数十亿的样本，计；算一步梯度也会消耗相当长的时间。", "keywords": "算一步梯度也会消耗相当长的时间, 随着训练集规模增长为数十亿的样本, 这个运算的计算代价是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "40047a3c-9494-4e0b-94e8-03777d12a805", "label": "摘要8", "info": "随机梯度下降的核心是，梯度是期望。期望可使用小规模的样本近似估；计。具体而言，在算法的每一步，我们从训练集中均匀抽出一小批量；。小批量的数目m'通常是", "keywords": "具体而言, 梯度是期望, 期望可使用小规模的样本近似估, 在算法的每一步, 随机梯度下降的核心是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0eadad01-78e3-4558-8aa2-55cc4a04754d", "label": "摘要9", "info": "梯度的估计可以表示成", "keywords": "梯度的估计可以表示成", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5e03597a-736f-47f4-8880-e6c15a8def32", "label": "摘要10", "info": "使用来自小批量B的样本。然后，随机梯度下降算法使用如下的梯度下；降估计：", "keywords": "降估计, 使用来自小批量, 的样本, 随机梯度下降算法使用如下的梯度下, 然后", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5e2205b2-be72-4a38-af29-0ad83ef36494", "label": "摘要11", "info": "其中，  是学习率。", "keywords": "是学习率, 其中", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6eddfe8c-8c64-4c5a-8fb0-9ef699da9bad", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；梯度下降往往被认为很慢或不可靠。以前，将梯度下降应用到非凸优化；问题被认为很鲁莽或没有原则。现在，我们知道梯度下降用于本书第2", "keywords": "问题被认为很鲁莽或没有原则, 以前, 将梯度下降应用到非凸优化, 现在, 我们知道梯度下降用于本书第", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3639eea0-dcad-40c6-a7fd-e174a21f9d8e", "label": "摘要13", "info": "随机梯度下降在深度学习之外有很多重要的应用。它是在大规模数据上；训练大型线性模型的主要方法。对于固定大小的模型，每一步随机梯度；下降更新的计算量不取决于训练集的大小m。在实践中，当训练集大小", "keywords": "训练大型线性模型的主要方法, 每一步随机梯度, 下降更新的计算量不取决于训练集的大小, 当训练集大小, 它是在大规模数据上", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "981ed653-fd98-4e7d-9c57-fc90578a3aef", "label": "摘要14", "info": "在深度学习兴起之前，学习非线性模型的主要方法是结合核技巧的线性；模型。很多核学习算法需要构建一个m×m的矩阵；。构建这个矩阵的计算量是O(m  2  )。当数据集是几十亿个样本时，这个", "keywords": "当数据集是几十亿个样本时, 很多核学习算法需要构建一个, 在深度学习兴起之前, 的矩阵, 学习非线性模型的主要方法是结合核技巧的线性", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "44e81305-3fe0-4964-b9a5-d6aeb6eca54c", "label": "摘要15", "info": "我们将会在第8章继续探讨随机梯度下降及其很多改进方法。", "keywords": "我们将会在第, 章继续探讨随机梯度下降及其很多改进方法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6326c52f-5650-4bc7-b886-c745c8456402", "label": "5.10：构建机器学习算法", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "78a9eb9e-4468-44ef-96d6-54ae4cb010e9", "label": "摘要1", "info": "几乎所有的深度学习算法都可以被描述为一个相当简单的配方：特定的；数据集、代价函数、优化过程和模型。", "keywords": "几乎所有的深度学习算法都可以被描述为一个相当简单的配方, 优化过程和模型, 特定的, 数据集, 代价函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1d4b494f-1854-40c2-93de-70c8b1c1e34d", "label": "摘要2", "info": "例如，线性回归算法由以下部分组成： X 和 y 构成的数据集，代价函数", "keywords": "线性回归算法由以下部分组成, 构成的数据集, 代价函数, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "76b94898-479c-453f-ba4b-af6232f5ae94", "label": "摘要3", "info": "模型是", "keywords": "模型是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "20a09a30-c061-44bc-89eb-5c8a19d3ed2a", "label": "摘要4", "info": "，在大多数情况下，", "keywords": "在大多数情况下", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d336a35c-a34b-4fb9-a5d5-8809625eaf7d", "label": "摘要5", "info": "优化算法可以定义为求解代价函数梯度为零的正规方程。", "keywords": "优化算法可以定义为求解代价函数梯度为零的正规方程", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3345b7e8-10d1-43e0-8421-b24e86118252", "label": "摘要6", "info": "意识到可以替换独立于其他组件的大多数组件，因此我们能得到很多不；同的算法。", "keywords": "意识到可以替换独立于其他组件的大多数组件, 因此我们能得到很多不, 同的算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "144d0fda-acf2-410f-a9ec-1f1b80961e33", "label": "摘要7", "info": "通常代价函数至少含有一项使学习过程进行统计估计的成分。最常见的；代价函数是负对数似然，最小化代价函数导致的最大似然估计。", "keywords": "通常代价函数至少含有一项使学习过程进行统计估计的成分, 最小化代价函数导致的最大似然估计, 代价函数是负对数似然, 最常见的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b0f11199-1dc3-4d04-a2f0-944ba1e07a0b", "label": "摘要8", "info": "代价函数也可能含有附加项，如正则化。例如，我们可以将权重衰减加；到线性回归的代价函数中", "keywords": "我们可以将权重衰减加, 代价函数也可能含有附加项, 例如, 到线性回归的代价函数中, 如正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7f066d66-0f2d-47c8-9f57-6d538dea1c2f", "label": "摘要9", "info": "该优化仍然有闭解。", "keywords": "该优化仍然有闭解", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "195fc0e3-0fdd-4c67-94d2-cc4cc533a51f", "label": "摘要10", "info": "如果我们将该模型变成非线性的，那么大多数代价函数不再能通过闭解；优化。这就要求我们选择一个迭代数值优化过程，如梯度下降等。", "keywords": "这就要求我们选择一个迭代数值优化过程, 如梯度下降等, 如果我们将该模型变成非线性的, 那么大多数代价函数不再能通过闭解, 优化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "557d1f38-c890-4a5b-bb47-f629165616f7", "label": "摘要11", "info": "组合模型、代价和优化算法来构建学习算法的配方同时适用于监督学习；和无监督学习。线性回归示例说明了如何适用于监督学习的。无监督学；习时，我们需要定义一个只包含 X 的数据集、一个合适的无监督代价和", "keywords": "线性回归示例说明了如何适用于监督学习的, 无监督学, 代价和优化算法来构建学习算法的配方同时适用于监督学习, 和无监督学习, 一个合适的无监督代价和", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "94ccbf04-b7a3-4f17-922d-779f23994582", "label": "摘要12", "info": "模型定义为重构函数", "keywords": "模型定义为重构函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3d2203d8-7e9e-47ab-9f17-239fdeee6da5", "label": "摘要13", "info": "，并且 w 有范数为1的限制。", "keywords": "并且, 有范数为, 的限制", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f16ba6c1-1797-4486-a916-6c2ede6b4fc9", "label": "摘要14", "info": "在某些情况下，由于计算原因，我们不能实际计算代价函数。在这种情；况下，只要有近似其梯度的方法，那么我们仍然可以使用迭代数值优化；近似最小化目标。", "keywords": "在这种情, 只要有近似其梯度的方法, 况下, 我们不能实际计算代价函数, 那么我们仍然可以使用迭代数值优化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "122ca4f9-ea3f-4d7f-9248-352b47fb83e5", "label": "摘要15", "info": "尽管有时候不明显，但大多数学习算法都用到了上述配方。如果一个机；器学习算法看上去特别独特或是手动设计的，那么通常需要使用特殊的；优化方法进行求解。有些模型，如决策树或k-均值，需要特殊的优化，", "keywords": "需要特殊的优化, 尽管有时候不明显, 那么通常需要使用特殊的, 但大多数学习算法都用到了上述配方, 优化方法进行求解", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "20700a5f-717e-4042-81ee-50701a67c98b", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；一长串各个不同的算法。", "keywords": "一长串各个不同的算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "96695315-3329-4e73-ab3e-c060814a12f9", "label": "5.11：促使深度学习发展的挑战", "level": 2, "group": "chapter-5", "type": "子章節"}, {"id": "b91833c7-1a13-4b2c-bd50-b49a46080163", "label": "摘要1", "info": "5.11.1　维数灾难", "keywords": "维数灾难", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "24ff0377-e01b-4308-b62e-9ef2fe36263c", "label": "摘要2", "info": "5.11.2　局部不变性和平滑正则化", "keywords": "局部不变性和平滑正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "9f2056e1-d0d7-451e-a4eb-3dd0e83dfee7", "label": "摘要3", "info": "5.11.3　流形学习", "keywords": "流形学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6fa88cb8-82b4-4341-83c3-9bfd6130e6bb", "label": "摘要4", "info": "第2部分　深度网络：现代实践", "keywords": "深度网络, 现代实践, 部分", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "a0d2f88f-be01-4967-a84f-aaada7c08b02", "label": "摘要5", "info": "本章描述的简单机器学习算法在很多不同的重要问题上效果都良好，但；是它们不能成功解决人工智能中的核心问题，如语音识别或者对象识；别。", "keywords": "如语音识别或者对象识, 是它们不能成功解决人工智能中的核心问题, 本章描述的简单机器学习算法在很多不同的重要问题上效果都良好", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "97f5d25a-6808-4ab2-ad05-b9d32cffac04", "label": "摘要6", "info": "促使深度学习发展的一部分原因是传统学习算法在这类人工智能问题上；泛化能力不足。", "keywords": "促使深度学习发展的一部分原因是传统学习算法在这类人工智能问题上, 泛化能力不足", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6b127fa1-0ffc-41df-9596-e9558131338e", "label": "摘要7", "info": "本节介绍为何处理高维数据时在新样本上泛化特别困难，以及为何在传；统机器学习中实现泛化的机制不适合学习高维空间中复杂的函数。这些；空间经常涉及巨大的计算代价，深度学习旨在克服这些以及其他一些难", "keywords": "统机器学习中实现泛化的机制不适合学习高维空间中复杂的函数, 本节介绍为何处理高维数据时在新样本上泛化特别困难, 深度学习旨在克服这些以及其他一些难, 这些, 空间经常涉及巨大的计算代价", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3674b618-e241-4578-aead-f45f4454a45d", "label": "摘要8", "info": "5.11.1　维数灾难", "keywords": "维数灾难", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ae8fd9bf-3dcb-40a7-8dea-5b0970e61f69", "label": "摘要9", "info": "当数据的维数很高时，很多机器学习问题变得相当困难。这种现象被称；为维数灾难  （curse  of  dimensionality）。特别值得注意的是，一组变量；不同的可能配置数量会随着变量数目的增加而指数级增长。", "keywords": "为维数灾难, 这种现象被称, 不同的可能配置数量会随着变量数目的增加而指数级增长, 很多机器学习问题变得相当困难, 特别值得注意的是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "7a13d620-2b4b-4e85-96d8-abd0aa5d046c", "label": "摘要10", "info": "维数灾难发生在计算机科学的许多地方，在机器学习中尤其如此。", "keywords": "维数灾难发生在计算机科学的许多地方, 在机器学习中尤其如此", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0834a4de-e25b-4de7-b5b8-0ad6405b1e9c", "label": "摘要11", "info": "由维数灾难带来的一个挑战是统计挑战。如图5.9所示，统计挑战产生；于 x 的可能配置数目远大于训练样本的数目。为了充分理解这个问题，；我们假设输入空间如图所示被分成网格。低维时，我们可以用由数据占", "keywords": "统计挑战产生, 我们可以用由数据占, 所示, 由维数灾难带来的一个挑战是统计挑战, 我们假设输入空间如图所示被分成网格", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bdcadbef-b98f-4ee6-b071-fb8e8f673eb2", "label": "摘要12", "info": "最接近的训练点的输出相同。", "keywords": "最接近的训练点的输出相同", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4a4b4ab7-17a3-40fb-8f9d-0f20594a1144", "label": "摘要13", "info": "图5.9　当数据的相关维度增大时（从左向右），我们感兴趣的配置数目会随之指数级增长。；（左）在这个一维的例子中，我们用一个变量来区分所感兴趣的仅仅10个区域。当每个区域都；有足够的样本数时（图中每个样本对应了一个细胞），学习算法能够轻易地泛化得很好。泛化", "keywords": "我们用一个变量来区分所感兴趣的仅仅, 图中每个样本对应了一个细胞, 当数据的相关维度增大时, 个区域, 有足够的样本数时", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "095c90bd-726a-4361-a518-b50b06117dff", "label": "摘要14", "info": "5.11.2　局部不变性和平滑正则化", "keywords": "局部不变性和平滑正则化", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5bd52e85-d149-46b0-ac75-a62a566a50bf", "label": "摘要15", "info": "为了更好地泛化，机器学习算法需要由先验信念引导应该学习什么类型；的函数。此前，我们已经看到过由模型参数的概率分布形成的先验。通；俗地讲，我们也可以说先验信念直接影响函数本身，而仅仅通过它们对", "keywords": "机器学习算法需要由先验信念引导应该学习什么类型, 而仅仅通过它们对, 的函数, 我们也可以说先验信念直接影响函数本身, 此前", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "70fdeb7f-3352-4f9e-a627-288c93031613", "label": "摘要16", "info": "其中使用最广泛的隐式“先验”是平滑先验 （smoothness prior），或局部；不变性先验  （local  constancy  prior）。这个先验表明我们学习的函数不；应在小区域内发生很大的变化。", "keywords": "应在小区域内发生很大的变化, 或局部, 其中使用最广泛的隐式, 不变性先验, 这个先验表明我们学习的函数不", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "d298060a-9461-49ef-9fb7-9ce70791c387", "label": "摘要17", "info": "许多简单算法完全依赖于此先验达到良好的泛化，其结果是不能推广去；解决人工智能级别任务中的统计挑战。本书中，我们将介绍深度学习如；何引入额外的（显式或隐式的）先验去降低复杂任务中的泛化误差。这", "keywords": "显式或隐式的, 解决人工智能级别任务中的统计挑战, 许多简单算法完全依赖于此先验达到良好的泛化, 其结果是不能推广去, 何引入额外的", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3c2cc706-f576-4973-ab1a-5c30ac8c4188", "label": "摘要18", "info": "有许多不同的方法来显式或隐式地表示学习函数应该具有光滑或局部不", "keywords": "有许多不同的方法来显式或隐式地表示学习函数应该具有光滑或局部不", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "122f9d78-31b9-46dd-9ae1-3a538b68b922", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；变的先验。所有这些不同的方法都旨在鼓励学习过程能够学习出函数f  ∗；对于大多数设置 x 和小变动  ，都满足条件", "keywords": "变的先验, 所有这些不同的方法都旨在鼓励学习过程能够学习出函数, 对于大多数设置, 都满足条件, 和小变动", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eed0d7d2-1723-4e52-821a-980492f2d13d", "label": "摘要20", "info": "换言之，如果我们知道对应输入 x 的答案（例如， x 是个有标签的训练；样本），那么该答案对于 x 的邻域应该也适用。如果在有些邻域中我们；有几个好答案，那么我们可以组合它们（通过某种形式的平均或插值", "keywords": "的邻域应该也适用, 有几个好答案, 样本, 换言之, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b1d30e90-e1cd-4797-9dc9-5923d58fa343", "label": "摘要21", "info": "局部不变方法的一个极端例子是k-最近邻系列的学习算法。当一个区域；里的所有点  x  在训练集中的k个最近邻是一样的，那么对这些点的预测；也是一样的。当k=1时，不同区域的数目不会比训练样本还多。", "keywords": "个最近邻是一样的, 在训练集中的, 当一个区域, 局部不变方法的一个极端例子是, 最近邻系列的学习算法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "693be4d0-8cd5-4aec-b0b7-b9c742a4793f", "label": "摘要22", "info": "虽然k-最近邻算法复制了附近训练样本的输出，大部分核机器也是在和；附近训练样本相关的训练集输出上插值。一类重要的核函数是局部核；（local kernel），其核函数k（ u，ν ）在  u=ν 时很大，当u和ν距离拉大", "keywords": "最近邻算法复制了附近训练样本的输出, 大部分核机器也是在和, 距离拉大, 虽然, 附近训练样本相关的训练集输出上插值", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "60289330-3772-46eb-830f-6f471bb88235", "label": "摘要23", "info": "决策树也有平滑学习的局限性，因为它将输入空间分成和叶节点一样多；的区间，并在每个区间使用单独的参数（或者有些决策树的拓展有多个；参数）。如果目标函数需要至少拥有n个叶节点的树才能精确表示，那", "keywords": "或者有些决策树的拓展有多个, 参数, 如果目标函数需要至少拥有, 个叶节点的树才能精确表示, 并在每个区间使用单独的参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "45707e77-c270-4cdd-8475-21f54fe261a6", "label": "摘要24", "info": "总的来说，区分输入空间中O(k)个区间，所有的这些方法需要O(k)个样；本。通常会有O(k)个参数，O(1)参数对应于O(k)区间之一。最近邻算法；中，每个训练样本至多用于定义一个区间，如图5.10所示。", "keywords": "最近邻算法, 所示, 参数对应于, 个区间, 个参数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e25eead2-b731-449a-9046-c193c79e3fb3", "label": "摘要25", "info": "图5.10　最近邻算法如何划分输入空间的示例。每个区域内的一个样本（这里用圆圈表示）定；义了区域边界（这里用线表示）。每个样本相关的y值定义了对应区域内所有数据点的输出。由；最近邻定义并且匹配几何模式的区域被称为Voronoi图。这些连续区域的数量不会比训练样本的", "keywords": "值定义了对应区域内所有数据点的输出, 这里用圆圈表示, 这些连续区域的数量不会比训练样本的, 最近邻算法如何划分输入空间的示例, 这里用线表示", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c22e8e2e-947e-467d-b7a7-8849981c8256", "label": "摘要26", "info": "有没有什么方法能表示区间数目比训练样本数目还多的复杂函数？显；然，只是假设函数的平滑性不能做到这点。例如，想象目标函数作用在；西洋跳棋盘上。棋盘包含许多变化，但只有一个简单的结构。想象一", "keywords": "棋盘包含许多变化, 只是假设函数的平滑性不能做到这点, 但只有一个简单的结构, 有没有什么方法能表示区间数目比训练样本数目还多的复杂函数, 例如", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "29e10ba0-f19b-40d2-a161-c5e3a236ad5d", "label": "摘要27", "info": "只要在要学习的真实函数的峰值和谷值处有足够多的样本，那么平滑性；假设和相关的无参数学习算法的效果都非常好。当要学习的函数足够平；滑，并且只在少数几维变化时，这样做一般没问题。在高维空间中，即", "keywords": "这样做一般没问题, 并且只在少数几维变化时, 假设和相关的无参数学习算法的效果都非常好, 只要在要学习的真实函数的峰值和谷值处有足够多的样本, 当要学习的函数足够平", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c3a95e55-c6ee-4d87-8210-cbffcd8c0d00", "label": "摘要28", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；这些问题，即是否可以有效地表示复杂的函数以及所估计的函数是否可；以很好地泛化到新的输入，答案是有的。关键观点是，只要我们通过额", "keywords": "这些问题, 只要我们通过额, 即是否可以有效地表示复杂的函数以及所估计的函数是否可, 答案是有的, 关键观点是", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f3cb5284-2e1d-4fa9-874f-a356fee784d9", "label": "摘要29", "info": "一些其他的机器学习方法往往会提出更强的、针对特定问题的假设。例；如，假设目标函数是周期性的，我们很容易解决棋盘问题。通常，神经；网络不会包含这些很强的（针对特定任务的）假设，因此神经网络可以", "keywords": "针对特定问题的假设, 一些其他的机器学习方法往往会提出更强的, 通常, 针对特定任务的, 神经", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "e3017152-fd41-416b-82cf-0f96c0607a2e", "label": "摘要30", "info": "5.11.3　流形学习", "keywords": "流形学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "03b7d849-be74-44a6-a2e3-20066d45fd41", "label": "摘要31", "info": "流形是一个机器学习中很多想法内在的重要概念。", "keywords": "流形是一个机器学习中很多想法内在的重要概念", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "0799cf0a-381c-4b3d-b899-8c5f6c76a27c", "label": "摘要32", "info": "流形  （manifold）指连接在一起的区域。数学上，它是指一组点，且每；个点都有其邻域。给定一个任意的点，其流形局部看起来像是欧几里得；空间。日常生活中，我们将地球视为二维平面，但实际上它是三维空间", "keywords": "它是指一组点, 但实际上它是三维空间, 数学上, 给定一个任意的点, 其流形局部看起来像是欧几里得", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bb1c4e5b-bd9c-48e9-85f5-4adc1e6fd5c5", "label": "摘要33", "info": "每个点周围邻域的定义暗示着存在变换能够从一个位置移动到其邻域位；置。例如在地球表面这个流形中，我们可以朝东南西北走。", "keywords": "例如在地球表面这个流形中, 每个点周围邻域的定义暗示着存在变换能够从一个位置移动到其邻域位, 我们可以朝东南西北走", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "b8c7eace-e5b5-4237-9963-fa7a8d189c71", "label": "摘要34", "info": "尽管术语“流形”有正式的数学定义，但是机器学习倾向于更松散地定义；一组点，只需要考虑少数嵌入在高维空间中的自由度或维数就能很好地；近似。每一维都对应着局部的变化方向。如图5.11所示，训练数据位于", "keywords": "有正式的数学定义, 所示, 每一维都对应着局部的变化方向, 训练数据位于, 如图", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "57a47a45-5ee3-429e-a507-6894465996a0", "label": "摘要35", "info": "点到另一个点有所变化。这经常发生于流形和自身相交的情况中。例；如，数字“8”形状的流形在大多数位置只有一维，但在中心的相交处有；两维。", "keywords": "但在中心的相交处有, 点到另一个点有所变化, 这经常发生于流形和自身相交的情况中, 两维, 数字", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "941f58f1-fc06-45c8-8a61-c96064ca02a5", "label": "摘要36", "info": "图5.11　从一个二维空间的分布中抽取的数据样本，这些样本实际上聚集在一维流形附近，像；一个缠绕的带子。实线代表学习器应该推断的隐式流形", "keywords": "一个缠绕的带子, 这些样本实际上聚集在一维流形附近, 实线代表学习器应该推断的隐式流形, 从一个二维空间的分布中抽取的数据样本", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c5acc865-3af8-4ca8-b8ba-fe29ecb08898", "label": "摘要37", "info": "如果我们希望机器学习算法学习整个；上有趣变化的函数，那么很；多机器学习问题看上去都是无望的。流形学习  （manifold  learning）算", "keywords": "多机器学习问题看上去都是无望的, 流形学习, 如果我们希望机器学习算法学习整个, 那么很, 上有趣变化的函数", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "853f984c-0caf-4a3f-ac23-ff46f9b52682", "label": "摘要38", "info": "数据位于低维流形的假设并不总是对的或者有用的。我们认为在人工智；能的一些场景中，如涉及处理图像、声音或者文本时，流形假设至少是；近似对的。这个假设的支持证据包含两类观察结果。", "keywords": "数据位于低维流形的假设并不总是对的或者有用的, 能的一些场景中, 流形假设至少是, 近似对的, 声音或者文本时", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "bdfb8335-5e7c-4516-9f26-e11f4d2e0cf0", "label": "摘要39", "info": "第一个支持流形假设  （manifold  hypothesis）的观察是现实生活中的图；像、文本、声音的概率分布都是高度集中的。均匀的噪声从来不会与这；类领域的结构化输入类似。图5.12显示均匀采样的点看上去像是没有信", "keywords": "的观察是现实生活中的图, 类领域的结构化输入类似, 显示均匀采样的点看上去像是没有信, 第一个支持流形假设, 均匀的噪声从来不会与这", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "095812c6-b13c-4188-b1d0-9c4356ccae36", "label": "摘要40", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；大部分字母长序列不对应着自然语言序列：自然语言序列的分布只占了；字母序列的总空间里非常小的一部分。", "keywords": "大部分字母长序列不对应着自然语言序列, 字母序列的总空间里非常小的一部分, 自然语言序列的分布只占了", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6819fbef-e8dd-405b-9022-7c582127243c", "label": "摘要41", "info": "图5.12　随机地均匀抽取图像（根据均匀分布随机地选择每一个像素）会得到噪声图像。尽管；在人工智能应用中以这种方式生成一个脸或者其他物体的图像是非零概率的，但是实际上我们；从来没有观察到这种现象。这也意味着人工智能应用中遇到的图像在所有图像空间中的占比可", "keywords": "但是实际上我们, 从来没有观察到这种现象, 随机地均匀抽取图像, 根据均匀分布随机地选择每一个像素, 会得到噪声图像", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8b8cdee7-c636-497d-bd87-1289ebccabbc", "label": "摘要42", "info": "当然，集中的概率分布不足以说明数据位于一个相当小的流形中。我们；还必须确保，所遇到的样本和其他样本相互连接，每个样本被其他高度；相似的样本包围，而这些高度相似的样本可以通过变换来遍历该流形得", "keywords": "而这些高度相似的样本可以通过变换来遍历该流形得, 还必须确保, 我们, 相似的样本包围, 所遇到的样本和其他样本相互连接", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "02260513-9ab1-4e76-8c6d-6fb2447d60d9", "label": "摘要43", "info": "到。支持流形假设的第二个论点是，我们至少能够非正式地想象这些邻；域和变换。在图像中，我们当然会认为有很多可能的变换仍然允许我们；描绘出图片空间的流形：我们可以逐渐变暗或变亮光泽、逐步移动或旋", "keywords": "我们至少能够非正式地想象这些邻, 我们可以逐渐变暗或变亮光泽, 逐步移动或旋, 在图像中, 我们当然会认为有很多可能的变换仍然允许我们", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f7d41838-e141-4718-b8e2-6ecbeedd761f", "label": "摘要44", "info": "这些支持流形假设的思维实验传递了一些支持它的直观理由。更严格的；实验（Cayton，2005；Narayanan  and  Mitter，2010；Schölkopf  et  al.  ，；1998a；Roweis  and  Saul，2000；Tenenbaum  et  al.  ，2000；Brand，", "keywords": "这些支持流形假设的思维实验传递了一些支持它的直观理由, 更严格的, 实验", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "c6570c38-adde-48eb-8d39-444bfa2387f8", "label": "摘要45", "info": "and  Niyogi，2003b；Donoho", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "05b09a6d-0c05-4436-8b4d-3edadec921a0", "label": "摘要46", "info": "中的坐标表示；当数据位于低维流形中时，使用流形中的坐标而非；机器学习数据更为自然。日常生活中，我们可以认为道路是嵌入在三维", "keywords": "机器学习数据更为自然, 中的坐标表示, 当数据位于低维流形中时, 使用流形中的坐标而非, 我们可以认为道路是嵌入在三维", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "31e3d4c3-4294-40f3-8501-048db2a8f282", "label": "摘要47", "info": "图5.13　QMUL Multiview Face数据集中的训练样本（Gong et al. ，2000），其中的物体是移动；的，从而覆盖对应两个旋转角度的二维流形。我们希望学习算法能够发现并且理出这些流形坐；标。图20.6提供了这样一个示例", "keywords": "提供了这样一个示例, 我们希望学习算法能够发现并且理出这些流形坐, 其中的物体是移动, 数据集中的训练样本, 从而覆盖对应两个旋转角度的二维流形", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "8590f3e8-102a-41e6-9a0a-379579686878", "label": "摘要48", "info": "本书第1部分介绍了数学和机器学习中的基本概念，这将用于本书其他", "keywords": "本书第, 这将用于本书其他, 部分介绍了数学和机器学习中的基本概念", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "87fb041f-0f76-4dca-9bab-db3b413cd417", "label": "摘要49", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；章节中。至此，我们已经做好了研究深度学习的准备。", "keywords": "章节中, 我们已经做好了研究深度学习的准备, 至此", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f5c5d21a-8375-4fbe-bb6a-a3520e922a74", "label": "摘要50", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "1eabacd9-2f9a-494b-9969-20c9f12caf9f", "label": "摘要51", "info": "(1)", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "03d14f59-3554-470a-b80e-c5dc518d1617", "label": "摘要52", "info": "除非有理由使用协方差矩阵的特定结构，我们通常假设其为对角协方差矩阵", "keywords": "除非有理由使用协方差矩阵的特定结构, 我们通常假设其为对角协方差矩阵", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "eef1ff56-65e1-4e78-bf1a-9af4b0ea20df", "label": "摘要53", "info": "。", "keywords": "", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "72a42edd-923d-4368-bae8-6a0c9d4653b9", "label": "摘要54", "info": "第2部分　深度网络：现代实践", "keywords": "深度网络, 现代实践, 部分", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "4f3192d5-7926-4ff0-9996-abef6e4b3154", "label": "摘要55", "info": "本书这一部分总结了现代深度学习用于解决实际应用的现状。", "keywords": "本书这一部分总结了现代深度学习用于解决实际应用的现状", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "2c1229c8-9130-4a1c-9aa8-1eb585df1191", "label": "摘要56", "info": "深度学习有着悠久的历史和许多愿景。数种提出的方法尚未完全结出果；实，数个雄心勃勃的目标尚未实现。这些较不发达的深度学习分支将出；现在本书的最后一部分。", "keywords": "数种提出的方法尚未完全结出果, 数个雄心勃勃的目标尚未实现, 深度学习有着悠久的历史和许多愿景, 这些较不发达的深度学习分支将出, 现在本书的最后一部分", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "6b9f3e6c-dc93-457f-b42b-72b9a1940411", "label": "摘要57", "info": "本书的第2部分仅关注那些基本上已在工业中大量使用的技术方法。", "keywords": "本书的第, 部分仅关注那些基本上已在工业中大量使用的技术方法", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5136ed32-e782-487c-bcd0-5e6d00fbe3b2", "label": "摘要58", "info": "现代深度学习为监督学习提供了一个强大的框架。通过添加更多层以及；向层内添加更多单元，深度网络可以表示复杂性不断增加的函数。给定；足够大的模型和足够大的标注训练数据集，我们可以通过深度学习将输", "keywords": "足够大的模型和足够大的标注训练数据集, 通过添加更多层以及, 深度网络可以表示复杂性不断增加的函数, 现代深度学习为监督学习提供了一个强大的框架, 向层内添加更多单元", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "174ac5c1-b3dd-4641-a1e0-be76e894905d", "label": "摘要59", "info": "本书这一部分描述参数化函数近似技术的核心，几乎所有现代实际应用；的深度学习背后都用到了这一技术。首先，我们描述用于表示这些函数；的前馈深度网络模型。其次，我们提出正则化和优化这种模型的高级技", "keywords": "其次, 我们描述用于表示这些函数, 几乎所有现代实际应用, 的前馈深度网络模型, 的深度学习背后都用到了这一技术", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "5ac914a5-acf1-4bed-a15c-e0e2e6f2e95b", "label": "摘要60", "info": "这些章节对于从业者来说是最重要的，也就是说，现在想开始实现和使；用深度学习算法解决现实问题的人需要阅读这些章节。", "keywords": "这些章节对于从业者来说是最重要的, 现在想开始实现和使, 也就是说, 用深度学习算法解决现实问题的人需要阅读这些章节", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "05af3740-eabf-4c25-89d3-789ec64f4cd9", "label": "摘要61", "info": "5.11.1　维数灾难", "keywords": "维数灾难", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "3797bcfd-1504-47f9-b769-a2d3bd0aac4a", "label": "摘要62", "info": "5.11.2　局部不变性和平；滑正则化", "keywords": "滑正则化, 局部不变性和平", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "f53385b4-1aa8-4f7a-9b33-92a4658f1680", "label": "摘要63", "info": "5.11.3　流形学习", "keywords": "流形学习", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "47b5fbdc-2a33-4d6c-8e4a-35b9b92d1e87", "label": "摘要64", "info": "第2部分　深度网络：现代实践", "keywords": "深度网络, 现代实践, 部分", "level": 3, "group": "chapter-5", "type": "段落"}, {"id": "ad95293b-2053-494b-b756-6b098a23365b", "label": "第6章：深度前馈网络", "level": 1, "group": "chapter-6", "type": "章節"}, {"id": "be1dd31f-9152-4934-a0c1-2658826c64c7", "label": "5.11：促使深度学习发展的挑战", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "0cdb6494-5b68-4c04-8c31-e09d1eca4a82", "label": "摘要1", "info": "feedforward  network），也叫作前馈神经网络；net-work）或者多层感知机  （multilayer", "keywords": "或者多层感知机, 也叫作前馈神经网络", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "74ab56e0-f43d-4b5d-af07-2be792d67564", "label": "摘要2", "info": "深度前馈网络  （deep；（feedforward；neural", "keywords": "深度前馈网络", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "55d32a00-5e4e-4a4c-9439-c05bb9f7d6aa", "label": "摘要3", "info": "将输入  x  映射到一个；，并且学习参数  θ  的", "keywords": "将输入, 映射到一个, 并且学习参数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "78d2f9de-b248-43fc-b144-d23f6fe55e74", "label": "摘要4", "info": "这种模型被称为前向 （feedforward）的，是因为信息流过 x 的函数，流；经用于定义f的中间计算过程，最终到达输出  y  。在模型的输出和模型；本身之间没有反馈  （feedback）连接。当前馈神经网络被扩展成包含反", "keywords": "最终到达输出, 经用于定义, 连接, 当前馈神经网络被扩展成包含反, 的函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fb350cd6-1d94-4d86-be62-368c2323e63e", "label": "摘要5", "info": "前馈网络对于机器学习的从业者是极其重要的。它们是许多重要商业应；用的基础。例如，用于对照片中的对象进行识别的卷积神经网络就是一；种专门的前馈网络。前馈网络是通往循环网络之路的概念基石，后者在", "keywords": "用于对照片中的对象进行识别的卷积神经网络就是一, 后者在, 例如, 前馈网络是通往循环网络之路的概念基石, 种专门的前馈网络", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c6303703-b0e1-45b3-967f-31bdc24d687c", "label": "摘要6", "info": "前馈神经网络之所以被称作网络  （network），是因为它们通常用许多；不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描；述了函数是如何复合在一起的。例如，我们有三个函数f  (1) 、f  (2)  和f  (3)", "keywords": "而图描, 该模型与一个有向无环图相关联, 前馈神经网络之所以被称作网络, 述了函数是如何复合在一起的, 例如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d5aecbc2-b1cf-45c6-bd3b-ba8b52fc6e36", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；必须决定如何使用这些层来最好地实现f * 的近似。因为训练数据并没有；给出这些层中的每一层所需的输出，所以这些层被称为隐藏层  （hidden", "keywords": "的近似, 因为训练数据并没有, 给出这些层中的每一层所需的输出, 所以这些层被称为隐藏层, 必须决定如何使用这些层来最好地实现", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7fe00d37-78c5-431f-88e2-d5e28b31b973", "label": "摘要8", "info": "最后，这些网络之所以被称为神经网络，是因为它们或多或少地受到神；经科学的启发。网络中的每个隐藏层通常都是向量值的。这些隐藏层的；维数决定了模型的宽度  （width）。向量的每个元素都可以被视为起到", "keywords": "向量的每个元素都可以被视为起到, 这些网络之所以被称为神经网络, 经科学的启发, 维数决定了模型的宽度, 是因为它们或多或少地受到神", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "94a09c93-58fa-43a0-8cde-40c09acf3ea5", "label": "摘要9", "info": "一种理解前馈网络的方式是从线性模型开始，并考虑如何克服它的局限；性。线性模型，例如逻辑回归和线性回归，是非常吸引人的，因为无论；是通过闭解形式还是使用凸优化，它们都能高效且可靠地拟合。线性模", "keywords": "线性模型, 线性模, 例如逻辑回归和线性回归, 是通过闭解形式还是使用凸优化, 是非常吸引人的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4e9244fe-81fc-49a3-b4da-bbd5dfc8999c", "label": "摘要10", "info": "为了扩展线性模型来表示 x 的非线性函数，我们可以不把线性模型用于；x  本身，而是用在一个变换后的输入φ(  x  )上，这里φ是一个非线性变；换。同样，我们可以使用第5.7.2节中描述的核技巧，来得到一个基于隐", "keywords": "本身, 的非线性函数, 节中描述的核技巧, 是一个非线性变, 这里", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "50465555-f79c-47d1-a7a2-e10d0bbcb00b", "label": "摘要11", "info": "剩下的问题就是如何选择映射φ。", "keywords": "剩下的问题就是如何选择映射", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "21017dee-ace2-4131-b610-1b5fa6bb8557", "label": "摘要12", "info": "（1）其中一种选择是使用一个通用的φ，例如无限维的φ，它隐含地用；在基于RBF核的核机器上。如果φ( x )具有足够高的维数，我们总是有足；够的能力来拟合训练集，但是对于测试集的泛化往往不佳。非常通用的", "keywords": "如果, 非常通用的, 它隐含地用, 其中一种选择是使用一个通用的, 在基于", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2efdd158-223a-4315-bc84-ba0ab807933e", "label": "摘要13", "info": "编码来解决高级问题。", "keywords": "编码来解决高级问题", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8ac6a260-a479-42c2-8cf2-a849a5aa096c", "label": "摘要14", "info": "（2）另一种选择是手动地设计φ。在深度学习出现以前，这一直是主流；的方法。这种方法对于每个单独的任务都需要人们数十年的努力，从业；者各自擅长特定的领域（如语音识别或计算机视觉），并且不同领域之", "keywords": "者各自擅长特定的领域, 另一种选择是手动地设计, 如语音识别或计算机视觉, 这种方法对于每个单独的任务都需要人们数十年的努力, 这一直是主流", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3fc78889-39bb-4fc1-a4c9-f197aa379a23", "label": "摘要15", "info": "（3）深度学习的策略是去学习φ。在这种方法中，我们有一个模型", "keywords": "在这种方法中, 深度学习的策略是去学习, 我们有一个模型", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b1b9301a-058e-47d3-a536-3cf6937deb77", "label": "摘要16", "info": "。我们现在有两种参数：用于；从一大类函数中学习φ的参数 θ  ，以及用于将φ( x )映射到所需的输出的；参数  w  。这是深度前馈网络的一个例子，其中φ定义了一个隐藏层。这", "keywords": "的参数, 参数, 以及用于将, 从一大类函数中学习, 映射到所需的输出的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fe9407e4-52ed-4587-a565-a6f9001659a3", "label": "摘要17", "info": "这种通过学习特征来改善模型的一般化原则不仅仅适用于本章描述的前；馈神经网络。它是深度学习中反复出现的主题，适用于本书描述的所有；种类的模型。前馈神经网络是这个原则的应用，它学习从 x 到 y 的确定", "keywords": "它学习从, 的确定, 适用于本书描述的所有, 这种通过学习特征来改善模型的一般化原则不仅仅适用于本章描述的前, 前馈神经网络是这个原则的应用", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cd305d57-0b8a-423c-bde4-54a40c52d18b", "label": "摘要18", "info": "本章我们先从前馈网络的一个简单例子说起。接着，我们讨论部署一个；前馈网络所需的每个设计决策。首先，训练一个前馈网络至少需要做和；线性模型同样多的设计决策：选择一个优化模型、代价函数以及输出单", "keywords": "训练一个前馈网络至少需要做和, 前馈网络所需的每个设计决策, 接着, 我们讨论部署一个, 本章我们先从前馈网络的一个简单例子说起", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3438ab78-67b2-484e-bdec-bcd37b101f2d", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；习中需要计算复杂函数的梯度。我们给出反向传播；propagation）算法和它的现代推广，它们可以用来高效地计算这些梯", "keywords": "算法和它的现代推广, 习中需要计算复杂函数的梯度, 我们给出反向传播, 它们可以用来高效地计算这些梯", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "60be9f52-f2de-4c29-be95-63850637e692", "label": "摘要20", "info": "（back", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d85db99f-0b81-450a-8db6-7377238e491e", "label": "6.1：实例：学习XOR", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "b820c62a-508e-47d9-bf34-7622ee14fe39", "label": "摘要1", "info": "为了使前馈网络的想法更加具体，我们首先从一个可以完整工作的前馈；网络说起。这个例子解决一个非常简单的任务：学习XOR函数。", "keywords": "这个例子解决一个非常简单的任务, 函数, 学习, 我们首先从一个可以完整工作的前馈, 网络说起", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5d843b8a-2ae0-41e9-8116-4857241ecc63", "label": "摘要2", "info": "XOR函数（“异或”逻辑）是两个二进制值x  1  和x  2  的运算。当这些二进；制值中恰好有一个为1时，XOR函数返回值为1。其余情况下返回值为；0。XOR函数提供了我们想要学习的目标函数", "keywords": "其余情况下返回值为, 当这些二进, 函数, 制值中恰好有一个为, 异或", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e8a29565-89bc-40b1-8d7f-7c74af7ef4b6", "label": "摘要3", "info": "。我们的模；，并且我们的学习算法会不断调整参", "keywords": "并且我们的学习算法会不断调整参, 我们的模", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "374c0656-6dee-4cc1-a619-5d2ea9ac598a", "label": "摘要4", "info": "在这个简单的例子中，我们不会关心统计泛化。我们希望网络在这4个；点；部这4个点来训练我们的网络，唯一的挑战是拟合训练集。", "keywords": "部这, 唯一的挑战是拟合训练集, 我们希望网络在这, 在这个简单的例子中, 我们不会关心统计泛化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "efa81fd8-f1f1-4b17-b9fc-3afafdb35765", "label": "摘要5", "info": "上表现正确。我们会用全", "keywords": "我们会用全, 上表现正确", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a955c012-cb26-4fd6-a0e2-88a75a0cba04", "label": "摘要6", "info": "我们可以把这个问题当作回归问题，并使用均方误差损失函数。选择这；个损失函数是为了尽可能地简化本例中用到的数学知识。在应用领域，；对于二进制数据建模时，MSE通常并不是一个合适的代价函数。更加合", "keywords": "通常并不是一个合适的代价函数, 在应用领域, 更加合, 对于二进制数据建模时, 我们可以把这个问题当作回归问题", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "760bbec5-0771-424f-8506-d275adf9e70c", "label": "摘要7", "info": "评估整个训练集上表现的MSE代价函数为", "keywords": "评估整个训练集上表现的, 代价函数为", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4f3bbb78-a54a-4cdc-bbef-157d27148933", "label": "摘要8", "info": "我们现在必须要选择模型f  (  x  ;  θ  )的形式。假设选择一个线性模型，  θ；包含 w 和b，那么模型被定义成", "keywords": "包含, 假设选择一个线性模型, 那么模型被定义成, 我们现在必须要选择模型, 的形式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f8cb88dd-321e-445e-9617-ce240cd8ff9b", "label": "摘要9", "info": "我们可以使用正规方程关于 w 和b最小化J( θ )，来得到一个闭式解。", "keywords": "最小化, 来得到一个闭式解, 我们可以使用正规方程关于", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8ec7f48d-afaf-47ab-b529-34c049455778", "label": "摘要10", "info": "解正规方程以后，我们得到  w  ＝0以及；一点都输出0.5。为什么会发生这种事？图6.1演示了线性模型为什么不；能用来表示XOR函数。解决这个问题的其中一种方法是使用一个模型来", "keywords": "解决这个问题的其中一种方法是使用一个模型来, 我们得到, 为什么会发生这种事, 能用来表示, 函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ef6148d1-3ea5-4be1-b15f-08c78d725715", "label": "摘要11", "info": "。线性模型仅仅是在任意", "keywords": "线性模型仅仅是在任意", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d7e07c07-4a3a-4a0e-b839-c04fd5254646", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；学习一个不同的特征空间，在这个空间上线性模型能够表示这个解。", "keywords": "学习一个不同的特征空间, 在这个空间上线性模型能够表示这个解", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "45acb4d5-c9d6-44e5-9859-942381d5abfa", "label": "摘要13", "info": "图6.1　通过学习一个表示来解决XOR问题。图上的粗体数字标明了学得的函数必须在每个点输；出的值。（左）直接应用于原始输入的线性模型不能实现XOR函数。当x 1 ＝0时，模型的输出；必须随着x 2 的增大而增大。当x 1 ＝1时，模型的输出必须随着x 2 的增大而减小。线性模型必", "keywords": "的增大而增大, 图上的粗体数字标明了学得的函数必须在每个点输, 通过学习一个表示来解决, 函数, 模型的输出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "de4f8a28-99b4-4c8f-a33c-18885db7484a", "label": "摘要14", "info": "都映射到了特征空间中的单个点", "keywords": "都映射到了特征空间中的单个点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f9b4bdef-71ba-4ccf-8a41-dfb781f40583", "label": "摘要15", "info": "。线性模型现在可以将函数描述为h 1 增大和h 2 减小。在该示例中，学习特征空；间的动机仅仅是使得模型的能力更大，使得它可以拟合训练集。在更现实的应用中，学习的表；示也可以帮助模型泛化", "keywords": "使得它可以拟合训练集, 在该示例中, 在更现实的应用中, 间的动机仅仅是使得模型的能力更大, 学习特征空", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3810a090-66be-47d7-9874-2cc290576781", "label": "摘要16", "info": "具体来说，我们这里引入一个非常简单的前馈神经网络，它有一层隐藏；层并且隐藏层中包含两个单元，见图6.2中对该模型的解释。这个前馈；网络有一个通过函数", "keywords": "中对该模型的解释, 它有一层隐藏, 见图, 具体来说, 网络有一个通过函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ea2d2b88-572c-446b-a578-c84dbf69539e", "label": "摘要17", "info": "x", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "11be5be3-16ed-4aa0-b381-094803f78b2e", "label": "摘要18", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a0433b44-5125-4c31-920c-6ec62277cc8f", "label": "摘要19", "info": "图6.2　使用两种不同样式绘制的前馈网络的示例。具体来说，这是我们用来解决XOR问题的前；馈网络。它有单个隐藏层，包含两个单元。（左）在这种样式中，我们将每个单元绘制为图中；的一个节点。这种风格是清楚而明确的，但对于比这个例子更大的网络，它可能会消耗太多的", "keywords": "的一个节点, 使用两种不同样式绘制的前馈网络的示例, 馈网络, 它可能会消耗太多的, 这种风格是清楚而明确的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "924c37d0-7a5a-44e6-bd36-efb0dec4e453", "label": "摘要20", "info": "描述从 x 到 h 的映射，用向量 w 描述从 h 到y的映射。当标记这", "keywords": "用向量, 当标记这, 的映射, 描述从", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a951affe-55c8-4c87-bc96-43d96bd1cdf2", "label": "摘要21", "info": "f (1) 应该是哪种函数？线性模型到目前为止都表现不错，让f (1) 也是线性；的似乎很有诱惑力。可惜的是，如果f  (1)  是线性的，那么前馈网络作为；一个整体对于输入仍然是线性的。暂时忽略截距项，假设", "keywords": "的似乎很有诱惑力, 如果, 一个整体对于输入仍然是线性的, 那么前馈网络作为, 是线性的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b5df1d10-a6b9-43fd-b6a7-f7352d7469f3", "label": "摘要22", "info": "。我们可以将这个函数重新表示成", "keywords": "我们可以将这个函数重新表示成", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4825aae4-200e-4214-98bf-23339a71503d", "label": "摘要23", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5616ac54-178f-4dd3-b665-a4ce8de1a0f8", "label": "摘要24", "info": "显然，我们必须用非线性函数来描述这些特征。大多数神经网络通过仿；射变换之后紧跟着一个被称为激活函数的固定非线性函数来实现这个目；标，其中仿射变换由学得的参数控制。我们这里使用这种策略，定义", "keywords": "显然, 定义, 射变换之后紧跟着一个被称为激活函数的固定非线性函数来实现这个目, 其中仿射变换由学得的参数控制, 我们这里使用这种策略", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "38891b7d-8712-4ba6-9ed4-0ccaf7530d6a", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；，其中", "keywords": "其中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fdf2b894-c8bc-4116-abbf-d73c0bce0627", "label": "摘要26", "info": "是线性变换的权重矩阵，  c  是偏；置。此前，为了描述线性回归模型，我们使用权重向量和一个标量的偏；置参数来描述从输入向量到输出标量的仿射变换。现在，因为描述的是", "keywords": "是偏, 因为描述的是, 我们使用权重向量和一个标量的偏, 是线性变换的权重矩阵, 现在", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "47cddc49-3058-417f-ab51-829ad00891ea", "label": "摘要27", "info": "。在现代神经网络中，默认的推荐是使用由激；活函数g(z)＝max{0,z}定义的整流线性单元  （rectified  linear  unit）或者；称为ReLU（Jarrett et al. ，2009b；Nair and Hinton，2010a；Glorot et al.", "keywords": "称为, 活函数, 定义的整流线性单元, 默认的推荐是使用由激, 或者", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ad52cc11-34ff-45d0-846a-009acb74c488", "label": "摘要28", "info": "图6.3　整流线性激活函数。该激活函数是被推荐用于大多数前馈神经网络的默认激活函数。将；此函数用于线性变换的输出将产生非线性变换。然而，函数仍然非常接近线性，在这种意义上；它是具有两个线性部分的分段线性函数。由于整流线性单元几乎是线性的，因此它们保留了许", "keywords": "整流线性激活函数, 它是具有两个线性部分的分段线性函数, 函数仍然非常接近线性, 由于整流线性单元几乎是线性的, 该激活函数是被推荐用于大多数前馈神经网络的默认激活函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "633a9db7-3c5f-48c2-a727-6f4059f38444", "label": "摘要29", "info": "现在可以指明我们的整个网络是", "keywords": "现在可以指明我们的整个网络是", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a97aa2de-445e-4b7c-aad1-0d55f86a47e8", "label": "摘要30", "info": "我们现在可以给出XOR问题的一个解。令", "keywords": "我们现在可以给出, 问题的一个解", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d66e052b-1b04-47ec-8c82-23bdd7ff6858", "label": "摘要31", "info": "以及b＝0。", "keywords": "以及", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a3eac910-8b20-450e-a33a-ddf2c6415e18", "label": "摘要32", "info": "我们现在可以了解这个模型如何处理一批输入。令   表示设计矩阵，；它包含二进制输入空间中全部的四个点，每个样本占一行，那么矩阵表；示为", "keywords": "那么矩阵表, 我们现在可以了解这个模型如何处理一批输入, 示为, 表示设计矩阵, 它包含二进制输入空间中全部的四个点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6db60cb9-cc59-4033-a408-726351cd4781", "label": "摘要33", "info": "神经网络的第一步是将输入矩阵乘以第一层的权重矩阵：", "keywords": "神经网络的第一步是将输入矩阵乘以第一层的权重矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1e935c38-4ed6-4a4a-a4d7-1102fa17f9b2", "label": "摘要34", "info": "然后，我们加上偏置向量 c ，得到", "keywords": "我们加上偏置向量, 得到, 然后", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a8d4f78e-69c0-448d-a271-906163eca1bf", "label": "摘要35", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在这个空间中，所有的样本都处在一条斜率为1的直线上。当我们沿着；这条直线移动时，输出需要从0升到1，然后再降回0。线性模型不能实", "keywords": "升到, 然后再降回, 这条直线移动时, 输出需要从, 当我们沿着", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d616c89b-c93b-477b-8193-f4bf7260cf88", "label": "摘要36", "info": "这个变换改变了样本间的关系。它们不再处于同一条直线上了。如图；6.1所示，它们现在处在一个可以用线性模型解决的空间上。", "keywords": "它们现在处在一个可以用线性模型解决的空间上, 所示, 它们不再处于同一条直线上了, 这个变换改变了样本间的关系, 如图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b4d39445-fbdf-40b0-95ae-24efdbcc97d9", "label": "摘要37", "info": "我们最后乘以一个权重向量 w ：", "keywords": "我们最后乘以一个权重向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3aa41c40-a67a-45ff-968a-9c785bbed4f8", "label": "摘要38", "info": "神经网络对这一批次中的每个样本都给出了正确的结果。", "keywords": "神经网络对这一批次中的每个样本都给出了正确的结果", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d7b524c9-e735-4dbf-ba7d-8c50893f32bb", "label": "摘要39", "info": "在这个例子中，我们简单地指定了解决方案，然后说明它得到的误差为；零。在实际情况中，可能会有数十亿的模型参数以及数十亿的训练样；本，所以不能像我们这里做的那样进行简单地猜解。与之相对的，基于", "keywords": "与之相对的, 我们简单地指定了解决方案, 基于, 所以不能像我们这里做的那样进行简单地猜解, 在这个例子中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "label": "6.2：基于梯度的学习", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "e37eeb1e-ff0d-4d1f-9700-0c0749a83349", "label": "摘要1", "info": "6.2.1　代价函数", "keywords": "代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6655a207-352a-4a48-94cf-6935f01cd175", "label": "摘要2", "info": "6.2.2　输出单元", "keywords": "输出单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b4a4429c-74d7-406d-b37a-7d310e951632", "label": "摘要3", "info": "设计和训练神经网络与使用梯度下降训练其他任何机器学习模型并没有", "keywords": "设计和训练神经网络与使用梯度下降训练其他任何机器学习模型并没有", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1f41573e-7575-4c80-a5bf-6975abf0780a", "label": "摘要4", "info": "太大不同。在第5.10节中，我们描述了如何通过指定一个优化过程、代；价函数和一个模型族来构建一个机器学习算法。", "keywords": "太大不同, 节中, 在第, 价函数和一个模型族来构建一个机器学习算法, 我们描述了如何通过指定一个优化过程", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "86a01d56-ae6c-4755-a853-5158b202424d", "label": "摘要5", "info": "我们到目前为止看到的线性模型和神经网络的最大区别，在于神经网络；的非线性导致大多数我们感兴趣的代价函数都变得非凸。这意味着神经；网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到", "keywords": "在于神经网络, 基于梯度的优化, 网络的训练通常使用迭代的, 仅仅使得代价函数达到, 这意味着神经", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9f960c9d-8a80-4425-98cd-d9637e1c1137", "label": "摘要6", "info": "我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模；型，并且事实上当训练集相当大时这是很常用的。从这一点来看，训练；神经网络和训练其他任何模型并没有太大区别。计算梯度对于神经网络", "keywords": "训练, 神经网络和训练其他任何模型并没有太大区别, 从这一点来看, 我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模, 并且事实上当训练集相当大时这是很常用的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "027f529d-70bb-4d5a-a39b-86ccb8368ee9", "label": "摘要7", "info": "和其他的机器学习模型一样，为了使用基于梯度的学习方法，我们必须；选择一个代价函数，并且必须选择如何表示模型的输出。现在，我们重；温这些设计上的考虑，并且特别强调神经网络的情景。", "keywords": "我们必须, 选择一个代价函数, 和其他的机器学习模型一样, 我们重, 温这些设计上的考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "89b871e6-6a7b-4caa-80cd-d09abf2840a9", "label": "摘要8", "info": "6.2.1　代价函数", "keywords": "代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a9487bea-ae8b-4f37-ab0d-aea0d89c136c", "label": "摘要9", "info": "深度神经网络设计中的一个重要方面是代价函数的选择。幸运的是，神；经网络的代价函数或多或少是和其他的参数模型（例如线性模型的代价；函数）相同的。", "keywords": "函数, 深度神经网络设计中的一个重要方面是代价函数的选择, 幸运的是, 经网络的代价函数或多或少是和其他的参数模型, 例如线性模型的代价", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "04b2660f-40c6-4758-936f-b2126f1804cb", "label": "摘要10", "info": "在大多数情况下，参数模型定义了一个分布p ( y | x ; θ )并且简单地使用", "keywords": "参数模型定义了一个分布, 并且简单地使用, 在大多数情况下", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "79e6272c-09ed-4ad4-9649-10c81c9deb04", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为；代价函数。", "keywords": "最大似然原理, 这意味着我们使用训练数据和模型预测间的交叉熵作为, 代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c1d0b874-bd47-47bf-bf03-5361b7b6ea10", "label": "摘要12", "info": "有时，我们使用一个更简单的方法，不是预测 y  的完整概率分布，而是；仅仅预测在给定 x 的条件下 y 的某种统计量。某些专门的损失函数允许；我们来训练这些估计量的预测器。", "keywords": "不是预测, 而是, 的条件下, 某些专门的损失函数允许, 有时", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a8fa2daf-7932-4e3e-a478-e5a949fac1a2", "label": "摘要13", "info": "用于训练神经网络的完整的代价函数，通常在我们这里描述的基本代价；函数的基础上结合一个正则项。我们已经在第5.2.2节中看到正则化应用；到线性模型中的一些简单的例子。用于线性模型的权重衰减方法也直接", "keywords": "节中看到正则化应用, 用于线性模型的权重衰减方法也直接, 用于训练神经网络的完整的代价函数, 到线性模型中的一些简单的例子, 通常在我们这里描述的基本代价", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ecd6171a-850c-4ba4-be2d-c215dcaa7338", "label": "摘要14", "info": "6.2.1.1　使用最大似然学习条件分布", "keywords": "使用最大似然学习条件分布", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "de7f0614-1632-4c62-9f31-53645aa263b7", "label": "摘要15", "info": "大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负；的对数似然，它与训练数据和模型分布间的交叉熵等价。这个代价函数；表示为", "keywords": "的对数似然, 大多数现代的神经网络使用最大似然来训练, 这个代价函数, 表示为, 这意味着代价函数就是负", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1a95f8c3-426b-4720-9c6c-166f695cbb2e", "label": "摘要16", "info": "代价函数的具体形式随着模型而改变，取决于；的具体形；式。上述方程的展开形式通常会有一些项不依赖于模型的参数，我们可", "keywords": "上述方程的展开形式通常会有一些项不依赖于模型的参数, 取决于, 我们可, 代价函数的具体形式随着模型而改变, 的具体形", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c235ec9e-0143-490e-b2d8-643f4b40d135", "label": "摘要17", "info": "，那么我们就重新得到了", "keywords": "那么我们就重新得到了", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1351ae64-8833-4749-a905-689027bbe788", "label": "摘要18", "info": "均方误差代价：", "keywords": "均方误差代价", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "75a53762-7106-4a16-ba2b-496eaf700d21", "label": "摘要19", "info": "至少系数   和常数项不依赖于  θ  。舍弃的常数是基于高斯分布的方", "keywords": "和常数项不依赖于, 舍弃的常数是基于高斯分布的方, 至少系数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ded52856-aa9e-4123-aa87-937e7d8f9320", "label": "摘要20", "info": "差，在这种情况下，我们选择不把它参数化。之前，我们看到了对输出；分布的最大似然估计和对线性模型均方误差的最小化之间的等价性，但；事实上，这种等价性并不要求f ( x ; θ )用于预测高斯分布的均值。", "keywords": "我们看到了对输出, 事实上, 在这种情况下, 用于预测高斯分布的均值, 分布的最大似然估计和对线性模型均方误差的最小化之间的等价性", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a89d606-ec14-472c-9d31-b6303d387c21", "label": "摘要21", "info": "使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模", "keywords": "使用最大似然来导出代价函数的方法的一个优势是, 它减轻了为每个模", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "09d010af-aa5e-43f8-9841-78576e7c5739", "label": "摘要22", "info": "型设计代价函数的负担。明确一个模型p ( y |  x  )则自动地确定了一个代；价函数logp ( y | x )。", "keywords": "型设计代价函数的负担, 价函数, 明确一个模型, 则自动地确定了一个代", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "158999ab-0698-442b-8a3e-a005b53cde4c", "label": "摘要23", "info": "贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的；大和具有足够的预测性，来为学习算法提供一个好的指引。饱和（变得；非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很", "keywords": "贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的, 变得, 的函数破坏了这一目标, 因为它们把梯度变得非常小, 这在很", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "eb84cb12-8597-434a-aa08-c014d2f49b5c", "label": "摘要24", "info": "用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就；是当它被应用于实践中经常遇到的模型时，它通常没有最小值。对于离；散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表", "keywords": "它通常没有最小值, 散型输出变量, 用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性, 那就, 是当它被应用于实践中经常遇到的模型时", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "07f82526-a7eb-4b21-995e-f1549f5e201d", "label": "摘要25", "info": "6.2.1.2　学习条件统计量", "keywords": "学习条件统计量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9625dd19-62fb-4565-ad6c-6d3bf0d35667", "label": "摘要26", "info": "有时我们并不是想学习一个完整的概率分布p ( y | x ; θ )，而仅仅是想学；习在给定 x 时 y 的某个条件统计量。", "keywords": "有时我们并不是想学习一个完整的概率分布, 的某个条件统计量, 习在给定, 而仅仅是想学", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "56efded3-b146-4119-8a3e-0cd10cb8efbb", "label": "摘要27", "info": "例如，我们可能有一个预测器f ( x ; θ )，想用它来预测 y  的均值。如果；使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一；大类函数中的任何一个函数f，这个类仅仅被一些特征所限制，例如连", "keywords": "如果, 例如连, 这个类仅仅被一些特征所限制, 使用一个足够强大的神经网络, 例如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "df88d151-e034-431d-ba6f-ff044f641375", "label": "摘要28", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；特殊的函数上，这个函数将 x 映射到给定 x 时 y 的期望值。对函数求解；优化问题需要用到变分法 （calculus of variations）这个数学工具，我们", "keywords": "这个函数将, 映射到给定, 优化问题需要用到变分法, 特殊的函数上, 我们", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4c17bc77-5cb4-42b8-8097-d7481f7f88b3", "label": "摘要29", "info": "我们使用变分法导出的第一个结果是解优化问题：", "keywords": "我们使用变分法导出的第一个结果是解优化问题", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1d9f7c71-f7b6-4e8f-aace-eb2ec02ed856", "label": "摘要30", "info": "得到", "keywords": "得到", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2e6b1da5-e8dc-4689-87c3-a00a9d2f2503", "label": "摘要31", "info": "要求这个函数处在我们要优化的类里。换句话说，如果我们能够用无穷；多的、来源于真实的数据生成分布的样本进行训练，最小化均方误差代；价函数将得到一个函数，它可以用来对每个 x 的值预测出 y 的均值。", "keywords": "的值预测出, 来源于真实的数据生成分布的样本进行训练, 最小化均方误差代, 价函数将得到一个函数, 它可以用来对每个", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6abae6d8-f2da-4c59-9e15-44a6bf13a0f3", "label": "摘要32", "info": "不同的代价函数给出不同的统计量。第二个使用变分法得到的结果是", "keywords": "不同的代价函数给出不同的统计量, 第二个使用变分法得到的结果是", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e707393d-d799-468d-9a24-273a4e38dc3f", "label": "摘要33", "info": "将得到一个函数可以对每个 x 预测 y 取值的中位数，只要这个函数在我；们要优化的函数族里。这个代价函数通常被称为平均绝对误差  （mean；absolute error）。", "keywords": "这个代价函数通常被称为平均绝对误差, 取值的中位数, 们要优化的函数族里, 预测, 只要这个函数在我", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c30b3f42-8231-423b-96ba-81a788cd3d73", "label": "摘要34", "info": "可惜的是，均方误差和平均绝对误差在使用基于梯度的优化方法时往往；成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的；梯度。这就是交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的", "keywords": "梯度, 均方误差和平均绝对误差在使用基于梯度的优化方法时往往, 一些饱和的输出单元当结合这些代价函数时会产生非常小的, 可惜的是, 成效不佳", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2bb75895-d0ba-4d58-80ac-e07e2c678033", "label": "摘要35", "info": "6.2.2　输出单元", "keywords": "输出单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "073fe3ee-a397-4a5c-8460-5435c46268bb", "label": "摘要36", "info": "代价函数的选择与输出单元的选择紧密相关。大多数时候，我们简单地；使用数据分布和模型分布间的交叉熵。选择如何表示输出决定了交叉熵；函数的形式。", "keywords": "代价函数的选择与输出单元的选择紧密相关, 使用数据分布和模型分布间的交叉熵, 我们简单地, 函数的形式, 大多数时候", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "684730ed-3632-48bc-8c40-ac7e0f5932e0", "label": "摘要37", "info": "任何可用作输出的神经网络单元，也可以被用作隐藏单元。这里，我们", "keywords": "这里, 任何可用作输出的神经网络单元, 也可以被用作隐藏单元, 我们", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "62bf17c6-9555-4491-a4f9-e6988b45984b", "label": "摘要38", "info": "着重讨论将这些单元用作模型输出时的情况，不过原则上它们也可以在；内部使用。我们将在第6.3节中重温这些单元，并且给出当它们被用作；隐藏单元时一些额外的细节。", "keywords": "隐藏单元时一些额外的细节, 内部使用, 节中重温这些单元, 我们将在第, 着重讨论将这些单元用作模型输出时的情况", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8c1e792a-6887-4460-bf7f-7c30c7d32139", "label": "摘要39", "info": "在本节中，我们假设前馈网络提供了一组定义为h  =f  (  x  ;  θ  )的隐藏特；征。输出层的作用是随后对这些特征进行一些额外的变换来完成整个网；络必须完成的任务。", "keywords": "的隐藏特, 在本节中, 输出层的作用是随后对这些特征进行一些额外的变换来完成整个网, 我们假设前馈网络提供了一组定义为, 络必须完成的任务", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "55c5e0a9-c724-41c0-89a5-9ec265fe2b88", "label": "摘要40", "info": "6.2.2.1　用于高斯输出分布的线性单元", "keywords": "用于高斯输出分布的线性单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "58d297d4-9cdb-436d-808f-bc35a2774cf3", "label": "摘要41", "info": "一种简单的输出单元是基于仿射变换的输出单元，仿射变换不具有非线；性。这些单元往往被直接称为线性单元。", "keywords": "这些单元往往被直接称为线性单元, 仿射变换不具有非线, 一种简单的输出单元是基于仿射变换的输出单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c64f08c7-941d-48a6-9b03-68332c62011a", "label": "摘要42", "info": "给定特征 h ，线性输出单元层产生一个向量", "keywords": "给定特征, 线性输出单元层产生一个向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "769f989b-99b5-429a-ad98-d349c9025273", "label": "摘要43", "info": "线性输出层经常被用来产生条件高斯分布的均值：", "keywords": "线性输出层经常被用来产生条件高斯分布的均值", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "665c557e-aaa7-4d2e-8560-e26a50024a26", "label": "摘要44", "info": "最大化其对数似然此时等价于最小化均方误差。", "keywords": "最大化其对数似然此时等价于最小化均方误差", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7bd51406-c488-48f5-b209-3e76e8eae097", "label": "摘要45", "info": "最大似然框架也使得学习高斯分布的协方差矩阵更加容易，或更容易地；使高斯分布的协方差矩阵作为输入的函数。然而，对于所有输入，协方；差矩阵都必须被限定成一个正定矩阵。线性输出层很难满足这种限定，", "keywords": "差矩阵都必须被限定成一个正定矩阵, 最大似然框架也使得学习高斯分布的协方差矩阵更加容易, 然而, 对于所有输入, 使高斯分布的协方差矩阵作为输入的函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "774a14f7-4090-4527-88ca-f2fb34f27c4b", "label": "摘要46", "info": "因为线性单元不会饱和，所以它们易于采用基于梯度的优化算法，甚至；可以使用其他多种优化算法。", "keywords": "因为线性单元不会饱和, 甚至, 可以使用其他多种优化算法, 所以它们易于采用基于梯度的优化算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8e468879-c6fb-48c1-8401-d8a94139852d", "label": "摘要47", "info": "6.2.2.2　用于Bernoulli输出分布的sigmoid单元", "keywords": "用于, 单元, 输出分布的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0e014b2d-53ab-4b53-a220-58df577216da", "label": "摘要48", "info": "许多任务需要预测二值型变量y的值。具有两个类的分类问题可以归结；为这种形式。", "keywords": "的值, 许多任务需要预测二值型变量, 具有两个类的分类问题可以归结, 为这种形式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1c070dfc-437a-484a-83dc-92d0412a192c", "label": "摘要49", "info": "此时最大似然的方法是定义y在 x 条件下的Bernoulli分布。", "keywords": "条件下的, 此时最大似然的方法是定义, 分布", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "949c11ef-bbae-407d-a13b-41fabdc1f12a", "label": "摘要50", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bernoulli分布仅需单个参数来定义。神经网络只需要预测", "keywords": "分布仅需单个参数来定义, 神经网络只需要预测", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f63b1a68-667e-480b-af92-c99bc1e1aca9", "label": "摘要51", "info": "即可。为了使这个数是有效的概率，它必须处在区间", "keywords": "为了使这个数是有效的概率, 它必须处在区间, 即可", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c08d641f-331a-4750-a1b9-78c695f0bf85", "label": "摘要52", "info": "［0,1］中。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "87eabb2b-1db5-4da1-9083-7c60bd792396", "label": "摘要53", "info": "为满足该约束条件需要一些细致的设计工作。假设我们打算使用线性单；元，并且通过阈值来限制它成为一个有效的概率：", "keywords": "并且通过阈值来限制它成为一个有效的概率, 为满足该约束条件需要一些细致的设计工作, 假设我们打算使用线性单", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f0a10ddf-f89b-43ec-bfb9-8f93f0320211", "label": "摘要54", "info": "这的确定义了一个有效的条件概率分布，但我们无法使用梯度下降来高；效地训练它。当；b处于单位区间外时，模型的输出对其参数的", "keywords": "处于单位区间外时, 效地训练它, 但我们无法使用梯度下降来高, 模型的输出对其参数的, 这的确定义了一个有效的条件概率分布", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "afd68c7e-98db-434c-b945-b5311fb0d5bc", "label": "摘要55", "info": "相反，最好是使用一种新的方法来保证无论何时模型给出了错误的答案；时，总能有一个较大的梯度。这种方法是基于使用sigmoid输出单元结；合最大似然来实现的。", "keywords": "这种方法是基于使用, 输出单元结, 总能有一个较大的梯度, 最好是使用一种新的方法来保证无论何时模型给出了错误的答案, 相反", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "117346ec-fe79-4acc-8eab-c821ea4831a1", "label": "摘要56", "info": "sigmoid输出单元定义为", "keywords": "输出单元定义为", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4d2902d3-498b-4088-866b-5d8b84c864d2", "label": "摘要57", "info": "这里σ是第3.10节中介绍的logistic sigmoid函数。", "keywords": "函数, 这里, 是第, 节中介绍的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d7bda35d-bbf2-4ace-acce-01f258f19ba5", "label": "摘要58", "info": "我们可以认为sigmoid输出单元具有两个部分。首先，它使用一个线性；层来计算z＝；率。", "keywords": "输出单元具有两个部分, 它使用一个线性, 层来计算, 首先, 我们可以认为", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f4314e28-7718-4687-bc0f-d1997585f484", "label": "摘要59", "info": "。其次，它使用sigmoid激活函数将z转化成概", "keywords": "其次, 它使用, 转化成概, 激活函数将", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "26e7ea3e-1f26-43b6-9e03-18bda5bc8245", "label": "摘要60", "info": "我们暂时忽略对于  x  的依赖性，只讨论如何用z的值来定义y的概率分；布。sigmoid可以通过构造一个非归一化（和不为1）的概率分布；来得到。我们可以随后除以一个合适的常数来得到有效的概率分布。如", "keywords": "的概率分布, 来得到, 只讨论如何用, 的依赖性, 的概率分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3f45c7b3-410d-4fce-bc1d-bb0346a165e3", "label": "摘要61", "info": "基于指数和归一化的概率分布在统计建模的文献中很常见。用于定义这；种二值型变量分布的变量z被称为分对数 （logit）。", "keywords": "被称为分对数, 种二值型变量分布的变量, 用于定义这, 基于指数和归一化的概率分布在统计建模的文献中很常见", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "80ee64c9-a61c-4ae6-945a-b79c51ac8bd8", "label": "摘要62", "info": "这种在对数空间里预测概率的方法可以很自然地使用最大似然学习。因；，代价函数中的log抵；为用于最大似然的代价函数是", "keywords": "这种在对数空间里预测概率的方法可以很自然地使用最大似然学习, 为用于最大似然的代价函数是, 代价函数中的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "90325a37-5b43-4f4d-b2b3-91b667c3be0c", "label": "摘要63", "info": "这个推导使用了第3.10节中的一些性质。通过将损失函数写成softplus函；数的形式，我们可以看到它仅仅在(1−2y)z取绝对值非常大的负值时才会；饱和。因此饱和只会出现在模型已经得到正确答案时——当y＝1且z取", "keywords": "取绝对值非常大的负值时才会, 通过将损失函数写成, 数的形式, 因此饱和只会出现在模型已经得到正确答案时, 这个推导使用了第", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e00078e4-5089-4885-bd03-d3988fc66488", "label": "摘要64", "info": "当我们使用其他的损失函数，例如均方误差之类的，损失函数就会在；σ(z)饱和时饱和。sigmoid激活函数在z取非常小的负值时会饱和到0，当；z取非常大的正值时会饱和到1。这种情况一旦发生，梯度会变得非常小", "keywords": "当我们使用其他的损失函数, 梯度会变得非常小, 这种情况一旦发生, 激活函数在, 取非常小的负值时会饱和到", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8b63e367-ceec-41ba-9365-9357ad7dbd9a", "label": "摘要65", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；理论上，sigmoid的对数总是确定和有限的，因为sigmoid的返回值总是；被限制在开区间（0，1）上，而不是使用整个闭区间［0，1］的有效概", "keywords": "因为, 的有效概, 被限制在开区间, 的返回值总是, 的对数总是确定和有限的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e4402da5-8df0-42c8-afbb-b6c860dfafb8", "label": "摘要66", "info": "的函数。如果sigmoid函数下溢到零，那么之", "keywords": "那么之, 如果, 函数下溢到零, 的函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9a7cfd1e-26ec-44db-966e-f6b6d46638e3", "label": "摘要67", "info": "6.2.2.3　用于Multinoulli输出分布的softmax单元", "keywords": "用于, 单元, 输出分布的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "dc9f6f02-de34-4afe-bfed-2603b48a1235", "label": "摘要68", "info": "任何时候，当我们想要表示一个具有n个可能取值的离散型随机变量的；分布时，都可以使用softmax函数。它可以看作sigmoid函数的扩展，其；中sigmoid函数用来表示二值型变量的分布。", "keywords": "当我们想要表示一个具有, 都可以使用, 函数用来表示二值型变量的分布, 任何时候, 函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5a7b46fe-edf0-46a7-9241-f7299a7222bb", "label": "摘要69", "info": "softmax函数最常用作分类器的输出，来表示n个不同类上的概率分布。；比较少见的是，softmax函数可以在模型内部使用，例如，如果我们想；要在某个内部变量的n个不同选项中进行选择。", "keywords": "个不同类上的概率分布, 要在某个内部变量的, 函数可以在模型内部使用, 例如, 个不同选项中进行选择", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d5425a4e-48ff-4b98-a133-294320957d9f", "label": "摘要70", "info": "在二值型变量的情况下，我们希望计算一个单独的数", "keywords": "在二值型变量的情况下, 我们希望计算一个单独的数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cf56faab-1b37-45fc-acb0-bd5d5fbd60b0", "label": "摘要71", "info": "因为这个数需要处在0和1之间，并且我们想要让这个数的对数可以很好；地用于对数似然的基于梯度的优化，因而我们选择去预测另外一个数", "keywords": "地用于对数似然的基于梯度的优化, 之间, 并且我们想要让这个数的对数可以很好, 因为这个数需要处在, 因而我们选择去预测另外一个数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "39c6826b-d878-4ed4-ad97-e86412b77906", "label": "摘要72", "info": "。对其指数化和归一化，就得到了一个由", "keywords": "就得到了一个由, 对其指数化和归一化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "27f8e852-eb3e-4de3-b4a2-f6503e526197", "label": "摘要73", "info": "sigmoid函数控制的Bernoulli分布。", "keywords": "分布, 函数控制的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2161108e-6de6-424d-b28b-14c4c30b8071", "label": "摘要74", "info": "为了推广到具有n个值的离散型变量的情况，现在需要创造一个向量；，它的每个元素是；介于0和1之间，还要使得整个向量的和为1，使得它表示一个有效的概", "keywords": "为了推广到具有, 使得它表示一个有效的概, 还要使得整个向量的和为, 个值的离散型变量的情况, 它的每个元素是", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5213b9f8-6a07-4f92-b983-783969fd9da6", "label": "摘要75", "info": "。我们不仅要求每个  元素", "keywords": "我们不仅要求每个, 元素", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0f104b94-34ab-41f9-bcd7-0350019f9300", "label": "摘要76", "info": "其中；化来获得需要的  。最终，softmax函数的形式为", "keywords": "函数的形式为, 化来获得需要的, 其中, 最终", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d7cbc92f-4364-4259-863e-6a13107c0b59", "label": "摘要77", "info": "。softmax函数然后可以对z指数化和归一", "keywords": "指数化和归一, 函数然后可以对", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ae98afc8-43d4-488f-9496-54a9ce938523", "label": "摘要78", "info": "和logistic  sigmoid一样，当使用最大化对数似然训练softmax来输出目标；值y时，使用指数函数工作地非常好。这种情况下，我们想要最大化", "keywords": "这种情况下, 我们想要最大化, 一样, 来输出目标, 当使用最大化对数似然训练", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f98172f8-9e46-46e8-91e9-eb517c5a29ae", "label": "摘要79", "info": "。将softmax定义成指数", "keywords": "定义成指数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4a56bb41-c72b-43fc-8e64-06beebd0ae20", "label": "摘要80", "info": "的形式是很自然的，因为对数似然中的log可以抵消softmax中的exp：", "keywords": "中的, 的形式是很自然的, 可以抵消, 因为对数似然中的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2dfca85a-09d8-4e52-82d7-0cbc0e5ece8e", "label": "摘要81", "info": "式（6.30）中的第一项表示输入z  i  总是对代价函数有直接的贡献。因为；这一项不会饱和，所以即使z  i  对式（6.30）的第二项的贡献很小，学习；依然可以进行。当最大化对数似然时，第一项鼓励z i 被推高，而第二项", "keywords": "因为, 总是对代价函数有直接的贡献, 第一项鼓励, 依然可以进行, 被推高", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6ab5dad7-ab9d-4db0-9209-4dba38749008", "label": "摘要82", "info": "则鼓励所有的z被压低。为了对第二项", "keywords": "则鼓励所有的, 被压低, 为了对第二项", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3cd43cfc-9a36-4586-a295-4926ac143512", "label": "摘要83", "info": "有一个直观的理解，注意到这一项可以大致近似为max  j  z  j  。这种近似；是基于对任何明显小于max j z j 的z k ，exp(z k )都是不重要的。我们能从；这种近似中得到的直觉是，负对数似然代价函数总是强烈地惩罚最活跃", "keywords": "注意到这一项可以大致近似为, 这种近似中得到的直觉是, 负对数似然代价函数总是强烈地惩罚最活跃, 我们能从, 都是不重要的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f2bf1fbb-d963-4710-bf76-5eeeb2b428b3", "label": "摘要84", "info": "i", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e4dfacd1-03c5-4de9-bd64-897bbb113b79", "label": "摘要85", "info": "项将大致抵消。这个样本对于整体训练代价贡献很小，这个代价主要由；其他未被正确分类的样本产生。", "keywords": "项将大致抵消, 其他未被正确分类的样本产生, 这个样本对于整体训练代价贡献很小, 这个代价主要由", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f33f1de8-dbd1-43b1-8810-85bef2b0e9e8", "label": "摘要86", "info": "到目前为止，我们只讨论了一个例子。总体来说，未正则化的最大似然；会驱动模型去学习一些参数，而这些参数会驱动softmax函数来预测在；训练集中观察到的每个结果的比率：", "keywords": "未正则化的最大似然, 总体来说, 会驱动模型去学习一些参数, 到目前为止, 而这些参数会驱动", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8e44dc01-c7a2-400e-8251-4bf4b3fed8ef", "label": "摘要87", "info": "因为最大似然是一致的估计量，所以只要模型族能够表示训练的分布，；这就能保证发生。在实践中，有限的模型能力和不完美的优化将意味着", "keywords": "所以只要模型族能够表示训练的分布, 因为最大似然是一致的估计量, 这就能保证发生, 有限的模型能力和不完美的优化将意味着, 在实践中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "38b4ced9-956f-4777-9784-aa6064ee5c48", "label": "摘要88", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；模型只能近似这些比率。", "keywords": "模型只能近似这些比率", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3cd3ac64-af73-4e25-81c8-97fd3bf95007", "label": "摘要89", "info": "对数似然之外的许多目标函数对softmax函数不起作用。具体来说，那；些不使用对数来抵消softmax中的指数的目标函数，当指数函数的变量；取非常小的负值时会造成梯度消失，从而无法学习。特别是平方误差，", "keywords": "中的指数的目标函数, 对数似然之外的许多目标函数对, 当指数函数的变量, 特别是平方误差, 具体来说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0257cd37-23d3-419e-aea8-7f33583e46b9", "label": "摘要90", "info": "像sigmoid一样，softmax激活函数可能会饱和。sigmoid函数具有单个输；出，当它的输入极端负或者极端正时会饱和。对于softmax的情况，它；有多个输出值。当输入值之间的差异变得极端时，这些输出值可能饱", "keywords": "激活函数可能会饱和, 这些输出值可能饱, 有多个输出值, 函数具有单个输, 的情况", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4a94718d-03d7-4f28-9033-2f374fd399ab", "label": "摘要91", "info": "为了说明softmax函数对于输入之间差异的响应，观察到当对所有的输；入都加上一个相同常数时softmax的输出不变：", "keywords": "函数对于输入之间差异的响应, 入都加上一个相同常数时, 观察到当对所有的输, 为了说明, 的输出不变", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1f73d9c5-52cd-43bd-9d73-cb0ed200bf66", "label": "摘要92", "info": "使用这个性质，我们可以导出一个数值方法稳定的softmax函数的变；体：", "keywords": "函数的变, 使用这个性质, 我们可以导出一个数值方法稳定的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9838c181-752a-4d1d-85d0-4537214c2a0e", "label": "摘要93", "info": "变换后的形式允许我们在对softmax函数求值时只有很小的数值误差，；即使是当z包含极正或者极负的数时。观察softmax数值稳定的变体，可；以看到softmax函数由它的变量偏离max i z i 的量来驱动。", "keywords": "即使是当, 函数由它的变量偏离, 包含极正或者极负的数时, 数值稳定的变体, 观察", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f049d4b5-d556-43e8-afe3-0f7e10a7cb93", "label": "摘要94", "info": "当其中一个输入是最大(z i ＝max i z i )并且z i 远大于其他的输入时，相应；的输出softmax(z)  i  会饱和到1。当z  i  不是最大值并且最大值非常大时，；相应的输出softmax(z)  i  也会饱和到0。这是sigmoid单元饱和方式的一般", "keywords": "相应的输出, 会饱和到, 当其中一个输入是最大, 的输出, 单元饱和方式的一般", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "75db2e62-6a12-450f-9ae8-0a6931f5038a", "label": "摘要95", "info": "softmax函数的变量z可以通过两种方式产生。最常见的是简单地使神经；网络较早的层输出z的每个元素，就像先前描述的使用线性层", "keywords": "的每个元素, 网络较早的层输出, 函数的变量, 可以通过两种方式产生, 就像先前描述的使用线性层", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d9afda89-e0f2-46d9-8259-c837fe56ae8c", "label": "摘要96", "info": "。虽然很直观，但这种方法是对分布的过度参数；化。n个输出总和必须为1的约束意味着只有n−1个参数是必要的；第n个；概率值可以通过1减去前面n−1个概率来获得。因此，我们可以强制要求", "keywords": "虽然很直观, 概率值可以通过, 减去前面, 个概率来获得, 因此", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ecd2cf87-a80c-4d0f-86e4-f4b4337f2f6c", "label": "摘要97", "info": "从神经科学的角度看，有趣的是认为softmax是一种在参与其中的单元；之间形成竞争的方式：softmax输出总是和为1，所以一个单元的值增加；必然对应着其他单元值的减少。这与被认为存在于皮质中相邻神经元间", "keywords": "必然对应着其他单元值的减少, 输出总是和为, 是一种在参与其中的单元, 这与被认为存在于皮质中相邻神经元间, 之间形成竞争的方式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3fa077cf-8e6f-4bb3-92d2-728e1f359955", "label": "摘要98", "info": "“softmax”的名称可能会让人产生困惑。这个函数更接近于argmax函数而；不是max函数。“soft”这个术语来源于softmax函数是连续可微；的。“argmax”函数的结果表示为一个one-hot向量（只有一个元素为1，", "keywords": "函数, 这个术语来源于, 的名称可能会让人产生困惑, 函数而, 向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2e4c200d-1644-4380-a3bb-ffd9ba466969", "label": "摘要99", "info": "6.2.2.4　其他的输出类型", "keywords": "其他的输出类型", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8e8ea56c-203f-4c0c-8021-3e0179129344", "label": "摘要100", "info": "之前描述的线性、sigmoid和softmax输出单元是最常见的。神经网络可；以推广到我们希望的几乎任何种类的输出层。最大似然原则给如何为几；乎任何种类的输出层设计一个好的代价函数提供了指导。", "keywords": "乎任何种类的输出层设计一个好的代价函数提供了指导, 之前描述的线性, 最大似然原则给如何为几, 神经网络可, 以推广到我们希望的几乎任何种类的输出层", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aa082429-fbd5-45ad-884d-f0efcfbbf7f8", "label": "摘要101", "info": "一般而言，如果我们定义了一个条件分布p ( y | x ; θ )，最大似然原则建；议我们使用-logp ( y | x ; θ ) 作为代价函数。", "keywords": "最大似然原则建, 一般而言, 如果我们定义了一个条件分布, 议我们使用, 作为代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "df116920-6fd2-485d-8688-928b142ad1bb", "label": "摘要102", "info": "一般来说，我们可以认为神经网络表示函数f ( x ; θ ) 。这个函数的输出", "keywords": "这个函数的输出, 我们可以认为神经网络表示函数, 一般来说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fd432fda-b853-464a-8621-ecd8b6a9fe4a", "label": "摘要103", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；不是对 y 值的直接预测。相反，；我们的损失函数就可以表示成", "keywords": "我们的损失函数就可以表示成, 不是对, 值的直接预测, 相反", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2c25d6d9-d0dd-4888-8099-e0c48fc0df13", "label": "摘要104", "info": "提供了y分布的参数。", "keywords": "分布的参数, 提供了", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "99027864-f726-45bf-bba5-f2ab8e2745a6", "label": "摘要105", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cc7d02c0-e509-4373-b8a8-ce76452a2f9f", "label": "摘要106", "info": "例如，我们想要学习在给定 x 时， y 的条件高斯分布的方差。简单情况；下，方差σ  2  是一个常数，此时有一个解析表达式，这是因为方差的最；大似然估计量仅仅是观测值y与它们的期望值的差值的平方平均。一种", "keywords": "的条件高斯分布的方差, 这是因为方差的最, 与它们的期望值的差值的平方平均, 例如, 我们想要学习在给定", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "924f5670-b2d5-47ed-aebb-b8cbbda88be2", "label": "摘要107", "info": "数可以是σ本身，或者可以是表示σ  2  的参数ν，或者可以是表示", "keywords": "本身, 的参数, 或者可以是表示, 数可以是", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7c526d63-3ac7-401f-89e0-db1d10337ccf", "label": "摘要108", "info": "的", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b6c84f11-f2f5-4c89-8514-5d3ebd8cd744", "label": "摘要109", "info": "参数β，取决于我们怎样对分布参数化。我们可能希望模型对不同的  x；值预测出  y  不同的方差。这被称为异方差  （heteroscedastic）模型。在；异方差情况下，我们简单地把方差指定为f (  x  ;  θ  )其中一个输出值。实", "keywords": "参数, 我们简单地把方差指定为, 其中一个输出值, 模型, 我们可能希望模型对不同的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4325493f-812b-434d-8313-ca3b2f037e53", "label": "摘要110", "info": "这个公式适用于梯度下降，因为由 β 参数化的高斯分布的对数似然的公；式仅涉及   的乘法和；的加法。乘法、加法和对数运算的梯度", "keywords": "参数化的高斯分布的对数似然的公, 乘法, 因为由, 式仅涉及, 的乘法和", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1b87f467-0e0e-40f0-9bff-287efc107510", "label": "摘要111", "info": "获得正的精度向量：；同样适用，也适用于常数乘以单位阵的情况。", "keywords": "获得正的精度向量, 也适用于常数乘以单位阵的情况, 同样适用", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "94deca49-a349-4fa1-ad86-31a07531c408", "label": "摘要112", "info": "。这种相同的策略对于方差或标准差", "keywords": "这种相同的策略对于方差或标准差", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5eb7a5c0-e3eb-43f4-a76e-0544551b1d63", "label": "摘要113", "info": "学习一个比对角矩阵具有更丰富结构的协方差或者精度矩阵是很少见；的。如果协方差矩阵是“满的”和有条件的，那么参数化的选择就必须要；保证预测的协方差矩阵是正定的。这可以通过写成", "keywords": "和有条件的, 满的, 学习一个比对角矩阵具有更丰富结构的协方差或者精度矩阵是很少见, 这可以通过写成, 如果协方差矩阵是", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8952546d-8885-4b85-9444-9fc934d8f7e2", "label": "摘要114", "info": "来实现，这里   是一个无约束的方阵。如果", "keywords": "如果, 这里, 是一个无约束的方阵, 来实现", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "24c9f939-cad3-448e-9989-69e0003bd815", "label": "摘要115", "info": "矩阵是满秩的，那么一个实际问题是计算似然的代价很高，计算一个；d×d的矩阵的行列式或者；特征值分解或者", "keywords": "计算一个, 的矩阵的行列式或者, 矩阵是满秩的, 那么一个实际问题是计算似然的代价很高, 特征值分解或者", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f7a969b2-ce27-4102-941a-f2d0a1662f15", "label": "摘要116", "info": "的特征值分解）需要O(d 3 )的计算量。", "keywords": "的特征值分解, 需要, 的计算量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e0ab7b0a-e8af-4691-a0dc-c961109b73ed", "label": "摘要117", "info": "的逆（或者等价地并且更常用地，对它", "keywords": "对它, 或者等价地并且更常用地, 的逆", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "010e602c-0ebd-4bbb-8188-38e657acaf74", "label": "摘要118", "info": "我们经常想要执行多峰回归（multimodal；regression），即预测条件分；布p ( y | x )的实值，该条件分布对于相同的  x 值在 y 空间中有多个不同", "keywords": "该条件分布对于相同的, 我们经常想要执行多峰回归, 即预测条件分, 值在, 的实值", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a6803f01-fbd2-4ebe-99d8-38d9fbb41609", "label": "摘要119", "info": "神经网络必须有3个输出：定义", "keywords": "定义, 个输出, 神经网络必须有", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "81e44237-87c5-4b7d-aa9e-0d9096a81eac", "label": "摘要120", "info": "的矩阵，以及对所有的i给出", "keywords": "以及对所有的, 的矩阵, 给出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3e9da2e4-2c8d-472c-bf21-c70f1ad7c52d", "label": "摘要121", "info": "的向量，对所有的i给出；的张量。这些输出必须", "keywords": "的张量, 对所有的, 这些输出必须, 给出, 的向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f6e1aeab-b0ab-45c7-813a-fd950b9514ad", "label": "摘要122", "info": "满足不同的约束：", "keywords": "满足不同的约束", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4573f3cb-56f8-4be7-a296-56bb09174370", "label": "摘要123", "info": "（1）混合组件；组件上形成Multinoulli分布。这个分布通常可以由n维向量的softmax来；获得，以确保这些输出是正的并且和为1。", "keywords": "获得, 组件上形成, 混合组件, 以确保这些输出是正的并且和为, 分布", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "720b57ba-0c25-48e1-8887-fb584c1e964c", "label": "摘要124", "info": "：它们由潜变量  (2)  c关联着，在n个不同", "keywords": "个不同, 它们由潜变量, 关联着", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2a2dc787-25d4-4dde-8065-40365770d6cd", "label": "摘要125", "info": "（2）均值；：它们指明了与第i个高斯组件相关联的中心或者均；值，并且是无约束的（通常对于这些输出单元完全没有非线性）。如果", "keywords": "如果, 个高斯组件相关联的中心或者均, 它们指明了与第, 并且是无约束的, 均值", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8c301997-004d-47e0-8895-c90ba58b4c65", "label": "摘要126", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；表达式将每个样本对每个组件的贡献进行赋权，权重的大小由相应的组；件产生这个样本的概率来决定。", "keywords": "权重的大小由相应的组, 表达式将每个样本对每个组件的贡献进行赋权, 件产生这个样本的概率来决定", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "82044638-2bf0-40a2-bfad-4948482088a2", "label": "摘要127", "info": "：它们指明了每个组件i的协方差矩阵。和学习单；（3）协方差；个高斯组件时一样，我们通常使用对角矩阵来避免计算行列式。和学习", "keywords": "的协方差矩阵, 和学习单, 和学习, 我们通常使用对角矩阵来避免计算行列式, 协方差", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "eb1348ef-54e5-4627-ada4-45f2a5197cb0", "label": "摘要128", "info": "有报告说，基于梯度的优化方法对于混合条件高斯（作为神经网络的输；出）可能是不可靠的，部分是因为涉及除法（除以方差）可能是数值不；稳定的（当某个方差对于特定的实例变得非常小时，会导致非常大的梯", "keywords": "可能是数值不, 基于梯度的优化方法对于混合条件高斯, 稳定的, 作为神经网络的输, 除以方差", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1fd10ebc-bb1e-47b2-8093-c246301a4ee8", "label": "摘要129", "info": "高斯混合输出在语音生成模型（Schuster，1999）和物理运动；（Graves，2013）中特别有效。混合密度策略为网络提供了一种方法来；表示多种输出模式，并且控制输出的方差，这对于在这些实数域中获得", "keywords": "混合密度策略为网络提供了一种方法来, 中特别有效, 这对于在这些实数域中获得, 表示多种输出模式, 高斯混合输出在语音生成模型", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "49eb84ce-fbdd-411a-9f87-78d1d29ceddc", "label": "摘要130", "info": "一般地，我们可能希望继续对包含更多变量的、更大的向量 y  来建模，；并在这些输出变量上施加更多更丰富的结构。例如，可能希望神经网络；输出字符序列形成一个句子。在这些情况下，我们可以继续使用最大似", "keywords": "输出字符序列形成一个句子, 更大的向量, 来建模, 例如, 我们可以继续使用最大似", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d704004e-e7e9-4ca3-9a2d-5ba7e7a3dc33", "label": "摘要131", "info": "图6.4　从具有混合密度输出层的神经网络中抽取的样本。输入 x 从均匀分布中采样，输出y从 p；model ( y |x）中采样。神经网络能够学习从输入到输出分布的参数的非线性映射。这些参数包括；控制3个组件中的哪一个将产生输出的概率，以及每个组件各自的参数。每个混合组件都是高斯", "keywords": "每个混合组件都是高斯, 这些参数包括, 输入, 从具有混合密度输出层的神经网络中抽取的样本, 从均匀分布中采样", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1ffdd1c7-1548-4f2d-bb11-584af147caf3", "label": "摘要132", "info": "6.2.1　代价函数", "keywords": "代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "855465b3-5c7c-4df5-adf1-31a9f06cd1c8", "label": "摘要133", "info": "6.2.2　输出单元", "keywords": "输出单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "label": "6.3：隐藏单元", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "227f4df3-22d8-4a6a-9c50-b8a8643a8d31", "label": "摘要1", "info": "6.3.1　整流线性单元及其扩展", "keywords": "整流线性单元及其扩展", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d5573836-74f9-427d-8925-5a56ec182edf", "label": "摘要2", "info": "6.3.2　logistic sigmoid与双曲正切函数", "keywords": "与双曲正切函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "57cd53e5-5f08-437d-89b6-b58916aabfa1", "label": "摘要3", "info": "6.3.3　其他隐藏单元", "keywords": "其他隐藏单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3ca46ade-0c3a-43b6-98ad-3ca74004bf57", "label": "摘要4", "info": "到目前为止，我们集中讨论了神经网络的设计选择，这对于使用基于梯；度的优化方法来训练的大多数参数化机器学习模型都是通用的。现在我；们转向一个前馈神经网络独有的问题：该如何选择隐藏单元的类型，这", "keywords": "现在我, 这对于使用基于梯, 度的优化方法来训练的大多数参数化机器学习模型都是通用的, 到目前为止, 我们集中讨论了神经网络的设计选择", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ec65ca04-6b55-407d-8bdb-85c64b26aa77", "label": "摘要5", "info": "隐藏单元的设计是一个非常活跃的研究领域，并且还没有许多明确的指；导性理论原则。", "keywords": "导性理论原则, 隐藏单元的设计是一个非常活跃的研究领域, 并且还没有许多明确的指", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4296c515-8e8e-4ffa-a583-b77a35c88102", "label": "摘要6", "info": "整流线性单元是隐藏单元极好的默认选择。许多其他类型的隐藏单元也；是可用的。决定何时使用哪种类型的隐藏单元是困难的事（尽管整流线；性单元通常是一个可接受的选择）。我们这里描述对于每种隐藏单元的", "keywords": "尽管整流线, 许多其他类型的隐藏单元也, 性单元通常是一个可接受的选择, 整流线性单元是隐藏单元极好的默认选择, 我们这里描述对于每种隐藏单元的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2d100f3c-08e4-4c92-a3d2-11c26873da10", "label": "摘要7", "info": "这里列出的一些隐藏单元可能并不是在所有的输入点上都是可微的。例；如，整流线性单元g(z)＝max{0,z}在z＝0处不可微。这似乎使得g对于基", "keywords": "处不可微, 这似乎使得, 对于基, 这里列出的一些隐藏单元可能并不是在所有的输入点上都是可微的, 整流线性单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0f193f3d-b37a-47d9-aff1-2f09ca26a827", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；于梯度的学习算法无效。在实践中，梯度下降对这些机器学习模型仍然；表现得足够好。部分原因是神经网络训练算法通常不会达到代价函数的", "keywords": "表现得足够好, 部分原因是神经网络训练算法通常不会达到代价函数的, 梯度下降对这些机器学习模型仍然, 在实践中, 于梯度的学习算法无效", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c8c861b4-48da-464b-9542-68e260444cca", "label": "摘要9", "info": "除非另有说明，大多数的隐藏单元都可以描述为接受输入向量 x ，计算；仿射变换z＝；，然后使用一个逐元素的非线性函数g(z)。大", "keywords": "然后使用一个逐元素的非线性函数, 仿射变换, 除非另有说明, 计算, 大多数的隐藏单元都可以描述为接受输入向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8e306ec5-28d9-437f-8cb5-35dc420aa10a", "label": "摘要10", "info": "6.3.1　整流线性单元及其扩展", "keywords": "整流线性单元及其扩展", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7b2a5031-c595-4ae1-8630-341c5ceab8b2", "label": "摘要11", "info": "整流线性单元使用激活函数g(z)＝max{0,z}。", "keywords": "整流线性单元使用激活函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "19557b72-26e4-4eda-9dde-b8aa70797973", "label": "摘要12", "info": "整流线性单元易于优化，因为它们和线性单元非常类似。线性单元和整；流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为；零。这使得只要整流线性单元处于激活状态，它的导数都能保持较大。", "keywords": "整流线性单元易于优化, 线性单元和整, 这使得只要整流线性单元处于激活状态, 它的导数都能保持较大, 流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2e769d66-2f3b-4833-bb5c-b61ff8fbf03d", "label": "摘要13", "info": "整流线性单元通常作用于仿射变换之上：", "keywords": "整流线性单元通常作用于仿射变换之上", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "03a8108f-8e2c-4e45-8134-bfe91d809ae2", "label": "摘要14", "info": "当初始化仿射变换的参数时，可以将  b  的所有元素设置成一个小的正；值，例如0.1。这使得整流线性单元很可能初始时就对训练集中的大多；数输入呈现激活状态，并且允许导数通过。", "keywords": "当初始化仿射变换的参数时, 可以将, 例如, 的所有元素设置成一个小的正, 并且允许导数通过", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a60e379-cd34-4f87-88d9-4816fb4b29a7", "label": "摘要15", "info": "有很多整流线性单元的扩展存在。大多数这些扩展的表现比得上整流线；性单元，并且偶尔表现得更好。", "keywords": "有很多整流线性单元的扩展存在, 性单元, 大多数这些扩展的表现比得上整流线, 并且偶尔表现得更好", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fa6cf602-59bd-4c5a-b9f4-e47c99dae92a", "label": "摘要16", "info": "整流线性单元的一个缺陷是它们不能通过基于梯度的方法学习那些使它；们激活为零的样本。整流线性单元的各种扩展保证了它们能在各个位置；都接收到梯度。", "keywords": "们激活为零的样本, 都接收到梯度, 整流线性单元的各种扩展保证了它们能在各个位置, 整流线性单元的一个缺陷是它们不能通过基于梯度的方法学习那些使它", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "58fe0d65-0472-4782-9a0f-029785bed2bc", "label": "摘要17", "info": "i", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "23d73c28-6b12-4df3-9108-ff524017e10a", "label": "摘要18", "info": "整流线性单元的3个扩展基于当z", "keywords": "个扩展基于当, 整流线性单元的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "97e99570-2bb8-408e-9f7b-122c81be794b", "label": "摘要19", "info": "＜0时使用一个非零的斜率；。绝；对值整流  （absolute  value  rectification）固定α  i  ＝−1来得到g(z)＝｜z", "keywords": "时使用一个非零的斜率, 对值整流, 固定, 来得到", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8e98e07b-4465-4a5b-9d2b-26665348a763", "label": "摘要20", "info": "i", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9ea40180-4943-472b-845a-b8db2926e2db", "label": "摘要21", "info": "maxout单元 （maxout unit）（Goodfellow et al. ，2013a）进一步扩展了；整流线性单元。maxout单元将z划分为每组具有k个值的组，而不是使用；作用于每个元素的函数g(z)。每个maxout单元则输出每组中的最大元", "keywords": "进一步扩展了, 作用于每个元素的函数, 而不是使用, 单元将, 单元则输出每组中的最大元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3450b179-dbb5-4337-a768-46c7938d826b", "label": "摘要22", "info": "这里；了一种方法来学习对输入 x 空间中多个方向响应的分段线性函数。", "keywords": "这里, 空间中多个方向响应的分段线性函数, 了一种方法来学习对输入", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "39eab5bb-2249-4edf-93c2-6c8de76779b0", "label": "摘要23", "info": "是组i的输入索引集", "keywords": "是组, 的输入索引集", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ef01f2b1-12cf-459b-887d-9a40fc59bc8f", "label": "摘要24", "info": "。这提供", "keywords": "这提供", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8665b1c9-0d7e-460b-8952-4b4327fd7c4c", "label": "摘要25", "info": "maxout单元可以学习具有多达k段的分段线性的凸函数。maxout单元因；此可以视为学习激活函数本身，而不仅仅是单元之间的关系。使用足够；大的k，maxout单元可以以任意的精确度来近似任何凸函数。特别地，", "keywords": "段的分段线性的凸函数, 单元可以学习具有多达, 特别地, 大的, 而不仅仅是单元之间的关系", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e7052df8-e4ac-4c80-9de7-05467ed2c424", "label": "摘要26", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；具有两块的maxout层可以学习实现和传统层相同的输入 x 的函数，这些；传统层可以使用整流线性激活函数、绝对值整流、渗漏整流线性单元或", "keywords": "绝对值整流, 层可以学习实现和传统层相同的输入, 渗漏整流线性单元或, 这些, 的函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b804bd66-5d87-4898-aa2e-3fc9a935e13a", "label": "摘要27", "info": "每个maxout单元现在由k个权重向量来参数化，而不仅仅是一个，所以；maxout单元通常比整流线性单元需要更多的正则化。如果训练集很大并；且每个单元的块数保持很低的话，它们可以在没有正则化的情况下工作", "keywords": "个权重向量来参数化, 且每个单元的块数保持很低的话, 而不仅仅是一个, 它们可以在没有正则化的情况下工作, 所以", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "eb886e9b-ea1f-46c7-9698-419bd362121a", "label": "摘要28", "info": "maxout单元还有一些其他的优点。在某些情况下，要求更少的参数可以；获得一些统计和计算上的优点。具体来说，如果由n个不同的线性过滤；器描述的特征可以在不损失信息的情况下，用每一组k个特征的最大值", "keywords": "用每一组, 器描述的特征可以在不损失信息的情况下, 个不同的线性过滤, 单元还有一些其他的优点, 具体来说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d1afcf5e-d8ea-4157-a482-eccc377a9788", "label": "摘要29", "info": "因为每个单元由多个过滤器驱动，maxout单元具有一些冗余来帮助它们；抵抗一种被称为灾难遗忘  （catastrophic  forgetting）的现象，这个现象；是说神经网络忘记了如何执行它们过去训练的任务（Goodfellow  et  al.", "keywords": "单元具有一些冗余来帮助它们, 是说神经网络忘记了如何执行它们过去训练的任务, 因为每个单元由多个过滤器驱动, 的现象, 这个现象", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "00e07bcf-706c-4f91-b0bb-d59d71988386", "label": "摘要30", "info": "整流线性单元和它们的这些扩展都是基于一个原则，那就是如果它们的；行为更接近线性，那么模型更容易优化。使用线性行为更容易优化的一；般性原则同样也适用于除深度线性网络以外的情景。循环网络可以从序", "keywords": "循环网络可以从序, 般性原则同样也适用于除深度线性网络以外的情景, 那么模型更容易优化, 使用线性行为更容易优化的一, 行为更接近线性", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0642e04a-5c17-4db6-9e44-7884366445ae", "label": "摘要31", "info": "6.3.2　logistic sigmoid与双曲正切函数", "keywords": "与双曲正切函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "bdc67320-6763-4b20-954c-14bf44d3da81", "label": "摘要32", "info": "在引入整流线性单元之前，大多数神经网络使用logistic  sigmoid激活函；数", "keywords": "在引入整流线性单元之前, 大多数神经网络使用, 激活函", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "48ebc3a3-994a-46b8-b66c-8ed90ec9f5af", "label": "摘要33", "info": "或者是双曲正切激活函数", "keywords": "或者是双曲正切激活函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "58ac2ae2-5022-4154-86a3-3275a3b9550f", "label": "摘要34", "info": "这些激活函数紧密相关，因为", "keywords": "因为, 这些激活函数紧密相关", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ab2505dc-ffb2-4fa8-bb4f-671226ee8540", "label": "摘要35", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "882d8514-e4bc-4935-bb5a-540e95ea2afc", "label": "摘要36", "info": "我们已经看过sigmoid单元作为输出单元用来预测二值型变量取值为1的；概率。与分段线性单元不同，sigmoid单元在其大部分定义域内都饱和；——当z取绝对值很大的正值时，它们饱和到一个高值，当z取绝对值很", "keywords": "与分段线性单元不同, 取绝对值很大的正值时, 我们已经看过, 取绝对值很, 概率", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fe0d968e-2315-446d-bb21-53bedb5c9b43", "label": "摘要37", "info": "当必须要使用sigmoid激活函数时，双曲正切激活函数通常要比logistic；sigmoid函数表现更好。在", "keywords": "当必须要使用, 激活函数时, 双曲正切激活函数通常要比, 函数表现更好", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5cf63b05-feb2-4aab-99f4-f43288c28673", "label": "摘要38", "info": "的意义上，", "keywords": "的意义上", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4504b3e9-0b1a-49fa-b812-021003f62b02", "label": "摘要39", "info": "它更像是单位函数。因为tanh在0附近与单位函数类似，训练深层神经；网络", "keywords": "因为, 网络, 训练深层神经, 它更像是单位函数, 附近与单位函数类似", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3f17b579-574a-473e-951b-4fe452890bc6", "label": "摘要40", "info": "类似于训练一个线性模型；，只要网络的激活能够被保持地很小。这使得训", "keywords": "只要网络的激活能够被保持地很小, 这使得训, 类似于训练一个线性模型", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "04eb6c96-a518-41ff-b5c3-f9ec28611ca5", "label": "摘要41", "info": "练tanh网络更加容易。", "keywords": "网络更加容易", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "279f0491-9282-4305-acea-13f4c853d238", "label": "摘要42", "info": "sigmoid激活函数在除了前馈网络以外的情景中更为常见。循环网络、；许多概率模型以及一些自编码器有一些额外的要求使得它们不能使用分；段线性激活函数，并且使得sigmoid单元更具有吸引力，尽管它存在饱", "keywords": "单元更具有吸引力, 尽管它存在饱, 循环网络, 激活函数在除了前馈网络以外的情景中更为常见, 并且使得", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8da49990-ceff-4895-8c89-aec53cbf0bb1", "label": "摘要43", "info": "6.3.3　其他隐藏单元", "keywords": "其他隐藏单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a0932f82-df69-4be9-830b-9bdc540e3d3b", "label": "摘要44", "info": "也存在许多其他种类的隐藏单元，但它们并不常用。", "keywords": "也存在许多其他种类的隐藏单元, 但它们并不常用", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "00bac383-4451-42ca-a078-c7e72489ed94", "label": "摘要45", "info": "一般来说，很多种类的可微函数都表现得很好。许多未发布的激活函数；与流行的激活函数表现得一样好。为了提供一个具体的例子，作者在；MNIST数据集上使用", "keywords": "很多种类的可微函数都表现得很好, 与流行的激活函数表现得一样好, 为了提供一个具体的例子, 一般来说, 作者在", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "181e4290-01d3-4a59-b715-682e2ad7734a", "label": "摘要46", "info": "测试了一个前馈网络，", "keywords": "测试了一个前馈网络", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "32e5497a-26f4-44c2-890b-565d95e27418", "label": "摘要47", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；并获得了小于1％的误差率，这可以与更为传统的激活函数获得的结果；相媲美。在新技术的研究和开发期间，通常会测试许多不同的激活函", "keywords": "的误差率, 在新技术的研究和开发期间, 通常会测试许多不同的激活函, 并获得了小于, 相媲美", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "32b3abb8-c9cf-4120-8c80-a765cfaecde7", "label": "摘要48", "info": "列出文献中出现的所有隐藏单元类型是不切实际的。我们只对一些特别；有用和独特的类型进行强调。", "keywords": "我们只对一些特别, 列出文献中出现的所有隐藏单元类型是不切实际的, 有用和独特的类型进行强调", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c129d25f-e486-427a-8a23-d07155744890", "label": "摘要49", "info": "其中一种是完全没有激活函数g(z)。也可以认为这是使用单位函数作为；激活函数的情况。我们已经看过线性单元可以用作神经网络的输出。它；也可以用作隐藏单元。如果神经网络的每一层都仅由线性变换组成，那", "keywords": "其中一种是完全没有激活函数, 激活函数的情况, 我们已经看过线性单元可以用作神经网络的输出, 如果神经网络的每一层都仅由线性变换组成, 也可以用作隐藏单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9d6e3b4d-ac88-4cf4-977d-d56717a4bdf8", "label": "摘要50", "info": "。我们可以用两层来代替它，一层使用权重矩阵 U；，另一层使用权重矩阵 V 。如果第一层没有激活函数，那么我们对基于；的原始层的权重矩阵进行因式分解。分解方法是计算", "keywords": "的原始层的权重矩阵进行因式分解, 如果第一层没有激活函数, 我们可以用两层来代替它, 一层使用权重矩阵, 另一层使用权重矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4d25e1a1-051a-4efa-84e9-dd8dd7a4cc87", "label": "摘要51", "info": "softmax单元是另外一种经常用作输出的单元（如第6.2.2.3节中所描述；的），但有时也可以用作隐藏单元。softmax单元很自然地表示具有k个；可能值的离散型随机变量的概率分布，所以它们可以用作一种开关。这", "keywords": "但有时也可以用作隐藏单元, 单元是另外一种经常用作输出的单元, 单元很自然地表示具有, 所以它们可以用作一种开关, 如第", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "78856499-b6f2-477a-9c4f-54ba0f684d36", "label": "摘要52", "info": "其他一些常见的隐藏单元类型包括：", "keywords": "其他一些常见的隐藏单元类型包括", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "290c1187-dad6-4e0a-b7e0-b03064dca0dc", "label": "摘要53", "info": "径向基函数", "keywords": "径向基函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "78f7b57b-88d8-4a3c-ab1a-e50b50282e72", "label": "摘要54", "info": "（radial", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "bc4951bf-599c-4eb1-a0c6-6ac191c93300", "label": "摘要55", "info": "basis", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f614c305-2ea0-477b-a806-c88c13ddee3e", "label": "摘要56", "info": "function，RBF）：", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a1b4d10e-7b4f-4332-9425-fae4c2ae9dd9", "label": "摘要57", "info": "。这个函数在  x  接近", "keywords": "这个函数在, 接近", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d6ddf464-2d5a-4097-939f-d86593f8be2c", "label": "摘要58", "info": "模板 W :, i 时更加活跃。因为它对大部分 x 都饱和到0，因此很难优；化。；。这是整流线", "keywords": "时更加活跃, 模板, 因此很难优, 都饱和到, 因为它对大部分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9fc9ce4e-9370-4a3a-ae85-ad1a683eaae2", "label": "摘要59", "info": "隐藏单元的设计仍然是一个活跃的研究领域，许多有用的隐藏单元类型；仍有待发现。", "keywords": "许多有用的隐藏单元类型, 仍有待发现, 隐藏单元的设计仍然是一个活跃的研究领域", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5fc4c334-23e6-4508-b7b6-eb43f00220e7", "label": "摘要60", "info": "6.3.1　整流线性单元及其；扩展", "keywords": "扩展, 整流线性单元及其", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ef6cb731-7892-480a-be16-52aab21cab8f", "label": "摘要61", "info": "6.3.2　logistic sigmoid与；双曲正切函数", "keywords": "双曲正切函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "239ea393-a64d-4061-82d8-0676baab4b68", "label": "摘要62", "info": "6.3.3　其他隐藏单元", "keywords": "其他隐藏单元", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "label": "6.4：架构设计", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "72cd391b-50a1-4726-8349-587fab476f6b", "label": "摘要1", "info": "6.4.1　万能近似性质和深度", "keywords": "万能近似性质和深度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c8c183ae-3591-41e2-bde0-97467fb20276", "label": "摘要2", "info": "6.4.2　其他架构上的考虑", "keywords": "其他架构上的考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7792105b-3e0d-4138-afb5-81c75c51f459", "label": "摘要3", "info": "神经网络设计的另一个关键点是确定它的架构。架构  （architecture）一；词是指网络的整体结构：它应该具有多少单元，以及这些单元应该如何；连接。", "keywords": "连接, 神经网络设计的另一个关键点是确定它的架构, 它应该具有多少单元, 以及这些单元应该如何, 架构", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1b1734ca-c874-4fa0-a6af-b1ca1391f8f8", "label": "摘要4", "info": "大多数神经网络被组织成称为层的单元组。大多数神经网络架构将这些；层布置成链式结构，其中每一层都是前一层的函数。在这种结构中，第；一层由下式给出：", "keywords": "大多数神经网络被组织成称为层的单元组, 大多数神经网络架构将这些, 其中每一层都是前一层的函数, 一层由下式给出, 在这种结构中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "041f0ddc-9110-4495-ac49-4fa2f9c11d5c", "label": "摘要5", "info": "第二层由", "keywords": "第二层由", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "72493f76-fc35-4457-8ab5-fc1e79fe2fd5", "label": "摘要6", "info": "给出，以此类推。", "keywords": "给出, 以此类推", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b9256407-93a5-4cea-b175-66e1a82832a3", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在这些链式架构中，主要的架构考虑是选择网络的深度和每一层的宽；度。我们将会看到，即使只有一个隐藏层的网络也足够适应训练集。更", "keywords": "在这些链式架构中, 即使只有一个隐藏层的网络也足够适应训练集, 我们将会看到, 主要的架构考虑是选择网络的深度和每一层的宽", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1274e955-7ac3-4a36-9dae-ce486f481d59", "label": "摘要8", "info": "6.4.1　万能近似性质和深度", "keywords": "万能近似性质和深度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6195e592-418a-4371-8336-d8d5f9ef9533", "label": "摘要9", "info": "线性模型，通过矩阵乘法将特征映射到输出，顾名思义，仅能表示线性；函数。它具有易于训练的优点，因为当使用线性模型时，许多损失函数；会导出凸优化问题。可惜的是，我们经常希望我们的系统学习非线性函", "keywords": "会导出凸优化问题, 线性模型, 我们经常希望我们的系统学习非线性函, 因为当使用线性模型时, 它具有易于训练的优点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4d3aa387-89d1-4db6-b778-7818855fd048", "label": "摘要10", "info": "（universal", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a0cbb9a0-3336-42d0-9f6a-16ea24306ac5", "label": "摘要11", "info": "乍一看，可能认为学习非线性函数需要为我们想要学习的那种非线性专；门设计一类模型族。幸运的是，具有隐藏层的前馈网络提供了一种万能；近似框架。具体来说，万能近似定理", "keywords": "乍一看, 万能近似定理, 幸运的是, 门设计一类模型族, 具体来说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3370ee46-6533-4a26-ac7e-41c68ed4c96c", "label": "摘要12", "info": "万能近似定理意味着无论我们试图学习什么函数，我们知道一个大的；MLP一定能够表示这个函数。然而，我们不能保证训练算法能够学得这；个函数。即使MLP能够表示该函数，学习也可能因两个不同的原因而失", "keywords": "一定能够表示这个函数, 学习也可能因两个不同的原因而失, 我们知道一个大的, 即使, 然而", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "77b681d8-5b2b-4a5b-b171-4723ab08cbad", "label": "摘要13", "info": "网络提供了表示函数的万能系统，在这种意义上，给定一个函数，存在；一个前馈网络能够近似该函数。不存在万能的过程既能够验证训练集上；的特殊样本，又能够选择一个函数来扩展到训练集上没有的点。", "keywords": "不存在万能的过程既能够验证训练集上, 网络提供了表示函数的万能系统, 在这种意义上, 又能够选择一个函数来扩展到训练集上没有的点, 存在", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ebcaed38-e7e2-4b68-9859-0a74c2d052c0", "label": "摘要14", "info": "万能近似定理说明，存在一个足够大的网络能够达到我们所希望的任意；精度，但是定理并没有说这个网络有多大。Barron（1993）提供了单层；网络近似一大类函数所需大小的一些界。不幸的是，在最坏情况下，可", "keywords": "精度, 网络近似一大类函数所需大小的一些界, 存在一个足够大的网络能够达到我们所希望的任意, 万能近似定理说明, 但是定理并没有说这个网络有多大", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5674814f-73c6-4a2a-83f4-1849a070ae9b", "label": "摘要15", "info": "，并且选择一个这样的函数需要2", "keywords": "并且选择一个这样的函数需要", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "66e5efe5-c130-4409-85b9-edff552e3bcd", "label": "摘要16", "info": "总之，具有单层的前馈网络足以表示任何函数，但是网络层可能大得不；可实现，并且可能无法正确地学习和泛化。在很多情况下，使用更深的；模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误", "keywords": "并且可能无法正确地学习和泛化, 并且可以减少泛化误, 具有单层的前馈网络足以表示任何函数, 可实现, 使用更深的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9d159d95-5f9d-449b-85fd-4978110d768f", "label": "摘要17", "info": "存在一些函数族能够在网络的深度大于某个值d时被高效地近似，而当；深度被限制到小于或等于d时需要一个远远大于之前的模型。在很多情；况下，浅层模型所需的隐藏单元的数量是n的指数级。这个结果最初被", "keywords": "而当, 况下, 的指数级, 深度被限制到小于或等于, 这个结果最初被", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c606c3fe-dfd8-4f28-a633-be531cfe72b9", "label": "摘要18", "info": "et", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5c210a2d-86b0-4127-875b-c3fe718de635", "label": "摘要19", "info": "et", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4951d11b-32e5-4903-a998-acb6a89300fe", "label": "摘要20", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；数级的分段线性区域，它们可以概括所有种类的规则模式（例如，重；复）。", "keywords": "它们可以概括所有种类的规则模式, 数级的分段线性区域, 例如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5662a378-1801-440c-bb66-d652f6c71c0e", "label": "摘要21", "info": "图6.5　关于更深的整流网络具有指数优势的一个直观的几何解释，来自Montufar et al.；（2014）。（左）绝对值整流单元对其输入中的每对镜像点有相同的输出。镜像的对称轴由单；元的权重和偏置定义的超平面给出。在该单元顶部计算的函数（绿色决策面）将是横跨该对称", "keywords": "绿色决策面, 将是横跨该对称, 绝对值整流单元对其输入中的每对镜像点有相同的输出, 在该单元顶部计算的函数, 元的权重和偏置定义的超平面给出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "46968c08-28c4-4f16-b6c6-0573f347fa20", "label": "摘要22", "info": "Montufar et al. （2014）的主要定理指出，具有d个输入、深度为l、每个；隐藏层具有n个单元的深度整流网络可以描述的线性区域的数量是", "keywords": "个单元的深度整流网络可以描述的线性区域的数量是, 的主要定理指出, 个输入, 深度为, 具有", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e17e0e45-b94f-4f86-b25c-17ab4ae92d21", "label": "摘要23", "info": "意味着，这是深度l的指数级。在每个单元具有k个过滤器的maxout网络；中，线性区域的数量是", "keywords": "网络, 的指数级, 个过滤器的, 在每个单元具有, 意味着", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8d409fbb-f49d-4223-9325-7764258ee8d8", "label": "摘要24", "info": "当然，我们不能保证在机器学习（特别是AI）的应用中想要学得的函数；类型享有这样的属性。", "keywords": "特别是, 类型享有这样的属性, 我们不能保证在机器学习, 当然, 的应用中想要学得的函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "688ddcde-aa47-40f6-9c31-5b1d41342ade", "label": "摘要25", "info": "还可能出于统计原因来选择深度模型。任何时候，当选择一个特定的机；器学习算法时，我们隐含地陈述了一些先验，这些先验是关于算法应该；学得什么样的函数的。选择深度模型默许了一个非常普遍的信念，那就", "keywords": "任何时候, 那就, 选择深度模型默许了一个非常普遍的信念, 学得什么样的函数的, 这些先验是关于算法应该", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "baa8d06b-b6ed-46a3-baf6-2688bbed26bb", "label": "摘要26", "info": "是包含多个步骤的计算机程序，其中每个步骤使用前一步骤的输出。这；些中间输出不一定是变差因素，而是可以类似于网络用来组织其内部处；理的计数器或指针。根据经验，更深的模型似乎确实在广泛的任务中泛", "keywords": "是包含多个步骤的计算机程序, 其中每个步骤使用前一步骤的输出, 根据经验, 些中间输出不一定是变差因素, 理的计数器或指针", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "da19caf8-b8bc-4267-853c-65ded043dece", "label": "摘要27", "info": "图6.6　深度的影响。实验结果表明，当从地址照片转录多位数字时，更深层的网络能够更好地；泛化。数据来自Goodfellow et al. （2014d）。测试集上的准确率随着深度的增加而不断增加。图；6.7给出了一个对照实验，它说明了对模型尺寸其他方面的增加并不能产生相同的效果", "keywords": "测试集上的准确率随着深度的增加而不断增加, 实验结果表明, 当从地址照片转录多位数字时, 给出了一个对照实验, 更深层的网络能够更好地", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "16a9752f-ffe3-4f1c-8bc5-fa8321ab5fcc", "label": "摘要28", "info": "图6.7　参数数量的影响。更深的模型往往表现更好。这不仅仅是因为模型更大。Goodfellow et；al. （2014d）的这项实验表明，增加卷积网络层中参数的数量，但是不增加它们的深度，在提", "keywords": "在提, 但是不增加它们的深度, 的这项实验表明, 这不仅仅是因为模型更大, 增加卷积网络层中参数的数量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aa934016-5c2c-4faf-8625-c756cb50a84e", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；升测试集性能方面几乎没有效果。图例标明了用于画出每条曲线的网络深度，以及曲线表示的；是卷积层还是全连接层的大小变化。我们可以观察到，在这种情况下，浅层模型在参数数量达", "keywords": "以及曲线表示的, 升测试集性能方面几乎没有效果, 图例标明了用于画出每条曲线的网络深度, 浅层模型在参数数量达, 在这种情况下", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e4d43bb3-50f1-4617-a055-4547f36cd4ec", "label": "摘要30", "info": "6.4.2　其他架构上的考虑", "keywords": "其他架构上的考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7bea7ca0-7d29-4066-a477-be5f8a65b78c", "label": "摘要31", "info": "到目前为止，我们都将神经网络描述成层的简单链式结构，主要的考虑；因素是网络的深度和每层的宽度。在实践中，神经网络显示出相当的多；样性。", "keywords": "神经网络显示出相当的多, 样性, 因素是网络的深度和每层的宽度, 主要的考虑, 到目前为止", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a1d6c88-8e54-4e3b-a182-c83646d7d0dd", "label": "摘要32", "info": "许多神经网络架构已经被开发用于特定的任务。用于计算机视觉的卷积；神经网络的特殊架构将在第9章中介绍。前馈网络也可以推广到用于序；列处理的循环神经网络，但有它们自己的架构考虑，这将在第10章中介", "keywords": "许多神经网络架构已经被开发用于特定的任务, 章中介, 章中介绍, 这将在第, 神经网络的特殊架构将在第", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "05e21790-dc69-4aff-bc24-a2e901bf881f", "label": "摘要33", "info": "一般来说，层不需要连接在链中，尽管这是最常见的做法。许多架构构；建了一个主链，但随后又添加了额外的架构特性，例如从层i到层i＋2或；者更高层的跳跃连接。这些跳跃连接使得梯度更容易从输出层流向更接", "keywords": "尽管这是最常见的做法, 例如从层, 到层, 者更高层的跳跃连接, 许多架构构", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ae4e4f65-c125-410d-990e-57360d9d4209", "label": "摘要34", "info": "架构设计考虑的另外一个关键点是如何将层与层之间连接起来。默认的；神经网络层采用矩阵  W  描述的线性变换，每个输入单元连接到每个输；出单元。在之后章节中的许多专用网络具有较少的连接，使得输入层中", "keywords": "使得输入层中, 描述的线性变换, 神经网络层采用矩阵, 架构设计考虑的另外一个关键点是如何将层与层之间连接起来, 每个输入单元连接到每个输", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "99e02803-90bb-436d-9fea-c724404a2293", "label": "摘要35", "info": "6.4.1　万能近似性质和深；度", "keywords": "万能近似性质和深", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "bac42a92-81f4-4162-8dfe-aed8a0d5a49b", "label": "摘要36", "info": "6.4.2　其他架构上的考虑", "keywords": "其他架构上的考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "label": "6.5：反向传播和其他的微分算法", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "7d31c368-4e11-45cd-bbc5-e18759527ccd", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；6.5.1　计算图", "keywords": "计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "dd7124d3-3b76-44ea-a914-4ad4d910ffc6", "label": "摘要2", "info": "6.5.2　微积分中的链式法则", "keywords": "微积分中的链式法则", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2ad8b517-f5ad-464d-aa05-205827279be6", "label": "摘要3", "info": "6.5.3　递归地使用链式法则来实现反向传播", "keywords": "递归地使用链式法则来实现反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "448cb6e6-5a35-43bb-8125-09f86efb6a9b", "label": "摘要4", "info": "6.5.4　全连接MLP中的反向传播计算", "keywords": "全连接, 中的反向传播计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2d15d851-989f-4bdc-8e72-8e7ace247a11", "label": "摘要5", "info": "6.5.5　符号到符号的导数", "keywords": "符号到符号的导数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "141e5f55-be45-4249-8204-2ebce6100bf0", "label": "摘要6", "info": "6.5.6　一般化的反向传播", "keywords": "一般化的反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "032ce2bc-b560-43ea-a924-220ed39753c6", "label": "摘要7", "info": "6.5.7　实例：用于MLP训练的反向传播", "keywords": "用于, 训练的反向传播, 实例", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "923e6090-9bb6-4055-bd06-c80bc9ec1eb0", "label": "摘要8", "info": "6.5.8　复杂化", "keywords": "复杂化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "19518340-4121-45e4-ac1a-8a5c24477570", "label": "摘要9", "info": "6.5.9　深度学习界以外的微分", "keywords": "深度学习界以外的微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "25693d43-81ca-44cd-af1a-bb48dd8f157a", "label": "摘要10", "info": "6.5.10　高阶微分", "keywords": "高阶微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6095dd79-e8c3-4b77-9309-c2b725ffe504", "label": "摘要11", "info": "当我们使用前馈神经网络接收输入 x 并产生输出  时，信息通过网络向", "keywords": "并产生输出, 信息通过网络向, 当我们使用前馈神经网络接收输入", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "94268bae-3f84-4cf8-b88a-d8719dc305df", "label": "摘要12", "info": "前流动。输入 x  提供初始信息，然后传播到每一层的隐藏单元，最终产；生输出   。这称之为前向传播  （forward  propagation）。在训练过程；中，前向传播可以持续向前直到它产生一个标量代价函数J( θ )。反向传", "keywords": "最终产, 这称之为前向传播, 然后传播到每一层的隐藏单元, 反向传, 前向传播可以持续向前直到它产生一个标量代价函数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "07bd5fd9-58bf-4ef0-a6b2-e57a50723478", "label": "摘要13", "info": "计算梯度的解析表达式是很直观的，但是数值化地求解这样的表达式在；计算上的代价可能很大。反向传播算法使用简单和廉价的程序来实现这；个目标。", "keywords": "计算梯度的解析表达式是很直观的, 计算上的代价可能很大, 但是数值化地求解这样的表达式在, 个目标, 反向传播算法使用简单和廉价的程序来实现这", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ff61dd75-272a-47ca-a7f4-76eca0eb3ef2", "label": "摘要14", "info": "反向传播这个术语经常被误解为用于多层神经网络的整个学习算法。实；际上，反向传播仅指用于计算梯度的方法，而另一种算法，例如随机梯；度下降，使用该梯度来进行学习。此外，反向传播经常被误解为仅适用", "keywords": "反向传播仅指用于计算梯度的方法, 例如随机梯, 此外, 使用该梯度来进行学习, 而另一种算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ee1e2de2-098c-4465-ab84-09864ac3c76c", "label": "摘要15", "info": "6.5.1　计算图", "keywords": "计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "10897e94-6834-48fa-8581-f251ad584a47", "label": "摘要16", "info": "到目前为止，我们已经用相对非正式的图形语言讨论了神经网络。为了；更精确地描述反向传播算法，使用更精确的计算图；（computational", "keywords": "为了, 我们已经用相对非正式的图形语言讨论了神经网络, 到目前为止, 使用更精确的计算图, 更精确地描述反向传播算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4fb69909-ac15-4f0e-beb3-0b13109c3cd3", "label": "摘要17", "info": "将计算形式化为图形的方法有很多。", "keywords": "将计算形式化为图形的方法有很多", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "82d6e097-af9e-47b5-b4f6-d0a1e1abe575", "label": "摘要18", "info": "这里，我们使用图中的每一个节点来表示一个变量。变量可以是标量、；向量、矩阵、张量或者甚至是另一类型的变量。", "keywords": "张量或者甚至是另一类型的变量, 矩阵, 变量可以是标量, 我们使用图中的每一个节点来表示一个变量, 向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b85224a6-3d87-4dc9-a163-61209b5b10dc", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；为了形式化图形，我们还需引入操作 （operation）这一概念。操作是指；一个或多个变量的简单函数。图形语言伴随着一组被允许的操作。我们", "keywords": "一个或多个变量的简单函数, 我们还需引入操作, 操作是指, 图形语言伴随着一组被允许的操作, 我们", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fb908e4b-9534-4722-b492-f03ff8e95ec8", "label": "摘要20", "info": "为了不失一般性，我们定义一个操作仅返回单个输出变量。这并没有失；去一般性，是因为输出变量可以有多个条目，例如向量。反向传播的软；件实现通常支持具有多个输出的操作，但是我们在描述中避免这种情", "keywords": "件实现通常支持具有多个输出的操作, 但是我们在描述中避免这种情, 反向传播的软, 我们定义一个操作仅返回单个输出变量, 是因为输出变量可以有多个条目", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8d41138f-d46b-4fcd-9235-13bdfba2baae", "label": "摘要21", "info": "如果变量y是变量x通过一个操作计算得到的，那么我们画一条从x到y的；有向边。有时我们用操作的名称来注释输出的节点，当上下文很明确；时，有时也会省略这个标注。", "keywords": "有向边, 通过一个操作计算得到的, 是变量, 那么我们画一条从, 当上下文很明确", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4ca9dbbe-1921-4cf0-b12b-b47f74190018", "label": "摘要22", "info": "计算图的示例可以参考图6.8。", "keywords": "计算图的示例可以参考图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3eea701b-dd58-44d5-b9db-3402293260e9", "label": "摘要23", "info": "图6.8　一些计算图的示例。（a）使用×操作计算z＝xy的图。（b）用于逻辑回归预测", "keywords": "的图, 一些计算图的示例, 用于逻辑回归预测, 使用, 操作计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c20c0882-320d-4265-8208-43b278d03e02", "label": "摘要24", "info": "的图。一些中间表达式在代数表达式中没有名称，但在图形中却需要。", "keywords": "的图, 一些中间表达式在代数表达式中没有名称, 但在图形中却需要", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ba6377e9-059e-44f0-b022-ec78e6cae08f", "label": "摘要25", "info": "我们简单地将第i个这样的变量命名为u (i) 。（c）表达式；的计算图，在给定包含小批量输入数据的设计矩阵 x 时，它计算整流线性单元激活的设计矩阵 H；。（d）示例（a）到（c）对每个变量最多只实施一个操作，但是对变量实施多个操作也是可能", "keywords": "表达式, 的计算图, 个这样的变量命名为, 对每个变量最多只实施一个操作, 在给定包含小批量输入数据的设计矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "932fb377-500e-4aab-9f98-b5b054d68706", "label": "摘要26", "info": "，也用于权重衰减罚项", "keywords": "也用于权重衰减罚项", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "02f8ea4f-4e67-49df-bf66-9a7b6b8280c0", "label": "摘要27", "info": "6.5.2　微积分中的链式法则", "keywords": "微积分中的链式法则", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c6179e2c-4aa6-4fcb-9f56-94d2ac0c437b", "label": "摘要28", "info": "微积分中的链式法则（为了不与概率中的链式法则相混淆）用于计算复；合函数的导数。反向传播是一种计算链式法则的算法，使用高效的特定；运算顺序。", "keywords": "微积分中的链式法则, 使用高效的特定, 合函数的导数, 反向传播是一种计算链式法则的算法, 用于计算复", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e759248d-63a4-4af9-8151-a38c254edc86", "label": "摘要29", "info": "设x是实数，f和g是从实数映射到实数的函数。假设y＝g(x)并且z＝；f(g(x))＝f(y)。那么链式法则是说", "keywords": "是实数, 是从实数映射到实数的函数, 并且, 假设, 那么链式法则是说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a178d2fb-66ca-4cad-b985-fe4d61e799df", "label": "摘要30", "info": "我们可以将这种标量情况进行扩展。假设；是从", "keywords": "假设, 是从, 我们可以将这种标量情况进行扩展", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0d93667c-b579-4f04-b8ef-174a6146b4fd", "label": "摘要31", "info": "的映射，f是从", "keywords": "是从, 的映射", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "bda59e7c-c323-4acb-8e08-a5f16cc08ad6", "label": "摘要32", "info": "，g；的映射。如果", "keywords": "如果, 的映射", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fb0072a9-6b03-44a5-bdeb-e15fd10ea14a", "label": "摘要33", "info": "，那么", "keywords": "那么", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2bcecd41-e086-4a6d-9a1c-f42ff23053cf", "label": "摘要34", "info": "使用向量记法，可以等价地写成", "keywords": "使用向量记法, 可以等价地写成", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e895cee5-bf55-4d9a-9896-af9484657bfb", "label": "摘要35", "info": "这里", "keywords": "这里", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d23d4187-efda-47cf-a570-e0197b4ea2fa", "label": "摘要36", "info": "是g的n×m的Jacobian矩阵。", "keywords": "矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6bf31b22-473b-49ce-9637-f40ba49cf2d0", "label": "摘要37", "info": "从这里我们看到，变量  x  的梯度可以通过Jacobian矩阵", "keywords": "矩阵, 的梯度可以通过, 从这里我们看到, 变量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a967bcc-4abf-4019-b59f-eed87ae098c9", "label": "摘要38", "info": "和梯度", "keywords": "和梯度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cf265601-f3e4-4207-85d0-ba5a3286dacc", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；相乘来得到。反向传播算法由图中每一个这样的Jacobian梯度的", "keywords": "反向传播算法由图中每一个这样的, 梯度的, 相乘来得到", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a7bfde3a-6a4a-4a03-b668-c5ecc571fe84", "label": "摘要40", "info": "乘积操作所组成。", "keywords": "乘积操作所组成", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1f18c7d1-71cf-4485-afd5-983460c8a19a", "label": "摘要41", "info": "通常我们将反向传播算法应用于任意维度的张量，而不仅仅用于向量。；从概念上讲，这与使用向量的反向传播完全相同。唯一的区别是如何将；数字排列成网格以形成张量。我们可以想象，在运行反向传播之前，将", "keywords": "在运行反向传播之前, 数字排列成网格以形成张量, 而不仅仅用于向量, 我们可以想象, 这与使用向量的反向传播完全相同", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "34a9bd13-3208-4942-bd58-d09620fe23d7", "label": "摘要42", "info": "为了表示值z关于张量Χ  的梯度，我们记为；，就像Χ  是向量一；样。Χ  的索引现在有多个坐标——例如，一个3维的张量由3个坐标索", "keywords": "我们记为, 是向量一, 个坐标索, 维的张量由, 例如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e40fdf15-81ef-4cf1-9fa6-e4d01f86438a", "label": "摘要43", "info": "。这与向量中索引的方", "keywords": "这与向量中索引的方", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "55026534-ac35-4850-977c-0502ebb27692", "label": "摘要44", "info": "式完全一致，", "keywords": "式完全一致", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f02d4b9a-13da-46ac-a029-1f9068ac537a", "label": "摘要45", "info": "。使用这种记法，我们", "keywords": "我们, 使用这种记法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f2c5271f-aad3-436d-8f1a-13717be1f864", "label": "摘要46", "info": "可以写出适用于张量的链式法则。如果；，那么", "keywords": "那么, 如果, 可以写出适用于张量的链式法则", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4fad72a5-782e-40b3-945b-9c50b866d9b4", "label": "摘要47", "info": "6.5.3　递归地使用链式法则来实现反向传播", "keywords": "递归地使用链式法则来实现反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1acae205-3685-43b9-abde-c74f233274f9", "label": "摘要48", "info": "使用链式规则，我们可以直接写出某个标量关于计算图中任何产生该标；量的节点的梯度的代数表达式。然而，实际在计算机中计算该表达式时；会引入一些额外的考虑。", "keywords": "使用链式规则, 量的节点的梯度的代数表达式, 然而, 我们可以直接写出某个标量关于计算图中任何产生该标, 会引入一些额外的考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a110b7eb-8e2b-459c-bcba-6b4163fe99aa", "label": "摘要49", "info": "具体来说，许多子表达式可能在梯度的整个表达式中重复若干次。任何；计算梯度的程序都需要选择是存储这些子表达式还是重新计算它们几；次。图6.9给出了一个例子来说明这些重复的子表达式是如何出现的。", "keywords": "任何, 具体来说, 许多子表达式可能在梯度的整个表达式中重复若干次, 给出了一个例子来说明这些重复的子表达式是如何出现的, 计算梯度的程序都需要选择是存储这些子表达式还是重新计算它们几", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "02c3603b-067a-4b0a-915d-e96ed596bd41", "label": "摘要50", "info": "图6.9　计算梯度时导致重复子表达式的计算图。令；一步使用相同的操作函数", "keywords": "一步使用相同的操作函数, 计算梯度时导致重复子表达式的计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8b39dfef-b2e9-4085-9532-a2bb4bace588", "label": "摘要51", "info": "为图的输入。我们对链中的每", "keywords": "为图的输入, 我们对链中的每", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fdd5d0d3-cc91-40e2-9898-30a5a25c165c", "label": "摘要52", "info": "，这样 x ＝ f ( w )， y ＝ f ( x )， z ＝ f ( y )。为了计算", "keywords": "为了计算, 这样", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "15279ab2-9b38-49dd-a89e-b358de46bb7b", "label": "摘要53", "info": "，我们应用式（6.44）得到", "keywords": "得到, 我们应用式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a6fbd085-ce21-48c6-abb6-1f5857a94c78", "label": "摘要54", "info": "式（6.50）建议我们采用的实现方式是，仅计算f  (w  )的值一次并将它存；储在变量x中。这是反向传播算法所采用的方法。式（6.51）提出了一；种替代方法，其中子表达式f (w )出现了不止一次。在替代方法中，每次", "keywords": "种替代方法, 其中子表达式, 建议我们采用的实现方式是, 在替代方法中, 的值一次并将它存", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "62da0d64-92b4-48de-b4db-6b1c25bac874", "label": "摘要55", "info": "我们首先给出一个版本的反向传播算法，它指明了梯度的直接计算方式；（算法6.2以及相关的正向计算的算法6.1  ），按照它实际完成的顺序并；且递归地使用链式法则。我们可以直接执行这些计算或者将算法的描述", "keywords": "按照它实际完成的顺序并, 算法, 它指明了梯度的直接计算方式, 我们首先给出一个版本的反向传播算法, 以及相关的正向计算的算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b1a7ae99-83c7-4f01-bf66-6d6c20543c29", "label": "摘要56", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；首先考虑描述如何计算单个标量u  (n)  （例如训练样本上的损失函数）的；计算图。我们想要计算这个标量对n i 个输入节点u (1) 到", "keywords": "例如训练样本上的损失函数, 首先考虑描述如何计算单个标量, 计算图, 个输入节点, 我们想要计算这个标量对", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f90ae7b3-799d-4d49-97e7-e29793235a29", "label": "摘要57", "info": "换句话说，我们希望对所有的", "keywords": "我们希望对所有的, 换句话说", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0bf3c754-1597-4b32-9c36-4505c38329fa", "label": "摘要58", "info": "计算", "keywords": "计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "02ab3d51-3095-4781-b042-194b3a71fbd1", "label": "摘要59", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c084a3ea-923d-44de-856d-d295ca582af9", "label": "摘要60", "info": "在使用反向传播计算梯度来实现参数的梯度下降时，u  (n)  将对应单个或；者小批量实例的代价函数，而u (1) 到", "keywords": "者小批量实例的代价函数, 在使用反向传播计算梯度来实现参数的梯度下降时, 将对应单个或", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7eae9d0b-1c84-467c-87d7-0054e7006ec6", "label": "摘要61", "info": "则对应于模型的参数。", "keywords": "则对应于模型的参数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "02be2170-4710-42b4-b586-24495a879ef5", "label": "摘要62", "info": "假设图的节点已经以一种特殊的方式被排序，使得我们可以一个接一个；开始，一直上升到u  (n)  。如算法6.1中；地计算他们的输出，从", "keywords": "使得我们可以一个接一个, 开始, 如算法, 地计算他们的输出, 假设图的节点已经以一种特殊的方式被排序", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a7c43795-2651-4cba-9a4b-64bc7d15f151", "label": "摘要63", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ce0d65c8-1d2d-473d-847f-bbea968eb9c4", "label": "摘要64", "info": "是u (i) 所有父节点的集合。", "keywords": "所有父节点的集合", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fe31137b-c478-491b-a533-f86d6f0a0d28", "label": "摘要65", "info": "该算法详细说明了前向传播的计算，我们可以将其放入图   中。为了；执行反向传播，我们可以构造一个依赖于   并添加额外一组节点的计；算图。这形成了一个子图   ，它的每个节点都是   的节点。   中的", "keywords": "该算法详细说明了前向传播的计算, 我们可以构造一个依赖于, 我们可以将其放入图, 这形成了一个子图, 的节点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "492480ef-f6fe-4178-a3e5-732b5691b0e4", "label": "摘要66", "info": "与前向图中的节点u  (i)  相关联。这通过对标量输出u  (n)  使用链", "keywords": "与前向图中的节点, 相关联, 使用链, 这通过对标量输出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d4328153-722d-4ed3-8d77-e3dde9a1e16e", "label": "摘要67", "info": "式法则来完成：", "keywords": "式法则来完成", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4561d0ae-4b21-4b66-be52-afd849b4a3e8", "label": "摘要68", "info": "算法6.1 　计算将n  i  个输入u  (1)  到；这定义了一个计算图，其中每个节点通过将函数f；(i)  的值，", "keywords": "这定义了一个计算图, 计算将, 算法, 个输入, 的值", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ed51ff17-f61d-4cda-adc8-092209b9bc7e", "label": "摘要69", "info": "映射到一个输出u  (n)  的程序。；(i)  应用到变量集合；(j)  的值满足j＜i且", "keywords": "的程序, 的值满足, 映射到一个输出, 应用到变量集合", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "59e32a84-a21e-43dd-8f1c-735dcef43e8c", "label": "摘要70", "info": "上来计算u", "keywords": "上来计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "468118bd-572d-447a-97ab-64763e68cbdc", "label": "摘要71", "info": "(1) 到", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0c288aa3-3097-4dd7-80d7-70499ac3990d", "label": "摘要72", "info": "。计算图的输出可以从最后一个（输出）节点u (n) 读出。", "keywords": "输出, 计算图的输出可以从最后一个, 节点, 读出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a3b597a-7b58-4c8f-a99d-20627eea8a2f", "label": "摘要73", "info": "算法6.2  　反向传播算法的简化版本，用于计算u  (n)  关于图中变量的导；数。这个示例旨在通过演示所有变量都是标量的简化情况来进一步理解；反向传播算法，这里我们希望计算关于", "keywords": "用于计算, 这个示例旨在通过演示所有变量都是标量的简化情况来进一步理解, 算法, 反向传播算法, 反向传播算法的简化版本", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e01a3905-986b-405c-8096-efbb51da9673", "label": "摘要74", "info": "例。这与前向传播的计算次数具有相同的阶。每个", "keywords": "每个, 这与前向传播的计算次数具有相同的阶", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9bdac309-9466-423c-8890-dbcf4501835d", "label": "摘要75", "info": "是u  (i)  的父", "keywords": "的父", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aab8a627-19bf-4337-81a7-97eff4d2cf4a", "label": "摘要76", "info": "(j)  的函数，从而将前向图的节点链接到反向传播图中添加的节", "keywords": "的函数, 从而将前向图的节点链接到反向传播图中添加的节", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "615a458c-c5d7-4697-b75b-b483decf763b", "label": "摘要77", "info": "节点u；点。", "keywords": "节点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e48fd6cb-6c61-4ff3-a2ae-4fe845946151", "label": "摘要78", "info": "运行前向传播（对于此例是算法6.1 ）获得网络的激活。", "keywords": "运行前向传播, 对于此例是算法, 获得网络的激活", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fa7883b9-e2ef-473d-bbd2-616c4408e233", "label": "摘要79", "info": "初始化grad  table  ，用于存储计算好的导数的数据结构。grad  table", "keywords": "初始化, 用于存储计算好的导数的数据结构", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "319b760e-3eae-4011-a62e-b619d692f5e3", "label": "摘要80", "info": "［u (i) ］将存储", "keywords": "将存储", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "edf622a4-d564-420a-bdf3-c07f1852bfa4", "label": "摘要81", "info": "计算好的值。", "keywords": "计算好的值", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "090ebcc1-d7fd-44a7-b7b4-6d4ca55422e6", "label": "摘要82", "info": "grad table ［u (n) ］←1", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "569d93df-fdb0-4f3a-b8ca-34eeba227a90", "label": "摘要83", "info": "for j＝n−1 down to 1 do", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c4a02f86-92ba-459b-9a5c-2bb281bda513", "label": "摘要84", "info": "下一行使用存储的值计算", "keywords": "下一行使用存储的值计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2a15c149-3bfc-4019-868e-b637256c675f", "label": "摘要85", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；end for", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "df495002-5995-42bf-989a-ed6b4a4d99a0", "label": "摘要86", "info": "这在算法6.2中详细说明。子图   恰好包含每一条对应着   中从节点u", "keywords": "子图, 中详细说明, 中从节点, 恰好包含每一条对应着, 这在算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ba29561c-a25d-4378-8965-864ba1e094dc", "label": "摘要87", "info": "(j) 到节点u  (i) 的边。从u  (j) 到u  (i)  的边对应着计算", "keywords": "到节点, 的边对应着计算, 的边", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "118e61b8-26eb-4c0f-b1a3-c2d1fdba09c4", "label": "摘要88", "info": "。另外，对于", "keywords": "对于, 另外", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2752922a-7e4c-49e3-a307-b2fb46aca47d", "label": "摘要89", "info": "每个节点都要执行一个内积，内积的一个因子是对于u  j  子节点u  (i)  的已", "keywords": "子节点, 内积的一个因子是对于, 的已, 每个节点都要执行一个内积", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a72b6e22-2aed-4726-adb3-8a8507d29ec9", "label": "摘要90", "info": "经计算的梯度，另一个因子是对于相同子节点u  (i)  的偏导数", "keywords": "另一个因子是对于相同子节点, 的偏导数, 经计算的梯度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "70b14d55-73eb-47d5-94dd-f87000399519", "label": "摘要91", "info": "组", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "15eab4ac-f9dd-4dbf-ab57-bac71bc0171b", "label": "摘要92", "info": "成的向量。总而言之，执行反向传播所需的计算量与   中的边的数量；成比例，其中每条边的计算包括计算偏导数（节点关于它的一个父节点；的偏导数）以及执行一次乘法和一次加法。下面，我们将此分析推广到", "keywords": "总而言之, 节点关于它的一个父节点, 其中每条边的计算包括计算偏导数, 成的向量, 执行反向传播所需的计算量与", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "31548d05-e633-48af-b1dd-1087addef646", "label": "摘要93", "info": "反向传播算法被设计为减少公共子表达式的数量而不考虑存储的开销。；具体来说，它大约对图中的每个节点执行一个Jacobian乘积。这可以从；算法6.2中看出，反向传播算法访问了图中的节点u  (j)  到节点u  (i)  的每条", "keywords": "反向传播算法被设计为减少公共子表达式的数量而不考虑存储的开销, 它大约对图中的每个节点执行一个, 这可以从, 算法, 到节点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ae93492c-6390-4420-9ac8-83f4556c2db7", "label": "摘要94", "info": "边一次，以获得相关的偏导数", "keywords": "边一次, 以获得相关的偏导数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6cc85755-c26e-4407-a96b-bf6e87a0468c", "label": "摘要95", "info": "。反向传播因此避免了重复子表", "keywords": "反向传播因此避免了重复子表", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ba675173-adc2-4f52-8e89-366d2a7a2946", "label": "摘要96", "info": "达式的指数爆炸。然而，其他算法可能通过对计算图进行简化来避免更；多的子表达式，或者也可能通过重新计算而不是存储这些子表达式来节；省内存。我们将在描述完反向传播算法本身后再重新审视这些想法。", "keywords": "其他算法可能通过对计算图进行简化来避免更, 达式的指数爆炸, 我们将在描述完反向传播算法本身后再重新审视这些想法, 然而, 省内存", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "98049242-e4cb-4eb1-ae21-3c0e6d0ae436", "label": "摘要97", "info": "6.5.4　全连接MLP中的反向传播计算", "keywords": "全连接, 中的反向传播计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a73c34c9-fb74-48b1-808e-3666e9ba9e0f", "label": "摘要98", "info": "为了阐明反向传播的上述定义，让我们考虑一个与全连接的多层MLP相；关联的特定图。", "keywords": "关联的特定图, 为了阐明反向传播的上述定义, 让我们考虑一个与全连接的多层", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "07fa70ff-99c8-4dfb-81a5-51e21469879b", "label": "摘要99", "info": "算法6.3首先给出了前向传播，它将参数映射到与单个训练样本（输；入，目标）（  x,y  ）相关联的监督损失函数；提供输入时神经网络的输出。", "keywords": "算法, 目标, 相关联的监督损失函数, 提供输入时神经网络的输出, 它将参数映射到与单个训练样本", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d599677d-b816-4741-b3dd-354a79763384", "label": "摘要100", "info": "，其中   是当  x", "keywords": "是当, 其中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "42d826a9-d4bc-4454-aef1-dbbf2d5a9491", "label": "摘要101", "info": "算法6.3  　典型深度神经网络中的前向传播和代价函数的计算。损失函；数；取决于输出   和目标  y  （参考第6.2.1.1节中损失函数的示", "keywords": "取决于输出, 算法, 和目标, 参考第, 典型深度神经网络中的前向传播和代价函数的计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a18324ab-84e0-4d3f-a6f7-5850c17a1a0b", "label": "摘要102", "info": "，模型的权重矩阵", "keywords": "模型的权重矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8be7d8a9-fb97-4975-941e-d9ac8f0c32ae", "label": "摘要103", "info": "，模型的偏置参数", "keywords": "模型的偏置参数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9cce3c2b-62aa-49e1-822a-9707793e05f0", "label": "摘要104", "info": "Require： 网络深度，l", "keywords": "网络深度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ac063121-b0d7-4690-bb8f-2652b8311f35", "label": "摘要105", "info": "Require：W", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "369a4390-7346-4050-abb7-04897afa3ba7", "label": "摘要106", "info": "Require：", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a42fb3d1-e4b9-453c-b13f-b0c234c820ce", "label": "摘要107", "info": "Require：x ，程序的输入", "keywords": "程序的输入", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "900d2fe3-3782-4b70-9345-f04f97146aa6", "label": "摘要108", "info": "Require：y ，目标输出", "keywords": "目标输出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "815df392-8da3-4368-ad96-4b19197ee51e", "label": "摘要109", "info": "h (0) ＝ x", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "23e0512f-8e9d-4571-a3c0-84a9ae4117c0", "label": "摘要110", "info": "for k＝1，…，l do", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1314871b-862c-4631-910e-6785992418df", "label": "摘要111", "info": "end for", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7a278f26-3724-4e5e-bc90-ec9033474301", "label": "摘要112", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；算法6.4随后说明了将反向传播应用于该图所需的相关计算。", "keywords": "随后说明了将反向传播应用于该图所需的相关计算, 算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c44f53da-65bc-45ea-8108-28862b70c50e", "label": "摘要113", "info": "算法6.3和算法6.4是简单而直观的演示。然而，它们专门针对特定的问；题。", "keywords": "它们专门针对特定的问, 是简单而直观的演示, 算法, 和算法, 然而", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cf67aa26-a199-4a34-82e8-34ac8b6328d3", "label": "摘要114", "info": "现在的软件实现基于之后第6.5.6节中描述的一般形式的反向传播，它可；以通过显式地操作表示符号计算的数据结构，来适应任何计算图。", "keywords": "现在的软件实现基于之后第, 来适应任何计算图, 节中描述的一般形式的反向传播, 它可, 以通过显式地操作表示符号计算的数据结构", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "43e57e7f-df54-4e2a-ab69-3ef1bd01605b", "label": "摘要115", "info": "6.5.5　符号到符号的导数", "keywords": "符号到符号的导数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3fd60bd5-52be-486a-9973-00c60e092379", "label": "摘要116", "info": "代数表达式和计算图都对符号  （symbol）或不具有特定值的变量进行；操作。这些代数或者基于图的表达式被称为符号表示；（symbolic", "keywords": "代数表达式和计算图都对符号, 操作, 或不具有特定值的变量进行, 这些代数或者基于图的表达式被称为符号表示", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e0679b35-223e-431a-adf2-7fdd66619d5c", "label": "摘要117", "info": "。", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e8024088-b479-4217-a1cd-52913d046c64", "label": "摘要118", "info": "算法6.4 　深度神经网络中算法6.3的反向计算，它不止使用了输入  x  和；的梯度，从输出层；目标  y  。该计算对于每一层k都产生了对激活", "keywords": "算法, 目标, 从输出层, 它不止使用了输入, 的梯度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fd3861ce-1e7d-4d2f-9000-e66e29c9da51", "label": "摘要119", "info": "在前向计算完成后，计算顶层的梯度：", "keywords": "计算顶层的梯度, 在前向计算完成后", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7277a5d3-1fa8-4eaf-afed-9376c6bf9812", "label": "摘要120", "info": "for k＝l，l−1，…，1 do", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "002852a2-20f5-4415-95bf-f0bcc9b8e3d5", "label": "摘要121", "info": "将关于层输出的梯度转换为非线性激活输入前的梯度（如果f是逐；元素的，则逐元素地相乘）：", "keywords": "元素的, 如果, 则逐元素地相乘, 将关于层输出的梯度转换为非线性激活输入前的梯度, 是逐", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c40d4934-298f-4bfb-919e-e23ee2c1d593", "label": "摘要122", "info": "计算关于权重和偏置的梯度（如果需要的话，还要包括正则项）：", "keywords": "计算关于权重和偏置的梯度, 还要包括正则项, 如果需要的话", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5a724698-b0e4-420e-aa6d-cba99335f25c", "label": "摘要123", "info": "关于下一更低层的隐藏层传播梯度：", "keywords": "关于下一更低层的隐藏层传播梯度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b831db3e-95d0-4383-bd9c-9ee3ca156424", "label": "摘要124", "info": "end for", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9c2d0812-1f67-44ef-8d27-d7dca35ca8c0", "label": "摘要125", "info": "一些反向传播的方法采用计算图和一组用于图的输入的数值，然后返回；在这些输入值处梯度的一组数值。我们将这种方法称为符号到数值  的；微分。这种方法用在诸如Torch（Collobert", "keywords": "我们将这种方法称为符号到数值, 然后返回, 在这些输入值处梯度的一组数值, 微分, 这种方法用在诸如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4cb68301-2af3-4673-a680-161066e63009", "label": "摘要126", "info": "et", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aef6a11f-038f-420e-9f5c-0f637d4e9463", "label": "摘要127", "info": "另一种方法是采用计算图以及添加一些额外的节点到计算图中，这些额；外的节点提供了我们所需导数的符号描述。这是Theano（Bergstra  et  al.；，2010b；Bastien  et  al.  ，2012b）和TensorFlow（Abadi  et  al.  ，2015）", "keywords": "另一种方法是采用计算图以及添加一些额外的节点到计算图中, 这是, 这些额, 外的节点提供了我们所需导数的符号描述", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c181cdea-c0f6-43e8-88c9-7ec8bb46a840", "label": "摘要128", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图6.10　使用符号到符号的方法计算导数的示例。在这种方法中，反向传播算法不需要访问任；何实际的特定数值。相反，它将节点添加到计算图中来描述如何计算这些导数。通用图形求值", "keywords": "在这种方法中, 它将节点添加到计算图中来描述如何计算这些导数, 通用图形求值, 何实际的特定数值, 使用符号到符号的方法计算导数的示例", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b6154a6b-5a3b-4baf-a49c-f1e93757f4c5", "label": "摘要129", "info": "开始。（右）我们运行反向传播算法，指导它构造表达式", "keywords": "我们运行反向传播算法, 开始, 指导它构造表达式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "717cc754-0405-42d4-83c2-314dcba8c0af", "label": "摘要130", "info": "对应的图。在这个例子中，我", "keywords": "在这个例子中, 对应的图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9b0f72aa-ebeb-474b-9de6-8d5ab56b0522", "label": "摘要131", "info": "们不解释反向传播算法如何工作。我们的目的只是说明想要的结果是什么：符号描述的导数的；计算图", "keywords": "们不解释反向传播算法如何工作, 我们的目的只是说明想要的结果是什么, 计算图, 符号描述的导数的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d1154209-6239-4911-8dba-ebdaf7640ec6", "label": "摘要132", "info": "这种方法的主要优点是导数可以使用与原始表达式相同的语言来描述。；因为导数只是另外一张计算图，我们可以再次运行反向传播，对导数再；进行求导就能得到更高阶的导数。高阶导数的计算在第6.5.10节中描", "keywords": "我们可以再次运行反向传播, 因为导数只是另外一张计算图, 进行求导就能得到更高阶的导数, 对导数再, 这种方法的主要优点是导数可以使用与原始表达式相同的语言来描述", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "7ecf44b4-4b91-4d57-b564-ea74a7fa2f29", "label": "摘要133", "info": "我们将使用后一种方法，并且使用构造导数的计算图的方法来描述反向；传播算法。图的任意子集之后都可以使用特定的数值来求值。这允许我；们避免精确地指明每个操作应该在何时计算。相反，通用的图计算引擎", "keywords": "我们将使用后一种方法, 并且使用构造导数的计算图的方法来描述反向, 传播算法, 图的任意子集之后都可以使用特定的数值来求值, 这允许我", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a249aa18-ae5c-484a-a277-7062e4da1c88", "label": "摘要134", "info": "基于符号到符号的方法的描述包含了符号到数值的方法。符号到数值的；方法可以理解为执行了与符号到符号的方法中构建图的过程中完全相同；的计算。关键的区别是符号到数值的方法不会显示出计算图。", "keywords": "方法可以理解为执行了与符号到符号的方法中构建图的过程中完全相同, 的计算, 关键的区别是符号到数值的方法不会显示出计算图, 基于符号到符号的方法的描述包含了符号到数值的方法, 符号到数值的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6eca65a4-a6a1-40fa-9ab2-27a6fd841289", "label": "摘要135", "info": "6.5.6　一般化的反向传播", "keywords": "一般化的反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3313aa7a-ab54-4725-ba90-5161a6cb7c54", "label": "摘要136", "info": "反向传播算法非常简单。为了计算某个标量z关于图中它的一个祖先  x", "keywords": "关于图中它的一个祖先, 反向传播算法非常简单, 为了计算某个标量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "749874a3-fe8a-4b4c-9124-3af236a0b77f", "label": "摘要137", "info": "的梯度，首先观察到它关于z的梯度由", "keywords": "的梯度由, 的梯度, 首先观察到它关于", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "92bdf2a0-a95c-4f61-a7c4-8ea1eb3ef728", "label": "摘要138", "info": "给出。然后，我们", "keywords": "然后, 我们, 给出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8c9f6d3e-cc58-4749-8822-18414d8f905d", "label": "摘要139", "info": "可以计算对图中z的每个父节点的梯度，通过现有的梯度乘以产生z的操；作的Jacobian。我们继续乘以Jacobian，以这种方式向后穿过图，直到到；达  x  。对于从z出发可以经过两个或更多路径向后行进而到达的任意节", "keywords": "可以计算对图中, 作的, 对于从, 出发可以经过两个或更多路径向后行进而到达的任意节, 直到到", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "467746b7-41af-4304-873d-f9844447bcd2", "label": "摘要140", "info": "更正式地，图   中的每个节点对应着一个变量。为了实现最大的一般；化，我们将这个变量描述为一个张量V  。张量通常可以具有任意维度，；并且包含标量、向量和矩阵。", "keywords": "我们将这个变量描述为一个张量, 中的每个节点对应着一个变量, 向量和矩阵, 并且包含标量, 为了实现最大的一般", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fa6835eb-95f2-49f2-acc4-9b4ff4135a09", "label": "摘要141", "info": "我们假设每个变量V 与下列子程序相关联：", "keywords": "与下列子程序相关联, 我们假设每个变量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "99ab9f49-2f50-4e33-8cfd-6996bdf00ce0", "label": "摘要142", "info": "get_operation(V )：它返回用于计算V 的操作，代表了在计算图中流；入V  的边。例如，可能有一个Python或者C＋＋的类表示矩阵乘法；操作，以及get_operation 函数。假设我们的一个变量是由矩阵乘法", "keywords": "的类表示矩阵乘法, 可能有一个, 它返回用于计算, 操作, 假设我们的一个变量是由矩阵乘法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "344906cb-527b-4573-b1d5-050c1d2dcc77", "label": "摘要143", "info": "：它返回一组变量，是计算图   中", "keywords": "是计算图, 它返回一组变量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6815f957-2dfb-4cc6-9d05-f594855635f4", "label": "摘要144", "info": "V 的子节点。", "keywords": "的子节点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9cb0fb37-3560-48e4-b073-af825cf7138d", "label": "摘要145", "info": "父节点。", "keywords": "父节点", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d5a8f7d8-698b-47c8-b353-11f6e605a21d", "label": "摘要146", "info": "：它返回一组变量，是计算图   中V  的", "keywords": "是计算图, 它返回一组变量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "846d12c7-14d4-44b6-8be5-52267e5ae281", "label": "摘要147", "info": "每个操作op  也与bprop  操作相关联。该bprop  操作可以计算如式；（6.47）所描述的Jacobian向量积。这是反向传播算法能够实现很大通；用性的原因。每个操作负责了解如何通过它参与的图中的边来反向传", "keywords": "这是反向传播算法能够实现很大通, 向量积, 操作可以计算如式, 操作相关联, 每个操作负责了解如何通过它参与的图中的边来反向传", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d6cd58a5-5edb-414f-84f9-a4a9b1d4ac8a", "label": "摘要148", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；梯度是；需要使用正确的参数调用每个操作的bprop", "keywords": "梯度是, 需要使用正确的参数调用每个操作的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "53885280-056f-4a71-abef-77f6535f9288", "label": "摘要149", "info": "。反向传播算法本身并不需要知道任何微分法则。它只；方法即可。正式地，", "keywords": "方法即可, 正式地, 反向传播算法本身并不需要知道任何微分法则, 它只", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1cd5f44a-eb80-4489-9553-6b35102d6f3b", "label": "摘要150", "info": "这只是如式（6.47）所表达的链式法则的实现。这里，inputs  是提供给；操作的一组输入，op.f  是操作实现的数学函数，X  是输入，我们想要计；算关于它的梯度，G 是操作对于输出的梯度。", "keywords": "是操作实现的数学函数, 这只是如式, 是操作对于输出的梯度, 是输入, 我们想要计", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "02cf665d-ba8d-48e2-b587-0720ddb1aaf7", "label": "摘要151", "info": "op.bprop 方法应该总是假装它的所有输入彼此不同，即使它们不是。例；如，如果mul  操作传递两个x来计算x  2  ，op.bprop  方法应该仍然返回x；作为对于两个输入的导数。反向传播算法后面会将这些变量加起来获得", "keywords": "如果, 即使它们不是, 反向传播算法后面会将这些变量加起来获得, 方法应该总是假装它的所有输入彼此不同, 来计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "45700180-7552-4e80-977d-f35da4c74228", "label": "摘要152", "info": "反向传播算法的软件实现通常提供操作和其bprop  方法，所以深度学习；软件库的用户能够对使用诸如矩阵乘法、指数运算、对数运算等常用操；作构建的图进行反向传播。构建反向传播新实现的软件工程师或者需要", "keywords": "对数运算等常用操, 指数运算, 方法, 反向传播算法的软件实现通常提供操作和其, 构建反向传播新实现的软件工程师或者需要", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4ccb0302-d1c5-413c-92ae-6cb0b29efe48", "label": "摘要153", "info": "反向传播算法的正式描述参考算法6.5。", "keywords": "反向传播算法的正式描述参考算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5cc805ea-9656-4899-b754-e3c9d2fa4421", "label": "摘要154", "info": "算法6.5  　反向传播算法最外围的骨架。这部分做简单的设置和清理工；作。大多数重要的工作发生在算法6.6的子程序build_grad 中。", "keywords": "这部分做简单的设置和清理工, 算法, 的子程序, 反向传播算法最外围的骨架, 大多数重要的工作发生在算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "01108fe0-5303-4cac-a96f-63c1b7af5892", "label": "摘要155", "info": "Require：", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3f998610-7b52-4f8c-a532-4fe4f1c27551", "label": "摘要156", "info": "，需要计算梯度的目标变量集", "keywords": "需要计算梯度的目标变量集", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d0b4ff81-63ac-4639-8341-1866ae7021a5", "label": "摘要157", "info": "Require：", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a4f5c988-5f06-4c78-92c6-5ecb3ef2b351", "label": "摘要158", "info": "，计算图", "keywords": "计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b0f66103-3e4b-45d3-8324-b0e5656b7e6e", "label": "摘要159", "info": "Require： z，要微分的变量", "keywords": "要微分的变量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b1a761d0-8668-41fe-8450-f9e7a9bca8f1", "label": "摘要160", "info": "令", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c8f724c9-1663-48dc-8b6f-31e7d1245fcb", "label": "摘要161", "info": "剪枝后的计算图，其中仅包括z的祖先以及   中节点的", "keywords": "其中仅包括, 的祖先以及, 中节点的, 剪枝后的计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "621cede5-ec07-4588-80f7-eba66a4ac08c", "label": "摘要162", "info": "后代。", "keywords": "后代", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b6b22cfd-ba8f-4692-b5cf-309f6730a8d7", "label": "摘要163", "info": "初始化grad table ，它是关联张量和对应导数的数据结构。", "keywords": "初始化, 它是关联张量和对应导数的数据结构", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f9206cde-71fb-4660-812e-cd1284d2dcbf", "label": "摘要164", "info": "grad table ［z］←1", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "857c3666-8f3a-4d28-8610-3ac4bdbe9108", "label": "摘要165", "info": "end for", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "eabee958-4560-48de-bfe7-3c94574e43f6", "label": "摘要166", "info": "Return grad table restricted to", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "817a5339-d7ea-471f-9961-741dafe1186b", "label": "摘要167", "info": "在第6.5.2节中，我们使用反向传播作为一种策略来避免多次计算链式法；则中的相同子表达式。由于这些重复子表达式的存在，简单的算法可能；具有指数运行时间。现在我们已经详细说明了反向传播算法，可以去理", "keywords": "现在我们已经详细说明了反向传播算法, 节中, 具有指数运行时间, 在第, 可以去理", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "dabe4829-7aab-4854-9601-6fb2b8378b89", "label": "摘要168", "info": "2", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "572f628b-a23c-4419-b313-b4c55d5137c6", "label": "摘要169", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；算法6.6", "keywords": "算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d65bb45b-f3c2-48fa-98ed-493282922062", "label": "摘要170", "info": "向传播算法调用。", "keywords": "向传播算法调用", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4f2d0da7-5df7-4a0a-a7cb-d7ff5d283c8a", "label": "摘要171", "info": "反向传播算法的内循环子程序；，由算法6.5中定义的反", "keywords": "反向传播算法的内循环子程序, 中定义的反, 由算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b7561b8a-4638-4694-a60b-3b89146be8ed", "label": "摘要172", "info": "由于节点j到节点n的路径数目可以关于这些路径的长度上指数地增长，；所以上述求和符号中的项数（这些路径的数目），可能以前向传播图的", "keywords": "由于节点, 到节点, 这些路径的数目, 可能以前向传播图的, 的路径数目可以关于这些路径的长度上指数地增长", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6f7075f4-bc46-414b-bd5a-c4a9f9c0d9ee", "label": "摘要173", "info": "深度的指数级增长。会产生如此大的成本是因为对于", "keywords": "会产生如此大的成本是因为对于, 深度的指数级增长", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f8c4a8fd-9649-4e4f-a4d7-7909e946dc86", "label": "摘要174", "info": "，相同的", "keywords": "相同的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fa69557b-15d4-4f2a-9847-a32c1974f37c", "label": "摘要175", "info": "计算会重复进行很多次。为了避免这种重新计算，我们可以将反向传播", "keywords": "我们可以将反向传播, 计算会重复进行很多次, 为了避免这种重新计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "342ae529-e69e-4586-a378-11d0ad521dff", "label": "摘要176", "info": "看作一种表填充算法，利用存储的中间结果", "keywords": "利用存储的中间结果, 看作一种表填充算法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "72c6e768-aa2f-4aef-ba15-915255284695", "label": "摘要177", "info": "来对表进行填充。", "keywords": "来对表进行填充", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "89f07747-d8aa-4553-899b-fb33930a0d41", "label": "摘要178", "info": "图中的每个节点对应着表中的一个位置，这个位置存储对该节点的梯；度。通过顺序填充这些表的条目，反向传播算法避免了重复计算许多公；共子表达式。这种表填充策略有时被称为动态规划", "keywords": "图中的每个节点对应着表中的一个位置, 共子表达式, 这个位置存储对该节点的梯, 这种表填充策略有时被称为动态规划, 通过顺序填充这些表的条目", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4569cca4-49fd-492e-ab74-961d1289bb35", "label": "摘要179", "info": "6.5.7　实例：用于MLP训练的反向传播", "keywords": "用于, 训练的反向传播, 实例", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1bdf529e-78de-4eb4-9136-d28036045a1b", "label": "摘要180", "info": "作为一个例子，我们利用反向传播算法来训练多层感知机。", "keywords": "我们利用反向传播算法来训练多层感知机, 作为一个例子", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1af4cfc6-b7c6-4064-8d4f-a65f9ab4bcc8", "label": "摘要181", "info": "这里，我们考虑一个具有单个隐藏层的非常简单的多层感知机。为了训；练这个模型，我们将使用小批量随机梯度下降算法。反向传播算法用于；计算单个小批量上的代价的梯度。具体来说，我们使用训练集上的一小", "keywords": "我们使用训练集上的一小, 为了训, 我们将使用小批量随机梯度下降算法, 反向传播算法用于, 练这个模型", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aa8c410c-2953-4816-a8e6-c8f99b45d184", "label": "摘要182", "info": "包含了交叉熵和系数为λ的权重衰减项。它的计算图在图6.11中给出。", "keywords": "中给出, 它的计算图在图, 的权重衰减项, 包含了交叉熵和系数为", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4fc87ad2-0420-408f-b707-93be8c1675d1", "label": "摘要183", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图6.11　用于计算代价函数的计算图，这个代价函数是使用交叉熵损失以及权重衰减训练我们；的单层MLP示例所产生的", "keywords": "用于计算代价函数的计算图, 示例所产生的, 的单层, 这个代价函数是使用交叉熵损失以及权重衰减训练我们", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b7f16a71-0b38-4f3d-a3d2-3a1d2f5f4f23", "label": "摘要184", "info": "这个示例的梯度计算图实在太大，以至于绘制或者阅读都将是乏味的。；这显示出了反向传播算法的优点之一，即它可以自动生成梯度，而这种；计算对于软件工程师来说需要进行直观但冗长的手动推导。", "keywords": "计算对于软件工程师来说需要进行直观但冗长的手动推导, 即它可以自动生成梯度, 以至于绘制或者阅读都将是乏味的, 这显示出了反向传播算法的优点之一, 这个示例的梯度计算图实在太大", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ce51811e-8335-4750-8e57-76986039e418", "label": "摘要185", "info": "我们可以通过观察图6.11中的正向传播图来粗略地描述反向传播算法的；行为。为了训练，我们希望计算；。有两种不同", "keywords": "有两种不同, 行为, 中的正向传播图来粗略地描述反向传播算法的, 我们希望计算, 我们可以通过观察图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b501bc3f-41d3-4a90-85ca-cd558b81315b", "label": "摘要186", "info": "另一条通过交叉熵代价的路径稍微复杂一些。令  G  是由cross_entropy；操作提供的对未归一化对数概率  U  (2)  的梯度。反向传播算法现在需要；探索两个不同的分支。在较短的分支上，它使用对矩阵乘法的第二个变", "keywords": "它使用对矩阵乘法的第二个变, 是由, 另一条通过交叉熵代价的路径稍微复杂一些, 反向传播算法现在需要, 的梯度", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "5fe2856a-2a73-4707-bf67-eaa1445ae450", "label": "摘要187", "info": "量的反向传播规则，将", "keywords": "量的反向传播规则", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a4588938-1435-419c-8e3e-b507ed05b0ff", "label": "摘要188", "info": "加到 W (2) 的梯度上。", "keywords": "加到, 的梯度上", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2c88952a-23c7-4baa-ac23-5c805897e5db", "label": "摘要189", "info": "在计算了这些梯度以后，梯度下降算法或者其他优化算法所要做的就是；使用这些梯度来更新参数。", "keywords": "在计算了这些梯度以后, 梯度下降算法或者其他优化算法所要做的就是, 使用这些梯度来更新参数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2adec6de-24e4-4e57-8ad7-ee658f3990f6", "label": "摘要190", "info": "对于MLP，计算成本主要来源于矩阵乘法。在前向传播阶段，我们乘以；每个权重矩阵，得到了O(w)数量的乘  -  加，其中w是权重的数量。在反；向传播阶段，我们乘以每个权重矩阵的转置，这具有相同的计算成本。", "keywords": "在反, 我们乘以每个权重矩阵的转置, 数量的乘, 这具有相同的计算成本, 向传播阶段", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e61cbdea-57af-4a8c-948e-54fe9e236fc7", "label": "摘要191", "info": "6.5.8　复杂化", "keywords": "复杂化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "af5ee38f-2076-467b-a0b2-1a0227523297", "label": "摘要192", "info": "我们这里描述的反向传播算法要比实践中实际使用的实现要简单。", "keywords": "我们这里描述的反向传播算法要比实践中实际使用的实现要简单", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a7235edb-5a16-4f38-9a56-173fb4f410e2", "label": "摘要193", "info": "正如前面提到的，我们将操作的定义限制为返回单个张量的函数。大多；数软件实现需要支持可以返回多个张量的操作。例如，如果我们希望计；算张量中的最大值和该值的索引，则最好在单次运算中计算两者，因此", "keywords": "算张量中的最大值和该值的索引, 正如前面提到的, 因此, 数软件实现需要支持可以返回多个张量的操作, 例如", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "42febe23-2feb-4901-a65e-31b4d244d59c", "label": "摘要194", "info": "我们还没有描述如何控制反向传播的内存消耗。反向传播经常涉及将许；多张量加在一起。在朴素方法中，将分别计算这些张量中的每一个，然；后在第二步中对所有这些张量求和。朴素方法具有过高的存储瓶颈，可", "keywords": "将分别计算这些张量中的每一个, 后在第二步中对所有这些张量求和, 朴素方法具有过高的存储瓶颈, 在朴素方法中, 我们还没有描述如何控制反向传播的内存消耗", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1c7fbc9d-87fe-4522-ac9e-3924ad44f985", "label": "摘要195", "info": "反向传播的现实实现还需要处理各种数据类型，例如32位浮点数、64位；浮点数和整型。处理这些类型的策略需要特别的设计考虑。", "keywords": "浮点数和整型, 反向传播的现实实现还需要处理各种数据类型, 例如, 位浮点数, 处理这些类型的策略需要特别的设计考虑", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aadcddde-9883-4311-a69a-c36d9c28ea4e", "label": "摘要196", "info": "一些操作具有未定义的梯度，并且重要的是跟踪这些情况并且确定用户；请求的梯度是否是未定义的。", "keywords": "并且重要的是跟踪这些情况并且确定用户, 一些操作具有未定义的梯度, 请求的梯度是否是未定义的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0f543540-30d1-4ec2-8d92-5a24bca3fc30", "label": "摘要197", "info": "各种其他技术的特性使现实世界的微分更加复杂。这些技术性并不是不；可逾越的，本章已经描述了计算微分所需的关键知识工具，但重要的是；要知道还有许多的精妙之处存在。", "keywords": "这些技术性并不是不, 但重要的是, 各种其他技术的特性使现实世界的微分更加复杂, 本章已经描述了计算微分所需的关键知识工具, 要知道还有许多的精妙之处存在", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1c4e721e-1017-48e6-9df2-32d751895ce9", "label": "摘要198", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；6.5.9　深度学习界以外的微分", "keywords": "深度学习界以外的微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9371ecea-7875-4978-9d46-4c500fdf29b0", "label": "摘要199", "info": "深度学习界在某种程度上已经与更广泛的计算机科学界隔离开来，并且；在很大程度上发展了自己关于如何进行微分的文化态度。一般来说，自；动微分  （automatic", "keywords": "一般来说, 动微分, 深度学习界在某种程度上已经与更广泛的计算机科学界隔离开来, 在很大程度上发展了自己关于如何进行微分的文化态度, 并且", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "2b8a24e1-c48b-493d-b793-e39c8f64320c", "label": "摘要200", "info": "例如，假设有变量p 1 ，p  2  …，p  n  表示概率，以及变量z  1  ，z  2  ，…z  n；表示未归一化的对数概率。假设定义", "keywords": "假设定义, 假设有变量, 表示概率, 例如, 表示未归一化的对数概率", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6e2ccd3b-310b-468f-9940-c6d7c14f020c", "label": "摘要201", "info": "其中我们通过指数化、求和与除法运算构建softmax函数，并构造交叉；。人类数学家可以观察到J对z i 的；熵损失函数", "keywords": "熵损失函数, 并构造交叉, 函数, 人类数学家可以观察到, 求和与除法运算构建", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "60ff71fb-80a4-4a13-8acc-4b0650eb7f54", "label": "摘要202", "info": "当前向图  具有单个输出节点，并且每个偏导数", "keywords": "具有单个输出节点, 并且每个偏导数, 当前向图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "473edc60-c829-44ac-b096-f5c27c44b1a5", "label": "摘要203", "info": "都可以用恒定", "keywords": "都可以用恒定", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cc02cf39-a1e0-4452-a082-3e6b34eab4d0", "label": "摘要204", "info": "的计算量来计算时，反向传播保证梯度计算的计算数目和前向计算的计；算数目是同一个量级：这可以在算法6.2中看出，因为每个局部偏导数", "keywords": "算数目是同一个量级, 反向传播保证梯度计算的计算数目和前向计算的计, 这可以在算法, 因为每个局部偏导数, 中看出", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f028192d-8c29-4743-ab49-1f25856dab06", "label": "摘要205", "info": "以及递归链式公式（式(6.53)）中相关的乘和加都只需计算一", "keywords": "中相关的乘和加都只需计算一, 以及递归链式公式", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b687dc76-0a7f-43df-9abf-c200b126d3f5", "label": "摘要206", "info": "次。因此，总的计算量是O(#edges)。然而，可能通过对反向传播算法构；建的计算图进行简化来减少这些计算量，并且这是NP完全问题。诸如；Theano和TensorFlow的实现使用基于匹配已知简化模式的试探法，以便", "keywords": "以便, 因此, 并且这是, 可能通过对反向传播算法构, 然而", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3ac88bc0-8301-4fc1-8456-db33a7ee67fb", "label": "摘要207", "info": "重复地尝试去简化图。我们定义反向传播仅用于计算标量输出的梯度，；但是反向传播可以扩展到计算Jacobian矩阵（该Jacobian矩阵或者来源于；图中的k个不同标量节点，或者来源于包含k个值的张量值节点）。朴素", "keywords": "我们定义反向传播仅用于计算标量输出的梯度, 朴素, 或者来源于包含, 矩阵, 图中的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "03b646ac-ad36-4ab2-a640-706095762640", "label": "摘要208", "info": "其中的矩阵可以认为是Jacobian矩阵。例如，如果 D 是列向量，而 A 有；很多行，那么这对应于一幅具有单个输出和多个输入的图，并且从最后；开始乘，反向进行，只需要矩阵-向量的乘积。这对应着反向模式。相", "keywords": "如果, 反向进行, 其中的矩阵可以认为是, 矩阵, 是列向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "583327fa-45fe-4200-9585-ef85d09aa8fc", "label": "摘要209", "info": "在机器学习以外的许多社区中，更常见的是使用传统的编程语言来直接；实现微分软件，例如用Python或者C来编程，并且自动生成使用这些语；言编写的不同函数的程序。在深度学习界中，计算图通常使用由专用库", "keywords": "更常见的是使用传统的编程语言来直接, 来编程, 在机器学习以外的许多社区中, 并且自动生成使用这些语, 实现微分软件", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "eaa849ee-63b1-44f2-86d7-711990a49cf1", "label": "摘要210", "info": "因此，反向传播不是计算梯度的唯一方式或最佳方式，但它是一个非常；实用的方法，继续为深度学习社区服务。在未来，深度网络的微分技术；可能会提高，因为深度学习的从业者更加懂得了更广泛的自动微分领域", "keywords": "实用的方法, 因此, 可能会提高, 反向传播不是计算梯度的唯一方式或最佳方式, 深度网络的微分技术", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d7065d69-850b-443a-9efb-45c37e639149", "label": "摘要211", "info": "6.5.10　高阶微分", "keywords": "高阶微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "112e804c-db0c-4244-83f2-c5b1e1755117", "label": "摘要212", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；一些软件框架支持使用高阶导数。在深度学习软件框架中，这至少包括；Theano和TensorFlow。这些库使用一种数据结构来描述要被微分的原始", "keywords": "这些库使用一种数据结构来描述要被微分的原始, 这至少包括, 在深度学习软件框架中, 一些软件框架支持使用高阶导数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "27dae5de-02a9-436d-bfcb-3e1991ea7dfe", "label": "摘要213", "info": "在深度学习的相关领域，很少会计算标量函数的单个二阶导数。相反，；我们通常对Hessian矩阵的性质比较感兴趣。如果我们有函数", "keywords": "矩阵的性质比较感兴趣, 在深度学习的相关领域, 很少会计算标量函数的单个二阶导数, 我们通常对, 相反", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "f06faa14-3731-4007-ae4c-db518ac404ff", "label": "摘要214", "info": "，那么Hessian矩阵的大小是n×n。在典型的深度学", "keywords": "那么, 矩阵的大小是, 在典型的深度学", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "da2b4702-4026-42e0-86e3-7121cdc9e864", "label": "摘要215", "info": "习应用中，n将是模型的参数数量，可能很容易达到数十亿。因此，完；整的Hessian矩阵甚至不能表示。", "keywords": "矩阵甚至不能表示, 因此, 将是模型的参数数量, 整的, 可能很容易达到数十亿", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4ed02108-8e05-4f43-9c23-06a74566da95", "label": "摘要216", "info": "典型的深度学习方法是使用Krylov方法  （Krylov  method），而不是显；式地计算Hessian矩阵。Krylov方法是用于执行各种操作的一组迭代技；术，这些操作包括像近似求解矩阵的逆或者近似矩阵的特征值/特征向", "keywords": "方法是用于执行各种操作的一组迭代技, 特征向, 矩阵, 而不是显, 式地计算", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "cacb356a-78c7-4cb6-8ca1-d8b7fdf87fef", "label": "摘要217", "info": "为了在Hesssian矩阵上使用Krylov方法，我们只需要能够计算Hessian矩；阵  H  和一个任意向量ν间的乘积即可。实现这一目标的一种直观方法；（Christianson，1992）是", "keywords": "间的乘积即可, 我们只需要能够计算, 矩阵上使用, 为了在, 和一个任意向量", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "738351a5-63f1-4896-ad75-79a0cb7126a6", "label": "摘要218", "info": "该表达式中两个梯度的计算都可以由适当的软件库自动完成。注意，外；部梯度表达式是内部梯度表达式的函数的梯度。", "keywords": "部梯度表达式是内部梯度表达式的函数的梯度, 注意, 该表达式中两个梯度的计算都可以由适当的软件库自动完成", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "367b0985-1be6-49eb-9410-a29b484424e1", "label": "摘要219", "info": "如果ν本身是由计算图产生的一个向量，那么重要的是指定自动微分软；件不要对产生ν的图进行微分。", "keywords": "如果, 的图进行微分, 本身是由计算图产生的一个向量, 件不要对产生, 那么重要的是指定自动微分软", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fb148968-f8df-44f5-901e-44a9886dc6a3", "label": "摘要220", "info": "虽然计算Hessian通常是不可取的，但是可以使用Hessian向量积。可以；对所有的i＝1,...,n简单地计算 He (i )，其中e (i )是；都为0的one-hot向量。", "keywords": "向量积, 简单地计算, 但是可以使用, 都为, 其中", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e21bfd53-d079-4c3d-b248-9b177fa14379", "label": "摘要221", "info": "并且其他元素", "keywords": "并且其他元素", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "fcb59cb5-bd16-405d-8fef-9bbc73213d7f", "label": "摘要222", "info": "6.5.1　计算图", "keywords": "计算图", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3fabd7c7-f7a0-46cc-804c-fc9feb38293e", "label": "摘要223", "info": "6.5.2　微积分中的链式法；则", "keywords": "微积分中的链式法", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "83721be8-2806-4fc1-b345-8918b5d9ed74", "label": "摘要224", "info": "6.5.3　递归地使用链式法；则来实现反向传播", "keywords": "递归地使用链式法, 则来实现反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aacc375b-a089-41ee-8a9d-f530157cc610", "label": "摘要225", "info": "6.5.4　全连接MLP中的反；向传播计算", "keywords": "向传播计算, 全连接, 中的反", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d2701c99-5f8a-400c-a645-bda976171ce6", "label": "摘要226", "info": "6.5.5　符号到符号的导数", "keywords": "符号到符号的导数", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6eaba12a-2972-48b1-bc0f-c5c35eb591c8", "label": "摘要227", "info": "6.5.6　一般化的反向传播", "keywords": "一般化的反向传播", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "627dbe9d-7f08-4edd-be47-270c2b6f0607", "label": "摘要228", "info": "6.5.7　实例：用于MLP训；练的反向传播", "keywords": "用于, 练的反向传播, 实例", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "1744abfb-5982-4270-8fe0-a23cadd5ad38", "label": "摘要229", "info": "6.5.8　复杂化", "keywords": "复杂化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "3685d30f-2787-48b7-9ea7-2a05f3243b54", "label": "摘要230", "info": "6.5.9　深度学习界以外的；微分", "keywords": "深度学习界以外的, 微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "65560cf8-2b48-47e2-954f-717b2c23fd0a", "label": "摘要231", "info": "6.5.10　高阶微分", "keywords": "高阶微分", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9199ddd6-1be9-4783-9da3-cd67a484335a", "label": "6.6：历史小记", "level": 2, "group": "chapter-6", "type": "子章節"}, {"id": "cd65d164-738b-4e0b-bd74-416fc8910325", "label": "摘要1", "info": "前馈网络可以被视为一种高效的非线性函数近似器，它以使用梯度下降；来最小化函数近似误差为基础。从这个角度来看，现代前馈网络是一般", "keywords": "来最小化函数近似误差为基础, 前馈网络可以被视为一种高效的非线性函数近似器, 现代前馈网络是一般, 它以使用梯度下降, 从这个角度来看", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "43b415e3-cf8f-4493-953a-085edb17c704", "label": "摘要2", "info": "函数近似任务的几个世纪进步的结晶。", "keywords": "函数近似任务的几个世纪进步的结晶", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "c13dac42-7b76-42d1-a96d-5cb52ee9572f", "label": "摘要3", "info": "处于反向传播算法底层的链式法则是17世纪发明的（Leibniz，1676；；L'Hôpital，1696）。微积分和代数长期以来被用于求解优化问题的封闭；形式，但梯度下降直到19世纪才作为优化问题的一种迭代近似的求解方", "keywords": "形式, 世纪才作为优化问题的一种迭代近似的求解方, 微积分和代数长期以来被用于求解优化问题的封闭, 但梯度下降直到, 世纪发明的", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4f715dfb-62e9-4a4e-b65a-aa13ca341007", "label": "摘要4", "info": "从20世纪40年代开始，这些函数近似技术被用于导出诸如感知机的机器；学习模型。然而，最早的模型都是基于线性模型。来自包括Marvin；Minsky的批评指出了线性模型族的几个缺陷，例如它无法学习XOR函", "keywords": "的批评指出了线性模型族的几个缺陷, 世纪, 这些函数近似技术被用于导出诸如感知机的机器, 例如它无法学习, 然而", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "6eb6eff6-44fb-47b5-95ff-e0154d5688d4", "label": "摘要5", "info": "学习非线性函数需要多层感知机的发展和计算该模型梯度的方法。基于；动态规划的链式法则的高效应用开始出现在20世纪60年代和70年代，主；要用于控制领域（Kelley，1960；Bryson and Denham，1961；Dreyfus，", "keywords": "要用于控制领域, 学习非线性函数需要多层感知机的发展和计算该模型梯度的方法, 世纪, 年代, 基于", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "0d0333a8-1562-4514-bb50-dcd537ea496a", "label": "摘要6", "info": "在反向传播的成功之后，神经网络研究获得了普及，并在20世纪90年代；初达到高峰。随后，其他机器学习技术变得更受欢迎，直到2006年开始；的现代深度学习复兴。", "keywords": "随后, 世纪, 的现代深度学习复兴, 年代, 初达到高峰", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "bd05669c-5e38-4437-b32d-576c7ee0528c", "label": "摘要7", "info": "现代前馈网络的核心思想自20世纪80年代以来没有发生重大变化，仍然；使用相同的反向传播算法和相同的梯度下降方法。1986∼2015年，神经；网络性能的大部分改进可归因于两个因素：第一，较大的数据集减少了", "keywords": "第一, 世纪, 使用相同的反向传播算法和相同的梯度下降方法, 神经, 年代以来没有发生重大变化", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "51a30a1d-4621-4601-a4c2-9b745ff9cd95", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；统计泛化对神经网络的挑战的程度。第二，神经网络由于更强大的计算；机和更好的软件基础设施已经变得更大。然而，少量算法上的变化也显", "keywords": "机和更好的软件基础设施已经变得更大, 神经网络由于更强大的计算, 然而, 统计泛化对神经网络的挑战的程度, 少量算法上的变化也显", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "767f7e9e-4363-4b93-874a-d838cb69d97d", "label": "摘要9", "info": "其中一个算法上的变化是用损失函数的交叉熵族替代均方误差。均方误；差在20世纪80年代和90年代流行，但逐渐被交叉熵损失替代，并且最大；似然原理的想法在统计学界和机器学习界之间广泛传播。使用交叉熵损", "keywords": "世纪, 但逐渐被交叉熵损失替代, 均方误, 并且最大, 年代流行", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9c3dd3ea-bcd6-41ab-9e0b-cc27c4e7061a", "label": "摘要10", "info": "另一个显著改善前馈网络性能的算法上的主要变化是使用分段线性隐藏；单元来替代sig-moid隐藏单元，例如用整流线性单元。使用max{0,z}函；数的整流在早期神经网络中已经被引入，并且至少可以追溯到认知机", "keywords": "隐藏单元, 单元来替代, 数的整流在早期神经网络中已经被引入, 例如用整流线性单元, 使用", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "aa74dd96-21ab-40da-b040-9d297b94621e", "label": "摘要11", "info": "对于小的数据集，Jarrett  et  al.  （2009b）观察到，使用整流非线性甚至；比学习隐藏层的权重值更加重要。随机的权重足以通过整流网络传播有；用的信息，允许在顶部的分类器层学习如何将不同的特征向量映射到类", "keywords": "允许在顶部的分类器层学习如何将不同的特征向量映射到类, 随机的权重足以通过整流网络传播有, 比学习隐藏层的权重值更加重要, 对于小的数据集, 用的信息", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "b1749f59-f012-4925-84e1-d8f90f86815f", "label": "摘要12", "info": "当有更多数据可用时，学习开始提取足够的有用知识来超越随机选择参；数的性能。Glorot  et  al.  （2011a）说明，在深度整流网络中的学习比在；激活函数具有曲率或两侧饱和的深度网络中的学习更容易。", "keywords": "激活函数具有曲率或两侧饱和的深度网络中的学习更容易, 说明, 在深度整流网络中的学习比在, 数的性能, 学习开始提取足够的有用知识来超越随机选择参", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9f7ea8b9-0232-4771-8431-efce175ede52", "label": "摘要13", "info": "整流线性单元还具有历史意义，因为它们表明神经科学继续对深度学习；算法的发展产生影响。Glorot  et  al.  （2011a）从生物学考虑整流线性单；元的导出。半整流非线性旨在描述生物神经元的这些性质：（1）对于", "keywords": "元的导出, 从生物学考虑整流线性单, 对于, 半整流非线性旨在描述生物神经元的这些性质, 算法的发展产生影响", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "e5023635-9998-4012-8538-731981721d91", "label": "摘要14", "info": "们不活跃的状态下进行操作（即它们应该具有稀疏激活；activation））。", "keywords": "即它们应该具有稀疏激活, 们不活跃的状态下进行操作", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "a22c257a-3827-42d4-8d3d-fa043ad97565", "label": "摘要15", "info": "（sparse", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "d24cabfb-eda0-414b-9fb2-5a821d327b33", "label": "摘要16", "info": "当2006年深度学习开始现代复兴时，前馈网络仍然有不良的声誉。从；2006∼2012年，人们普遍认为，前馈网络不会表现良好，除非它们得到；其他模型的辅助，例如概率模型。现在已经知道，只要具备适当的资源", "keywords": "年深度学习开始现代复兴时, 例如概率模型, 前馈网络不会表现良好, 前馈网络仍然有不良的声誉, 只要具备适当的资源", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "9031d709-d5d4-4c76-9b66-8116c8b195fd", "label": "摘要17", "info": "前馈网络还有许多未实现的潜力。未来，我们期望它们用于更多的任；务，优化算法和模型设计的进步将进一步提高它们的性能。本章主要描；述了神经网络模型族。在接下来的章节中，我们将讨论如何使用这些模", "keywords": "本章主要描, 优化算法和模型设计的进步将进一步提高它们的性能, 我们期望它们用于更多的任, 前馈网络还有许多未实现的潜力, 述了神经网络模型族", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "34277e1b-c251-4596-99e5-4ddea7f06519", "label": "摘要18", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "4fff156e-b13c-4d1a-8fd9-21941da27953", "label": "摘要19", "info": "(1)   译者注：这里原文是“If  we  use  a  diagonal  matrix，or  a  scalar  times  the  diagonal  matrix…”，；即“如果我们使用对角矩阵，或者是一个标量乘以对角矩阵……  ”，但一个标量乘以对角矩阵和；对角矩阵没区别，结合上下文可以看出，这里原作者误把“identity”写成了“diagonal  matrix”，因", "keywords": "或者是一个标量乘以对角矩阵, 写成了, 这里原作者误把, 译者注, 如果我们使用对角矩阵", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "8bd14232-4131-4f9f-a06d-4d13dc4129a9", "label": "摘要20", "info": "(2)  之所以认为c是潜在的，是因为我们不能直接在数据中观测到它：给定输入 x 和目标 y ，不；可能确切地知道是哪个高斯组件产生 y ，但我们可以想象 y 是通过选择其中一个来产生的，并且；将那个未被观测到的选择作为随机变量。", "keywords": "是潜在的, 是通过选择其中一个来产生的, 将那个未被观测到的选择作为随机变量, 和目标, 是因为我们不能直接在数据中观测到它", "level": 3, "group": "chapter-6", "type": "段落"}, {"id": "ec2fde5a-a05f-4958-b321-9249210671fd", "label": "第7章：深度学习中的正则化", "level": 1, "group": "chapter-7", "type": "章節"}, {"id": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "label": "6.6：历史小记", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "7e443c4e-3b42-44a2-a72c-3634eb4a1a65", "label": "摘要1", "info": "机器学习中的一个核心问题是设计不仅在训练数据上表现好，而且能在；新输入上泛化好的算法。在机器学习中，许多策略被显式地设计来减少；测试误差（可能会以增大训练误差为代价）。这些策略被统称为正则", "keywords": "新输入上泛化好的算法, 许多策略被显式地设计来减少, 测试误差, 机器学习中的一个核心问题是设计不仅在训练数据上表现好, 而且能在", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f6562582-6834-49cc-90b0-5ef5895ca41a", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；第5章介绍了泛化、欠拟合、过拟合、偏差、方差和正则化的基本概；念。如果你不熟悉这些概念，请先参考第5章，然后再继续阅读本章。", "keywords": "过拟合, 然后再继续阅读本章, 章介绍了泛化, 请先参考第, 欠拟合", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a60d7310-fc6a-4cda-a4f9-e0ed257f6d44", "label": "摘要3", "info": "在本章中，我们会更详细地介绍正则化，重点介绍深度模型（或组成深；度模型的模块）的正则化策略。", "keywords": "或组成深, 的正则化策略, 度模型的模块, 重点介绍深度模型, 我们会更详细地介绍正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "97321fd9-e763-4d42-926f-c95f07baa32b", "label": "摘要4", "info": "本章中的某些章节涉及机器学习中的标准概念。如果你已经熟悉了这些；概念，可以随意跳过相关章节。然而，本章的大多数内容是关于这些基；本概念在特定神经网络中的扩展概念。", "keywords": "可以随意跳过相关章节, 概念, 然而, 本章的大多数内容是关于这些基, 本章中的某些章节涉及机器学习中的标准概念", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b66ad34d-0ccf-42b7-8316-1dd3297dbe72", "label": "摘要5", "info": "在第5.2.2节中，我们将正则化定义为“对学习算法的修改——旨在减少；泛化误差而不是训练误差”。目前有许多正则化策略。有些策略向机器；学习模型添加限制参数值的额外约束。有些策略向目标函数增加额外项", "keywords": "对学习算法的修改, 有些策略向机器, 有些策略向目标函数增加额外项, 节中, 目前有许多正则化策略", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f62956d5-d416-438a-bd7c-1983068bab9d", "label": "摘要6", "info": "在深度学习的背景下，大多数正则化策略都会对估计进行正则化。估计；的正则化以偏差的增加换取方差的减少。一个有效的正则化是有利；的“交易”，也就是能显著减少方差而不过度增加偏差。我们在第5章中", "keywords": "估计, 我们在第, 章中, 也就是能显著减少方差而不过度增加偏差, 一个有效的正则化是有利", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f49a08e1-79fa-4ebe-a7a6-eb295648cdff", "label": "摘要7", "info": "在实践中，过于复杂的模型族不一定包括目标函数或真实数据生成过；程，甚至也不包括近似过程。我们几乎从未知晓真实数据的生成过程，；所以我们永远不知道被估计的模型族是否包括生成过程。然而，深度学", "keywords": "深度学, 我们几乎从未知晓真实数据的生成过程, 然而, 甚至也不包括近似过程, 过于复杂的模型族不一定包括目标函数或真实数据生成过", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ac6d8d7a-f6a8-4039-a206-6c88b58a2b7d", "label": "摘要8", "info": "（模型族）。", "keywords": "模型族", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "22ee5f95-f2bd-4087-b326-e59eb0cf69b4", "label": "摘要9", "info": "这意味着控制模型的复杂度不是找到合适规模的模型（带有正确的参数；个数）这样一个简单的事情。相反，我们可能会发现，或者说在实际的；深度学习场景中我们几乎总是会发现，最好的拟合模型（从最小化泛化", "keywords": "深度学习场景中我们几乎总是会发现, 这样一个简单的事情, 个数, 从最小化泛化, 最好的拟合模型", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "027a3ce6-4d46-4f42-baa5-088eca9fcf33", "label": "摘要10", "info": "现在我们回顾几种策略，以创建这些正则化的大型深度模型。", "keywords": "以创建这些正则化的大型深度模型, 现在我们回顾几种策略", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d5c79e44-3213-4a6a-87ac-0ee0194a55dc", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；7.1　参数范数惩罚", "keywords": "参数范数惩罚", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0fb28f3e-fd1e-4e23-8126-46c32788caff", "label": "摘要12", "info": "7.1.1　L^2参数正则化", "keywords": "参数正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "53d97857-ade1-4d00-a023-6dbd394766d8", "label": "摘要13", "info": "7.1.2　L^1正则化", "keywords": "正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "12313b40-950b-412b-8af8-0fba3447b317", "label": "7.1：参数范数惩罚", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "7d582850-aba1-40cc-8416-3d231376f499", "label": "摘要1", "info": "7.1.1　L 2 参数正则化", "keywords": "参数正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "16803577-087a-40c8-b206-eca55d90e990", "label": "摘要2", "info": "7.1.2　L 1 正则化", "keywords": "正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c5d5ffd8-f246-46cb-bc36-15679a0df75c", "label": "摘要3", "info": "正则化在深度学习的出现前就已经被使用了数十年。线性模型，如线性；回归和逻辑回归，可以使用简单、直接、有效的正则化策略。", "keywords": "线性模型, 回归和逻辑回归, 有效的正则化策略, 可以使用简单, 如线性", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d754813f-75b7-4f87-a108-4a01f5f2e3d1", "label": "摘要4", "info": "，限制；许多正则化方法通过对目标函数J  添加一个参数范数惩罚；模型（如神经网络、线性回归或逻辑回归）的学习能力。我们将正则化", "keywords": "许多正则化方法通过对目标函数, 添加一个参数范数惩罚, 线性回归或逻辑回归, 如神经网络, 的学习能力", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e216b835-bb62-46a7-8f76-05e85ba713f9", "label": "摘要5", "info": "其中α∈［0，∞）是权衡范数惩罚项Ω和标准目标函数；贡献的超参数。将α设为0表示没有正则化。α越大，对应正则化惩罚越；大。", "keywords": "和标准目标函数, 是权衡范数惩罚项, 贡献的超参数, 对应正则化惩罚越, 其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4d95884e-efdf-4857-8996-f23de8ce20b1", "label": "摘要6", "info": "相对", "keywords": "相对", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "52f519aa-0ea4-4f00-abdc-811455bdfae4", "label": "摘要7", "info": "当我们的训练算法最小化正则化后的目标函数  时，它会降低原始目标；J关于训练数据的误差并同时减小在某些衡量标准下参数  θ  （或参数子；集）的规模。选择不同的参数范数Ω会偏好不同的解。在本节中，我们", "keywords": "或参数子, 在本节中, 关于训练数据的误差并同时减小在某些衡量标准下参数, 选择不同的参数范数, 会偏好不同的解", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d8b29c40-ab1a-4455-a3d9-1a535cbaa01d", "label": "摘要8", "info": "在探究不同范数的正则化表现之前，需要说明一下，在神经网络中，参；数包括每一层仿射变换的权重和偏置，我们通常只对权重做惩罚而不对；偏置做正则惩罚。精确拟合偏置所需的数据通常比拟合权重少得多。每", "keywords": "我们通常只对权重做惩罚而不对, 在探究不同范数的正则化表现之前, 需要说明一下, 偏置做正则惩罚, 数包括每一层仿射变换的权重和偏置", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6663802d-932f-444a-ace9-f1cc9ec31222", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；数惩罚影响的权重，而向量 θ 表示所有参数（包括 w 和无须正则化的参；数）。", "keywords": "数惩罚影响的权重, 表示所有参数, 而向量, 包括, 和无须正则化的参", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5326e002-a665-4923-8c9a-d935e4e3f90e", "label": "摘要10", "info": "在神经网络的情况下，有时希望对网络的每一层使用单独的惩罚，并分；配不同的α系数。寻找合适的多个超参数的代价很大，因此为了减少搜；索空间，我们会在所有层使用相同的权重衰减。", "keywords": "系数, 寻找合适的多个超参数的代价很大, 在神经网络的情况下, 有时希望对网络的每一层使用单独的惩罚, 并分", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "163fa939-b79a-48d6-9557-aa7d6a22cf6b", "label": "摘要11", "info": "7.1.1　L 2 参数正则化", "keywords": "参数正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f2c4a9e5-54f4-48f3-8dc2-4516c2d1a323", "label": "摘要12", "info": "在第5.2节中我们已经看到过最简单而又最常见的参数范数惩罚，即通；常被称为权重衰减 （weight decay）的L 2 参数范数惩罚。这个正则化策", "keywords": "节中我们已经看到过最简单而又最常见的参数范数惩罚, 这个正则化策, 参数范数惩罚, 在第, 常被称为权重衰减", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "439073e1-78e6-439e-aa5d-e70213932a25", "label": "摘要13", "info": "略通过向目标函数添加一个正则项", "keywords": "略通过向目标函数添加一个正则项", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b46435aa-55e4-4a50-9da9-4c9193be9f7b", "label": "摘要14", "info": "，使", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c54c95af-c8e7-4bcc-b55e-53992de54d8e", "label": "摘要15", "info": "权重更加接近原点  (1)  。在其他学术圈，L  2  也被称为岭回归或Tikhonov；正则。", "keywords": "正则, 也被称为岭回归或, 在其他学术圈, 权重更加接近原点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "01191360-a468-4c0f-95ad-ff9f533a91c7", "label": "摘要16", "info": "我们可以通过研究正则化后目标函数的梯度，洞察一些权重衰减的正则；化表现。为了简单起见，我们假定其中没有偏置参数，因此 θ 就是 w 。；这样一个模型具有以下总的目标函数：", "keywords": "洞察一些权重衰减的正则, 就是, 因此, 化表现, 这样一个模型具有以下总的目标函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d17366fd-b91b-46b7-a3e7-ac7e0bd6ef43", "label": "摘要17", "info": "与之对应的梯度为", "keywords": "与之对应的梯度为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2853f49b-45eb-48a6-a7ac-b72a4fe1dfe0", "label": "摘要18", "info": "使用单步梯度下降更新权重，即执行以下更新：", "keywords": "使用单步梯度下降更新权重, 即执行以下更新", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6917c3b3-f10c-4d68-a0da-276ec3f74318", "label": "摘要19", "info": "换种写法就是", "keywords": "换种写法就是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ae2110f3-63a9-4298-a3b5-0c13d71920d8", "label": "摘要20", "info": "我们可以看到，加入权重衰减后会引起学习规则的修改，即在每步执行；通常的梯度更新之前先收缩权重向量（将权重向量乘以一个常数因；子）。这是单个步骤发生的变化。但是，在训练的整个过程会发生什么", "keywords": "通常的梯度更新之前先收缩权重向量, 将权重向量乘以一个常数因, 但是, 加入权重衰减后会引起学习规则的修改, 我们可以看到", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "276ae556-09d7-465e-8456-aa478ba93c65", "label": "摘要21", "info": "呢？", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e60197f5-04f8-4bfc-8ab9-d8cc61a5dd14", "label": "摘要22", "info": "为未正则化的目标函数取得最小训练误；我们进一步简化分析，令；差时的权重向量，即", "keywords": "我们进一步简化分析, 为未正则化的目标函数取得最小训练误, 差时的权重向量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0b76fe76-80c0-4572-8412-10e286a7fef5", "label": "摘要23", "info": "，并在", "keywords": "并在", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ee196232-5d78-4137-bbd3-76bc14f17ae6", "label": "摘要24", "info": "如下", "keywords": "如下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8a915624-73a0-4d80-87a7-5a0334d75e1d", "label": "摘要25", "info": "其中  H  是J在；义为最优，即梯度消失为0，所以该二次近似中没有一阶项。同样地，；因为", "keywords": "因为, 同样地, 即梯度消失为, 其中, 义为最优", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d79645df-3046-4239-8d5b-0553d30b37fb", "label": "摘要26", "info": "是J的一个最优点，我们可以得出 H 是半正定的结论。", "keywords": "是半正定的结论, 的一个最优点, 我们可以得出", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "02e7501e-6b39-4376-b5cb-d262069a7c61", "label": "摘要27", "info": "处计算的Hessian矩阵（关于  w  ）。因为", "keywords": "因为, 矩阵, 关于, 处计算的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f72df2e3-377d-4e8a-bc70-c3a632d224a1", "label": "摘要28", "info": "被定", "keywords": "被定", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e8b3077e-f55c-475b-98f6-6c8e579f0557", "label": "摘要29", "info": "当  取得最小时，其梯度", "keywords": "其梯度, 取得最小时", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "423a70e3-05db-4428-890c-bc895bfb74a0", "label": "摘要30", "info": "为0。", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7740c5bb-aa06-4fda-a06c-ca0ccf7497f6", "label": "摘要31", "info": "为了研究权重衰减带来的影响，我们在式（7.7）中添加权重衰减的梯；度。现在我们探讨最小化正则化后的   。我们使用变量   表示此时的；最优点：", "keywords": "为了研究权重衰减带来的影响, 我们在式, 现在我们探讨最小化正则化后的, 我们使用变量, 表示此时的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2a79cde1-7754-4fc3-8259-d9b54f3a0087", "label": "摘要32", "info": "。那么当α增加时会发生什；当α趋向于0时，正则化的解  会趋向；么呢？因为  H  是实对称的，所以我们可以将其分解为一个对角矩阵Λ", "keywords": "因为, 所以我们可以将其分解为一个对角矩阵, 那么当, 会趋向, 是实对称的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5a1bf1d0-8dfc-4280-b0f0-cebb709fdf37", "label": "摘要33", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；我们可以看到权重衰减的效果是沿着由  H  的特征向量所定义的轴缩放", "keywords": "的特征向量所定义的轴缩放, 我们可以看到权重衰减的效果是沿着由", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "28c1bf3b-9e94-4e01-a4db-c5a8343177ad", "label": "摘要34", "info": "。具体来说，我们会根据", "keywords": "我们会根据, 具体来说", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0fafd6f8-5a6c-4a10-99ca-fc4239691b40", "label": "摘要35", "info": "因子缩放与  H  第i个特征向量", "keywords": "个特征向量, 因子缩放与", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0df26a57-1ec0-4490-ad46-9ed1b9300f3c", "label": "摘要36", "info": "对齐的", "keywords": "对齐的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "db15a3a7-c64d-44b3-b9aa-b5e890ce68b4", "label": "摘要37", "info": "的分量。（不妨查看图2.3，回顾这种缩放的原理）。", "keywords": "回顾这种缩放的原理, 不妨查看图, 的分量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "711def18-bac4-4bba-a4e6-9e9071d39bb9", "label": "摘要38", "info": "沿着  H  特征值较大的方向（如", "keywords": "特征值较大的方向, 沿着", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "47fff4ef-a7a5-4d59-988b-66c0da7ce9bd", "label": "摘要39", "info": "）正则化的影响较小。而", "keywords": "正则化的影响较小", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3e87f925-d6d9-46f1-8f20-772c0f12c8ba", "label": "摘要40", "info": "的分量将会收缩到几乎为零。这种效应如图7.1所示。", "keywords": "所示, 这种效应如图, 的分量将会收缩到几乎为零", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "cfe6ad5c-c770-48b7-b705-a5d3655f2e92", "label": "摘要41", "info": "图7.1　L 2 （或权重衰减）正则化对最佳 w 值的影响。实线椭圆表示没有正则化目标的等值；线。虚线圆圈表示L 2 正则化项的等值线。在；Hessian的第一维特征值很小。当从", "keywords": "值的影响, 虚线圆圈表示, 当从, 正则化对最佳, 的第一维特征值很小", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d3f041ea-099e-481f-bc2b-fce05b3ab87a", "label": "摘要42", "info": "点，这两个竞争目标达到平衡。目标函数J的；水平移动时，目标函数不会增加得太多。因为目标函", "keywords": "目标函数不会增加得太多, 因为目标函, 目标函数, 这两个竞争目标达到平衡, 水平移动时", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "26154c6b-6135-498a-9b24-d6563807e8ac", "label": "摘要43", "info": "的移动非常敏感。对应的特征值较大，表示高曲率。因", "keywords": "表示高曲率, 对应的特征值较大, 的移动非常敏感", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0ef1a013-1ada-46d2-bdb3-0cd63101e4db", "label": "摘要44", "info": "只有在显著减小目标函数方向上的参数会保留得相对完好。在无助于目；标函数减小的方向（对应Hessian矩阵较小的特征值）上改变参数不会显", "keywords": "上改变参数不会显, 在无助于目, 矩阵较小的特征值, 标函数减小的方向, 对应", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "19cd76de-e581-44bc-aba3-84923d8facff", "label": "摘要45", "info": "著增加梯度。这种不重要方向对应的分量会在训练过程中因正则化而衰；减掉。", "keywords": "减掉, 这种不重要方向对应的分量会在训练过程中因正则化而衰, 著增加梯度", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "eb63656b-67e0-4f98-89c0-a4fc465f3847", "label": "摘要46", "info": "目前为止，我们讨论了权重衰减对优化一个抽象通用的二次代价函数的；影响。这些影响具体是怎么和机器学习关联的呢？我们可以研究线性回；归，它的真实代价函数是二次的，因此我们可以使用相同的方法分析。", "keywords": "影响, 它的真实代价函数是二次的, 目前为止, 因此我们可以使用相同的方法分析, 这些影响具体是怎么和机器学习关联的呢", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a127acd0-c6c9-4664-a6cf-58487094740c", "label": "摘要47", "info": "我们添加L 2 正则项后，目标函数变为", "keywords": "我们添加, 正则项后, 目标函数变为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d71e5e0b-8e72-4719-97fe-9e6fbb0ddc44", "label": "摘要48", "info": "这将正规方程的解从", "keywords": "这将正规方程的解从", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "bac2a7b5-85c2-49a2-ac4d-6e7b434dc74b", "label": "摘要49", "info": "变为", "keywords": "变为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "da8e426a-13a3-4d42-8026-ce57d1e15b2d", "label": "摘要50", "info": "与协方差矩阵", "keywords": "与协方差矩阵", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7a94d28f-3eee-4343-9477-28126050d811", "label": "摘要51", "info": "式（7.16）中的矩阵；将这个矩阵替换为式（7.17）中的；来的是一样的，不同的仅仅是在对角加了α。这个矩阵的对角项对应每", "keywords": "将这个矩阵替换为式, 中的矩阵, 这个矩阵的对角项对应每, 来的是一样的, 不同的仅仅是在对角加了", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6a394924-400b-48e9-8831-d50b56f89312", "label": "摘要52", "info": "成正比。L 2 正则项；，这个新矩阵与原", "keywords": "成正比, 这个新矩阵与原, 正则项", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "97e111ca-99a8-4e05-b5ee-81c64a1a9f0c", "label": "摘要53", "info": "7.1.2　L 1 正则化", "keywords": "正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "90fb022d-944f-4096-a89b-4bfc1d78f08a", "label": "摘要54", "info": "L  2  权重衰减是权重衰减最常见的形式，我们还可以使用其他的方法限；制模型参数的规模。一个选择是使用L 1 正则化。", "keywords": "权重衰减是权重衰减最常见的形式, 我们还可以使用其他的方法限, 正则化, 一个选择是使用, 制模型参数的规模", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "003f418d-499d-44ff-bbc3-a13d71a344a3", "label": "摘要55", "info": "形式地，对模型参数 w 的L 1 正则化被定义为", "keywords": "正则化被定义为, 形式地, 对模型参数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "37a0771f-fd3e-4b74-b432-783ae7bbdc1a", "label": "摘要56", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；即各个参数的绝对值之和  (2)  。接着我们将讨论L  1  正则化对简单线性回；归模型的影响，与分析L  2  正则化时一样不考虑偏置参数。我们尤其感", "keywords": "即各个参数的绝对值之和, 正则化对简单线性回, 我们尤其感, 正则化时一样不考虑偏置参数, 接着我们将讨论", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2f53fdae-d892-4a1b-952b-eb0a8adb4a35", "label": "摘要57", "info": "对应的梯度（实际上是次梯度）：", "keywords": "对应的梯度, 实际上是次梯度", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d6c27c23-12c1-4164-a9b3-9646b8bb3aba", "label": "摘要58", "info": "其中sign( w )只是简单地取 w 各个元素的正负号。", "keywords": "各个元素的正负号, 只是简单地取, 其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8c1438db-8565-4ae1-98c9-c03bceaf3a44", "label": "摘要59", "info": "观察式（7.20），我们立刻发现L  1  的正则化效果与L  2  大不一样。具体；来说，我们可以看到正则化对梯度的影响不再是线性地缩放每个w  i  ；；而是添加了一项与sign(w  i  )同号的常数。使用这种形式的梯度之后，我", "keywords": "我们可以看到正则化对梯度的影响不再是线性地缩放每个, 具体, 的正则化效果与, 同号的常数, 使用这种形式的梯度之后", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "65cb45ef-c78b-4292-ba2e-bbe0cf7ccaed", "label": "摘要60", "info": "简单线性模型具有二次代价函数，我们可以通过泰勒级数表示。或者我；们可以设想，这是逼近更复杂模型的代价函数的截断泰勒级数。在这个；设定下，梯度由下式给出", "keywords": "设定下, 们可以设想, 这是逼近更复杂模型的代价函数的截断泰勒级数, 在这个, 简单线性模型具有二次代价函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3f0d2514-a6f8-44a4-81c1-2f866544d12c", "label": "摘要61", "info": "同样， H 是J在", "keywords": "同样", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "52bca142-fae5-476d-88d9-88c22307fe74", "label": "摘要62", "info": "处的Hessian矩阵（关于 w ）。", "keywords": "矩阵, 关于, 处的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a7ba3004-f2e6-4b70-8d44-eeefa6d6c590", "label": "摘要63", "info": "由于L  1  惩罚项在完全一般化的Hessian的情况下，无法得到直接清晰的；代数表达式，因此我们将进一步简化假设Hessian是对角的，即", "keywords": "惩罚项在完全一般化的, 因此我们将进一步简化假设, 代数表达式, 由于, 无法得到直接清晰的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5c4ad456-ba2f-40ae-8745-c92e00ef79b8", "label": "摘要64", "info": "。如果线；性回归问题中的数据已被预处理（如可以使用PCA），去除了输入特征；之间的相关性，那么这一假设成立。", "keywords": "那么这一假设成立, 如果线, 去除了输入特征, 之间的相关性, 如可以使用", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0ee81a3f-e4b5-4887-ac9c-5d5fd9d656cd", "label": "摘要65", "info": "，其中每个", "keywords": "其中每个", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f68fb71a-91f8-41b5-bb95-04b0728c7b42", "label": "摘要66", "info": "我们可以将L 1 正则化目标函数的二次近似分解成关于参数的求和：", "keywords": "正则化目标函数的二次近似分解成关于参数的求和, 我们可以将", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1c48769f-fcb9-4c9a-a4c5-88fde03ab5ae", "label": "摘要67", "info": "如下列形式的解析解（对每一维i）可以最小化这个近似代价函数：", "keywords": "对每一维, 如下列形式的解析解, 可以最小化这个近似代价函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5975a77d-d306-4b0c-a60e-13bd95e5f9ad", "label": "摘要68", "info": "对每个i，考虑", "keywords": "对每个, 考虑", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "828246f4-fcc9-4edf-ac43-41ae1e1a4a20", "label": "摘要69", "info": "的情形，会有两种可能结果：", "keywords": "的情形, 会有两种可能结果", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "69421411-42cb-4ea3-b7f2-f67aab89c627", "label": "摘要70", "info": "（1）", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0f6731c5-9d29-4155-a799-8bcfaf01be3c", "label": "摘要71", "info": "的情况。正则化后目标中的w i 最优值是w", "keywords": "最优值是, 的情况, 正则化后目标中的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9c7d1042-75bc-452d-b2d9-3cc30883d85a", "label": "摘要72", "info": "i  ＝0。这是因为在方向i上；L 1 正则化项将w i 推至0。", "keywords": "推至, 这是因为在方向, 正则化项将", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8da43100-c2fe-49db-a188-b8f3e4a99f2c", "label": "摘要73", "info": "的贡献被抵消，", "keywords": "的贡献被抵消", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b590b42a-35cd-41a3-88be-c25628579784", "label": "摘要74", "info": "（2）", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "da62a084-9463-484a-a478-5a3d0b654805", "label": "摘要75", "info": "的情况。在这种情况下，正则化不会将w  i", "keywords": "正则化不会将, 在这种情况下, 的情况", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "10da2b8a-356e-453b-84d3-d9546f94bdd3", "label": "摘要76", "info": "的最优值推至0，而仅仅在那个方向上移动", "keywords": "而仅仅在那个方向上移动, 的最优值推至", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "64cc4848-5983-4ec7-a225-040e4a965686", "label": "摘要77", "info": "的距离。", "keywords": "的距离", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fdd4025b-5df0-4827-b753-ffd2d3d5ef8d", "label": "摘要78", "info": "的情况与此类似，但是L 1 惩罚项使w i 更接近0（增加", "keywords": "但是, 更接近, 的情况与此类似, 惩罚项使, 增加", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b528df85-5805-4ef2-9429-106f3b667b23", "label": "摘要79", "info": "）或者为0。", "keywords": "或者为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "077da3d8-f4e9-4347-9dde-8b8e5e8e8681", "label": "摘要80", "info": "相比L  2  正则化，L  1  正则化会产生更稀疏  （sparse）的解。此处稀疏性；指的是最优值中的一些参数为0。和L  2  正则化相比，L  1  正则化的稀疏；性具有本质的不同。式（7.13）给出了L  2  正则化的解  。如果我们使", "keywords": "正则化相比, 如果我们使, 正则化会产生更稀疏, 正则化, 此处稀疏性", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "aacbebe9-e2e3-4adc-b215-ee9432836d28", "label": "摘要81", "info": "重新考虑这个等式，会发现", "keywords": "重新考虑这个等式, 会发现", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6d14d04d-e3ff-46a9-9a33-89db29462341", "label": "摘要82", "info": "。如果   不是", "keywords": "如果, 不是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e7d28435-40c2-4ff4-a40f-7d308fc7609c", "label": "摘要83", "info": "零，那么   也会保持非零。这表明L  2  正则化不会使参数变得稀疏，；而L 1 正则化有可能通过足够大的α实现稀疏。", "keywords": "也会保持非零, 那么, 正则化不会使参数变得稀疏, 实现稀疏, 这表明", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "118632c0-5324-4539-bd49-e48d61960e04", "label": "摘要84", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；1  正则化导出的稀疏性质已经被广泛地用于特征选择  （feature", "keywords": "正则化导出的稀疏性质已经被广泛地用于特征选择", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fb90ef35-9c76-43c6-99a5-8a015d81f660", "label": "摘要85", "info": "由L；selection）机制。特征选择从可用的特征子集选择出有意义的特征，化；简机器学习问题。著名的LASSO（Tibshirani，1995）（Least  Absolute", "keywords": "简机器学习问题, 特征选择从可用的特征子集选择出有意义的特征, 著名的, 机制", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "966c20d1-959c-448c-9dec-de6835357f23", "label": "摘要86", "info": "在第5.6.1节，我们看到许多正则化策略可以被解释为MAP贝叶斯推断，；特别是L 2 正则化相当于权重是高斯先验的MAP贝叶斯推断。对于L  1  正；则化，用于正则化代价函数的惩罚项", "keywords": "则化, 正则化相当于权重是高斯先验的, 特别是, 贝叶斯推断, 对于", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "99e3b749-0225-4427-9f17-6db8bb0a303d", "label": "摘要87", "info": "断最大化的对数先验项是等价的（；同性的拉普拉斯分布（式（3.26）））：", "keywords": "断最大化的对数先验项是等价的, 同性的拉普拉斯分布", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d420a52c-e727-4ae2-b7c2-2e29f4c770fb", "label": "摘要88", "info": "与通过MAP贝叶斯推", "keywords": "贝叶斯推, 与通过", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d2afbf51-1d08-4f57-91fb-232b52d4efb7", "label": "摘要89", "info": "并且权重先验是各向", "keywords": "并且权重先验是各向", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3a9af73a-5873-4f8a-b30c-ed8ed839d416", "label": "摘要90", "info": "因为是关于  w  最大化进行学习，我们可以忽略logα−log  2项，因为它们；与 w 无关。", "keywords": "我们可以忽略, 无关, 因为它们, 因为是关于, 最大化进行学习", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "label": "7.2：作为约束的范数惩罚", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "840da5ef-7011-44a7-9524-09062c9dfdb1", "label": "摘要1", "info": "考虑经过参数范数正则化的代价函数：", "keywords": "考虑经过参数范数正则化的代价函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4d719fd6-30d1-465a-b07c-12f0d56e19ab", "label": "摘要2", "info": "回顾第4.4节，我们可以构造一个广义Lagrange函数来最小化带约束的函；数，即在原始目标函数上添加一系列惩罚项。每个惩罚是一个被称；为Karush-Kuhn-Tucker  （Karush-Kuhn-Tucker）乘子的系数以及一个", "keywords": "即在原始目标函数上添加一系列惩罚项, 每个惩罚是一个被称, 回顾第, 函数来最小化带约束的函, 我们可以构造一个广义", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0ae7457b-bd42-4c2c-a6b2-a84a2564ac8a", "label": "摘要3", "info": "这个约束问题的解由下式给出", "keywords": "这个约束问题的解由下式给出", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1d8f741c-a3cc-4d2b-9828-fc4a383a587c", "label": "摘要4", "info": "如第4.4节中描述的，要解决这个问题，我们需要对  θ  和α都做出调整。；第4.5节给出了一个带L  2  约束的线性回归实例。还有许多不同的优化方；法，有些可能会使用梯度下降而其他可能会使用梯度为0的解析解，但", "keywords": "节中描述的, 还有许多不同的优化方, 我们需要对, 的解析解, 如第", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "27af9262-54d2-4f27-b3ba-fcbc840c45b1", "label": "摘要5", "info": "为了洞察约束的影响，我们可以固定α  *  ，把这个问题看成只跟  θ  有关；的函数：", "keywords": "为了洞察约束的影响, 有关, 的函数, 把这个问题看成只跟, 我们可以固定", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "55bbe753-943d-491e-80d6-ebb33cd9dae9", "label": "摘要6", "info": "这和最小化  的正则化训练问题是完全一样的。因此，我们可以把参数；范数惩罚看作对权重强加的约束。如果Ω是L 2 范数，那么权重就是被约；束在一个L 2 球中。如果Ω是L 1 范数，那么权重就是被约束在一个L 1 范", "keywords": "如果, 范数惩罚看作对权重强加的约束, 我们可以把参数, 因此, 球中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9d421223-6976-4ea0-abac-f5f011547e10", "label": "摘要7", "info": "有时候，我们希望使用显式的限制，而不是惩罚。如第4.4节所述，我；们可以修改下降算法（如随机梯度下降算法），使其先计算J( θ )的下降；步，然后将  θ  投影到满足Ω(  θ  )＜k的最近点。如果我们知道什么样的k", "keywords": "的最近点, 的下降, 如随机梯度下降算法, 然后将, 如第", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "31ce12ac-5cc8-48a2-8a57-b813986c832f", "label": "摘要8", "info": "另一个使用显式约束和重投影而不是使用惩罚强加约束的原因是，惩罚；可能会导致目标函数非凸而使算法陷入局部极小（对应于小的 θ ）。当；训练神经网络时，这通常表现为训练带有几个“死亡单元”的神经网络。", "keywords": "可能会导致目标函数非凸而使算法陷入局部极小, 训练神经网络时, 的神经网络, 惩罚, 对应于小的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "57626ea1-4fa0-473c-af06-b6c58252553b", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最后，因为重投影的显式约束还对优化过程增加了一定的稳定性，所以；这是另一个好处。当使用较高的学习率时，很可能进入正反馈，即大的", "keywords": "当使用较高的学习率时, 很可能进入正反馈, 这是另一个好处, 最后, 即大的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a9994d7b-88af-4502-aeb0-634958e213f5", "label": "摘要10", "info": "Hinton et al. （2012c）尤其推荐由Srebro and Shraibman（2005）引入的；策略：约束神经网络层的权重矩阵每列的范数，而不是限制整个权重矩；阵的Frobenius范数。分别限制每一列的范数可以防止某一隐藏单元有非", "keywords": "策略, 约束神经网络层的权重矩阵每列的范数, 阵的, 引入的, 分别限制每一列的范数可以防止某一隐藏单元有非", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "label": "7.3：正则化和欠约束问题", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "9150ce94-7f53-4b64-9dd2-16d8128d1813", "label": "摘要1", "info": "在某些情况下，为了正确定义机器学习问题，正则化是必要的。机器学；求；习中许多线性模型，包括线性回归和PCA，都依赖于对矩阵", "keywords": "习中许多线性模型, 都依赖于对矩阵, 正则化是必要的, 为了正确定义机器学习问题, 包括线性回归和", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4b47d111-1b31-45b1-ac65-412c651a9e16", "label": "摘要2", "info": "相关矩阵可逆时，这些线性问题有闭式解。没有闭式解的问题也可能是；欠定的。一个例子是应用于线性可分问题的逻辑回归。如果权重向量  w；能够实现完美分类，那么2  w  也会以更高似然实现完美分类。类似随机", "keywords": "也会以更高似然实现完美分类, 类似随机, 欠定的, 这些线性问题有闭式解, 那么", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "671cd96d-a5cb-42be-82b0-5f5b680b197e", "label": "摘要3", "info": "大多数形式的正则化能够保证应用于欠定问题的迭代方法收敛。例如，；当似然的斜率等于权重衰减的系数时，权重衰减将阻止梯度下降继续增", "keywords": "当似然的斜率等于权重衰减的系数时, 大多数形式的正则化能够保证应用于欠定问题的迭代方法收敛, 例如, 权重衰减将阻止梯度下降继续增", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fe08eb71-1741-4c83-b899-3a69da496f64", "label": "摘要4", "info": "加权重的大小。", "keywords": "加权重的大小", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7c642f7c-dd94-4ceb-b65e-dddcabe6d4e8", "label": "摘要5", "info": "使用正则化解决欠定问题的想法不局限于机器学习。同样的想法在几个；基本线性代数问题中也非常有用。", "keywords": "同样的想法在几个, 基本线性代数问题中也非常有用, 使用正则化解决欠定问题的想法不局限于机器学习", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ee3ae3ab-df66-4c3b-a1de-f5f062751054", "label": "摘要6", "info": "正如我们在第2.9节看到的，我们可以使用Moore-Penrose求解欠定线性；方程。回想  伪逆", "keywords": "我们可以使用, 方程, 伪逆, 回想, 节看到的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3f484a95-6faf-4616-b6ce-e79f333b8ea0", "label": "摘要7", "info": "的一个定义：", "keywords": "的一个定义", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "30a35798-baca-45a2-b89d-dc3aebbbbf00", "label": "摘要8", "info": "现在我们可以将式（7.29）看作进行具有权重衰减的线性回归。具体来；说，当正则化系数趋向0时，式（7.29）是式（7.17）的极限。因此，我；们可以将伪逆解释为使用正则化来稳定欠定问题。", "keywords": "具体来, 们可以将伪逆解释为使用正则化来稳定欠定问题, 是式, 因此, 现在我们可以将式", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c3aa290c-0413-4def-8b44-52c813a43d81", "label": "7.4：数据集增强", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "3f990e01-7695-4be3-974b-8b3050668f55", "label": "摘要1", "info": "让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当；然，在实践中，我们拥有的数据量是很有限的。解决这个问题的一种方；法是创建假数据并添加到训练集中。对于一些机器学习任务，创建新的", "keywords": "创建新的, 对于一些机器学习任务, 让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练, 法是创建假数据并添加到训练集中, 我们拥有的数据量是很有限的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "41602768-d404-473f-bc0e-7a32acd9bf18", "label": "摘要2", "info": "对分类来说这种方法是最简单的。分类器需要一个复杂的高维输入 x ，；并用单个类别标识y概括  x  。这意味着分类面临的一个主要任务是要对；各种各样的变换保持不变。我们可以轻易通过转换训练集中的 x 来生成", "keywords": "分类器需要一个复杂的高维输入, 对分类来说这种方法是最简单的, 各种各样的变换保持不变, 这意味着分类面临的一个主要任务是要对, 概括", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e3bd0dfa-6e96-43bd-a454-e33c08f2e979", "label": "摘要3", "info": "这种方法对于其他许多任务来说并不那么容易。例如，除非我们已经解；决了密度估计问题，否则在密度估计任务中生成新的假数据是很困难；的。", "keywords": "决了密度估计问题, 除非我们已经解, 否则在密度估计任务中生成新的假数据是很困难, 例如, 这种方法对于其他许多任务来说并不那么容易", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "236a375e-4174-4738-9fb2-f2b75e814c7e", "label": "摘要4", "info": "数据集增强对一个具体的分类问题来说是特别有效的方法：对象识别。；图像是高维的并包括各种巨大的变化因素，其中有许多可以轻易地模；拟。即使模型已使用卷积和池化技术（第9章）对部分平移保持不变，", "keywords": "其中有许多可以轻易地模, 对象识别, 数据集增强对一个具体的分类问题来说是特别有效的方法, 对部分平移保持不变, 即使模型已使用卷积和池化技术", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4ae62511-63f1-4c6f-b4b9-d7f7df517644", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；我们必须要小心，不能使用会改变类别的转换。例如，光学字符识别任；务需要认识到“b”和“d”以及“6”和“9”的区别，所以对这些任务来说，水", "keywords": "的区别, 所以对这些任务来说, 例如, 不能使用会改变类别的转换, 以及", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0c50d1e6-8951-487a-a312-dc7d12853c11", "label": "摘要6", "info": "能保持我们希望的分类不变，但不容易执行的转换也是存在的。例如，；平面外绕轴转动难以通过简单的几何运算在输入像素上实现。", "keywords": "但不容易执行的转换也是存在的, 平面外绕轴转动难以通过简单的几何运算在输入像素上实现, 能保持我们希望的分类不变, 例如", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d4c4f0ff-c17a-47d6-8fea-a7572306c18e", "label": "摘要7", "info": "数据集增强对语音识别任务也是有效的（Jaitly and Hinton，2013）。", "keywords": "数据集增强对语音识别任务也是有效的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8185b2a7-7ced-44bf-8c23-649d1372ef80", "label": "摘要8", "info": "在神经网络的输入层注入噪声（Sietsma and Dow，1991）也可以看作数；据增强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随；机噪声被加到输入，任务仍应该是能够被解决的。然而，神经网络被证", "keywords": "据增强的一种方式, 在神经网络的输入层注入噪声, 即使小的随, 也可以看作数, 然而", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "168b4f73-0dd4-4519-8079-b8b7a65b94d2", "label": "摘要9", "info": "在比较机器学习基准测试的结果时，考虑其采取的数据集增强是很重要；的。通常情况下，人工设计的数据集增强方案可以大大减少机器学习技；术的泛化误差。将一个机器学习算法的性能与另一个进行对比时，对照", "keywords": "在比较机器学习基准测试的结果时, 对照, 通常情况下, 术的泛化误差, 人工设计的数据集增强方案可以大大减少机器学习技", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "label": "7.5：噪声鲁棒性", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "cfc33171-977a-4656-88ab-788102b3c52d", "label": "摘要1", "info": "7.5.1　向输出目标注入噪声", "keywords": "向输出目标注入噪声", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "607974ca-1645-4c03-8f2b-12a4e377f53f", "label": "摘要2", "info": "第7.4节已经提出将噪声作用于输入，作为数据集增强策略。对于某些；模型而言，向输入添加方差极小的噪声等价于对权重施加范数惩罚；（Bishop，1995a，b）。在一般情况下，注入噪声远比简单地收缩参数", "keywords": "对于某些, 注入噪声远比简单地收缩参数, 模型而言, 在一般情况下, 作为数据集增强策略", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "91410fda-dbd3-4e0d-9416-be922be7c0b7", "label": "摘要3", "info": "另一种正则化模型的噪声使用方式是将其加到的权重。这项技术主要用；于循环神经网络（Jim  et  al.  ，1996；Graves，2011）。这可以被解释为；关于权重的贝叶斯推断的随机实现。贝叶斯学习过程将权重视为不确定", "keywords": "关于权重的贝叶斯推断的随机实现, 另一种正则化模型的噪声使用方式是将其加到的权重, 这可以被解释为, 这项技术主要用, 于循环神经网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "17046fd6-3601-4069-965b-7bd5ae67d237", "label": "摘要4", "info": "在某些假设下，施加于权重的噪声可以被解释为与更传统的正则化形式；等同，鼓励要学习的函数保持稳定。我们研究回归的情形，也就是训练；将一组特征 x 映射成一个标量的函数", "keywords": "也就是训练, 在某些假设下, 等同, 我们研究回归的情形, 施加于权重的噪声可以被解释为与更传统的正则化形式", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2d57cd9d-a525-4263-9f93-f2e9f21cdbfa", "label": "摘要5", "info": "与真实值y的误差：", "keywords": "的误差, 与真实值", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "14ac89af-7d0e-4dde-b2a0-559abdcffb78", "label": "摘要6", "info": "训练集包含m对标注样例", "keywords": "训练集包含, 对标注样例", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fbd9b7d0-f721-437a-8543-5ebe4821cada", "label": "摘要7", "info": "。", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e3f7f3ee-a2f1-4602-8458-402c50c0d86c", "label": "摘要8", "info": "现在我们假设对每个输入表示，网络权重添加随机扰动", "keywords": "现在我们假设对每个输入表示, 网络权重添加随机扰动", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b5b7a1f6-f4ad-45b6-b431-68014fa5115f", "label": "摘要9", "info": "。想象我们有一个标准的l层MLP。我们将扰动；。尽管有噪声注入，我们仍然希望减少网络输出误", "keywords": "尽管有噪声注入, 我们仍然希望减少网络输出误, 我们将扰动, 想象我们有一个标准的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "99b1dcf1-92d1-48cd-b527-33e636b97440", "label": "摘要10", "info": "模型记为；差的平方。因此目标函数变为：", "keywords": "因此目标函数变为, 模型记为, 差的平方", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1b2044c4-70f2-4163-969e-27776917eb1f", "label": "摘要11", "info": "对于小的η，最小化带权重噪声（方差为   ）的J等同于最小化附加正；则化项：；的J。这种形式的正则化鼓励参数进", "keywords": "等同于最小化附加正, 对于小的, 这种形式的正则化鼓励参数进, 则化项, 方差为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a8aa3261-e373-4a2b-86c4-4bbedb9e574d", "label": "摘要12", "info": "and", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "af27ebe2-f14f-41ac-89ab-80148883cd52", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；1995）。在简化的线性回归中（例如，；项退化为", "keywords": "在简化的线性回归中, 项退化为, 例如", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9faa7f3f-33d6-4a43-a779-1d85f0768b87", "label": "摘要14", "info": "），正则；，这与函数的参数无关，因此不会对   关于模", "keywords": "正则, 因此不会对, 关于模, 这与函数的参数无关", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "50bb7b20-f5be-43e8-a373-1ca20884ef2f", "label": "摘要15", "info": "7.5.1　向输出目标注入噪声", "keywords": "向输出目标注入噪声", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "191af081-88b2-4910-81d6-8c453d5fa129", "label": "摘要16", "info": "大多数数据集的y标签都有一定错误。错误的y不利于最大化", "keywords": "标签都有一定错误, 错误的, 大多数数据集的, 不利于最大化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ab989a2d-b7c8-4189-9e7a-2c338e1b878c", "label": "摘要17", "info": "。避免这种情况的一种方法是显式地对标签上的噪声；进行建模。例如，我们可以假设，对于一些小常数   ，训练集标记y是；正确的概率是", "keywords": "训练集标记, 例如, 正确的概率是, 我们可以假设, 避免这种情况的一种方法是显式地对标签上的噪声", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b6f56709-b76e-4ff8-911d-d8fe16a56dee", "label": "摘要18", "info": "标从0和1替换成", "keywords": "标从, 替换成", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d0626754-587f-480e-af3b-f3d5476ada36", "label": "摘要19", "info": "，正则化具有k个输出", "keywords": "正则化具有, 个输出", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fe805bc0-7e41-44d1-8fff-db749912686d", "label": "摘要20", "info": "的softmax函数的模型。标准交叉熵损失可以用在这些非确切目标的输；出上。使用softmax函数和明确目标的最大似然学习可能永远不会收敛；——softmax函数永远无法真正预测0概率或1概率，因此它会继续学习", "keywords": "函数和明确目标的最大似然学习可能永远不会收敛, 函数永远无法真正预测, 标准交叉熵损失可以用在这些非确切目标的输, 函数的模型, 概率", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d0375ecf-d654-4fc9-9dfe-11bb97d137de", "label": "摘要21", "info": "7.5.1　向输出目标注入噪；声", "keywords": "向输出目标注入噪", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "label": "7.6：半监督学习", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "c1b13d3e-53f4-4b33-82b0-abef08314825", "label": "摘要1", "info": "在半监督学习的框架下，P(x)产生的未标记样本和P(x,y)中的标记样本都；用于估计P(y｜x)或者根据x预测y。", "keywords": "用于估计, 或者根据, 在半监督学习的框架下, 中的标记样本都, 预测", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8cac93ad-8a11-4782-ba02-674a4b5655e9", "label": "摘要2", "info": "在深度学习的背景下，半监督学习通常指的是学习一个表示  h  ＝f(x)。；学习表示的目的是使相同类中的样本有类似的表示。无监督学习可以为；如何在表示空间聚集样本提供有用线索。在输入空间紧密聚集的样本应", "keywords": "无监督学习可以为, 学习表示的目的是使相同类中的样本有类似的表示, 半监督学习通常指的是学习一个表示, 如何在表示空间聚集样本提供有用线索, 在深度学习的背景下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "230309ae-cc14-4162-898d-6019efb7c559", "label": "摘要3", "info": "我们可以构建这样一个模型，其中生成模型P(x)或P(x,y)与判别模型P(y；｜x)共享参数，而不用分离无监督和监督部分。我们权衡监督模型准则；−log  P(y｜x)和无监督或生成模型准则（如−log  P(x)或−log  P(x,y)）。生", "keywords": "我们权衡监督模型准则, 共享参数, 和无监督或生成模型准则, 其中生成模型, 我们可以构建这样一个模型", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dec47f56-a673-4547-b0f7-a0bc7c48f921", "label": "摘要4", "info": "Salakhutdinov  and  Hinton（2008）描述了一种学习回归核机器中核函数；的方法，其中建模P(x)时使用的未标记样本大大提高了P(y｜x)的效果。", "keywords": "的效果, 其中建模, 描述了一种学习回归核机器中核函数, 的方法, 时使用的未标记样本大大提高了", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c6503ae2-4dbb-42e3-b217-c8aefe4ec660", "label": "摘要5", "info": "更多半监督学习的信息，请参阅Chapelle et al. （2006）。", "keywords": "请参阅, 更多半监督学习的信息", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "label": "7.7：多任务学习", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "26fa5386-aa14-45ca-acaa-4ccc3dbb85aa", "label": "摘要1", "info": "多任务学习（Caruana，1993）是通过合并几个任务中的样例（可以视；为对参数施加的软约束）来提高泛化的一种方式。正如额外的训练样本；能够将模型参数推向具有更好泛化能力的值一样，当模型的一部分被多", "keywords": "正如额外的训练样本, 可以视, 能够将模型参数推向具有更好泛化能力的值一样, 当模型的一部分被多, 多任务学习", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8ccd30c6-4e8e-42d5-8391-b782781fd42a", "label": "摘要2", "info": "图7.2展示了多任务学习中非常普遍的一种形式，其中不同的监督任务；（给定x预测y (i) ）共享相同的输入x以及一些中间层表示 h （share） ，能；学习共同的因素池。该模型通常可以分为两类相关的参数：", "keywords": "其中不同的监督任务, 该模型通常可以分为两类相关的参数, 学习共同的因素池, 以及一些中间层表示, 预测", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "44515f02-1c5b-4d55-aa1d-886fa6e0621f", "label": "摘要3", "info": "（1）具体任务的参数（只能从各自任务的样本中实现良好的泛化），；如图7.2中的上层。", "keywords": "只能从各自任务的样本中实现良好的泛化, 具体任务的参数, 如图, 中的上层", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "272e2e8d-1bc7-4bfa-9d19-eac72429806e", "label": "摘要4", "info": "（2）所有任务共享的通用参数（从所有任务的汇集数据中获益），如；图7.2中的下层。", "keywords": "从所有任务的汇集数据中获益, 所有任务共享的通用参数, 中的下层", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "36e792c6-b8c0-44f3-a519-bdbd65021404", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图7.2　多任务学习在深度学习框架中可以以多种方式进行，该图说明了任务共享相同输入但涉；及不同目标随机变量的常见情况。深度网络的较低层（无论是监督前馈的，还是包括向下箭头", "keywords": "无论是监督前馈的, 还是包括向下箭头, 及不同目标随机变量的常见情况, 该图说明了任务共享相同输入但涉, 多任务学习在深度学习框架中可以以多种方式进行", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ddbe52fa-c85c-4574-877f-719281d88c60", "label": "摘要6", "info": "因为共享参数，其统计强度可大大提高（共享参数的样本数量相对于单；任务模式增加的比例），并能改善泛化和泛化误差的范围（Baxter，；1995）。当然，仅当不同的任务之间存在某些统计关系的假设是合理", "keywords": "并能改善泛化和泛化误差的范围, 共享参数的样本数量相对于单, 其统计强度可大大提高, 任务模式增加的比例, 当然", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dd0ce933-445d-4174-8a02-fbf82bdde68f", "label": "摘要7", "info": "从深度学习的观点看，底层的先验知识如下：能解释数据变化（在与之；相关联的不同任务中观察到）的因素中，某些因素是跨两个或更多任务；共享的。", "keywords": "的因素中, 某些因素是跨两个或更多任务, 在与之, 相关联的不同任务中观察到, 能解释数据变化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "label": "7.8：提前终止", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "5d1b5e54-8de4-42e9-99c6-fc5871fc1dd0", "label": "摘要1", "info": "当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，；训练误差会随着时间的推移逐渐降低但验证集的误差会再次上升。图；7.3是这些现象的一个例子，这种现象几乎一定会出现。", "keywords": "我们经常观察到, 是这些现象的一个例子, 这种现象几乎一定会出现, 训练误差会随着时间的推移逐渐降低但验证集的误差会再次上升, 当训练有足够的表示能力甚至会过拟合的大模型时", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6fb7aa1e-18ba-460a-87a3-41a73eae0b9c", "label": "摘要2", "info": "图7.3　学习曲线显示负对数似然损失如何随时间变化（表示为遍历数据集的训练迭代数，或 轮；数 （epochs））。在这个例子中，我们在MNIST上训练了一个maxout网络。我们可以观察到训；练目标随时间持续减小，但验证集上的平均损失最终会再次增加，形成不对称的U形曲线", "keywords": "网络, 学习曲线显示负对数似然损失如何随时间变化, 上训练了一个, 形成不对称的, 我们可以观察到训", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "264ae62e-0968-4a48-923b-7081dc8d2e8e", "label": "摘要3", "info": "这意味着我们只要返回使验证集误差最低的参数设置，就可以获得验证；集误差更低的模型（并且因此有希望获得更好的测试误差）。在每次验；证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，", "keywords": "我们存储模型参数的副本, 在每次验, 就可以获得验证, 并且因此有希望获得更好的测试误差, 集误差更低的模型", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "29fab669-20e7-43ab-9291-866cb4058c94", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；这种策略被称为提前终止 （early stopping）。这可能是深度学习中最常；用的正则化形式。它的流行主要是因为有效性和简单性。", "keywords": "用的正则化形式, 这种策略被称为提前终止, 这可能是深度学习中最常, 它的流行主要是因为有效性和简单性", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "929ce490-bb14-46f3-94a0-d35d5ef81dc1", "label": "摘要5", "info": "我们可以认为提前终止是非常高效的超参数选择算法。按照这种观点，；训练步数仅是另一个超参数。我们从图7.3可以看到，这个超参数在验；证集上具有U型性能曲线。很多控制模型容量的超参数在验证集上都是", "keywords": "我们从图, 训练步数仅是另一个超参数, 按照这种观点, 证集上具有, 可以看到", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "738a086b-2545-4f78-b0f9-5952868b2b61", "label": "摘要6", "info": "另一个提前终止的额外代价是需要保持最佳的参数副本。这种代价一般；是可忽略的，因为可以将它储存在较慢较大的存储器上（例如，在GPU；内存中训练，但将最佳参数存储在主存储器或磁盘驱动器上）。由于最", "keywords": "内存中训练, 是可忽略的, 但将最佳参数存储在主存储器或磁盘驱动器上, 例如, 另一个提前终止的额外代价是需要保持最佳的参数副本", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3d368aae-53f4-46a1-9f91-4a30db91c6f8", "label": "摘要7", "info": "提前终止是一种非常不显眼的正则化形式，它几乎不需要改变基本训练；过程、目标函数或一组允许的参数值。这意味着，无须破坏学习动态就；能很容易地使用提前终止。相对于权重衰减，必须小心不能使用太多的", "keywords": "它几乎不需要改变基本训练, 无须破坏学习动态就, 提前终止是一种非常不显眼的正则化形式, 相对于权重衰减, 必须小心不能使用太多的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2b1af5c1-9275-4f1a-bf54-ee20fb43cc92", "label": "摘要8", "info": "提前终止可单独使用或与其他的正则化策略结合使用。即使为鼓励更好；泛化，使用正则化策略改进目标函数，在训练目标的局部极小点达到最；好泛化也是非常罕见的。", "keywords": "提前终止可单独使用或与其他的正则化策略结合使用, 使用正则化策略改进目标函数, 在训练目标的局部极小点达到最, 好泛化也是非常罕见的, 泛化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "705c7385-287d-4058-a14b-41d703feddbc", "label": "摘要9", "info": "提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了；更好地利用这一额外的数据，我们可以在完成提前终止的首次训练之；后，进行额外的训练。在第二轮，即额外的训练步骤中，所有的训练数", "keywords": "为了, 在第二轮, 更好地利用这一额外的数据, 所有的训练数, 我们可以在完成提前终止的首次训练之", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c6e02c19-f73d-470a-b564-42e5b75b7b2c", "label": "摘要10", "info": "算法7.1  　用于确定最佳训练时间量的提前终止元算法。这种元算法是；一种通用策略，可以很好地在各种训练算法和各种量化验证集误差的方；法上工作。", "keywords": "可以很好地在各种训练算法和各种量化验证集误差的方, 用于确定最佳训练时间量的提前终止元算法, 这种元算法是, 算法, 法上工作", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "bacd18ad-3e7a-4e8f-b1bf-130b08270650", "label": "摘要11", "info": "令n为评估间隔的步数。", "keywords": "为评估间隔的步数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "74ecefb7-bbd4-43ed-ac9d-aed0151fd065", "label": "摘要12", "info": "令p为“耐心（patience）”，即观察到较坏的验证集表现p次后终止。", "keywords": "即观察到较坏的验证集表现, 耐心, 次后终止", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "af6ee1bc-be8c-4dff-9754-57e35c1f8bb0", "label": "摘要13", "info": "令 θ o 为初始参数。", "keywords": "为初始参数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c1071ae0-ec9b-4737-a05c-f11ac8606e86", "label": "摘要14", "info": "θ ← θ o", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1200db73-c0e8-4144-8f7c-e1eff3e8f467", "label": "摘要15", "info": "i←0", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8d703831-4150-430a-bcfd-21d8655e10d5", "label": "摘要16", "info": "j←0", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "05db4d95-df74-4e01-8e4e-8d513e0778ce", "label": "摘要17", "info": "ν←∞", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1b8dd287-2f51-4e20-9ca5-e6a83920b0e6", "label": "摘要18", "info": "θ * ← θ", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2550791d-8221-4d02-957e-89be5e437779", "label": "摘要19", "info": "i * ←i", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f44cf2da-e006-4d00-b426-c827710ec29d", "label": "摘要20", "info": "while j＜p do", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "acd1ed9f-6ded-45e0-b4d9-8fd967611e81", "label": "摘要21", "info": "运行训练算法n步，更新 θ 。", "keywords": "运行训练算法, 更新", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "09387fad-13dd-4313-8732-8786f6e3226d", "label": "摘要22", "info": "i←i＋n", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2d435a64-940b-429c-8cc1-a44f6afd17c8", "label": "摘要23", "info": "ν＇←ValidationSetError( θ )", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ddbd38cc-cbfa-4f37-a8bd-7a292524234a", "label": "摘要24", "info": "if ν＇＜ν then", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "78c09362-43f6-4b83-94a2-b9f12671d703", "label": "摘要25", "info": "j←0", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "90539333-56ce-409e-95bc-4c9fffec7126", "label": "摘要26", "info": "θ * ← θ", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d03d410d-1fe7-495b-a830-cde86b947ea8", "label": "摘要27", "info": "i * ←i", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "347caaa4-4170-40c0-801b-f58bae9798a9", "label": "摘要28", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；ν←ν＇", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5e6b85a4-a7ec-45f4-8ab4-4c9b9e972822", "label": "摘要29", "info": "else", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0fd878c0-d620-42f5-bedb-9c43247d1908", "label": "摘要30", "info": "j←j＋1", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c8ecf46f-e2fa-43bc-8680-84a5d5551121", "label": "摘要31", "info": "end if", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "13fa1ec6-dd27-4a2a-adb9-38e22c982fb9", "label": "摘要32", "info": "end while", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7abb0b08-ebb5-4eb2-849d-e05cfd3a3902", "label": "摘要33", "info": "最佳参数为 θ * ，最佳训练步数为i *", "keywords": "最佳训练步数为, 最佳参数为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "16a0e528-f758-4e22-9386-1607ce6224c8", "label": "摘要34", "info": "一个策略（算法7.2  ）是再次初始化模型，然后使用所有数据再次训；练。在这个第二轮训练过程中，我们使用第一轮提前终止训练确定的最；佳步数。此过程有一些细微之处。例如，我们没有办法知道重新训练", "keywords": "一个策略, 然后使用所有数据再次训, 算法, 是再次初始化模型, 在这个第二轮训练过程中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "135110df-4e27-4b73-8865-b8bc3ae460d0", "label": "摘要35", "info": "另一个策略是保持从第一轮训练获得的参数，然后使用全部的数据继续；训练。在这个阶段，已经没有验证集指导我们需要在训练多少步后终；止。取而代之，我们可以监控验证集的平均损失函数，并继续训练，直", "keywords": "训练, 取而代之, 然后使用全部的数据继续, 另一个策略是保持从第一轮训练获得的参数, 在这个阶段", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b522e282-c9dd-46b6-bf4b-b7ed1c1b20fe", "label": "摘要36", "info": "提前终止对减少训练过程的计算成本也是有用的。除了由于限制训练的；迭代次数而明显减少的计算成本，还带来了正则化的益处（不需要添加；惩罚项的代价函数或计算这种附加项的梯度）。", "keywords": "惩罚项的代价函数或计算这种附加项的梯度, 除了由于限制训练的, 不需要添加, 还带来了正则化的益处, 提前终止对减少训练过程的计算成本也是有用的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d7b40ebe-2699-4c52-b61a-9b67e4be00c2", "label": "摘要37", "info": "算法7.2  　使用提前终止确定训练步数，然后在所有数据上训练的元算；法。", "keywords": "使用提前终止确定训练步数, 然后在所有数据上训练的元算, 算法", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "067a89b8-0bed-4199-a8e9-e9e34e7c97ee", "label": "摘要38", "info": "令", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c870de4f-e32b-47d6-8d6d-e7142a838c2b", "label": "摘要39", "info": "为训练集。", "keywords": "为训练集", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3f1939d2-b75d-42d7-a5b2-725849ddf496", "label": "摘要40", "info": "从随机  θ  开始，使用", "keywords": "使用, 开始, 从随机", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "67fe940e-b423-4606-b938-10b492c9c3c6", "label": "摘要41", "info": "作为训练集，", "keywords": "作为训练集", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "bd50b36a-8df0-4dc1-b643-c65d9ed161fa", "label": "摘要42", "info": "作为验证集，", "keywords": "作为验证集", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "faeb128a-1054-41be-81af-bda5cfd0c2e0", "label": "摘要43", "info": "运行（算法7.1 ）。这将返回最佳训练步数i * 。", "keywords": "这将返回最佳训练步数, 运行, 算法", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f6e35320-c78e-4ad7-9627-fd10003b1442", "label": "摘要44", "info": "将 θ 再次设为随机值。", "keywords": "再次设为随机值", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3de8afb9-2987-40a6-98d9-bbbabaf377bf", "label": "摘要45", "info": "上训练i * 步。", "keywords": "上训练", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "43f808a5-06c4-4b14-b25f-1e604e62c8e1", "label": "摘要46", "info": "算法7.3  　使用提前终止确定将会过拟合的目标值，然后在所有数据上；训练直到再次达到该值的元算法。", "keywords": "训练直到再次达到该值的元算法, 然后在所有数据上, 使用提前终止确定将会过拟合的目标值, 算法", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5cc2818a-0772-46fb-bdff-4a9b5a65d152", "label": "摘要47", "info": "提前终止为何具有正则化效果：  目前为止，我们已经声明提前终止是；一种正则化策略，但只通过展示验证集误差的学习曲线是一个U型曲线；来支持这种说法。提前终止正则化模型的真正机制是什么呢？", "keywords": "一种正则化策略, 型曲线, 目前为止, 来支持这种说法, 但只通过展示验证集误差的学习曲线是一个", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f6712cfb-48a9-4f60-9e7d-e4043a77e2ef", "label": "摘要48", "info": "的效果就好像是权重衰减系数的倒数。", "keywords": "的效果就好像是权重衰减系数的倒数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e25b16d9-8d4c-4070-bbb6-cb4aa31ed6fd", "label": "摘要49", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图7.4　提前终止效果的示意图。（左）实线轮廓线表示负对数似然的轮廓。虚线表示从原点开；始的SGD所经过的轨迹。提前终止的轨迹在较早的点", "keywords": "始的, 提前终止效果的示意图, 提前终止的轨迹在较早的点, 虚线表示从原点开, 所经过的轨迹", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d55ff9cc-1209-436f-8734-eee1b56468a7", "label": "摘要50", "info": "处停止，而不是停止在最小化代价的点", "keywords": "而不是停止在最小化代价的点, 处停止", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "efc798ae-61a5-45b6-a20b-d893dc2b9a16", "label": "摘要51", "info": "事实上，在二次误差的简单线性模型和简单的梯度下降情况下，我们可；以展示提前终止相当于L 2 正则化。", "keywords": "我们可, 事实上, 正则化, 以展示提前终止相当于, 在二次误差的简单线性模型和简单的梯度下降情况下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3442aee6-ada6-4e1f-9c08-8c3dfbead85a", "label": "摘要52", "info": "为了与经典L", "keywords": "为了与经典", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "89776f97-187a-4cf3-bab7-a58bd680b0c5", "label": "摘要53", "info": "2  正则化比较，我们只考察唯一的参数是线性权重；的简单情形。我们在权重 w 的经验最佳值 w * 附近以二次近", "keywords": "的经验最佳值, 我们只考察唯一的参数是线性权重, 正则化比较, 附近以二次近, 的简单情形", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1ec13b24-85aa-452a-b0ac-977a28718b3d", "label": "摘要54", "info": "似建模代价函数J：", "keywords": "似建模代价函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "57cecbc8-f001-446a-905b-aa722d669935", "label": "摘要55", "info": "其中 H 是J关于 w 在 w * 点的Hessian。鉴于假设 w * 是J( w )的最小点，；我们知道 H 为半正定。在局部泰勒级数逼近下，梯度由下式给出：", "keywords": "鉴于假设, 为半正定, 其中, 梯度由下式给出, 在局部泰勒级数逼近下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d3d65e83-73c9-4892-80e4-bdd497975381", "label": "摘要56", "info": "接下来我们研究训练时参数向量的轨迹。为简化起见，我们将参数向量；初始化为原点 (3) ，也就是 w (0) ＝0。我们通过分析  上的梯度下降来研；究J上近似的梯度下降的效果：", "keywords": "我们将参数向量, 上的梯度下降来研, 也就是, 我们通过分析, 初始化为原点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "28e645e3-e8e1-408e-aa16-ab1c097e201c", "label": "摘要57", "info": "现在让我们在  H  特征向量的空间中改写表达式，利用  H  的特征分解：", "keywords": "的特征分解, 现在让我们在, 特征向量的空间中改写表达式, 利用", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "561dcd60-567f-42ac-9f14-2240dcb96577", "label": "摘要58", "info": "，其中Λ  是对角矩阵，  Q  是特征向量的一组标准正交", "keywords": "是特征向量的一组标准正交, 是对角矩阵, 其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "95b490b3-9415-447c-abe5-6e068b51998f", "label": "摘要59", "info": "基。", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "84494bff-5962-478d-9d96-9ce8c3abc54f", "label": "摘要60", "info": "假定  w  (0)  ＝0并且   选择得足够小以保证；参数更新后轨迹如下：", "keywords": "并且, 选择得足够小以保证, 假定, 参数更新后轨迹如下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d0d4d742-e2db-4d03-bc69-bfaa28438d11", "label": "摘要61", "info": "，经过τ次", "keywords": "经过", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fa813d5e-6dfd-4df4-baf8-4bd27e26da7e", "label": "摘要62", "info": "现在，式（7.13）中", "keywords": "现在", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f8fda9f9-226d-4da1-a958-afe873f4feda", "label": "摘要63", "info": "的表达式能被重写为", "keywords": "的表达式能被重写为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dbf695a1-348b-46e8-9db5-052017ca1239", "label": "摘要64", "info": "比较式（7.40）和式（7.42），我们能够发现，如果超参数；满足", "keywords": "比较式, 满足, 和式, 我们能够发现, 如果超参数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "16e8d08a-bdaf-4e8f-8c6f-4122da688a81", "label": "摘要65", "info": "和τ", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d720e5a8-0ae0-45c6-8e7f-ff2552dfdb39", "label": "摘要66", "info": "那么L  2  正则化和提前终止可以看作等价的（至少在目标函数的二次近；似下）。进一步取对数，使用log(1＋x)的级数展开，我们可以得出结；论：如果所有λ i 是小的（即", "keywords": "如果所有, 的级数展开, 进一步取对数, 至少在目标函数的二次近, 那么", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "98d4eedf-9599-48ec-ac0a-5236705363a9", "label": "摘要67", "info": "），那么", "keywords": "那么", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9a02e54d-19d8-4587-9229-1e1f5f675562", "label": "摘要68", "info": "且", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "acaf9820-ce22-43c2-bc20-99efed901225", "label": "摘要69", "info": "也就是说，在这些假设下，训练迭代次数τ起着与L  2  参数成反比的作；用，  的倒数与权重衰减系数的作用类似。", "keywords": "在这些假设下, 起着与, 参数成反比的作, 的倒数与权重衰减系数的作用类似, 训练迭代次数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "69136c89-e36f-4405-829e-82f7216e4ad9", "label": "摘要70", "info": "在大曲率（目标函数）方向上的参数值受正则化影响小于小曲率方向。；当然，在提前终止的情况下，这实际上意味着在大曲率方向的参数比较；小曲率方向的参数更早地学习到。", "keywords": "在提前终止的情况下, 在大曲率, 小曲率方向的参数更早地学习到, 这实际上意味着在大曲率方向的参数比较, 目标函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0cc56e55-d940-4665-9c9d-732732ccfd86", "label": "摘要71", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；本节中的推导表明，长度为τ的轨迹结束于L  2  正则化目标的极小点。当；然，提前终止比简单的轨迹长度限制更丰富；取而代之，提前终止通常", "keywords": "长度为, 取而代之, 的轨迹结束于, 本节中的推导表明, 提前终止比简单的轨迹长度限制更丰富", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7e75318b-5daa-49de-8d70-96de284ca966", "label": "7.9：参数绑定和参数共享", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "d58f0f8e-210f-47f7-b43f-15ed596185f3", "label": "摘要1", "info": "7.9.1　卷积神经网络", "keywords": "卷积神经网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "fc1a7ea5-90a4-4888-9b0e-39d1242cbdf2", "label": "摘要2", "info": "目前为止，本章讨论对参数添加约束或惩罚时，一直是相对于固定的区；域或点。例如，L  2  正则化（或权重衰减）对参数偏离零的固定值进行；惩罚。然而，有时我们可能需要其他的方式来表达我们对模型参数适当", "keywords": "对参数偏离零的固定值进行, 正则化, 一直是相对于固定的区, 目前为止, 例如", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "efd2268e-33c3-470d-ac4c-32f465093f13", "label": "摘要3", "info": "我们经常想要表达的一种常见依赖是某些参数应当彼此接近。考虑以下；情形：有两个模型执行相同的分类任务（具有相同类别），但输入分布；稍有不同。形式地，我们有参数为 w  (A)  的模型A和参数为 w  (B)  的模型", "keywords": "情形, 考虑以下, 我们有参数为, 形式地, 的模型", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3210bce0-26d2-4af3-b83d-6321f89589c3", "label": "摘要4", "info": "我们可以想象，这些任务会足够相似（或许具有相似的输入和输出分", "keywords": "我们可以想象, 或许具有相似的输入和输出分, 这些任务会足够相似", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f8661310-79a9-4d9e-9b6b-ba4916c63aa8", "label": "摘要5", "info": "布），因此我们认为模型参数应彼此靠近：", "keywords": "因此我们认为模型参数应彼此靠近", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2aa1fae9-9640-458d-a7ad-2c8f39421494", "label": "摘要6", "info": "应该与", "keywords": "应该与", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8a8a330c-044d-4828-ad1c-826ea5ee1bdd", "label": "摘要7", "info": "接近。我们可以通过正则化利用此信息。具体来说，可以使", "keywords": "具体来说, 我们可以通过正则化利用此信息, 可以使, 接近", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2dc52559-3465-481d-b39c-aad0124a5ed9", "label": "摘要8", "info": "用以下形式的参数范数惩罚：", "keywords": "用以下形式的参数范数惩罚", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4d335102-76ae-4945-acf5-706e34889f91", "label": "摘要9", "info": "这里我", "keywords": "这里我", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8999ba65-0817-43e1-9d92-06f601491b49", "label": "摘要10", "info": "们使用L 2 惩罚，但也可以使用其他选择。", "keywords": "但也可以使用其他选择, 惩罚, 们使用", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "3b3c0a5b-8ac4-4e7d-86b6-afcc422014d0", "label": "摘要11", "info": "这种方法由Lasserre et al. （2006）提出，正则化一个模型（监督模式下；训练的分类器）的参数，使其接近另一个无监督模式下训练的模型（捕；捉观察到的输入数据的分布）的参数。构造的这种架构使得分类模型中", "keywords": "监督模式下, 的参数, 这种方法由, 提出, 训练的分类器", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "014a7b3e-4b51-4cf2-b391-884119a15a79", "label": "摘要12", "info": "的许多参数能与无监督模型中对应的的参数匹配。", "keywords": "的许多参数能与无监督模型中对应的的参数匹配", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6c665316-0664-4e1b-9ad5-d2304ab1e479", "label": "摘要13", "info": "参数范数惩罚是正则化参数使其彼此接近的一种方式，而更流行的方法；是使用约束：强迫某些参数相等。由于我们将各种模型或模型组件解释；为共享唯一的一组参数，这种正则化方法通常被称为参数共享", "keywords": "这种正则化方法通常被称为参数共享, 为共享唯一的一组参数, 由于我们将各种模型或模型组件解释, 而更流行的方法, 参数范数惩罚是正则化参数使其彼此接近的一种方式", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4e536734-4982-4c84-93c2-2ad4e5ce7cd2", "label": "摘要14", "info": "7.9.1　卷积神经网络", "keywords": "卷积神经网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "721c72a9-9f67-452c-baee-3f4964614442", "label": "摘要15", "info": "目前为止，最流行和广泛使用的参数共享出现在应用于计算机视觉的卷；积神经网络 （CNN）中。", "keywords": "最流行和广泛使用的参数共享出现在应用于计算机视觉的卷, 积神经网络, 目前为止", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5aa45ddc-2196-49ab-b0f4-e2ac47f0dec7", "label": "摘要16", "info": "自然图像有许多统计属性是对转换不变的。例如，猫的照片即使向右边；移了一个像素，仍保持猫的照片。CNN通过在图像多个位置共享参数来；考虑这个特性。相同的特征（具有相同权重的隐藏单元）在输入的不同", "keywords": "在输入的不同, 自然图像有许多统计属性是对转换不变的, 相同的特征, 具有相同权重的隐藏单元, 例如", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c5ef8fcb-6d04-4a19-8400-14856a52e6f2", "label": "摘要17", "info": "参数共享显著降低了CNN模型的参数数量，并显著提高了网络的大小而；不需要相应地增加训练数据。它仍然是将领域知识有效地整合到网络架；构的最佳范例之一。", "keywords": "模型的参数数量, 它仍然是将领域知识有效地整合到网络架, 并显著提高了网络的大小而, 构的最佳范例之一, 不需要相应地增加训练数据", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e7d2b99f-e34d-4833-933b-3035e309c26d", "label": "摘要18", "info": "我们将会在第9章中更详细地讨论卷积神经网络。", "keywords": "我们将会在第, 章中更详细地讨论卷积神经网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "528cc544-e8dd-477d-aa75-7577e4082d5a", "label": "摘要19", "info": "7.9.1　卷积神经网络", "keywords": "卷积神经网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "bc032186-c788-4135-a392-30615b0f5582", "label": "7.10：稀疏表示", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "ce2854a6-6970-428d-8d33-dea56cd7028e", "label": "摘要1", "info": "前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中；的激活单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂；惩罚。", "keywords": "前文所述的权重衰减直接惩罚模型参数, 稀疏化激活单元, 这种策略间接地对模型参数施加了复杂, 惩罚, 的激活单元", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "60a8ecb4-8eab-44d1-9b76-4bd959ae5260", "label": "摘要2", "info": "我们已经讨论过（在第7.1.2节中）L  1  惩罚如何诱导稀疏的参数，即许；多参数为零（或接近于零）。另一方面，表示的稀疏描述了许多元素是；零（或接近零）的表示。我们可以线性回归的情况简单说明这种区别：", "keywords": "我们已经讨论过, 的表示, 惩罚如何诱导稀疏的参数, 节中, 另一方面", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "78e6afcd-7d45-4001-9453-0df5399e0bc1", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；第一个表达式是参数稀疏的线性回归模型的例子。第二个表达式是数据；x 具有稀疏表示 h 的线性回归。也就是说， h 是 x 的一个函数，在某种", "keywords": "在某种, 的一个函数, 的线性回归, 第一个表达式是参数稀疏的线性回归模型的例子, 第二个表达式是数据", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4b0ee05e-57a3-4322-8579-8938796146e7", "label": "摘要4", "info": "表示的正则化可以使用参数正则化中同种类型的机制实现。", "keywords": "表示的正则化可以使用参数正则化中同种类型的机制实现", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a0e43c83-0cb9-45b3-b091-8d1e8a72c5e9", "label": "摘要5", "info": "表示的范数惩罚正则化是通过向损失函数J添加对表示的范数惩罚来实；现的。我们将这个惩罚记作Ω(  h  )。和以前一样，我们将正则化后的损；失函数记作  ：", "keywords": "和以前一样, 现的, 失函数记作, 我们将这个惩罚记作, 添加对表示的范数惩罚来实", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9eba17d9-463a-4f80-b59e-8df1100cdeef", "label": "摘要6", "info": "其中α∈[0,∞]权衡范数惩罚项的相对贡献，越大的α对应越多的正则化。", "keywords": "对应越多的正则化, 其中, 权衡范数惩罚项的相对贡献, 越大的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c8d690e5-52b4-49fa-998a-1be2280efe07", "label": "摘要7", "info": "正如对参数的L  1  惩罚诱导参数稀疏性，对表示元素的L  1  惩罚诱导稀疏；当然L  1  惩罚是使表示稀疏的方法之；的表示：Ω(h)＝", "keywords": "的表示, 惩罚诱导稀疏, 正如对参数的, 惩罚是使表示稀疏的方法之, 当然", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "861212b1-9bed-496d-8e67-dc0fe09c4a9f", "label": "摘要8", "info": "and", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "28fa15f6-1b73-4f9d-b030-e84c96a05f4b", "label": "摘要9", "info": "化几个样本平均激活的例子，即令", "keywords": "化几个样本平均激活的例子, 即令", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1678adbc-d2b4-454e-b00b-4b8e60ddbdc2", "label": "摘要10", "info": "接近某些目标值", "keywords": "接近某些目标值", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0aa4c7d3-064a-4631-8249-ed8680521200", "label": "摘要11", "info": "（如每项都是.01的向量）。", "keywords": "的向量, 如每项都是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0377f431-1609-42e7-b0df-f61b8d2bb10d", "label": "摘要12", "info": "还有一些其他方法通过激活值的硬性约束来获得表示稀疏。例如，正交；匹配追踪 （orthogonal matching pursuit）（Pati et al. ，1993）通过解决；以下约束优化问题将输入值 x 编码成表示 h", "keywords": "匹配追踪, 编码成表示, 通过解决, 例如, 还有一些其他方法通过激活值的硬性约束来获得表示稀疏", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "845a087a-d783-4c77-a559-68d78701bbb0", "label": "摘要13", "info": "是  h  中非零项的个数。当  W  被约束为正交时，我们可以高", "keywords": "中非零项的个数, 被约束为正交时, 我们可以高", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dc2cae19-5e11-4195-8b4f-1415646ec106", "label": "摘要14", "info": "其中；效地解决这个问题。这种方法通常被称为OMP-k，通过k指定允许的非；零特征数量。Coates  and  Ng（2011）证明OMP-1可以成为深度架构中非", "keywords": "效地解决这个问题, 这种方法通常被称为, 其中, 指定允许的非, 证明", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "328147c5-a5b0-4c99-a443-46d599bc6a9e", "label": "摘要15", "info": "含有隐藏单元的模型在本质上都能变得稀疏。在本书中，我们将看到在；各种情况下使用稀疏正则化的例子。", "keywords": "在本书中, 含有隐藏单元的模型在本质上都能变得稀疏, 我们将看到在, 各种情况下使用稀疏正则化的例子", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "label": "7.11：Bagging和其他集成方法", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "4010e581-f144-4557-be49-5d64cee33be2", "label": "摘要1", "info": "Bagging  （bootstrap  aggregating）是通过结合几个模型降低泛化误差的；技术（Breiman，1994）。主要想法是分别训练几个不同的模型，然后；让所有模型表决测试样例的输出。这是机器学习中常规策略的一个例", "keywords": "主要想法是分别训练几个不同的模型, 技术, 是通过结合几个模型降低泛化误差的, 这是机器学习中常规策略的一个例, 然后", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "12088dff-16be-4a68-b800-717bbef5b0b5", "label": "摘要2", "info": "模型平均 （model averaging）奏效的原因是不同的模型通常不会在测试；集上产生完全相同的误差。", "keywords": "奏效的原因是不同的模型通常不会在测试, 集上产生完全相同的误差, 模型平均", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4842e23c-2f5e-4900-9c03-dd31dddbf51b", "label": "摘要3", "info": "假设我们有k个回归模型。假设每个模型在每个例子上的误差是   ，；的多；这个误差服从零均值方差为", "keywords": "的多, 假设每个模型在每个例子上的误差是, 这个误差服从零均值方差为, 个回归模型, 假设我们有", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2fb20c4d-c1d5-4b25-88be-e13bd23ba84c", "label": "摘要4", "info": "且协方差为", "keywords": "且协方差为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5ae0a624-c4fa-4870-bef9-64d7af47f33a", "label": "摘要5", "info": "维正态分布。通过所有集成模型的平均预测所得误差是", "keywords": "通过所有集成模型的平均预测所得误差是, 维正态分布", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ec55fa40-351b-4853-a215-7d56296bc291", "label": "摘要6", "info": "。集成预测器平方误差的期望是", "keywords": "集成预测器平方误差的期望是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2f8e498f-7f47-4c34-a3ec-af9712da9e95", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在误差完全相关即c＝ν的情况下，均方误差减少到ν，所以模型平均没；有任何帮助。在错误完全不相关即c＝0的情况下，该集成平方误差的期", "keywords": "均方误差减少到, 在误差完全相关即, 所以模型平均没, 在错误完全不相关即, 的情况下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f66712b2-019e-4d30-9f16-125f56bb0eaa", "label": "摘要8", "info": "望仅为", "keywords": "望仅为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e40016c7-bd4f-455e-9db6-d37b99a41ab9", "label": "摘要9", "info": "。这意味着集成平方误差的期望会随着集成规模增大而线", "keywords": "这意味着集成平方误差的期望会随着集成规模增大而线", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "bc7b0389-9d75-407c-a59b-998ff932f91d", "label": "摘要10", "info": "性减小。换言之，平均上，集成至少与它的任何成员表现得一样好，并；且如果成员的误差是独立的，集成将显著地比其成员表现得更好。", "keywords": "换言之, 且如果成员的误差是独立的, 平均上, 集成至少与它的任何成员表现得一样好, 集成将显著地比其成员表现得更好", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "359e0c24-090f-4678-a036-437c6756d2d7", "label": "摘要11", "info": "不同的集成方法以不同的方式构建集成模型。例如，集成的每个成员可；以使用不同的算法和目标函数训练成完全不同的模型。Bagging是一种；允许重复多次使用同一种模型、训练算法和目标函数的方法。", "keywords": "以使用不同的算法和目标函数训练成完全不同的模型, 是一种, 例如, 允许重复多次使用同一种模型, 集成的每个成员可", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ddb1ac32-c2cd-4641-94a4-79b3b5a54820", "label": "摘要12", "info": "具体来说，Bagging涉及构造k个不同的数据集。每个数据集从原始数据；集中重复采样构成，和原始数据集具有相同数量的样例。这意味着，每；个数据集以高概率缺少一些来自原始数据集的例子，还包含若干重复的", "keywords": "还包含若干重复的, 个不同的数据集, 个数据集以高概率缺少一些来自原始数据集的例子, 和原始数据集具有相同数量的样例, 具体来说", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c85dc7a5-72b6-46f1-b12e-6ffb1ecc762f", "label": "摘要13", "info": "图7.5　描述Bagging如何工作的草图。假设我们在上述数据集（包含一个8、一个6和一个9）上；训练数字8的检测器，假设我们制作了两个不同的重采样数据集，Bagging训练程序通过有放回；采样构建这些数据集。第一个数据集忽略9并重复8。在这个数据集上，检测器得知数字顶部有", "keywords": "并重复, 如何工作的草图, 在这个数据集上, 检测器得知数字顶部有, 假设我们在上述数据集", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "09e59c78-2b33-435e-b6c5-48c4c741bcda", "label": "摘要14", "info": "一个环就对应于一个8。第二个数据集中，我们忽略6并重复9。在这种情况下，检测器得知数字；底部有一个环就对应于一个8。这些单独的分类规则中的每一个都是不可靠的，但如果我们平均；它们的输出，就能得到鲁棒的检测器，只有当8的两个环都存在时才能实现最大置信度", "keywords": "并重复, 的两个环都存在时才能实现最大置信度, 只有当, 这些单独的分类规则中的每一个都是不可靠的, 检测器得知数字", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1787699f-c931-4b7e-8ec8-0f3161292375", "label": "摘要15", "info": "神经网络能找到足够多的不同的解，意味着它们可以从模型平均中受益；（即使所有模型都在同一数据集上训练）。神经网络中随机初始化的差；异、小批量的随机选择、超参数的差异或不同输出的非确定性实现往往", "keywords": "意味着它们可以从模型平均中受益, 小批量的随机选择, 神经网络中随机初始化的差, 超参数的差异或不同输出的非确定性实现往往, 即使所有模型都在同一数据集上训练", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8af43414-8ba5-4c4c-b958-e0f483d5aeff", "label": "摘要16", "info": "模型平均是一个减少泛化误差的非常强大可靠的方法。在作为科学论文；算法的基准时，它通常是不鼓励使用的，因为任何机器学习算法都可以；从模型平均中大幅获益（以增加计算和存储为代价）。", "keywords": "它通常是不鼓励使用的, 模型平均是一个减少泛化误差的非常强大可靠的方法, 以增加计算和存储为代价, 在作为科学论文, 算法的基准时", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "acfefdf9-f953-4830-baad-63d084f04066", "label": "摘要17", "info": "机器学习比赛中的取胜算法通常是使用超过几十种模型平均的方法。最；近一个突出的例子是Netflix Grand Prize（Koren，2009）。", "keywords": "机器学习比赛中的取胜算法通常是使用超过几十种模型平均的方法, 近一个突出的例子是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e8859f0a-7d59-4883-9332-cbcbe8f845d4", "label": "摘要18", "info": "不是所有构建集成的技术都是为了让集成模型比单一模型更加正则化。；例如，一种被称为Boosting 的技术（Freund and Schapire，1996b，a）构；建比单个模型容量更高的集成模型。通过向集成逐步添加神经网络，", "keywords": "建比单个模型容量更高的集成模型, 例如, 的技术, 不是所有构建集成的技术都是为了让集成模型比单一模型更加正则化, 一种被称为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "453c3afe-c160-423c-8813-2cca53025ee9", "label": "摘要19", "info": "and  Bengio，", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a502d92e-71c2-41a3-a2fc-b216c85a24b3", "label": "摘要20", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；7.12　Dropout", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "df8ea3a6-5f24-41a2-ba6c-64327f249454", "label": "摘要21", "info": "Dropout  （Srivastava  et  al.  ，2014）提供了正则化一大类模型的方法，；计算方便但功能强大。在第一种近似下，Dropout可以被认为是集成大；量深层神经网络的实用Bagging方法。Bagging涉及训练多个模型，并在", "keywords": "在第一种近似下, 计算方便但功能强大, 并在, 可以被认为是集成大, 提供了正则化一大类模型的方法", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "418bccd9-8765-491c-aa20-440e04999c77", "label": "摘要22", "info": "具体而言，Dropout训练的集成包括所有从基础网络除去非输出单元后；形成的子网络，如图7.6所示。最先进的神经网络基于一系列仿射变换；和非线性变换，我们只需将一些单元的输出乘零就能有效地删除一个单", "keywords": "具体而言, 和非线性变换, 训练的集成包括所有从基础网络除去非输出单元后, 我们只需将一些单元的输出乘零就能有效地删除一个单, 形成的子网络", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "34f56e1b-eb53-4b38-b1cf-d218a3a6c574", "label": "摘要23", "info": "图7.6　Dropout训练由所有子网络组成的集成，其中子网络通过从基本网络中删除非输出单元构；建。我们从具有两个可见单元和两个隐藏单元的基本网络开始。这4个单元有16个可能的子集。；右图展示了从原始网络中丢弃不同的单元子集而形成的所有16个子网络。在这个小例子中，所", "keywords": "训练由所有子网络组成的集成, 个可能的子集, 其中子网络通过从基本网络中删除非输出单元构, 在这个小例子中, 我们从具有两个可见单元和两个隐藏单元的基本网络开始", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0fa32c25-73f7-4069-b6b0-bdbdea0238b2", "label": "摘要24", "info": "回想一下Bagging学习，我们定义k个不同的模型，从训练集有放回采样；构造k个不同的数据集，然后在训练集i上训练模型i。Dropout的目标是；在指数级数量的神经网络上近似这个过程。具体来说，在训练中使用", "keywords": "从训练集有放回采样, 个不同的数据集, 构造, 在指数级数量的神经网络上近似这个过程, 个不同的模型", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f912fb63-f6b0-4064-b57f-3f2045bb8ff5", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图7.7　在使用Dropout的前馈网络中前向传播的示例。（顶部）在此示例中，我们使用具有两个；输入单元，具有两个隐藏单元的隐藏层以及一个输出单元的前馈网络。（底部）为了执行具有", "keywords": "我们使用具有两个, 的前馈网络中前向传播的示例, 底部, 顶部, 输入单元", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "82d5535b-8dec-4e04-a2de-0427084085fb", "label": "摘要26", "info": "是由；更正式地说，假设一个掩码向量  μ  指定被包括的单元，；参数  θ  和掩码  μ  定义的模型代价。那么Dropout训练的目标是最小化", "keywords": "是由, 参数, 定义的模型代价, 更正式地说, 假设一个掩码向量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d8ab4764-596f-4283-a593-02f6cebae7b3", "label": "摘要27", "info": "。这个期望包含多达指数级的项，但我们可以通过抽样  μ", "keywords": "但我们可以通过抽样, 这个期望包含多达指数级的项", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d46a9691-e917-4d50-9bb8-7b4cfa9bc590", "label": "摘要28", "info": "获得梯度的无偏估计。", "keywords": "获得梯度的无偏估计", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "faaaa789-3741-48a2-810e-202adf82e242", "label": "摘要29", "info": "Dropout训练与Bagging训练不太一样。在Bagging的情况下，所有模型都；是独立的。在Dropout的情况下，所有模型共享参数，其中每个模型继；承父神经网络参数的不同子集。参数共享使得在有限可用的内存下表示", "keywords": "训练不太一样, 承父神经网络参数的不同子集, 参数共享使得在有限可用的内存下表示, 其中每个模型继, 训练与", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f5db7ef3-94ce-407f-aa6c-e1bbf30c56d1", "label": "摘要30", "info": "Bagging集成必须根据所有成员的累积投票做一个预测。在这种背景；下，我们将这个过程称为推断  （inference）。目前为止，我们在介绍；Bagging和Dropout时没有要求模型具有明确的概率。现在，我们假定该", "keywords": "我们将这个过程称为推断, 目前为止, 我们在介绍, 集成必须根据所有成员的累积投票做一个预测, 我们假定该", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1eb5d11e-b37e-4836-983d-2a410b7fddc5", "label": "摘要31", "info": "在Dropout的情况下，通过掩码", "keywords": "的情况下, 通过掩码", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "56125b30-de30-482c-b22b-ea8546fcd416", "label": "摘要32", "info": "μ", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9e2e1162-dd50-4619-b721-22ea8fa4c739", "label": "摘要33", "info": "定义每个子模型的概率分布", "keywords": "定义每个子模型的概率分布", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6a267310-5da7-4b8b-99e1-1de9a63325f3", "label": "摘要34", "info": "。所有掩码的算术平均值由下式给出：", "keywords": "所有掩码的算术平均值由下式给出", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dba71d6d-c2c9-47a0-a38d-b7976ed655f2", "label": "摘要35", "info": "其中p( μ )是训练时采样 μ 的概率分布。", "keywords": "是训练时采样, 的概率分布, 其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0e9664e0-255a-44a7-bd8e-f61be5a5802f", "label": "摘要36", "info": "因为这个求和包含多达指数级的项，除非该模型的结构允许某种形式的；简化，否则是不可能计算的。目前为止，无法得知深度神经网络是否允；许某种可行的简化。相反，我们可以通过采样近似推断，即平均许多掩", "keywords": "无法得知深度神经网络是否允, 目前为止, 简化, 我们可以通过采样近似推断, 除非该模型的结构允许某种形式的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4b404369-44d5-4680-8731-a5712765633d", "label": "摘要37", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；然而，一个更好的方法能不错地近似整个集成的预测，且只需一个前向；传播的代价。要做到这一点，我们改用集成成员预测分布的几何平均而", "keywords": "一个更好的方法能不错地近似整个集成的预测, 传播的代价, 然而, 要做到这一点, 我们改用集成成员预测分布的几何平均而", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ed40b7b8-ca91-4f28-9ce4-372aec594cac", "label": "摘要38", "info": "多个概率分布的几何平均不能保证是一个概率分布。为了保证结果是一；个概率分布，我们要求没有子模型给某一事件分配概率0，并重新标准；化所得分布。通过几何平均直接定义的非标准化概率分布由下式给出：", "keywords": "并重新标准, 我们要求没有子模型给某一事件分配概率, 个概率分布, 通过几何平均直接定义的非标准化概率分布由下式给出, 化所得分布", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "35661162-8246-412d-aaf1-e37baf8646af", "label": "摘要39", "info": "其中d是可被丢弃的单元数。这里为简化介绍，我们使用均匀分布的  μ；，但非均匀分布也是可以的。为了作出预测，我们必须重新标准化集；成：", "keywords": "我们必须重新标准化集, 其中, 我们使用均匀分布的, 但非均匀分布也是可以的, 这里为简化介绍", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f7fd90cd-7b3f-43e5-bd63-a8d0ac0a017e", "label": "摘要40", "info": "涉及Dropout的一个重要观点（Hinton et al. ，2012c）是，我们可以通过；来近似p  ensemble  ：该模型具有所有单元，但我们；评估模型中", "keywords": "涉及, 但我们, 我们可以通过, 该模型具有所有单元, 的一个重要观点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "cf9c7bd2-ae03-4c1f-92fe-e8244f245285", "label": "摘要41", "info": "因为我们通常使用  的包含概率，权重比例规则一般相当于在训练结束", "keywords": "因为我们通常使用, 权重比例规则一般相当于在训练结束, 的包含概率", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "28f8bca5-fe82-4e33-9814-0f42e36d8850", "label": "摘要42", "info": "后将权重除2，然后像平常一样使用模型。实现相同结果的另一种方法；是在训练期间将单元的状态乘2。无论哪种方式，我们的目标是确保在；测试时一个单元的期望总输入与在训练时该单元的期望总输入是大致相", "keywords": "实现相同结果的另一种方法, 测试时一个单元的期望总输入与在训练时该单元的期望总输入是大致相, 然后像平常一样使用模型, 我们的目标是确保在, 后将权重除", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "556e64b8-34df-45e7-8ff9-5766524dc86f", "label": "摘要43", "info": "对许多不具有非线性隐藏单元的模型族而言，权重比例推断规则是精确；的。举个简单的例子，考虑softmax函数回归分类，其中由向量v  表示n；个输入变量：", "keywords": "表示, 个输入变量, 对许多不具有非线性隐藏单元的模型族而言, 函数回归分类, 权重比例推断规则是精确", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e616c255-4dac-4973-89e5-863e180cc7c0", "label": "摘要44", "info": "我们可以根据二值向量 d 逐元素的乘法将一类子模型进行索引：", "keywords": "逐元素的乘法将一类子模型进行索引, 我们可以根据二值向量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f84c5f7e-eb58-47f6-b3b9-9745c85dba51", "label": "摘要45", "info": "集成预测器被定义为重新标准化所有集成成员预测的几何平均：", "keywords": "集成预测器被定义为重新标准化所有集成成员预测的几何平均", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "00ea110c-4adf-4324-8c9f-893ce157c4af", "label": "摘要46", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d113f0c9-c3c8-4e5c-ac98-8534d50e664d", "label": "摘要47", "info": "为了证明权重比例推断规则是精确的，我们简化", "keywords": "我们简化, 为了证明权重比例推断规则是精确的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6f521af7-0741-4df3-8e4b-835bbce011e4", "label": "摘要48", "info": "：", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "605c6612-53f1-4bc7-8ded-7169c75b1a25", "label": "摘要49", "info": "由于  将被标准化，我们可以放心地忽略那些相对y不变的乘法：", "keywords": "不变的乘法, 我们可以放心地忽略那些相对, 将被标准化, 由于", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c5b21875-29cf-48cd-9e5e-a7f0c024bf70", "label": "摘要50", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；将其代入式（7.58），我们得到了一个权重为", "keywords": "我们得到了一个权重为, 将其代入式", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "26bc271e-0d2c-42f1-8603-69d3c600b089", "label": "摘要51", "info": "的softmax函数", "keywords": "函数", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "18bd6a9c-29a4-437c-be1f-49fa8504b370", "label": "摘要52", "info": "分类器。", "keywords": "分类器", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "a2efe8d7-c797-40fa-a349-7925589e5e5b", "label": "摘要53", "info": "权重比例推断规则在其他设定下也是精确的，包括条件正态输出的回归；网络以及那些隐藏层不包含非线性的深度网络。然而，权重比例推断规；则对具有非线性的深度模型仅仅是一个近似。虽然这个近似尚未有理论", "keywords": "虽然这个近似尚未有理论, 权重比例推断规则在其他设定下也是精确的, 然而, 网络以及那些隐藏层不包含非线性的深度网络, 权重比例推断规", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5dd3697b-3428-4839-ab8f-06afc838e2ad", "label": "摘要54", "info": "Srivastava et al. （2014）显示，Dropout比其他标准的计算开销小的正则；化方法（如权重衰减、过滤器范数约束和稀疏激活的正则化）更有效。；Dropout也可以与其他形式的正则化合并，得到进一步的提升。", "keywords": "化方法, 显示, 比其他标准的计算开销小的正则, 更有效, 过滤器范数约束和稀疏激活的正则化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6754cd71-607f-48f5-aaad-9006ab29ae69", "label": "摘要55", "info": "计算方便是Dropout的一个优点。训练过程中使用Dropout产生n个随机二；的计算复杂度。根据；进制数与状态相乘，每个样本每次更新只需", "keywords": "进制数与状态相乘, 根据, 训练过程中使用, 产生, 计算方便是", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e85e8c4e-fe17-4997-9cdc-5a040d033f07", "label": "摘要56", "info": "Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。几乎；在所有使用分布式表示且可以用随机梯度下降训练的模型上都表现很；好。包括前馈神经网络、概率模型，如受限玻尔兹曼机（Srivastava", "keywords": "几乎, 包括前馈神经网络, 如受限玻尔兹曼机, 的另一个显著优点是不怎么限制适用的模型或训练过程, 在所有使用分布式表示且可以用随机梯度下降训练的模型上都表现很", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d34c6969-cafb-4d1c-a078-ed53aadb1141", "label": "摘要57", "info": "虽然Dropout在特定模型上每一步的代价是微不足道的，但在一个完整；的系统上使用Dropout的代价可能非常显著。因为Dropout是一个正则化；技术，它减少了模型的有效容量。为了抵消这种影响，我们必须增大模", "keywords": "的系统上使用, 因为, 它减少了模型的有效容量, 为了抵消这种影响, 虽然", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "c85d7a42-15f7-4ca0-9710-f6d28826867b", "label": "摘要58", "info": "常大的数据集，正则化带来的泛化误差减少得很小。在这些情况下，使；用Dropout和更大模型的计算代价可能超过正则化带来的好处。", "keywords": "在这些情况下, 正则化带来的泛化误差减少得很小, 和更大模型的计算代价可能超过正则化带来的好处, 常大的数据集", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4073b33a-2891-47ec-8802-1ae7e7fc84c1", "label": "摘要59", "info": "只有极少的训练样本可用时，Dropout不会很有效。在只有不到5000的；样本的Alternative Splicing数据集上（Xiong et al. ，2011），贝叶斯神经；网络（Neal，1996）比Dropout表现得更好（Srivastava et al. ，2014）。", "keywords": "网络, 贝叶斯神经, 表现得更好, 样本的, 只有极少的训练样本可用时", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f7dc67fc-17c9-4a3b-b0c8-026cdff8828b", "label": "摘要60", "info": "Wager  et  al.  （2013）表明，当Dropout作用于线性回归时，相当于每个；输入特征具有不同权重衰减系数的L  2  权重衰减。每个特征的权重衰减；系数的大小是由其方差来确定的。其他线性模型也有类似的结果。而对", "keywords": "输入特征具有不同权重衰减系数的, 权重衰减, 而对, 相当于每个, 系数的大小是由其方差来确定的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "094fdf78-861f-408b-98e3-5429ceff72c6", "label": "摘要61", "info": "使用Dropout训练时的随机性不是这个方法成功的必要条件。它仅仅是；近似所有子模型总和的一个方法。Wang  and  Manning（2013）导出了近；似这种边缘分布的解析解。他们的近似被称为快速Dropout", "keywords": "近似所有子模型总和的一个方法, 它仅仅是, 训练时的随机性不是这个方法成功的必要条件, 似这种边缘分布的解析解, 使用", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "24a17ed3-258c-4860-85d4-277b095fbebe", "label": "摘要62", "info": "随机性对实现Dropout的正则化效果不是必要的，同时也不是充分的。；为了证明这一点，Warde-Farley  et  al.  （2014）使用一种被称为Dropout；Boosting  的方法设计了一个对照实验，具有与传统Dropout方法完全相", "keywords": "方法完全相, 的正则化效果不是必要的, 的方法设计了一个对照实验, 具有与传统, 使用一种被称为", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "dd882bb9-392c-4daa-9a3c-4ed8b1abdb57", "label": "摘要63", "info": "Dropout启发其他以随机方法训练指数量级的共享权重的集成。；DropConnect是Dropout的一个特殊情况，其中一个标量权重和单个隐藏；单元状态之间的每个乘积被认为是可以丢弃的一个单元（Wan  et  al.  ，", "keywords": "启发其他以随机方法训练指数量级的共享权重的集成, 单元状态之间的每个乘积被认为是可以丢弃的一个单元, 的一个特殊情况, 其中一个标量权重和单个隐藏", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "ef01b4c0-57a6-4410-88dc-44d06afa36f8", "label": "摘要64", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；2013）。随机池化是构造卷积神经网络集成的一种随机化池化的形式；（见第9.3节），其中每个卷积网络参与每个特征图的不同空间位置。", "keywords": "其中每个卷积网络参与每个特征图的不同空间位置, 随机池化是构造卷积神经网络集成的一种随机化池化的形式, 见第", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7e668013-fff0-460c-82ff-408120184c94", "label": "摘要65", "info": "一个关于Dropout的重要见解是，通过随机行为训练网络并平均多个随；机决定进行预测，实现了一种参数共享的Bagging形式。早些时候，我；们将Dropout描述为通过包括或排除单元形成模型集成的Bagging。然", "keywords": "一个关于, 形式, 的重要见解是, 机决定进行预测, 实现了一种参数共享的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "999726e3-5ac0-4e2c-a015-198dc05abc82", "label": "摘要66", "info": "推断规则。", "keywords": "推断规则", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "38be9613-7154-4eb0-91b2-e493c2e9ab8f", "label": "摘要67", "info": "目前为止，我们将Dropout介绍为一种纯粹高效近似Bagging的方法。然；而，还有比这更进一步的Dropout观点。Dropout不仅仅是训练一个；Bagging的集成模型，而且是共享隐藏单元的集成模型。这意味着无论", "keywords": "这意味着无论, 我们将, 的集成模型, 目前为止, 观点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "99a02722-b2fb-4755-8800-337a68c872e4", "label": "摘要68", "info": "Dropout强大的大部分原因来自施加到隐藏单元的掩码噪声，了解这一；事实是重要的。这可以看作对输入内容的信息高度智能化、自适应破坏；的一种形式，而不是对输入原始值的破坏。例如，如果模型学得通过鼻", "keywords": "自适应破坏, 的一种形式, 如果模型学得通过鼻, 了解这一, 这可以看作对输入内容的信息高度智能化", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "5274ea74-8ed9-42fc-8374-70ac7f2c3ea2", "label": "摘要69", "info": "型必须学习另一种h i ，要么是鼻子存在的冗余编码，要么是像嘴这样的；脸部的另一特征。传统的噪声注入技术，在输入端加非结构化的噪声不；能够随机地从脸部图像中抹去关于鼻子的信息，除非噪声的幅度大到几", "keywords": "传统的噪声注入技术, 型必须学习另一种, 要么是像嘴这样的, 在输入端加非结构化的噪声不, 能够随机地从脸部图像中抹去关于鼻子的信息", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8269631f-94c4-4f32-9ccf-abb35b3410e9", "label": "摘要70", "info": "Dropout的另一个重要方面是噪声是乘性的。如果是固定规模的加性噪；声，那么加了噪声   的整流线性隐藏单元可以简单地学会使h  i  变得很；大（使增加的噪声   变得不显著）。乘性噪声不允许这样病态地解决", "keywords": "的另一个重要方面是噪声是乘性的, 使增加的噪声, 变得不显著, 如果是固定规模的加性噪, 的整流线性隐藏单元可以简单地学会使", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7fb911b2-2391-42e8-b77b-18a3f6918a51", "label": "摘要71", "info": "另一种深度学习算法——批标准化，在训练时向隐藏单元引入加性和乘；性噪声重新参数化模型。批标准化的主要目的是改善优化，但噪声具有；正则化的效果，有时没必要再使用Dropout。批标准化将会在第8.7.1节", "keywords": "但噪声具有, 性噪声重新参数化模型, 在训练时向隐藏单元引入加性和乘, 批标准化将会在第, 正则化的效果", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "204d0357-586a-4366-bbb8-ce554617c42a", "label": "7.13：对抗训练", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "d82e258b-e40c-41f4-9ee0-825a6a4b6fd7", "label": "摘要1", "info": "在许多情况下，神经网络在独立同分布的测试集上进行评估已经达到了；人类表现。因此，我们自然要怀疑这些模型在这些任务上是否获得了真；正的人类层次的理解。为了探索网络对底层任务的理解层次，我们可以", "keywords": "我们可以, 人类表现, 在许多情况下, 因此, 神经网络在独立同分布的测试集上进行评估已经达到了", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "1bad68ce-4f0d-4433-bd24-7329c489d58b", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图7.8　在ImageNet上应用GoogLeNet（Szegedy et al. ，2014a）的对抗样本生成的演示。通过添；加一个不可察觉的小向量（其中元素等于代价函数相对于输入的梯度元素的符号），我们可以", "keywords": "上应用, 我们可以, 通过添, 的对抗样本生成的演示, 加一个不可察觉的小向量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "333e1ba3-80b0-4ca5-978e-756e9735b51e", "label": "摘要3", "info": "对抗样本在很多领域有很多影响，例如计算机安全，这超出了本章的范；围。然而，它们在正则化的背景下很有意思，因为我们可以通过对抗训；练 （adversarial  training）减少原有独立同分布的测试集的错误率——在", "keywords": "它们在正则化的背景下很有意思, 例如计算机安全, 然而, 减少原有独立同分布的测试集的错误率, 因为我们可以通过对抗训", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "114698f8-1256-48b3-bab3-c718c4b5419d", "label": "摘要4", "info": "Goodfellow et  al.  （2014b）表明，这些对抗样本的主要原因之一是过度；线性。神经网络主要是基于线性块构建的。因此在一些实验中，它们实；现的整体函数被证明是高度线性的。这些线性函数很容易优化。不幸的", "keywords": "神经网络主要是基于线性块构建的, 因此在一些实验中, 这些线性函数很容易优化, 它们实, 不幸的", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2a4a4482-006e-435d-ac0a-ef152af40e87", "label": "摘要5", "info": "对抗训练有助于体现积极正则化与大型函数族结合的力量。纯粹的线性；模型，如逻辑回归，由于它们被限制为线性而无法抵抗对抗样本。神经；网络能够将函数从接近线性转化为局部近似恒定，从而可以灵活地捕获", "keywords": "纯粹的线性, 神经, 如逻辑回归, 模型, 对抗训练有助于体现积极正则化与大型函数族结合的力量", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2b4e250e-93b6-48c3-8d49-9085a38ae1b6", "label": "摘要6", "info": "对抗样本也提供了一种实现半监督学习的方法。在与数据集中的标签不；相关联的点 x 处，模型本身为其分配一些标签  。模型的标记  未必是；真正的标签，但如果模型是高品质的，那么   提供正确标签的可能性很", "keywords": "未必是, 但如果模型是高品质的, 模型的标记, 对抗样本也提供了一种实现半监督学习的方法, 那么", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "d124111e-8fc5-444a-8be0-e909a1e41acd", "label": "7.14：切面距离、正切传播和流形正切分", "level": 2, "group": "chapter-7", "type": "子章節"}, {"id": "3f520135-6a5e-4918-a208-5e48033af047", "label": "摘要1", "info": "如第5.11.3节所述，许多机器学习通过假设数据位于低维流形附近来克；服维数灾难。", "keywords": "服维数灾难, 如第, 节所述, 许多机器学习通过假设数据位于低维流形附近来克", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4a5b6fdd-0156-41e7-893c-d1c01bc0f7a9", "label": "摘要2", "info": "distance）算法；一个利用流形假设的早期尝试是切面距离  （tangent；（Simard  et  al.  ，1993，1998）。它是一种非参数的最近邻算法，其中", "keywords": "它是一种非参数的最近邻算法, 一个利用流形假设的早期尝试是切面距离, 算法, 其中", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "f3e38609-29b3-4ef4-a7f7-5d2c2ba85374", "label": "摘要3", "info": "受相关启发，正切传播  （tangent  prop）算法（Simard  et  al.  ，1992）；（见图7.9）训练带有额外惩罚的神经网络分类器，使神经网络的每个；输出f( x )对已知的变化因素是局部不变的。这些变化因素对应于沿着的", "keywords": "这些变化因素对应于沿着的, 算法, 受相关启发, 对已知的变化因素是局部不变的, 见图", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "8666aa77-3e7b-4477-98cb-129370d3a136", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；与已知流形的切向  ν  (i)  正交，或者等价地通过正则化惩罚Ω", "keywords": "正交, 或者等价地通过正则化惩罚, 与已知流形的切向", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b5903855-961d-40f1-a295-017b928f08b3", "label": "摘要5", "info": "使f在 x 的 ν (i) 方向的导数较小：", "keywords": "方向的导数较小", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "7a088862-24c0-4e92-ac9c-ff7164388c7a", "label": "摘要6", "info": "这个正则化项当然可以通过适当的超参数缩放，并且对于大多数神经网；络，我们需要对许多输出求和（此处为了描述简单，f(；)为唯一输", "keywords": "我们需要对许多输出求和, 并且对于大多数神经网, 此处为了描述简单, 这个正则化项当然可以通过适当的超参数缩放, 为唯一输", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e15a6fce-ad42-4a05-bac7-0218d2cbaef5", "label": "摘要7", "info": "x", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "0efe37bc-cff7-4cbe-8a18-2a08fb7bbdcd", "label": "摘要8", "info": "图7.9　正切传播算法（Simard et al. ，1992）和流形正切分类器主要思想的示意图（Rifai et al.；，2011c），它们都正则化分类器的输出函数f( x )。每条曲线表示不同类别的流形，这里表示嵌；入二维空间中的一维流形。在一条曲线上，我们选择单个点并绘制一个与类别流形（平行并接", "keywords": "和流形正切分类器主要思想的示意图, 正切传播算法, 每条曲线表示不同类别的流形, 在一条曲线上, 我们选择单个点并绘制一个与类别流形", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6c7c35c4-54c5-45be-9ec6-55323089cdf9", "label": "摘要9", "info": "正切传播与数据集增强密切相关。在这两种情况下，该算法的用户通过", "keywords": "正切传播与数据集增强密切相关, 该算法的用户通过, 在这两种情况下", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "b9ff8809-30a3-4f87-82af-d7c374d7e911", "label": "摘要10", "info": "指定一组应当不会改变网络输出的转换，将其先验知识编码至算法中。；不同的是在数据集增强的情况下，网络显式地训练正确分类这些施加大；量变换后产生的不同输入。正切传播不需要显式访问一个新的输入点。", "keywords": "网络显式地训练正确分类这些施加大, 不同的是在数据集增强的情况下, 将其先验知识编码至算法中, 量变换后产生的不同输入, 正切传播不需要显式访问一个新的输入点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "6952fe85-7142-4d83-a646-ac505c6446a5", "label": "摘要11", "info": "正切传播也和双反向传播（Drucker  and  LeCun，1992）以及对抗训练；（Szegedy et al. ，2014b；Goodfellow et al. ，2014b）有关联。双反向传；播正则化使Jacobian矩阵偏小，而对抗训练找到原输入附近的点，训练", "keywords": "双反向传, 训练, 有关联, 以及对抗训练, 而对抗训练找到原输入附近的点", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "9962c3ac-fb06-4fed-995a-6789a998d4ac", "label": "摘要12", "info": "流形正切分类器（Rifai et al. ，2011d）无须知道切线向量的先验。我们；将在第14章看到，自编码器可以估算流形的切向量。流形正切分类器使；用这种技术来避免用户指定切向量。如图14.10所示，这些估计的切向", "keywords": "所示, 流形正切分类器使, 流形正切分类器, 我们, 章看到", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "44a034a3-479c-4625-ad17-ef3bea8c9ab1", "label": "摘要13", "info": "在本章中，我们已经描述了大多数用于正则化神经网络的通用策略。正；则化是机器学习的中心主题，因此我们将不时在其余各章中重新回顾。；机器学习的另一个中心主题是优化，我们将在下一章描述。", "keywords": "机器学习的另一个中心主题是优化, 则化是机器学习的中心主题, 我们将在下一章描述, 因此我们将不时在其余各章中重新回顾, 我们已经描述了大多数用于正则化神经网络的通用策略", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "e552e34e-ef76-466f-9168-d4ea8a4b1b99", "label": "摘要14", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "154469c4-319e-41e4-9b9c-dd4e3ef80851", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；(1)    更一般地，我们可以将参数正则化为接近空间中的任意特定点，令人惊讶的是这样也仍有；正则化效果，但是特定点越接近真实值结果越好。当我们不知道正确的值应该是正还是负时，", "keywords": "更一般地, 正则化效果, 令人惊讶的是这样也仍有, 当我们不知道正确的值应该是正还是负时, 但是特定点越接近真实值结果越好", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4976a03b-aa38-422d-8f26-1cf22c166ee0", "label": "摘要16", "info": "(2)  如同L 2 正则化，我们能将参数正则化到其他非零值 w (o) 。在这种情况下，L 1 正则化将会；引入不同的项", "keywords": "引入不同的项, 正则化将会, 正则化, 如同, 我们能将参数正则化到其他非零值", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "2017b0d6-e98a-4761-a558-4d1e70d21672", "label": "摘要17", "info": "(3)    对于神经网络，我们需要打破隐藏单元间的对称平衡，因此不能将所有参数都初始化为  0；（如第6.2节所讨论的）。然而，对于其他任何初始值 w (0) 该论证都成立。", "keywords": "然而, 因此不能将所有参数都初始化为, 如第, 该论证都成立, 对于其他任何初始值", "level": 3, "group": "chapter-7", "type": "段落"}, {"id": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "label": "第8章：深度模型中的优化", "level": 1, "group": "chapter-8", "type": "章節"}, {"id": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6", "label": "7.14：切面距离、正切传播和流形正切分", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "8a0bcb2a-5383-4be2-979f-947225e32834", "label": "摘要1", "info": "深度学习算法在许多情况下都涉及优化。例如，模型中的进行推断（如；PCA）涉及求解优化问题。我们经常使用解析优化去证明或设计算法。；在深度学习涉及的诸多优化问题中，最难的是神经网络训练。甚至是用", "keywords": "我们经常使用解析优化去证明或设计算法, 最难的是神经网络训练, 涉及求解优化问题, 例如, 在深度学习涉及的诸多优化问题中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c9d3680b-994f-47a4-a8e2-8ad9e9292916", "label": "摘要2", "info": "如果你不熟悉基于梯度优化的基本原则，我们建议回顾第4章。该章简；要概述了一般的数值优化。", "keywords": "如果你不熟悉基于梯度优化的基本原则, 该章简, 要概述了一般的数值优化, 我们建议回顾第", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fd31deb5-270d-4722-8a83-132c2a791929", "label": "摘要3", "info": "本章主要关注这一类特定的优化问题：寻找神经网络上的一组参数 θ ，；它能显著地降低代价函数J（  θ  ），该代价函数通常包括整个训练集上；的性能评估和额外的正则化项。", "keywords": "它能显著地降低代价函数, 本章主要关注这一类特定的优化问题, 该代价函数通常包括整个训练集上, 寻找神经网络上的一组参数, 的性能评估和额外的正则化项", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "aee90122-d451-4f31-a0bb-650fcd8fc6b9", "label": "摘要4", "info": "首先，我们会介绍在机器学习任务中作为训练算法使用的优化与纯优化；有哪些不同。其次，我们会介绍导致神经网络优化困难的几个具体挑；战。再次，我们会介绍几个实用算法，包括优化算法本身和初始化参数", "keywords": "其次, 我们会介绍在机器学习任务中作为训练算法使用的优化与纯优化, 我们会介绍导致神经网络优化困难的几个具体挑, 再次, 有哪些不同", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "label": "8.1：学习和纯优化有什么不同", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "bdee96bb-c9a6-4323-90a7-b684250dac33", "label": "摘要1", "info": "8.1.1　经验风险最小化", "keywords": "经验风险最小化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9d2612f6-a590-4db0-b462-9b1da39913d0", "label": "摘要2", "info": "8.1.2　代理损失函数和提前终止", "keywords": "代理损失函数和提前终止", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "80c59ec5-ce1d-4fe5-abc7-47add5ff515f", "label": "摘要3", "info": "8.1.3　批量算法和小批量算法", "keywords": "批量算法和小批量算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7193ba2b-7c19-4fbe-b8b3-e7af3089807e", "label": "摘要4", "info": "用于深度模型训练的优化算法与传统的优化算法在几个方面有所不同。；机器学习通常是间接作用的。在大多数机器学习问题中，我们关注某些；性能度量P，其定义于测试集上并且可能是不可解的。因此，我们只是", "keywords": "机器学习通常是间接作用的, 在大多数机器学习问题中, 性能度量, 其定义于测试集上并且可能是不可解的, 因此", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cb468fba-0692-4833-8aab-2733b501e2e2", "label": "摘要5", "info": "通常，代价函数可写为训练集上的平均，如", "keywords": "通常, 代价函数可写为训练集上的平均", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a49e6b9d-6082-4f32-b7f9-1c769c4d0547", "label": "摘要6", "info": "其中L是每个样本的损失函数，", "keywords": "是每个样本的损失函数, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c5c077fc-1fad-4c44-9af9-fe433f1cd8eb", "label": "摘要7", "info": "是输入  x  时所预测的输出，；是经验分布。监督学习中，y是目标输出。在本章中，我们会介；绍不带正则化的无监督学习，L的变量是", "keywords": "的变量是, 我们会介, 监督学习中, 时所预测的输出, 绍不带正则化的无监督学习", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e3011207-4833-4e6c-ab30-58ba17cfafeb", "label": "摘要8", "info": "式（8.1）定义了训练集上的目标函数。通常，我们更希望最小化取自；数据生成分布p data 的期望，而不仅仅是有限训练集上的对应目标函数：", "keywords": "定义了训练集上的目标函数, 通常, 我们更希望最小化取自, 数据生成分布, 而不仅仅是有限训练集上的对应目标函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cc0d1ad0-a1e3-497d-8efc-143f1c924e98", "label": "摘要9", "info": "8.1.1　经验风险最小化", "keywords": "经验风险最小化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f62ac043-b5aa-4bb3-920a-bb8505eef7fb", "label": "摘要10", "info": "机器学习算法的目标是降低式（8.2）所示的期望泛化误差。这个数据；量被称为风险  （risk）。在这里，我们强调该期望取自真实的潜在分布；p data 。如果我们知道了真实分布p  data ( x ,y)，那么最小化风险变成了一", "keywords": "在这里, 那么最小化风险变成了一, 这个数据, 机器学习算法的目标是降低式, 所示的期望泛化误差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a9cf1850-e570-49b4-9ae2-4240b1b0cbda", "label": "摘要11", "info": "将机器学习问题转化回一个优化问题的最简单方法是最小化训练集上的；替代真实分布p(  x；期望损失。这意味着用训练集上的经验分布", "keywords": "期望损失, 替代真实分布, 这意味着用训练集上的经验分布, 将机器学习问题转化回一个优化问题的最简单方法是最小化训练集上的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bc7ec3fa-a78e-4023-9cc6-2ddf0056da66", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其中m表示训练样本的数目。", "keywords": "表示训练样本的数目, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c3b0302c-d6ef-4b05-8d8e-cd50d104cb6e", "label": "摘要13", "info": "基于最小化这种平均训练误差的训练过程被称为经验风险最小化；（empirical risk minimization）在这种情况下，机器学习仍然和传统的直；接优化很相似。我们并不直接最优化风险，而是最优化经验风险，希望", "keywords": "机器学习仍然和传统的直, 而是最优化经验风险, 在这种情况下, 接优化很相似, 基于最小化这种平均训练误差的训练过程被称为经验风险最小化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a068dc00-e996-4a74-a671-f5832c590672", "label": "摘要14", "info": "然而，经验风险最小化很容易导致过拟合。高容量的模型会简单地记住；训练集。在很多情况下，经验风险最小化并非真的可行。最有效的现代；优化算法是基于梯度下降的，但是很多有用的损失函数，如0-1损失，", "keywords": "训练集, 经验风险最小化很容易导致过拟合, 最有效的现代, 然而, 经验风险最小化并非真的可行", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4a4e4565-3945-4e37-a6dd-f40e3bb453cd", "label": "摘要15", "info": "8.1.2　代理损失函数和提前终止", "keywords": "代理损失函数和提前终止", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3e71427a-281c-4dbc-9e9a-22e609085464", "label": "摘要16", "info": "有时，我们真正关心的损失函数（比如分类误差）并不能被高效地优；化。例如，即使对于线性分类器而言，精确地最小化0-1损失通常是不；可解的（复杂度是输入维数的指数级别）（Marcotte", "keywords": "比如分类误差, 损失通常是不, 有时, 例如, 我们真正关心的损失函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "57fb3785-29e1-46d6-a4d0-059d9d18bf5e", "label": "摘要17", "info": "and", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "29fb5858-8eaa-4b91-8ea7-e0eb92f7ced1", "label": "摘要18", "info": "在某些情况下，代理损失函数比原函数学到的更多。例如，使用对数似；然替代函数时，在训练集上的0-1损失达到0之后，测试集上的0-1损失还；能持续下降很长一段时间。这是因为即使0-1损失期望是零时，我们还", "keywords": "使用对数似, 之后, 我们还, 然替代函数时, 在训练集上的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "be1d1758-162f-47c7-8917-20a42e017ab2", "label": "摘要19", "info": "一般的优化和我们用于训练算法的优化有一个重要不同：训练算法通常；不会停止在局部极小点。反之，机器学习通常优化代理损失函数，但是", "keywords": "训练算法通常, 机器学习通常优化代理损失函数, 但是, 不会停止在局部极小点, 一般的优化和我们用于训练算法的优化有一个重要不同", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fc4ba4f4-720e-45e5-a710-2f2bdf8c17bc", "label": "摘要20", "info": "在基于提前终止（第7.8节）的收敛条件满足时停止。通常，提前终止；使用真实潜在损失函数，如验证集上的0-1损失，并设计为在过拟合发；生之前终止。与纯优化不同的是，提前终止时代理损失函数仍然有较大", "keywords": "生之前终止, 通常, 提前终止时代理损失函数仍然有较大, 在基于提前终止, 的收敛条件满足时停止", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4f41c90d-391a-4853-85f7-31410d26a170", "label": "摘要21", "info": "8.1.3　批量算法和小批量算法", "keywords": "批量算法和小批量算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e41f1425-88b7-4af2-8c62-da4b4888f676", "label": "摘要22", "info": "机器学习算法和一般优化算法不同的一点是，机器学习算法的目标函数；通常可以分解为训练样本上的求和。机器学习中的优化算法在计算参数；的每一次更新时通常仅使用整个代价函数中一部分项来估计代价函数的", "keywords": "通常可以分解为训练样本上的求和, 机器学习中的优化算法在计算参数, 机器学习算法和一般优化算法不同的一点是, 机器学习算法的目标函数, 的每一次更新时通常仅使用整个代价函数中一部分项来估计代价函数的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5eddb272-0bde-4a59-9677-5cbda59d61e6", "label": "摘要23", "info": "例如，最大似然估计问题可以在对数空间中分解成各个样本的总和：", "keywords": "例如, 最大似然估计问题可以在对数空间中分解成各个样本的总和", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d3d00c33-a7b1-41d1-bde7-29ea529cee63", "label": "摘要24", "info": "最大化这个总和等价于最大化训练集在经验分布上的期望：", "keywords": "最大化这个总和等价于最大化训练集在经验分布上的期望", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cd4df32d-d698-44ae-bcf4-b9b97f226637", "label": "摘要25", "info": "优化算法用到的目标函数J中的大多数属性也是训练集上的期望。例；如，最常用的属性是梯度：", "keywords": "最常用的属性是梯度, 中的大多数属性也是训练集上的期望, 优化算法用到的目标函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f0b6ffe8-b1c6-4ff0-9335-89eca046138b", "label": "摘要26", "info": "准确计算这个期望的计算代价非常大，因为我们需要在整个数据集上的；每个样本上评估模型。在实践中，我们可以从数据集中随机采样少量的；样本，然后计算这些样本上的平均值。", "keywords": "我们可以从数据集中随机采样少量的, 样本, 准确计算这个期望的计算代价非常大, 在实践中, 然后计算这些样本上的平均值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "59997aa1-eb49-419d-955e-2f87664673d6", "label": "摘要27", "info": "，其中σ是；回想一下，n个样本均值的标准差（式（5.46））是；样本值真实的标准差。分母  表明使用更多样本来估计梯度的方法的", "keywords": "分母, 表明使用更多样本来估计梯度的方法的, 其中, 样本值真实的标准差, 个样本均值的标准差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2fa9a702-d62b-40b4-92bd-6e49a4d1a2a3", "label": "摘要28", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；另一个促使我们从小数目样本中获得梯度的统计估计的动机是训练集的；冗余。在最坏的情况下，训练集中所有的m个样本都是彼此相同的拷", "keywords": "训练集中所有的, 在最坏的情况下, 另一个促使我们从小数目样本中获得梯度的统计估计的动机是训练集的, 个样本都是彼此相同的拷, 冗余", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "08a5a657-d17a-4e57-bbc8-9f139f5ecf47", "label": "摘要29", "info": "使用整个训练集的优化算法被称为批量；（deterministic）梯度算法，因为它们会在一个大批量中同时处理所有；样本。这个术语可能有点令人困惑，因为这个词“批量”也经常被用来描", "keywords": "因为这个词, 样本, 梯度算法, 这个术语可能有点令人困惑, 使用整个训练集的优化算法被称为批量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d1482079-31a1-443b-b6c3-d3b428333efe", "label": "摘要30", "info": "（batch）或确定性", "keywords": "或确定性", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "69da2004-2eb9-46f4-820e-41811db4aee5", "label": "摘要31", "info": "每次只使用单个样本的优化算法有时被称为随机  （stochastic）或者在；线  （online）算法。术语“在线”通常是指从连续产生样本的数据流中抽；取样本的情况，而不是从一个固定大小的训练集中遍历多次采样的情", "keywords": "或者在, 算法, 在线, 术语, 每次只使用单个样本的优化算法有时被称为随机", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c941cf1c-62dd-4e37-b854-feaad1fcc00f", "label": "摘要32", "info": "大多数用于深度学习的算法介于以上两者之间，使用一个以上而又不是；全部的训练样本。传统上，这些会被称为小批量  （minibatch）或小批；量随机  （minibatch  stochastic）方法，现在通常将它们简单地称为随机", "keywords": "量随机, 大多数用于深度学习的算法介于以上两者之间, 或小批, 现在通常将它们简单地称为随机, 使用一个以上而又不是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a4deda0a-2a9a-4952-a1f3-d81841ac4a67", "label": "摘要33", "info": "随机方法的典型示例是随机梯度下降，这将在第8.3.1节中详细描述。", "keywords": "节中详细描述, 这将在第, 随机方法的典型示例是随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bed08686-3dd9-45f1-a5e2-0dec8af94646", "label": "摘要34", "info": "小批量的大小通常由以下几个因素决定：", "keywords": "小批量的大小通常由以下几个因素决定", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1e7d730e-4f99-499a-b754-582fc6d03e6a", "label": "摘要35", "info": "更大的批量会计算更精确的梯度估计，但是回报却是小于线性的。；极小批量通常难以充分利用多核架构。这促使我们使用一些绝对最；小批量，低于这个值的小批量处理不会减少计算时间。", "keywords": "更大的批量会计算更精确的梯度估计, 这促使我们使用一些绝对最, 极小批量通常难以充分利用多核架构, 低于这个值的小批量处理不会减少计算时间, 但是回报却是小于线性的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bd61c1f2-4caa-494c-91e2-7c3c0a7917c5", "label": "摘要36", "info": "可能是由于小批量在学习过程中加入了噪声，它们会有一些正则化；效果（Wilson  and  Martinez，2003）。泛化误差通常在批量大小为1；时最好。因为梯度估计的高方差，小批量训练需要较小的学习率以", "keywords": "效果, 因为梯度估计的高方差, 泛化误差通常在批量大小为, 小批量训练需要较小的学习率以, 可能是由于小批量在学习过程中加入了噪声", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "03facb8b-4e0f-40a5-a6ec-7d2c9920bac9", "label": "摘要37", "info": "不同的算法使用不同的方法从小批量中获取不同的信息。有些算法对采；样误差比其他算法更敏感，这通常有两个可能原因。一个是它们使用了；很难在少量样本上精确估计的信息，另一个是它们以放大采样误差的方", "keywords": "不同的算法使用不同的方法从小批量中获取不同的信息, 很难在少量样本上精确估计的信息, 一个是它们使用了, 另一个是它们以放大采样误差的方, 有些算法对采", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "dee92c2a-d5f8-47bc-8c5f-998f49524d4f", "label": "摘要38", "info": "小批量是随机抽取的这点也很重要。从一组样本中计算出梯度期望的无；偏估计要求这些样本是独立的。我们也希望两个连续的梯度估计是互相；独立的，因此两个连续的小批量样本也应该是彼此独立的。很多现实的", "keywords": "很多现实的, 从一组样本中计算出梯度期望的无, 我们也希望两个连续的梯度估计是互相, 因此两个连续的小批量样本也应该是彼此独立的, 偏估计要求这些样本是独立的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a247d713-db6a-482d-9967-494875a0f3b2", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；很多机器学习上的优化问题都可以分解成并行地计算不同样本上单独的；更新。换言之，我们在计算小批量样本 X 上最小化J ( X )的更新时，同", "keywords": "我们在计算小批量样本, 更新, 换言之, 上最小化, 很多机器学习上的优化问题都可以分解成并行地计算不同样本上单独的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "806a9a23-37af-4aef-a036-c1e453254ffe", "label": "摘要40", "info": "小批量随机梯度下降的一个有趣动机是，只要没有重复使用样本，它将；遵循着真实泛化误差（式（8.2））的梯度。很多小批量随机梯度下降；方法的实现都会打乱数据顺序一次，然后多次遍历数据来更新参数。第", "keywords": "它将, 然后多次遍历数据来更新参数, 很多小批量随机梯度下降, 小批量随机梯度下降的一个有趣动机是, 的梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "50a67f82-68c7-40ba-bcb2-97aec8753596", "label": "摘要41", "info": "我们不难从在线学习的情况中看出随机梯度下降最小化泛化误差的原；因。这时样本或者小批量都是从数据流  （stream）中抽取出来的。换言；之，学习器好像是一个每次看到新样本的人，每个样本（  x  ,y）都来自", "keywords": "每个样本, 这时样本或者小批量都是从数据流, 学习器好像是一个每次看到新样本的人, 我们不难从在线学习的情况中看出随机梯度下降最小化泛化误差的原, 中抽取出来的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3b4e0c0b-39b2-4a42-a95a-44f6eab7cde8", "label": "摘要42", "info": "在  x  和y是离散时，以上的等价性很容易得到。在这种情况下，泛化误；差（式（8.2））可以表示为", "keywords": "是离散时, 泛化误, 在这种情况下, 以上的等价性很容易得到, 可以表示为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "22fc5fd6-3ddd-4654-a201-bedb5e27e158", "label": "摘要43", "info": "上式的准确梯度为", "keywords": "上式的准确梯度为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "85bc6fa3-acab-48e3-bc03-318e3feeadb8", "label": "摘要44", "info": "在式（8.5）和式（8.6）中，我们已经在对数似然中看到了相同的结；果，现在我们发现这一点在包括似然的其他函数L上也是成立的。在一；些关于p  data  和L的温和假设下，在  x  和y是连续时也能得到类似的结", "keywords": "上也是成立的, 的温和假设下, 在式, 我们已经在对数似然中看到了相同的结, 在一", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8ed852c1-e2a2-4254-8486-be191b9d4f9b", "label": "摘要45", "info": "因此，我们可以从数据生成分布p", "keywords": "我们可以从数据生成分布, 因此", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8bfdb0f4-9ab4-4a9a-8e81-24de295ada80", "label": "摘要46", "info": "抽取小批量样本；以及对应的目标y  (i)  ，然后计算该小批量上损失函", "keywords": "抽取小批量样本, 然后计算该小批量上损失函, 以及对应的目标", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ba2e7fe5-9772-4ada-94a7-1a5f1b64906c", "label": "摘要47", "info": "data", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "54d9b6f8-82a3-4dde-9642-0445318f045c", "label": "摘要48", "info": "数关于对应参数的梯度", "keywords": "数关于对应参数的梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "600d1ba8-f7ae-449d-88bb-44a71bc42e04", "label": "摘要49", "info": "以此获得泛化误差准确梯度的无偏估计。最后，在泛化误差上使用SGD；方法在方向  上更新 θ 。", "keywords": "方法在方向, 在泛化误差上使用, 上更新, 以此获得泛化误差准确梯度的无偏估计, 最后", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5de83757-7011-40d2-a69a-a00b99834d8f", "label": "摘要50", "info": "当然，这个解释只能用于样本没有重复使用的情况。然而，除非训练集；特别大，通常最好是多次遍历训练集。当多次遍历数据集更新时，只有；第一遍满足泛化误差梯度的无偏估计。但是，额外的遍历更新当然会由", "keywords": "当多次遍历数据集更新时, 除非训练集, 但是, 然而, 这个解释只能用于样本没有重复使用的情况", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0a2bc486-b97e-48b0-aa97-f478ca50c64d", "label": "摘要51", "info": "随着数据集的规模迅速增长，超越了计算能力的增速，机器学习应用每；个样本只使用一次的情况变得越来越常见，甚至是不完整地使用训练；集。在使用一个非常大的训练集时，过拟合不再是问题，而欠拟合和计", "keywords": "过拟合不再是问题, 个样本只使用一次的情况变得越来越常见, 在使用一个非常大的训练集时, 甚至是不完整地使用训练, 随着数据集的规模迅速增长", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "036f3910-66e4-4c21-bf7d-976c0d00e3d5", "label": "摘要52", "info": "8.1.1　经验风险最小化", "keywords": "经验风险最小化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "21812f1f-a517-46c8-a9ba-31ec931e0d42", "label": "摘要53", "info": "8.1.2　代理损失函数和提；前终止", "keywords": "代理损失函数和提, 前终止", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f1bd5468-25e2-47fa-a2e7-256b94d3b464", "label": "摘要54", "info": "8.1.3　批量算法和小批量；算法", "keywords": "批量算法和小批量, 算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "label": "8.2：神经网络优化中的挑战", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "d4a7a7cd-a9b8-419f-8f2f-c775a3de7054", "label": "摘要1", "info": "8.2.1　病态", "keywords": "病态", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8713d692-bba6-4e15-a4cf-6cf5043b400f", "label": "摘要2", "info": "8.2.2　局部极小值", "keywords": "局部极小值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "861e9891-9af3-4f72-bdb4-6aa94425bf7b", "label": "摘要3", "info": "8.2.3　高原、鞍点和其他平坦区域", "keywords": "鞍点和其他平坦区域, 高原", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4de6fd18-0c70-488f-96f8-3a21950425f1", "label": "摘要4", "info": "8.2.4　悬崖和梯度爆炸", "keywords": "悬崖和梯度爆炸", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0e68d101-a5bc-4a56-bf54-7867b1ea9ff1", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；8.2.5　长期依赖", "keywords": "长期依赖", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4fac2bf1-49d2-4091-ae56-908b691d11fa", "label": "摘要6", "info": "8.2.6　非精确梯度", "keywords": "非精确梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cd7eea27-ad1d-44b4-bebd-44c225bb0955", "label": "摘要7", "info": "8.2.7　局部和全局结构间的弱对应", "keywords": "局部和全局结构间的弱对应", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b3108fce-dbda-4554-9cb8-d331da1f7e54", "label": "摘要8", "info": "8.2.8　优化的理论限制", "keywords": "优化的理论限制", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f3cacd97-1405-403a-be6b-c5c13ea93f18", "label": "摘要9", "info": "优化通常是一个极其困难的任务。传统的机器学习会小心设计目标函数；和约束，以确保优化问题是凸的，从而避免一般优化问题的复杂度。在；训练神经网络时，我们肯定会遇到一般的非凸情况。即使是凸优化，也", "keywords": "优化通常是一个极其困难的任务, 训练神经网络时, 我们肯定会遇到一般的非凸情况, 即使是凸优化, 从而避免一般优化问题的复杂度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "060fed1c-94c7-4a66-8083-daede47421fd", "label": "摘要10", "info": "8.2.1　病态", "keywords": "病态", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b00dba53-09ea-4a13-a37b-666bafa029e0", "label": "摘要11", "info": "在优化凸函数时，会遇到一些挑战。这其中最突出的是Hessian矩阵  H；的病态。这是数值优化、凸优化或其他形式的优化中普遍存在的问题，；更多细节请回顾第4.3.1节。", "keywords": "矩阵, 会遇到一些挑战, 凸优化或其他形式的优化中普遍存在的问题, 更多细节请回顾第, 这是数值优化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7fe9f75d-6dd8-425e-88a5-51c019920434", "label": "摘要12", "info": "病态问题一般被认为存在于神经网络训练过程中。病态体现在随机梯度", "keywords": "病态体现在随机梯度, 病态问题一般被认为存在于神经网络训练过程中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7cb08905-ca5e-4eba-ae97-1ae444c93688", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；下降会“卡”在某些情况，此时即使很小的更新步长也会增加代价函数。", "keywords": "下降会, 在某些情况, 此时即使很小的更新步长也会增加代价函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "79e75bac-ef39-4298-8850-cdacb9b3a8d6", "label": "摘要14", "info": "回顾式（4.9），代价函数的二阶泰勒级数展开预测梯度下降中的", "keywords": "回顾式, 代价函数的二阶泰勒级数展开预测梯度下降中的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "64639c60-7868-4ff3-8c81-f9db04cbf283", "label": "摘要15", "info": "会增加", "keywords": "会增加", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8a281922-d8a1-45b0-9df8-95584dfc8f86", "label": "摘要16", "info": "到代价中。当", "keywords": "到代价中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b3f37760-8431-4527-8517-bc584860fab3", "label": "摘要17", "info": "超过", "keywords": "超过", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "278d4aad-ba37-4dad-824d-cb022d0159b8", "label": "摘要18", "info": "时，梯度的病态会成", "keywords": "梯度的病态会成", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "af5ec4ca-3fba-406f-92a0-31bb4c87eff8", "label": "摘要19", "info": "为问题。判断病态是否不利于神经网络训练任务，我们可以监测平方梯；。在很多情况中，梯度范数不会在训练过程；度范数", "keywords": "为问题, 梯度范数不会在训练过程, 我们可以监测平方梯, 度范数, 在很多情况中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0cb857ba-131e-4c8e-ac17-a22bc5e2b245", "label": "摘要20", "info": "图8.1　梯度下降通常不会到达任何类型的临界点。此示例中，在用于对象检测的卷积网络的整；个训练期间，梯度范数持续增加。（左）各个梯度计算的范数如何随时间分布的散点图。为了；方便作图，每轮仅绘制一个梯度范数。我们将所有梯度范数的移动平均绘制为实曲线。梯度范", "keywords": "我们将所有梯度范数的移动平均绘制为实曲线, 每轮仅绘制一个梯度范数, 为了, 个训练期间, 梯度范数持续增加", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2c3c3c65-e20e-4998-b263-6ffde36dbe79", "label": "摘要21", "info": "尽管病态还存在于除了神经网络训练的其他情况中，有些适用于其他情；况的解决病态的技术并不适用于神经网络。例如，牛顿法在解决带有病；态条件的Hessian矩阵的凸优化问题时，是一个非常优秀的工具，但是我", "keywords": "是一个非常优秀的工具, 况的解决病态的技术并不适用于神经网络, 牛顿法在解决带有病, 但是我, 态条件的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cb13125f-ef93-4afc-ac75-e1784fed236a", "label": "摘要22", "info": "8.2.2　局部极小值", "keywords": "局部极小值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9ae42f2c-5254-4b21-bb21-0ca11daa5916", "label": "摘要23", "info": "凸优化问题的一个突出特点是其可以简化为寻找一个局部极小点的问；题。任何一个局部极小点都是全局最小点。有些凸函数的底部是一个平；坦的区域，而不是单一的全局最小点，但该平坦区域中的任意点都是一", "keywords": "但该平坦区域中的任意点都是一, 任何一个局部极小点都是全局最小点, 而不是单一的全局最小点, 有些凸函数的底部是一个平, 凸优化问题的一个突出特点是其可以简化为寻找一个局部极小点的问", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3d502acc-881c-4545-901b-651a82da9948", "label": "摘要24", "info": "对于非凸函数时，如神经网络，有可能会存在多个局部极小值。事实；上，几乎所有的深度模型基本上都会有非常多的局部极小值。然而，我；们会发现这并不是主要问题。", "keywords": "们会发现这并不是主要问题, 有可能会存在多个局部极小值, 如神经网络, 然而, 对于非凸函数时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "419de115-0f27-4c8c-a382-6aa4e8067c59", "label": "摘要25", "info": "由于模型可辨识性  （model  identifiability）问题，神经网络和任意具有；多个等效参数化潜变量的模型都会具有多个局部极小值。如果一个足够；大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的。", "keywords": "大的训练集可以唯一确定一组模型参数, 那么该模型被称为可辨认的, 神经网络和任意具有, 多个等效参数化潜变量的模型都会具有多个局部极小值, 问题", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b87048d3-9f78-4a33-bd2f-c43a23aaf4eb", "label": "摘要26", "info": "除了权重空间对称性，很多神经网络还有其他导致不可辨认的原因。例；如，在任意整流线性网络或者maxout网络中，我们可以将传入权重和偏", "keywords": "网络中, 很多神经网络还有其他导致不可辨认的原因, 我们可以将传入权重和偏, 除了权重空间对称性, 在任意整流线性网络或者", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ffda09ae-9762-42f5-ab12-37ae66a703f6", "label": "摘要27", "info": "置扩大α倍，然后将传出权重扩大   倍，而保持模型等价。这意味着，", "keywords": "这意味着, 而保持模型等价, 置扩大, 然后将传出权重扩大", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7e8c2e4b-a8f1-4207-89e5-0d478f7588e0", "label": "摘要28", "info": "如果代价函数不包括如权重衰减这种直接依赖于权重而非模型输出的；项，那么整流线性网络或者maxout网络的每一个局部极小点都在等价的；局部极小值的（m×n）维双曲线上。", "keywords": "局部极小值的, 网络的每一个局部极小点都在等价的, 维双曲线上, 那么整流线性网络或者, 如果代价函数不包括如权重衰减这种直接依赖于权重而非模型输出的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "32bf76fa-62e2-4864-96a8-033af9b54472", "label": "摘要29", "info": "这些模型可辨识性问题意味着，神经网络代价函数具有非常多甚至不可；数无限多的局部极小值。然而，所有这些由于不可辨识性问题而产生的；局部极小值都有相同的代价函数值。因此，这些局部极小值并非是非凸", "keywords": "这些模型可辨识性问题意味着, 因此, 数无限多的局部极小值, 然而, 神经网络代价函数具有非常多甚至不可", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e80eb9f1-7397-40d8-aa30-b2af725eaf46", "label": "摘要30", "info": "如果局部极小值相比全局最小点拥有很大的代价，局部极小值会带来很；大的隐患。我们可以构建没有隐藏单元的小规模神经网络，其局部极小", "keywords": "局部极小值会带来很, 其局部极小, 我们可以构建没有隐藏单元的小规模神经网络, 大的隐患, 如果局部极小值相比全局最小点拥有很大的代价", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "850bff39-fa9a-4357-9fd9-70389c9b681c", "label": "摘要31", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；and  Sussman，1989；；值的代价比全局最小点的代价大很多（Sontag", "keywords": "值的代价比全局最小点的代价大很多", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "695e63bf-61b0-4a7c-8d76-8ee3feced18e", "label": "摘要32", "info": "对于实际中感兴趣的网络，是否存在大量代价很高的局部极小值，优化；算法是否会碰到这些局部极小值，都是尚未解决的公开问题。多年来，；大多数从业者认为局部极小值是困扰神经网络优化的常见问题。如今，", "keywords": "大多数从业者认为局部极小值是困扰神经网络优化的常见问题, 算法是否会碰到这些局部极小值, 多年来, 如今, 是否存在大量代价很高的局部极小值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d0af07c2-0157-44aa-b389-7f651487eadb", "label": "摘要33", "info": "很多从业者将神经网络优化中的所有困难都归结于局部极小值。我们鼓；励从业者要仔细分析特定的问题。一种能够排除局部极小值是主要问题；的检测方法是画出梯度范数随时间的变化。如果梯度范数没有缩小到一", "keywords": "如果梯度范数没有缩小到一, 我们鼓, 一种能够排除局部极小值是主要问题, 励从业者要仔细分析特定的问题, 很多从业者将神经网络优化中的所有困难都归结于局部极小值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "57ed80a0-d906-455d-ab34-2855684e266d", "label": "摘要34", "info": "8.2.3　高原、鞍点和其他平坦区域", "keywords": "鞍点和其他平坦区域, 高原", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6aa7d850-f1e1-4532-ba5f-a83007bb3ad2", "label": "摘要35", "info": "对于很多高维非凸函数而言，局部极小值（以及极大值）事实上都远少；于另一类梯度为零的点：鞍点。鞍点附近的某些点比鞍点有更大的代；价，而其他点则有更小的代价。在鞍点处，Hessian矩阵同时具有正负特", "keywords": "鞍点附近的某些点比鞍点有更大的代, 而其他点则有更小的代价, 矩阵同时具有正负特, 局部极小值, 以及极大值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d96810b1-4cae-45c6-a79b-db67292184f9", "label": "摘要36", "info": "多类随机函数表现出以下性质：低维空间中，局部极小值很普遍。在更；高维空间中，局部极小值很罕见，而鞍点则很常见。对于这类函数", "keywords": "在更, 对于这类函数, 局部极小值很罕见, 多类随机函数表现出以下性质, 高维空间中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c2902641-a5d9-47ee-a074-aab6f9833c70", "label": "摘要37", "info": "而言，鞍点和局部极小值的数目比率的期望随n指数；级增长。我们可以从直觉上理解这种现象——Hessian矩阵在局部极小点；处只有正特征值。而在鞍点处，Hessian矩阵则同时具有正负特征值。试", "keywords": "级增长, 而言, 鞍点和局部极小值的数目比率的期望随, 我们可以从直觉上理解这种现象, 矩阵则同时具有正负特征值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8e4eaefd-da4d-496b-81df-53f9153d06cb", "label": "摘要38", "info": "想一下，每个特征值的正负号由抛硬币决定。在一维情况下，很容易抛；硬币得到正面朝上一次而获取局部极小点。在n-维空间中，要抛掷n次；硬币都正面朝上的难度是指数级的。具体可以参考Dauphin", "keywords": "每个特征值的正负号由抛硬币决定, 维空间中, 要抛掷, 具体可以参考, 在一维情况下", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5746af90-7035-491f-93d4-59d3feb98b41", "label": "摘要39", "info": "et", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "400ded32-786a-44a8-95a8-a307c3530039", "label": "摘要40", "info": "al.", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8930f568-2a02-4785-9ff3-0cd6e7ce0d79", "label": "摘要41", "info": "很多随机函数一个惊人性质是，当我们到达代价较低的区间时，Hessian；矩阵的特征值为正的可能性更大。和抛硬币类比，这意味着如果我们处；于低代价的临界点时，抛掷硬币正面朝上n次的概率更大。这也意味", "keywords": "和抛硬币类比, 这也意味, 当我们到达代价较低的区间时, 于低代价的临界点时, 矩阵的特征值为正的可能性更大", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "74f74ebc-0adb-4518-9809-16c58983175c", "label": "摘要42", "info": "以上现象出现在许多种类的随机函数中。那么是否在神经网络中也有发；生呢？Baldi  and  Hornik（1989）从理论上证明，不具非线性的浅层自编；码器（第14章中将介绍的一种将输出训练为输入拷贝的前馈网络）只有", "keywords": "不具非线性的浅层自编, 章中将介绍的一种将输出训练为输入拷贝的前馈网络, 从理论上证明, 以上现象出现在许多种类的随机函数中, 码器", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4afe1014-17fd-4357-94ce-92c00f266c80", "label": "摘要43", "info": "鞍点激增对于训练算法来说有哪些影响呢？对于只使用梯度信息的一阶；优化算法而言，目前情况还不清楚。鞍点附近的梯度通常会非常小。另；一方面，实验中梯度下降似乎可以在许多情况下逃离鞍点。Goodfellow", "keywords": "鞍点附近的梯度通常会非常小, 目前情况还不清楚, 一方面, 实验中梯度下降似乎可以在许多情况下逃离鞍点, 对于只使用梯度信息的一阶", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "dae95684-a9cc-4d65-b89b-093ed59b1e97", "label": "摘要44", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图8.2　神经网络代价函数的可视化。这些可视化对应用于真实对象识别和自然语言处理任务的；前馈神经网络、卷积网络和循环网络而言是类似的。令人惊讶的是，这些可视化通常不会显示", "keywords": "前馈神经网络, 这些可视化通常不会显示, 这些可视化对应用于真实对象识别和自然语言处理任务的, 令人惊讶的是, 神经网络代价函数的可视化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e959fb4b-5775-4a83-a5ab-9282fbb0b856", "label": "摘要45", "info": "对于牛顿法而言，鞍点显然是一个问题。梯度下降旨在朝“下坡”移动，；而非明确寻求临界点。而牛顿法的目标是寻求梯度为零的点。如果没有；适当的修改，牛顿法就会跳进一个鞍点。高维空间中鞍点的激增或许解", "keywords": "下坡, 移动, 对于牛顿法而言, 如果没有, 高维空间中鞍点的激增或许解", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1ed0ebd3-00c0-4122-b471-09c7b6ab4da2", "label": "摘要46", "info": "除了极小值和鞍点，还存在其他梯度为零的点。例如从优化的角度看与；鞍点很相似的极大值，很多算法不会被吸引到极大值，除了未经修改的；牛顿法。和极小值一样，许多种类的随机函数的极大值在高维空间中也", "keywords": "除了极小值和鞍点, 牛顿法, 许多种类的随机函数的极大值在高维空间中也, 很多算法不会被吸引到极大值, 例如从优化的角度看与", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9e9c4e74-fcff-45e5-b04d-395e172c46bc", "label": "摘要47", "info": "也可能存在恒值的、宽且平坦的区域。在这些区域，梯度和Hessian矩阵；都是零。这种退化的情形是所有数值优化算法的主要问题。在凸问题；中，一个宽而平坦的区间肯定包含全局极小值，但是对于一般的优化问", "keywords": "也可能存在恒值的, 宽且平坦的区域, 一个宽而平坦的区间肯定包含全局极小值, 都是零, 这种退化的情形是所有数值优化算法的主要问题", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2aea8606-4dac-4295-9bbd-51d059a16403", "label": "摘要48", "info": "题而言，这样的区域可能会对应着目标函数中一个较高的值。", "keywords": "这样的区域可能会对应着目标函数中一个较高的值, 题而言", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a49061c5-e309-4144-81a7-a8fb9fea8827", "label": "摘要49", "info": "8.2.4　悬崖和梯度爆炸", "keywords": "悬崖和梯度爆炸", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c22f9375-17f5-4848-95c4-c8eb39a06b2f", "label": "摘要50", "info": "多层神经网络通常存在像悬崖一样的斜率较大区域，如图8.3所示。这；是由于几个较大的权重相乘导致的。遇到斜率极大的悬崖结构时，梯度；更新会很大程度地改变参数值，通常会完全跳过这类悬崖结构。", "keywords": "梯度, 是由于几个较大的权重相乘导致的, 遇到斜率极大的悬崖结构时, 多层神经网络通常存在像悬崖一样的斜率较大区域, 所示", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "320a82e7-02d5-45a9-8a14-c179a83bc9d9", "label": "摘要51", "info": "图8.3　高度非线性的深度神经网络或循环神经网络的目标函数通常包含由几个参数连乘而导致；的参数空间中尖锐非线性。这些非线性在某些区域会产生非常大的导数。当参数接近这样的悬；崖区域时，梯度下降更新可以使参数弹射得非常远，可能会使大量已完成的优化工作成为无用", "keywords": "可能会使大量已完成的优化工作成为无用, 的参数空间中尖锐非线性, 梯度下降更新可以使参数弹射得非常远, 当参数接近这样的悬, 崖区域时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4dc8bb7b-8931-461a-ae1a-86e258a192b5", "label": "摘要52", "info": "不管我们是从上还是从下接近悬崖，情况都很糟糕，但幸运的是，我们；可以使用第10.11.1节介绍的启发式梯度截断 （gradient clipping）来避免；其严重的后果。其基本想法源自梯度并没有指明最佳步长，只说明了在", "keywords": "情况都很糟糕, 节介绍的启发式梯度截断, 其基本想法源自梯度并没有指明最佳步长, 我们, 但幸运的是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "682cd9cc-07ad-42b4-aa02-8a2f2f120e39", "label": "摘要53", "info": "8.2.5　长期依赖", "keywords": "长期依赖", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "380bfeaa-af7c-470f-ba46-23be8286acdf", "label": "摘要54", "info": "当计算图变得极深时，神经网络优化算法会面临的另一个难题就是长期；依赖问题——由于变深的结构使模型丧失了学习到先前信息的能力，让", "keywords": "神经网络优化算法会面临的另一个难题就是长期, 依赖问题, 当计算图变得极深时, 由于变深的结构使模型丧失了学习到先前信息的能力", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b540011f-c677-4c90-bd6b-f0249df771ae", "label": "摘要55", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；优化变得极其困难。深层的计算图不仅存在于前馈网络，还存在于之后；介绍的循环网络中（在第10章中描述）。因为循环网络要在很长时间序", "keywords": "介绍的循环网络中, 还存在于之后, 深层的计算图不仅存在于前馈网络, 章中描述, 在第", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f4ab50dc-5645-4cdf-b1d8-a52c316bbabf", "label": "摘要56", "info": "例如，假设某个计算图中包含一条反复与矩阵  W  相乘的路径。那么t步；后，相当于乘以 W t 。假设 W 有特征值分解；。", "keywords": "假设某个计算图中包含一条反复与矩阵, 相当于乘以, 相乘的路径, 例如, 那么", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b63db74d-a4de-4633-9c46-b248767d9e6c", "label": "摘要57", "info": "当特征值λ  i  不在1附近时，若在量级上大于1则会爆炸；若小于1时则会；消失。梯度消失与爆炸问题  （vanishing；gradient", "keywords": "若在量级上大于, 则会爆炸, 消失, 时则会, 附近时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e88429fe-167f-4352-8068-28efa9568ee8", "label": "摘要58", "info": "exploding", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3c6db0f1-2963-49c5-81b4-3b1cd5f73e02", "label": "摘要59", "info": "and", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1fe18d99-aa5c-485e-a5a6-cc181d4a9959", "label": "摘要60", "info": "此处描述的在各时间步重复与 W 相乘非常类似于寻求矩阵 W 的最大特；征值及对应特征向量的幂方法  （power  method）。从这个观点来看，", "keywords": "的最大特, 征值及对应特征向量的幂方法, 相乘非常类似于寻求矩阵, 此处描述的在各时间步重复与, 从这个观点来看", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7129e019-5de8-458a-937e-7d02db93088e", "label": "摘要61", "info": "最终会丢弃 x 中所有与 W 的主特征向量正交的成分。", "keywords": "最终会丢弃, 中所有与, 的主特征向量正交的成分", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3e36bcd6-b56d-40a2-bb5a-beef56c1d402", "label": "摘要62", "info": "循环网络在各时间步上使用相同的矩阵  W  ，而前馈网络并没有。所以；即使使用非常深层的前馈网络，也能很大程度上有效地避免梯度消失与；爆炸问题（Sussillo，2014）。", "keywords": "即使使用非常深层的前馈网络, 循环网络在各时间步上使用相同的矩阵, 也能很大程度上有效地避免梯度消失与, 爆炸问题, 而前馈网络并没有", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8f10410d-45b4-4bf9-9dae-120dba06856a", "label": "摘要63", "info": "在更详细地描述循环网络之后，我们将会在第10.7节进一步讨论循环网；络训练中的挑战。", "keywords": "我们将会在第, 节进一步讨论循环网, 在更详细地描述循环网络之后, 络训练中的挑战", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0a70056f-9c83-418b-9b99-9f3a1359214e", "label": "摘要64", "info": "8.2.6　非精确梯度", "keywords": "非精确梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "03e1baee-f9d8-4359-972e-574debe4db61", "label": "摘要65", "info": "大多数优化算法的先决条件都是我们知道精确的梯度或是Hessian矩阵。；在实践中，通常这些量会有噪声，甚至是有偏的估计。几乎每一个深度；学习算法都需要基于采样的估计，至少使用训练样本的小批量来计算梯", "keywords": "大多数优化算法的先决条件都是我们知道精确的梯度或是, 至少使用训练样本的小批量来计算梯, 几乎每一个深度, 矩阵, 通常这些量会有噪声", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "af391ce4-aa93-4bc1-adfd-c91698b3efbb", "label": "摘要66", "info": "在其他情况下，我们希望最小化的目标函数实际上是难以处理的。当目；标函数不可解时，通常其梯度也是难以处理的。在这种情况下，我们只；能近似梯度。这些问题主要出现在本书第3部分更高级的模型中。例", "keywords": "这些问题主要出现在本书第, 通常其梯度也是难以处理的, 我们只, 我们希望最小化的目标函数实际上是难以处理的, 当目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6bebcebb-5038-407c-82c5-0dee21a1ca01", "label": "摘要67", "info": "各种神经网络优化算法的设计都考虑到了梯度估计的缺陷。我们可以选；择比真实损失函数更容易估计的代理损失函数来避免这个问题。", "keywords": "择比真实损失函数更容易估计的代理损失函数来避免这个问题, 各种神经网络优化算法的设计都考虑到了梯度估计的缺陷, 我们可以选", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "663845da-31f1-42aa-af34-d07091ca31e5", "label": "摘要68", "info": "8.2.7　局部和全局结构间的弱对应", "keywords": "局部和全局结构间的弱对应", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "73dcb447-2790-431c-aa2a-e8f69308b82b", "label": "摘要69", "info": "迄今为止，我们讨论的许多问题都是关于损失函数在单个点的性质——；若J（ θ ）是当前点 θ 的病态条件，或者 θ 在悬崖中，或者 θ 是一个下；降方向不明显的鞍点，那么会很难更新当前步。", "keywords": "是当前点, 是一个下, 的病态条件, 降方向不明显的鞍点, 或者", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "45c1657a-0eef-422b-863d-e0496c128588", "label": "摘要70", "info": "如果该方向在局部改进很大，但并没有指向代价低得多的遥远区域，那；么我们有可能在单点处克服以上所有困难，但仍然表现不佳。", "keywords": "如果该方向在局部改进很大, 但并没有指向代价低得多的遥远区域, 么我们有可能在单点处克服以上所有困难, 但仍然表现不佳", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2cdab351-08b6-4f3e-9c90-5a305c280ada", "label": "摘要71", "info": "Goodfellow  et  al.  （2015）认为大部分训练的运行时间取决于到达解决；方案的轨迹长度。如图8.2所示，学习轨迹将花费大量的时间探寻一个；围绕山形结构的宽弧。", "keywords": "认为大部分训练的运行时间取决于到达解决, 所示, 围绕山形结构的宽弧, 方案的轨迹长度, 如图", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8e78481c-fcfe-4e12-bfb3-4ab9d3cd014c", "label": "摘要72", "info": "大多数优化研究的难点集中于训练是否找到了全局最小点、局部极小点；或是鞍点，但在实践中神经网络不会到达任何一种临界点。图8.1表明；神经网络通常不会到达梯度很小的区域。甚至，这些临界点不一定存", "keywords": "大多数优化研究的难点集中于训练是否找到了全局最小点, 但在实践中神经网络不会到达任何一种临界点, 或是鞍点, 这些临界点不一定存, 表明", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3f138df3-80fa-4f13-9d9a-72765f7a0464", "label": "摘要73", "info": "可以没有全局最小点，而是", "keywords": "可以没有全局最小点, 而是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "241e8a5f-969e-4a93-85e5-3f8bde2a4ed8", "label": "摘要74", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图8.4　如果局部表面没有指向全局解，基于局部下坡移动的优化可能就会失败。这里我们提供；一个例子，说明即使在没有鞍点或局部极小值的情况下，优化过程会如何失败。此例中的代价", "keywords": "如果局部表面没有指向全局解, 基于局部下坡移动的优化可能就会失败, 此例中的代价, 一个例子, 说明即使在没有鞍点或局部极小值的情况下", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "df745947-b8da-475f-a9e2-dc9aa4009506", "label": "摘要75", "info": "未来的研究需要进一步探索影响学习轨迹长度和更好地表征训练过程的；结果。", "keywords": "未来的研究需要进一步探索影响学习轨迹长度和更好地表征训练过程的, 结果", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ffde9527-dc88-4c4e-994b-b3baa0e1ebba", "label": "摘要76", "info": "许多现有研究方法在求解具有困难全局结构的问题时，旨在寻求良好的；初始点，而不是开发非局部范围更新的算法。", "keywords": "许多现有研究方法在求解具有困难全局结构的问题时, 而不是开发非局部范围更新的算法, 旨在寻求良好的, 初始点", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "23ce8210-3cc3-4974-8f46-d907cc9b7d65", "label": "摘要77", "info": "梯度下降和基本上所有的可以有效训练神经网络的学习算法，都是基于；局部较小更新。之前的小节主要集中于为何这些局部范围更新的正确方；向难以计算。我们也许能计算目标函数的一些性质，如近似的有偏梯度", "keywords": "局部较小更新, 都是基于, 梯度下降和基本上所有的可以有效训练神经网络的学习算法, 之前的小节主要集中于为何这些局部范围更新的正确方, 向难以计算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4ccec422-fee2-47b3-950d-49ed76f2e453", "label": "摘要78", "info": "心，朝着下坡方向移动，却和所有可行解南辕北辙，如图8.4所示，或；者是用舍近求远的方法来求解问题，如图8.2所示。目前，我们还不了；解这些问题中的哪一个与神经网络优化中的难点最相关，这是研究领域", "keywords": "却和所有可行解南辕北辙, 我们还不了, 这是研究领域, 所示, 目前", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "37cf1c6e-0415-4141-b66d-48e7f5ccbd2f", "label": "摘要79", "info": "不管哪个问题最重要，如果存在一个区域，我们遵循局部下降便能合理；地直接到达某个解，并且我们能够在该良好区域上初始化学习，那么这；些问题都可以避免。最终的观点还是建议在传统优化算法上研究怎样选", "keywords": "并且我们能够在该良好区域上初始化学习, 最终的观点还是建议在传统优化算法上研究怎样选, 不管哪个问题最重要, 我们遵循局部下降便能合理, 些问题都可以避免", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6cd47f75-8a2b-48a9-b388-237c46b57f54", "label": "摘要80", "info": "8.2.8　优化的理论限制", "keywords": "优化的理论限制", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "83153732-7920-4fcf-aa2c-406f6fbdda1b", "label": "摘要81", "info": "一些理论结果表明，我们为神经网络设计的任何优化算法都有性能限制；（Blum  and  Rivest，1992；Judd，1989；Wolpert  and  MacReady，；1997）。通常这些结果不影响神经网络在实践中的应用。", "keywords": "我们为神经网络设计的任何优化算法都有性能限制, 通常这些结果不影响神经网络在实践中的应用, 一些理论结果表明", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "711a6bbe-7a29-4252-9294-1e39207aef36", "label": "摘要82", "info": "一些理论结果仅适用于神经网络的单元输出离散值的情况。然而，大多；数神经网络单元输出光滑的连续值，使得局部搜索求解优化可行。一些；理论结果表明，存在某类问题是不可解的，但很难判断一个特定问题是", "keywords": "一些, 数神经网络单元输出光滑的连续值, 然而, 但很难判断一个特定问题是, 一些理论结果仅适用于神经网络的单元输出离散值的情况", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3c0d5daa-6dc2-455c-98c4-d94064d1003f", "label": "摘要83", "info": "8.2.1　病态", "keywords": "病态", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bbad1140-d7f9-4a61-a41c-acd088dd9b01", "label": "摘要84", "info": "8.2.2　局部极小值", "keywords": "局部极小值", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2c76aa82-9dff-4395-997a-9cf649c9c8f1", "label": "摘要85", "info": "8.2.3　高原、鞍点和其他；平坦区域", "keywords": "平坦区域, 高原, 鞍点和其他", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "57a46f50-57f1-4da9-818b-f8493aaa133a", "label": "摘要86", "info": "8.2.4　悬崖和梯度爆炸", "keywords": "悬崖和梯度爆炸", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bd41ce97-2c9a-4948-b3dd-bcd0b64528b9", "label": "摘要87", "info": "8.2.5　长期依赖", "keywords": "长期依赖", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c713132f-2d14-4054-ba73-62d78f13636b", "label": "摘要88", "info": "8.2.6　非精确梯度", "keywords": "非精确梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b96d550d-8846-4ebc-8d30-fb88bc4ddc91", "label": "摘要89", "info": "8.2.7　局部和全局结构间；的弱对应", "keywords": "局部和全局结构间, 的弱对应", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d532e090-4ead-48d4-898f-0bd2b76696c7", "label": "摘要90", "info": "8.2.8　优化的理论限制", "keywords": "优化的理论限制", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ab211937-fe59-4303-9618-47518307adc4", "label": "8.3：基本算法", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "450d3798-e1cc-4ec4-bfa2-53b985fb9a0f", "label": "摘要1", "info": "8.3.1　随机梯度下降", "keywords": "随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9939437d-9274-4744-994d-8b896db5597f", "label": "摘要2", "info": "8.3.2　动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "31177599-5c1c-4c21-bc1c-a49831311c7a", "label": "摘要3", "info": "8.3.3　Nesterov动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "461ea639-9ae8-43a0-9303-0c01b7a9c827", "label": "摘要4", "info": "之前我们已经介绍了梯度下降（第4.3节），即沿着整个训练集的梯度；方向下降。这可以使用随机梯度下降很大程度地加速，沿着随机挑选的；小批量数据的梯度下降方向，就像第5.9节和第8.1.3节中讨论的一样。", "keywords": "小批量数据的梯度下降方向, 就像第, 方向下降, 节和第, 沿着随机挑选的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "676abb63-90aa-47cc-81bb-cf9d8db524e0", "label": "摘要5", "info": "8.3.1　随机梯度下降", "keywords": "随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bf65bdd1-377c-4024-ad6d-71ffd62b1130", "label": "摘要6", "info": "随机梯度下降（SGD）及其变种很可能是一般机器学习中应用最多的的；优化算法，特别是在深度学习中。如第8.1.3节中所讨论的，按照数据生", "keywords": "及其变种很可能是一般机器学习中应用最多的的, 特别是在深度学习中, 节中所讨论的, 优化算法, 如第", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c7c6da35-6a9c-4599-9037-d5421eaf5e6a", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；成分布抽取m个小批量（独立同分布的）样本，通过计算它们梯度均；值，我们可以得到梯度的无偏估计。", "keywords": "样本, 通过计算它们梯度均, 成分布抽取, 独立同分布的, 个小批量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d066d7f2-9c29-43e1-8405-d5cdeed61518", "label": "摘要8", "info": "算法8.1展示了如何沿着这个梯度的估计下降。", "keywords": "展示了如何沿着这个梯度的估计下降, 算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1dfd19f9-b3ce-4659-a454-ab25ec5a6012", "label": "摘要9", "info": "算法8.1 　随机梯度下降（SGD）在第k个训练迭代的更新。", "keywords": "随机梯度下降, 在第, 算法, 个训练迭代的更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "85192e0b-1cc7-492f-9117-bf3a368903a7", "label": "摘要10", "info": "Require： 学习率", "keywords": "学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "18854aa5-ec12-40e8-9777-406c11455f7a", "label": "摘要11", "info": "Require： 初始参数 θ", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c6971fd7-fb0f-4645-a0c9-5cdefa6dcec2", "label": "摘要12", "info": "while 停止准则未满足do", "keywords": "停止准则未满足", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "63717420-3e0c-4083-b8e3-3517f4646d80", "label": "摘要13", "info": "从训练集中采包含m个样本；(i) 对应目标为 y (i) 。", "keywords": "对应目标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "51b385e1-c025-4d84-880f-7c2447280e1d", "label": "摘要14", "info": "计算梯度估计：", "keywords": "计算梯度估计", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4f574eba-291b-4dff-a3a7-943285bc68af", "label": "摘要15", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "063a3eee-322b-4ad2-a06f-877f27d2dfab", "label": "摘要16", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "397eb9ec-2576-45fd-9a24-0ab88a3188ba", "label": "摘要17", "info": "的小批量，其中  x", "keywords": "的小批量, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c80604fc-d1ce-4396-8d00-9d69e3867c13", "label": "摘要18", "info": "SGD算法中的一个关键参数是学习率。之前，我们介绍的SGD使用固定；的学习率。在实践中，有必要随着时间的推移逐渐降低学习率，因此我；们将第k步迭代的学习率记作  。", "keywords": "算法中的一个关键参数是学习率, 因此我, 使用固定, 步迭代的学习率记作, 的学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7122c81c-469b-4a8b-adc5-74182ed3f4cd", "label": "摘要19", "info": "这是因为SGD中梯度估计引入的噪声源（m个训练样本的随机采样）并；不会在极小点处消失。相比之下，当我们使用批量梯度下降到达极小点；时，整个代价函数的真实梯度会变得很小，之后为0  ，因此批量梯度下", "keywords": "之后为, 不会在极小点处消失, 这是因为, 当我们使用批量梯度下降到达极小点, 中梯度估计引入的噪声源", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9f87a14b-e2e0-4223-9a5c-319a66238fa2", "label": "摘要20", "info": "且", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7ab46e05-f664-4242-96a4-b325287700b8", "label": "摘要21", "info": "实践中，一般会线性衰减学习率直到第τ次迭代：", "keywords": "一般会线性衰减学习率直到第, 次迭代, 实践中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e11f1167-67fe-45b2-a874-3caf2981cad7", "label": "摘要22", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "270eb440-b326-4282-9ad6-1612e95318db", "label": "摘要23", "info": "。在τ步迭代之后，一般使  保持常数。", "keywords": "一般使, 步迭代之后, 保持常数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1ed13c81-e760-4ae9-ab45-9df070c77711", "label": "摘要24", "info": "学习率可通过试验和误差来选取，通常最好的选择方法是监测目标函数；值随时间变化的学习曲线。与其说是科学，这更像是一门艺术，我们应；该谨慎地参考关于这个问题的大部分指导。使用线性策略时，需要选择", "keywords": "需要选择, 值随时间变化的学习曲线, 这更像是一门艺术, 通常最好的选择方法是监测目标函数, 学习率可通过试验和误差来选取", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "07300653-62ec-4c60-b4a8-fdd334d20716", "label": "摘要25", "info": "SGD及相关的小批量亦或更广义的基于梯度优化的在线学习算法，一个；重要的性质是每一步更新的计算时间不依赖训练样本数目的多寡。即使；训练样本数目非常大时，它们也能收敛。对于足够大的数据集，SGD可", "keywords": "对于足够大的数据集, 及相关的小批量亦或更广义的基于梯度优化的在线学习算法, 即使, 重要的性质是每一步更新的计算时间不依赖训练样本数目的多寡, 训练样本数目非常大时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "56c3d036-19e0-4b93-b103-efb9298ad6e3", "label": "摘要26", "info": "研究优化算法的收敛率，一般会衡量额外误差", "keywords": "研究优化算法的收敛率, 一般会衡量额外误差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5f4fde0d-de1e-4988-9118-09a7b524a892", "label": "摘要27", "info": "error）；，即当前代价函数超出最低可能代价的量。", "keywords": "即当前代价函数超出最低可能代价的量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7b29cc2f-ad14-4e9c-9a67-257c06ca89ad", "label": "摘要28", "info": "（excess", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3b89a015-d10a-4d19-a999-22b90aa42089", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；SGD应用于凸问题时，k步迭代后的额外误差量级是", "keywords": "步迭代后的额外误差量级是, 应用于凸问题时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c7399a8e-91b6-4be5-8f0b-cae2e9e13944", "label": "摘要30", "info": "，在强", "keywords": "在强", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0c52dac9-e19e-422a-bb0e-9beebe28a7e6", "label": "摘要31", "info": "凸情况下是", "keywords": "凸情况下是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ccb04fd5-2dd1-4630-b7b8-a4cf57931942", "label": "摘要32", "info": "。除非假定额外的条件，否则这些界限不能进一", "keywords": "除非假定额外的条件, 否则这些界限不能进一", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3403f33a-aac2-4458-ab06-a49a41f13789", "label": "摘要33", "info": "步改进。批量梯度下降在理论上比随机梯度下降有更好的收敛率。然；而，Cramér-Rao界限（Cramér，1946；Rao，1945）指出，泛化误差的", "keywords": "指出, 步改进, 界限, 批量梯度下降在理论上比随机梯度下降有更好的收敛率, 泛化误差的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4e884de4-d64a-4601-9430-0af19bb9d82c", "label": "摘要34", "info": "下降速度不会快于", "keywords": "下降速度不会快于", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1f6dbf5b-26fd-4da1-8f3b-18a5ccd1e86c", "label": "摘要35", "info": "）。Bottou and Bousquet（2008b）因此认", "keywords": "因此认", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1b5117f8-b74e-4b2a-b5b3-bc687803b5c3", "label": "摘要36", "info": "为对于机器学习任务，不值得探寻收敛快于", "keywords": "不值得探寻收敛快于, 为对于机器学习任务", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "47ff2651-3290-4ed0-a6ec-a4865950de02", "label": "摘要37", "info": "）的优化算法", "keywords": "的优化算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "588c255f-5526-481d-8b51-4370d0761fd4", "label": "摘要38", "info": "——更快的收敛可能对应着过拟合。此外，渐近分析掩盖了随机梯度下；降在少量更新步之后的很多优点。对于大数据集，SGD只需非常少量样；本计算梯度从而实现初始快速更新，远远超过了其缓慢的渐近收敛。本", "keywords": "只需非常少量样, 本计算梯度从而实现初始快速更新, 远远超过了其缓慢的渐近收敛, 此外, 渐近分析掩盖了随机梯度下", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9b228f2c-707a-49d0-902c-88f67f801ed9", "label": "摘要39", "info": "常数倍", "keywords": "常数倍", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "62bf0614-34ca-4d99-aa30-810c6cb04a90", "label": "摘要40", "info": "）的渐近分析。我们也可以在学习过程中逐渐增大小", "keywords": "我们也可以在学习过程中逐渐增大小, 的渐近分析", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ae425390-fbf1-4f10-b4e7-2be31437d4bd", "label": "摘要41", "info": "批量的大小，以此权衡批量梯度下降和随机梯度下降两者的优点。", "keywords": "批量的大小, 以此权衡批量梯度下降和随机梯度下降两者的优点", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a2b0ea2c-5c9c-4235-ba36-2e14a0cdf91e", "label": "摘要42", "info": "了解SGD更多的信息，请查看Bottou（1998）。", "keywords": "了解, 请查看, 更多的信息", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "30ccfe45-d2e0-40ac-b601-bd163a0db38b", "label": "摘要43", "info": "8.3.2　动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5366694d-dcad-47ea-8e65-cddf0ea462df", "label": "摘要44", "info": "虽然随机梯度下降仍然是非常受欢迎的优化方法，但其学习过程有时会；很慢。动量方法（Polyak，1964）旨在加速学习，特别是处理高曲率、；小但一致的梯度，或是带噪声的梯度。动量算法积累了之前梯度指数级", "keywords": "很慢, 动量方法, 特别是处理高曲率, 动量算法积累了之前梯度指数级, 虽然随机梯度下降仍然是非常受欢迎的优化方法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2796efa0-6d14-4b34-97f9-3aaf6d1972a9", "label": "摘要45", "info": "从形式上看，动量算法引入了变量 ν  充当速度角色——它代表参数在参；数空间移动的方向和速率。速度被设为负梯度的指数衰减平均。名称动；量  （momentum）来自物理类比，根据牛顿运动定律，负梯度是移动参", "keywords": "从形式上看, 根据牛顿运动定律, 它代表参数在参, 负梯度是移动参, 数空间移动的方向和速率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7eadccab-15e1-4f6b-874b-e625cbb84cd2", "label": "摘要46", "info": "速度  ν  累积了梯度元素", "keywords": "速度, 累积了梯度元素", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5794fd1c-9202-4b02-8007-1154e35d0325", "label": "摘要47", "info": "。相对于，；越大，之前梯度对现在方向的影响也越大。带动量的SGD算法如算", "keywords": "算法如算, 相对于, 之前梯度对现在方向的影响也越大, 越大, 带动量的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e0ab8185-24ce-4340-beb4-aade920c455e", "label": "摘要48", "info": "法8.2所示。", "keywords": "所示", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "10ba7069-954a-49b9-8718-33fc0cc946cd", "label": "摘要49", "info": "图8.5　动量的主要目的是解决两个问题：Hessian矩阵的病态条件和随机梯度的方差。我们通过；此图说明动量如何克服这两个问题的第一个。等高线描绘了一个二次损失函数（具有病态条件；的Hessian矩阵）。横跨轮廓的红色路径表示动量学习规则所遵循的路径，它使该函数最小化。", "keywords": "我们通过, 它使该函数最小化, 此图说明动量如何克服这两个问题的第一个, 等高线描绘了一个二次损失函数, 矩阵", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "68df0984-d5cb-4fb0-883e-a93a34521b03", "label": "摘要50", "info": "算法8.2 　使用动量的随机梯度下降（SGD）。", "keywords": "算法, 使用动量的随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7488c6e1-a0ed-40fd-9572-0681d1450fef", "label": "摘要51", "info": "Require： 学习率  ，动量参数α", "keywords": "动量参数, 学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ac48fd63-d358-446d-8e42-cf517c6365e9", "label": "摘要52", "info": "Require： 初始参数 θ ，初始速度 ν", "keywords": "初始速度, 初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cf4aacc9-a855-455c-9350-acd74499a6e8", "label": "摘要53", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "300d38df-be01-4fb6-a973-c69a116ac1aa", "label": "摘要54", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的小批量，对应目标", "keywords": "对应目标, 的小批量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "911ef710-20cf-486f-87ae-616a6d7b563e", "label": "摘要55", "info": "从训练集中采包含m个样本；为  。", "keywords": "个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b1f80345-fc99-488d-a106-9e57eb9c52c5", "label": "摘要56", "info": "计算梯度估计：", "keywords": "计算梯度估计", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "488e24cf-d008-454a-97e8-651bef9333eb", "label": "摘要57", "info": "计算速度更新：", "keywords": "计算速度更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "dd9b200a-eb0f-4841-8b90-6467146ec657", "label": "摘要58", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a282979a-bb79-4b18-9ac3-2db2803fc938", "label": "摘要59", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "483f3c22-a75b-4345-aa41-3c4133b87263", "label": "摘要60", "info": "之前，步长只是梯度范数乘以学习率。现在，步长取决于梯度序列的大；小和排列。当许多连续的梯度指向相同的方向时，步长最大。如果动量；算法总是观测到梯度 g ，那么它会在方向−g上不停加速，直到达到最终", "keywords": "步长只是梯度范数乘以学习率, 步长最大, 上不停加速, 那么它会在方向, 如果动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9b8ee9ab-05ee-4b0d-84c3-fddad5b41db7", "label": "摘要61", "info": "因此将动量的超参数视为", "keywords": "因此将动量的超参数视为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "67e2f6fb-309c-45e9-bef6-2fc0685f1b47", "label": "摘要62", "info": "有助于理解。例如，α＝0.9对应着最", "keywords": "例如, 有助于理解, 对应着最", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ea9c0cd9-45de-4fbe-a464-2be36ad372de", "label": "摘要63", "info": "大速度10倍于梯度下降算法。", "keywords": "倍于梯度下降算法, 大速度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ea0e8980-0856-4f23-9d84-f4f37ada3d17", "label": "摘要64", "info": "在实践中，α的一般取值为0.5、0.9和0.99。和学习率一样，α也会随着；时间不断调整。一般初始值是一个较小的值，随后会慢慢变大。随着时；间推移调整α没有收缩  重要。", "keywords": "时间不断调整, 和学习率一样, 随后会慢慢变大, 一般初始值是一个较小的值, 没有收缩", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d4f6e755-1249-49ed-8eb5-08fd9eeab793", "label": "摘要65", "info": "我们可以将动量算法视为模拟连续时间下牛顿动力学下的粒子。这种物；理类比有助于直觉上理解动量和梯度下降算法是如何表现的。", "keywords": "理类比有助于直觉上理解动量和梯度下降算法是如何表现的, 这种物, 我们可以将动量算法视为模拟连续时间下牛顿动力学下的粒子", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9f04ae0a-3cae-43fe-b1c7-5832702b6995", "label": "摘要66", "info": "粒子在任意时间点的位置由  θ (t)给定。粒子会受到净力 f  (t)。该力会导；致粒子加速：", "keywords": "该力会导, 粒子会受到净力, 粒子在任意时间点的位置由, 致粒子加速, 给定", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "522159ba-0d4f-4c2f-b6f0-5cce47c18bec", "label": "摘要67", "info": "与其将其视为位置的二阶微分方程，我们不如引入表示粒子在时间t处；速度的变量 ν (t)，将牛顿动力学重写为一阶微分方程：", "keywords": "与其将其视为位置的二阶微分方程, 我们不如引入表示粒子在时间, 速度的变量, 将牛顿动力学重写为一阶微分方程", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7de42920-b893-471e-b401-f9653bc2bb00", "label": "摘要68", "info": "由此，动量算法包括通过数值模拟求解微分方程。求解微分方程的一个；简单数值方法是欧拉方法，通过在每个梯度方向上小且有限的步来简单；模拟该等式定义的动力学。", "keywords": "动量算法包括通过数值模拟求解微分方程, 模拟该等式定义的动力学, 由此, 求解微分方程的一个, 简单数值方法是欧拉方法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6857fad3-8830-4cfc-9647-e874684fac30", "label": "摘要69", "info": "这解释了动量更新的基本形式，但具体什么是力呢？力正比于代价函数；的负梯度；。该力推动粒子沿着代价函数表面下坡的方向移", "keywords": "但具体什么是力呢, 该力推动粒子沿着代价函数表面下坡的方向移, 力正比于代价函数, 的负梯度, 这解释了动量更新的基本形式", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bd78ea1e-913b-47b9-a5d8-a0d448fcba78", "label": "摘要70", "info": "另一个力也是必要的。如果代价函数的梯度是唯一的力，那么粒子可能；永远不会停下来。想象一下，假设理想情况下冰面没有摩擦，一个冰球；从山谷的一端下滑，上升到另一端，永远来回振荡。要解决这个问题，", "keywords": "那么粒子可能, 永远来回振荡, 另一个力也是必要的, 上升到另一端, 如果代价函数的梯度是唯一的力", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9bbc2c7b-0bda-44b3-9f96-3d52f1d080c7", "label": "摘要71", "info": "为什么要特别使用− ν (t)和黏性阻力呢？部分原因是因为− ν (t)在数学上；的便利——速度的整数幂很容易处理。然而，其他物理系统具有基于速；度的其他整数幂的其他类型的阻力。例如，颗粒通过空气时会受到正比", "keywords": "速度的整数幂很容易处理, 在数学上, 度的其他整数幂的其他类型的阻力, 颗粒通过空气时会受到正比, 其他物理系统具有基于速", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2485f464-8582-456a-a3b0-9a57ed8442ae", "label": "摘要72", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；干摩擦，那么力太强了。当代价函数的梯度表示的力很小但非零时，由；于摩擦导致的恒力会使得粒子在达到局部极小点之前就停下来。黏性阻", "keywords": "当代价函数的梯度表示的力很小但非零时, 干摩擦, 黏性阻, 那么力太强了, 于摩擦导致的恒力会使得粒子在达到局部极小点之前就停下来", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5596b860-638c-4951-aa10-28f1ca2e663f", "label": "摘要73", "info": "8.3.3　Nesterov动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "470a1bf2-cd06-4bd7-b7ed-ca83e3c18abe", "label": "摘要74", "info": "受Nesterov加速梯度算法（Nesterov，1983，2004）启发，Sutskever；al. （2013）提出了动量算法的一个变种。这种情况的更新规则如下：", "keywords": "启发, 提出了动量算法的一个变种, 这种情况的更新规则如下, 加速梯度算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8f08f04e-784f-4253-8699-166e62cf60e0", "label": "摘要75", "info": "et", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "488ce9ab-46cc-405d-9a5a-23ff0785038a", "label": "摘要76", "info": "其中参数α和发挥了和标准动量方法中类似的作用。Nesterov动量和标准；动量之间的区别体现在梯度计算上。Nesterov动量中，梯度计算在施加；当前速度之后。因此，Nesterov动量可以解释为往标准动量方法中添加", "keywords": "动量和标准, 动量中, 因此, 和发挥了和标准动量方法中类似的作用, 当前速度之后", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c112f45d-113e-4b42-a0fc-fcb4ec198455", "label": "摘要77", "info": "算法8.3 　使用Nesterov动量的随机梯度下降（SGD）。", "keywords": "使用, 算法, 动量的随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "73f73648-567c-455c-9777-612be3e205a5", "label": "摘要78", "info": "Require： 学习率  ，动量参数α", "keywords": "动量参数, 学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fbc1304e-3f13-4ef4-9597-8633da1b4f24", "label": "摘要79", "info": "Require： 初始参数 θ ，初始速度 ν", "keywords": "初始速度, 初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d7008fc3-bac1-4574-af7a-30d9de438876", "label": "摘要80", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "62936849-19b4-4c56-9de1-2205deff9663", "label": "摘要81", "info": "从训练集中采包含m个样本；标为y (i) 。", "keywords": "标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "85fa1754-8dc4-4fcd-987c-e8e09607b082", "label": "摘要82", "info": "应用临时更新：", "keywords": "应用临时更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "89b27aed-d098-462d-8b77-426f2e1a8d14", "label": "摘要83", "info": "计算梯度（在临时点）：", "keywords": "计算梯度, 在临时点", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "83fdff29-481b-4f0b-9aa1-15b9d8c21c3e", "label": "摘要84", "info": "的小批量，对应目", "keywords": "的小批量, 对应目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "56c4b12c-01b6-43d0-8a6e-717b23d1c0a7", "label": "摘要85", "info": "计算速度更新：", "keywords": "计算速度更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1aae05d9-8bb5-4401-8ce7-67341194bd4f", "label": "摘要86", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f37c20fd-9ad0-4844-b76f-83aeeb71e707", "label": "摘要87", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "309a4eda-e9ea-4d93-8026-0093c9fb82fc", "label": "摘要88", "info": "在凸批量梯度的情况下，Nesterov动量将额外误差收敛率从O(1/k)（k步；后）改进到O(1/k 2 )，如Nesterov（1983）所示。可惜，在随机梯度的情；况下，Nesterov动量没有改进收敛率。", "keywords": "在随机梯度的情, 况下, 动量没有改进收敛率, 在凸批量梯度的情况下, 改进到", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8d4281bd-0e14-4303-a245-4b564c7f14c6", "label": "摘要89", "info": "8.3.1　随机梯度下降", "keywords": "随机梯度下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5c9f49d3-41cd-4682-99eb-d6744dc04c79", "label": "摘要90", "info": "8.3.2　动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "32fd12d2-d5a8-49bd-b029-019a2510984f", "label": "摘要91", "info": "8.3.3　Nesterov动量", "keywords": "动量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "98efa724-66cd-4c75-82f1-c59af22b3b8e", "label": "摘要92", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；8.4　参数初始化策略", "keywords": "参数初始化策略", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "label": "8.4：参数初始化策略", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "cfe34f3b-956f-4e55-9e4f-ead3f72c748c", "label": "摘要1", "info": "有些优化算法本质上是非迭代的，只是求解一个解点。有些其他优化算；法本质上是迭代的，但是应用于这一类的优化问题时，能在可接受的时；间内收敛到可接受的解，并且与初始值无关。深度学习训练算法通常没", "keywords": "但是应用于这一类的优化问题时, 能在可接受的时, 有些其他优化算, 只是求解一个解点, 并且与初始值无关", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "70d45260-72b0-44fe-81f3-1e3183c39492", "label": "摘要2", "info": "现代的初始化策略是简单的、启发式的。设定改进的初始化策略是一项；困难的任务，因为神经网络优化至今还未被很好地理解。大多数初始化；策略基于在神经网络初始化时实现一些很好的性质。然而，我们并没有", "keywords": "设定改进的初始化策略是一项, 大多数初始化, 策略基于在神经网络初始化时实现一些很好的性质, 我们并没有, 启发式的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3bce00d9-16fc-41ef-841c-e2a88c681653", "label": "摘要3", "info": "也许完全确知的唯一特性是初始参数需要在不同单元间“破坏对称性”。；如果具有相同激活函数的两个隐藏单元连接到相同的输入，那么这些单；元必须具有不同的初始参数。如果它们具有相同的初始参数，然后应用", "keywords": "如果它们具有相同的初始参数, 也许完全确知的唯一特性是初始参数需要在不同单元间, 元必须具有不同的初始参数, 然后应用, 如果具有相同激活函数的两个隐藏单元连接到相同的输入", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8a660a04-4176-4653-9c98-07d3f148b47e", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；单元。即使模型或训练算法能够使用随机性为不同的单元计算不同的更；新（例如使用Dropout的训练），通常来说，最好还是初始化每个单元", "keywords": "例如使用, 即使模型或训练算法能够使用随机性为不同的单元计算不同的更, 通常来说, 最好还是初始化每个单元, 的训练", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6044b2e2-5795-40ef-a27f-645f57dcdc8c", "label": "摘要5", "info": "通常情况下，我们可以为每个单元的偏置设置启发式挑选的常数，仅随；机初始化权重。额外的参数（例如用于编码预测条件方差的参数）通常；和偏差一样设置为启发式选择的常数。", "keywords": "通常情况下, 机初始化权重, 仅随, 额外的参数, 例如用于编码预测条件方差的参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "50091255-14ca-4f0a-9cdc-9a94a473dca2", "label": "摘要6", "info": "我们几乎总是初始化模型的权重为高斯或均匀分布中随机抽取的值。高；斯或均匀分布的选择似乎不会有很大的差别，但也没有被详尽地研究。；然而，初始分布的大小确实对优化过程的结果和网络泛化能力都有很大", "keywords": "斯或均匀分布的选择似乎不会有很大的差别, 但也没有被详尽地研究, 然而, 我们几乎总是初始化模型的权重为高斯或均匀分布中随机抽取的值, 初始分布的大小确实对优化过程的结果和网络泛化能力都有很大", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f73f20ff-cdf8-404a-b7cb-a05eb93180f1", "label": "摘要7", "info": "更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单；元。它们也有助于避免在每层线性成分的前向或反向传播中丢失信号；——矩阵中更大的值在矩阵乘法中有更大的输出。如果初始权重太大，", "keywords": "更大的初始权重具有更强的破坏对称性的作用, 矩阵中更大的值在矩阵乘法中有更大的输出, 有助于避免冗余的单, 如果初始权重太大, 它们也有助于避免在每层线性成分的前向或反向传播中丢失信号", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3a138d8b-cc60-4e3a-8f18-899b8d9c2d91", "label": "摘要8", "info": "关于如何初始化网络，正则化和优化有着非常不同的观点。优化观点建；议权重应该足够大以成功传播信息，但是正则化希望其小一点。诸如随；机梯度下降这类对权重较小的增量更新，趋于停止在更靠近初始参数的", "keywords": "机梯度下降这类对权重较小的增量更新, 关于如何初始化网络, 优化观点建, 诸如随, 议权重应该足够大以成功传播信息", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "96807cfd-ff41-419a-883c-9cfecb14ff29", "label": "摘要9", "info": "情况下，提前终止的梯度下降和权重衰减不同，但是提供了一个宽松的；类比去考虑初始化的影响。我们可以将初始化参数 θ  为  θ  0  类比于强置；均值为 θ 0 的高斯先验p( θ )。从这个角度来看，选择 θ 0 接近0是有道理", "keywords": "提前终止的梯度下降和权重衰减不同, 我们可以将初始化参数, 情况下, 类比于强置, 均值为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5ca96d0e-0451-4878-9fe7-944058f3532f", "label": "摘要10", "info": "有些启发式方法可用于选择权重的初始大小。一种初始化m个输入和n；输出的全连接层的权重的启发式方法是从分布", "keywords": "一种初始化, 输出的全连接层的权重的启发式方法是从分布, 有些启发式方法可用于选择权重的初始大小, 个输入和", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0d69b18f-e165-46fd-82a0-276434b16fbf", "label": "摘要11", "info": "中采样权重，而Glorot and Bengio（2010）建", "keywords": "中采样权重", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0f248213-8a93-4522-a62f-f58713a4abc6", "label": "摘要12", "info": "议使用标准初始化 （normalized initialization）", "keywords": "议使用标准初始化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7d124d30-fa00-4cd9-aada-1a6833bed99f", "label": "摘要13", "info": "后一种启发式方法初始化所有的层，折衷于使其具有相同激活方差和使；其具有相同梯度方差之间。这假设网络是不含非线性的链式矩阵乘法，；据此推导得出。现实的神经网络显然会违反这个假设，但很多设计于线", "keywords": "但很多设计于线, 折衷于使其具有相同激活方差和使, 这假设网络是不含非线性的链式矩阵乘法, 后一种启发式方法初始化所有的层, 其具有相同梯度方差之间", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b02a85c3-28d7-4d68-9fb9-88294e855ffa", "label": "摘要14", "info": "Saxe  et  al.  （2013）推荐初始化为随机正交矩阵，仔细挑选负责每一层；非线性缩放或增益  （gain）因子g。他们得到了用于不同类型的非线性；激活函数的特定缩放因子。这种初始化方案也是启发于不含非线性的矩", "keywords": "推荐初始化为随机正交矩阵, 激活函数的特定缩放因子, 这种初始化方案也是启发于不含非线性的矩, 他们得到了用于不同类型的非线性, 仔细挑选负责每一层", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b051a8c6-f88e-4cd3-ab93-8a77b576fd45", "label": "摘要15", "info": "增加缩放因子g将网络推向网络前向传播时激活范数增加，反向传播时；梯度范数增加的区域。Sussillo（2014）表明，正确设置缩放因子足以训；练深达1000层的网络，而不需要使用正交初始化。这种方法的一个重要", "keywords": "将网络推向网络前向传播时激活范数增加, 梯度范数增加的区域, 反向传播时, 层的网络, 这种方法的一个重要", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4264a9b4-a98d-4b3d-b0c7-43538a634bc6", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；可惜，这些初始权重的最佳准则往往不会带来最佳效果。这可能有三种；不同的原因。首先，我们可能使用了错误的标准——它实际上并不利于", "keywords": "我们可能使用了错误的标准, 这些初始权重的最佳准则往往不会带来最佳效果, 它实际上并不利于, 这可能有三种, 不同的原因", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "958ae5c8-0cd6-4d13-8ce5-af04c072578c", "label": "摘要17", "info": "数值范围准则的一个缺点是，设置所有的初始权重具有相同的标准差，", "keywords": "数值范围准则的一个缺点是, 设置所有的初始权重具有相同的标准差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f181449b-70fd-48a4-973c-24e1a8142e36", "label": "摘要18", "info": "例如", "keywords": "例如", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a3efc137-f9ce-4cf9-999a-811d4f3b352e", "label": "摘要19", "info": "，会使得层很大时每个单一权重会变得极其小。", "keywords": "会使得层很大时每个单一权重会变得极其小", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "649f6a0f-0553-49ce-a3b0-c04121960db2", "label": "摘要20", "info": "Martens（2010）提出了一种被称为稀疏初始化  （sparse  initialization）；的替代方案，每个单元初始化为恰好有k个非零权重。这个想法保持该；单元输入的总数量独立于输入数目m，而不使单一权重元素的大小随m", "keywords": "个非零权重, 这个想法保持该, 而不使单一权重元素的大小随, 单元输入的总数量独立于输入数目, 提出了一种被称为稀疏初始化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "36d7e7aa-1fe1-4516-81b7-57c81947cf9f", "label": "摘要21", "info": "如果计算资源允许，将每层权重的初始数值范围设为超参数通常是个好；主意，使用第11.4.2节介绍的超参数搜索算法，如随机搜索，挑选这些；数值范围。是否选择使用密集或稀疏初始化也可以设为一个超参数。作", "keywords": "主意, 数值范围, 如随机搜索, 节介绍的超参数搜索算法, 使用第", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a5078c7c-0a10-434f-bda7-d880c53122f3", "label": "摘要22", "info": "目前为止，我们关注在权重的初始化上。幸运的是，其他参数的初始化；通常更容易。", "keywords": "其他参数的初始化, 幸运的是, 目前为止, 我们关注在权重的初始化上, 通常更容易", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "70560447-2a2b-4311-a030-7423913270ae", "label": "摘要23", "info": "设置偏置的方法必须和设置权重的方法协调。设置偏置为零通常在大多", "keywords": "设置偏置为零通常在大多, 设置偏置的方法必须和设置权重的方法协调", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d4941862-39a5-4665-a14b-c84cb11a08ed", "label": "摘要24", "info": "数权重初始化方案中是可行的。存在一些我们可能设置偏置为非零值的；情况：", "keywords": "存在一些我们可能设置偏置为非零值的, 数权重初始化方案中是可行的, 情况", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1312020b-4f6d-407e-b840-ccfe36a62b00", "label": "摘要25", "info": "如果偏置是作为输出单元，那么初始化偏置以获取正确的输出边缘；统计通常是有利的。要做到这一点，我们假设初始权重足够小，该；单元的输出仅由偏置决定。这说明设置偏置为应用于训练集上输出", "keywords": "单元的输出仅由偏置决定, 统计通常是有利的, 我们假设初始权重足够小, 如果偏置是作为输出单元, 这说明设置偏置为应用于训练集上输出", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a5cc4735-86bf-47c7-b820-7ba3a30a6823", "label": "摘要26", "info": "，那么我们可", "keywords": "那么我们可", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1fa44104-bde1-4172-b13f-6e95ffcbecfd", "label": "摘要27", "info": "另一种常见类型的参数是方差或精确度参数。例如，我们用以下模型进；行带条件方差估计的线性回归", "keywords": "另一种常见类型的参数是方差或精确度参数, 行带条件方差估计的线性回归, 例如, 我们用以下模型进", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ac6be952-2ec2-486c-a8f2-d8fd7fcd34e6", "label": "摘要28", "info": "其中β是精确度参数。通常我们能安全地初始化方差或精确度参数为1。；另一种方法假设初始权重足够接近零，设置偏置可以忽略权重的影响，；然后设定偏置以产生输出的正确边缘均值，并将方差参数设置为训练集", "keywords": "设置偏置可以忽略权重的影响, 通常我们能安全地初始化方差或精确度参数为, 其中, 然后设定偏置以产生输出的正确边缘均值, 另一种方法假设初始权重足够接近零", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "56080438-ef05-48f5-b482-6ada6eb75f6c", "label": "摘要29", "info": "除了这些初始化模型参数的简单常数或随机方法，还有可能使用机器学；习初始化模型参数。在本书第3部分讨论的一个常用策略是使用相同的", "keywords": "除了这些初始化模型参数的简单常数或随机方法, 在本书第, 部分讨论的一个常用策略是使用相同的, 还有可能使用机器学, 习初始化模型参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e5086b76-303e-4596-b468-e598e46b55e7", "label": "摘要30", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；输入数据集，用无监督模型训练出来的参数来初始化监督模型。我们也；可以在相关问题上使用监督训练。即使是在一个不相关的任务上运行监", "keywords": "可以在相关问题上使用监督训练, 输入数据集, 用无监督模型训练出来的参数来初始化监督模型, 我们也, 即使是在一个不相关的任务上运行监", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d60085f6-0f47-4106-9517-2fb59dfb5768", "label": "8.5：自适应学习率算法", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "9e60de25-bf17-4015-8f31-95a18e2c5b9b", "label": "摘要1", "info": "8.5.1　AdaGrad", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "804e282c-4683-4180-b742-ef92674405dd", "label": "摘要2", "info": "8.5.2　RMSProp", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ab4aea01-e433-4f4c-848a-63550e97fb16", "label": "摘要3", "info": "8.5.3　Adam", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9e9caf30-b0c3-451c-82b2-29c32e09b846", "label": "摘要4", "info": "8.5.4　选择正确的优化算法", "keywords": "选择正确的优化算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8f6b8359-23e3-497f-a0b0-146783e949aa", "label": "摘要5", "info": "神经网络研究员早就意识到学习率肯定是难以设置的超参数之一，因为；它对模型的性能有显著的影响。正如我们在第4.3节和第8.2节中所探讨；的，损失通常高度敏感于参数空间中的某些方向，而不敏感于其他。动", "keywords": "因为, 它对模型的性能有显著的影响, 节和第, 神经网络研究员早就意识到学习率肯定是难以设置的超参数之一, 节中所探讨", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f544a10b-b00a-4aeb-8fc3-9321545f34bd", "label": "摘要6", "info": "Delta-bar-delta  算法（Jacobs，1988）是一个早期的在训练时适应模型；参数各自学习率的启发式方法。该方法基于一个很简单的想法，如果损；失对于某个给定模型参数的偏导保持相同的符号，那么学习率应该增", "keywords": "那么学习率应该增, 算法, 参数各自学习率的启发式方法, 该方法基于一个很简单的想法, 如果损", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "193389da-4b06-443f-a8cb-4bd41d9d91c4", "label": "摘要7", "info": "最近，提出了一些增量（或者基于小批量）的算法来自适应模型参数的；学习率。这节将简要回顾其中一些算法。", "keywords": "这节将简要回顾其中一些算法, 的算法来自适应模型参数的, 提出了一些增量, 最近, 或者基于小批量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "64052bb7-4c54-426b-95be-e61678b96c47", "label": "摘要8", "info": "8.5.1　AdaGrad", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "442b9ea6-cef3-4166-9109-d350c2c7bbf4", "label": "摘要9", "info": "AdaGrad算法，如算法8.4所示，独立地适应所有模型参数的学习率，缩；放每个参数反比于其所有梯度历史平方值总和的平方根（Duchi et al. ，；2011）。具有损失最大偏导的参数相应地有一个快速下降的学习率，而", "keywords": "算法, 独立地适应所有模型参数的学习率, 具有损失最大偏导的参数相应地有一个快速下降的学习率, 放每个参数反比于其所有梯度历史平方值总和的平方根, 如算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1966b85f-64a0-4453-9e5b-829543d0cbe5", "label": "摘要10", "info": "在凸优化背景中，AdaGrad算法具有一些令人满意的理论性质。然而，", "keywords": "算法具有一些令人满意的理论性质, 然而, 在凸优化背景中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "07dfb2b6-b0e0-450c-ae77-2457e18917f6", "label": "摘要11", "info": "经验上已经发现，对于训练深度神经网络模型而言，从训练开始时积累；梯度平方会导致有效学习率过早和过量的减小。AdaGrad在某些深度学；习模型上效果不错，但不是全部。", "keywords": "在某些深度学, 经验上已经发现, 但不是全部, 习模型上效果不错, 梯度平方会导致有效学习率过早和过量的减小", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "089ca358-a8b0-46cb-9272-6d71753ab661", "label": "摘要12", "info": "算法8.4 　AdaGrad算法。", "keywords": "算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4fe9d504-2482-4123-8379-20c0ce836e52", "label": "摘要13", "info": "Require： 全局学习率", "keywords": "全局学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3af39288-f923-4e8f-8915-0b6813d1d1f1", "label": "摘要14", "info": "Require： 初始参数 θ", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "84267945-3e9f-4cae-b77b-dd3299e88e4b", "label": "摘要15", "info": "Require： 小常数δ，为了数值稳定大约设为10 −7", "keywords": "为了数值稳定大约设为, 小常数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "063f0f88-379b-4744-bc58-533c158580bd", "label": "摘要16", "info": "初始化梯度累积变量 r ＝0", "keywords": "初始化梯度累积变量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ae78eac2-b518-4fb7-ade1-062b6d9f9056", "label": "摘要17", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f5c13248-8eba-4b35-8733-1f462045cd18", "label": "摘要18", "info": "从训练集中采包含m个样本；标为  。", "keywords": "标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fd189eae-dd75-42c0-a22a-be0bd6f285f4", "label": "摘要19", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7abe8e43-6145-4830-a356-c0cecbc0252d", "label": "摘要20", "info": "累积平方梯度：", "keywords": "累积平方梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9f9ac61d-ffa3-4d5f-9af8-e6391082fe7b", "label": "摘要21", "info": "的小批量，对应目", "keywords": "的小批量, 对应目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "218f736e-151b-44e5-8d93-cc60d4298cb7", "label": "摘要22", "info": "计算更新：", "keywords": "计算更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fb298752-66ea-4f9d-8177-1a2a98ab8f56", "label": "摘要23", "info": "（逐元素地应用除和求平方根）", "keywords": "逐元素地应用除和求平方根", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "de2931ce-5b8a-4585-84d3-5c0dbcb110d6", "label": "摘要24", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cb18b1cb-47a5-4457-b5d8-e0cc05aa0014", "label": "摘要25", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "332a4954-760b-42f7-8751-e5355392d355", "label": "摘要26", "info": "8.5.2　RMSProp", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a0597476-986b-43ee-b538-bca9f56107ff", "label": "摘要27", "info": "RMSProp  算法（Hinton，2012）修改AdaGrad以在非凸设定下效果更；好，改变梯度积累为指数加权的移动平均。AdaGrad旨在应用于凸问题；时快速收敛。当应用于非凸函数训练神经网络时，学习轨迹可能穿过了", "keywords": "算法, 修改, 学习轨迹可能穿过了, 改变梯度积累为指数加权的移动平均, 旨在应用于凸问题", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7580001f-a266-47b2-9a07-500d6f80686f", "label": "摘要28", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；很多不同的结构，最终到达一个局部是凸碗的区域。AdaGrad根据平方；梯度的整个历史收缩学习率，可能使得学习率在达到这样的凸结构前就", "keywords": "可能使得学习率在达到这样的凸结构前就, 最终到达一个局部是凸碗的区域, 梯度的整个历史收缩学习率, 很多不同的结构, 根据平方", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3741f63a-26b7-4b55-963e-4236d6ee3c4a", "label": "摘要29", "info": "RMSProp的标准形式如算法8.5所示，结合Nesterov动量的形式如算法8.6；所示。相比于AdaGrad，使用移动平均引入了一个新的超参数ρ，用来控；制移动平均的长度范围。", "keywords": "使用移动平均引入了一个新的超参数, 动量的形式如算法, 相比于, 用来控, 制移动平均的长度范围", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5d519d74-fe2f-4cd1-b657-c9761e9d434f", "label": "摘要30", "info": "算法8.5 　RMSProp算法。", "keywords": "算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7fbcaf3b-1eff-4fe3-abed-8b55d4926b45", "label": "摘要31", "info": "Require： 全局学习率  ，衰减速率ρ", "keywords": "衰减速率, 全局学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6d1670cf-2ce5-4057-985c-d68b0fbff67f", "label": "摘要32", "info": "Require： 初始参数 θ", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3c06b38a-8e02-4796-b284-ee0ebd7e1333", "label": "摘要33", "info": "Require： 小常数δ，通常设为10 −6 （用于被小数除时的数值稳定）", "keywords": "通常设为, 用于被小数除时的数值稳定, 小常数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "48bc2c38-f308-4d2c-bd14-4b2373b177d6", "label": "摘要34", "info": "初始化累积变量 r ＝0", "keywords": "初始化累积变量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0cf8b121-31d9-41fd-9b83-3c87b1a346da", "label": "摘要35", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "398fecae-80e5-476e-aa1b-283e75fc03bb", "label": "摘要36", "info": "从训练集中采包含m个样本；标为  。", "keywords": "标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b84e0409-488f-47c1-84a2-18e5c4646030", "label": "摘要37", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "aba449aa-cea1-47ea-8d48-c6a9ba4edc76", "label": "摘要38", "info": "累积平方梯度：", "keywords": "累积平方梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9cfb92e0-e926-42f6-9822-cad263598f40", "label": "摘要39", "info": "的小批量，对应目", "keywords": "的小批量, 对应目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7c29d4a0-ee9f-4cb5-8dd2-126e8b039df6", "label": "摘要40", "info": "计算参数更新：", "keywords": "计算参数更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c084001d-d454-4639-b8bc-b2b557baf30f", "label": "摘要41", "info": "（", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "358fa50f-ba0e-4a38-97c6-525033e230e3", "label": "摘要42", "info": "逐元素应用）", "keywords": "逐元素应用", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a9b2b914-9ab1-48fc-bc9b-64d4875b6065", "label": "摘要43", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6da8c7fd-55d2-40a2-b84d-8672c80c1cef", "label": "摘要44", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d3a78e1c-6fe2-48b5-be73-923bf5fbb5c2", "label": "摘要45", "info": "算法8.6 　使用Nesterov动量的RMSProp算法。", "keywords": "使用, 算法, 动量的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2f3a3dc5-0774-4261-8efe-a9a83ecca3a5", "label": "摘要46", "info": "Require： 全局学习率  ，衰减速率ρ，动量系数α", "keywords": "衰减速率, 动量系数, 全局学习率", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "81e8a5a5-8990-4c79-87c0-8462014c0c18", "label": "摘要47", "info": "Require： 初始参数 θ ，初始参数 ν", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "342adb72-8d97-4e78-a16a-557696765092", "label": "摘要48", "info": "初始化累积变量 r ＝0", "keywords": "初始化累积变量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "47258ae2-baac-4561-845f-933538eb6f69", "label": "摘要49", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "77043b6d-0efc-4034-8301-3fd6b6bdaa08", "label": "摘要50", "info": "从训练集中采包含m个样本；标为  。", "keywords": "标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "255b8f0f-fc28-4084-a4b4-857f2c0142fd", "label": "摘要51", "info": "计算临时更新：", "keywords": "计算临时更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "282d0221-b27f-4e09-a61e-1fa3a165e0b6", "label": "摘要52", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b02592df-d255-4d4c-bfb8-486765b89ce5", "label": "摘要53", "info": "累积梯度：", "keywords": "累积梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fd7e8628-55ae-4d86-b916-75aa785e9ae0", "label": "摘要54", "info": "的小批量，对应目", "keywords": "的小批量, 对应目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "191ac078-c5ae-49c2-a543-eaa4386842e5", "label": "摘要55", "info": "计算速度更新：", "keywords": "计算速度更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6a395206-6887-4c15-a380-e2782429290a", "label": "摘要56", "info": "（  逐元素应用）", "keywords": "逐元素应用", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "23c95708-d4b1-4675-88d7-b2fb1e6085c8", "label": "摘要57", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6b9a6112-9588-4526-bd9e-64dddab95d80", "label": "摘要58", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "122064c8-9292-426a-84ef-8b6e55deed45", "label": "摘要59", "info": "经验上，RMSProp已被证明是一种有效且实用的深度神经网络优化算；法。目前它是深度学习从业者经常采用的优化方法之一。", "keywords": "已被证明是一种有效且实用的深度神经网络优化算, 经验上, 目前它是深度学习从业者经常采用的优化方法之一", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "577d0ae0-7a5f-4496-9b22-585a690c5fa4", "label": "摘要60", "info": "8.5.3　Adam", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7157c2ef-9b6a-4cd4-b73f-a8b9d95222ce", "label": "摘要61", "info": "Adam （Kingma and Ba，2014）是另一种学习率自适应的优化算法，如", "keywords": "是另一种学习率自适应的优化算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c40daf28-7ee2-40de-b15f-783266e16d36", "label": "摘要62", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；算法8.7所示。“Adam”这个名字派生自短语“adaptive  moments”。早期算；法背景下，它也许最好被看作结合RMSProp和具有一些重要区别的动量", "keywords": "算法, 和具有一些重要区别的动量, 这个名字派生自短语, 早期算, 所示", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9879a39c-2b21-4689-a099-760b2ed2a73c", "label": "摘要63", "info": "算法8.7 　Adam算法。", "keywords": "算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b8669e64-50e8-4fae-8f07-889b9e47dd0b", "label": "摘要64", "info": "Require： 步长  （建议默认为：0.001）", "keywords": "建议默认为, 步长", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b13483f9-e448-4bf1-97e7-1f5a6857ed7f", "label": "摘要65", "info": "Require： 矩估计的指数衰减速率，ρ  1  和ρ  2  在区间［0,1）内。（建议；默认为：分别为0.9和0.999）", "keywords": "默认为, 分别为, 矩估计的指数衰减速率, 在区间, 建议", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "792b71ff-cf23-4596-87bb-4de436735d97", "label": "摘要66", "info": "Require： 用于数值稳定的小常数δ（建议默认为：10 −8 ）", "keywords": "用于数值稳定的小常数, 建议默认为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0f2d6630-a1a5-46cb-8399-99d9f726e834", "label": "摘要67", "info": "Require： 初始参数 θ", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "156cdffc-6fb0-4bd2-803a-d6a882eb549e", "label": "摘要68", "info": "初始化一阶和二阶矩变量 s ＝0， r ＝0", "keywords": "初始化一阶和二阶矩变量", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8127021f-aae2-4fee-94df-ca12ce1bf5a8", "label": "摘要69", "info": "初始化时间步t＝0", "keywords": "初始化时间步", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ce545bc8-e6ab-4d31-90f5-993ec2944afc", "label": "摘要70", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bddb0daa-43f0-481b-baa9-3c936e5a4fd0", "label": "摘要71", "info": "从训练集中采包含m个样本；标为  。", "keywords": "标为, 个样本, 从训练集中采包含", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "889839b1-b89c-4da3-a28a-e4600e107c4b", "label": "摘要72", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "93b5d6e1-673c-48f0-a7ea-96468e315b58", "label": "摘要73", "info": "t←t＋1", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "36b52f94-1957-4c2b-9bbf-3729068eb74d", "label": "摘要74", "info": "的小批量，对应目", "keywords": "的小批量, 对应目", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "39f6b0d3-3dbc-42cc-ad88-ef0b8bdcde4c", "label": "摘要75", "info": "更新有偏一阶矩估计：", "keywords": "更新有偏一阶矩估计", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "507b787b-ae5f-4045-8072-079b759d61f1", "label": "摘要76", "info": "更新有偏二阶矩估计：", "keywords": "更新有偏二阶矩估计", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d56b712b-22a7-45be-8b6b-8d3e4140d725", "label": "摘要77", "info": "修正一阶矩的偏差：", "keywords": "修正一阶矩的偏差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9f043dc3-75fd-48fc-bd8a-596b6a807e70", "label": "摘要78", "info": "修正二阶矩的偏差：", "keywords": "修正二阶矩的偏差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5c5a8033-befd-43e4-afbd-80aa006aeb51", "label": "摘要79", "info": "计算更新：", "keywords": "计算更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cc482a6a-c0df-4a60-bcc4-aaaa5e9311be", "label": "摘要80", "info": "（逐元素应用操作）", "keywords": "逐元素应用操作", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1eeb12eb-b3dc-43ae-9d63-820f7fa15f99", "label": "摘要81", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ab4a1e8a-36ea-4315-94e9-500549461765", "label": "摘要82", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2619e1eb-893c-4843-bd15-659cc845f0e5", "label": "摘要83", "info": "8.5.4　选择正确的优化算法", "keywords": "选择正确的优化算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9f56fdee-7cd5-428e-b838-796714f8954d", "label": "摘要84", "info": "在本节中，我们讨论了一系列算法，通过自适应每个模型参数的学习率；以解决优化深度模型中的难题。此时，一个自然的问题是：该选择哪种；算法呢？", "keywords": "算法呢, 在本节中, 通过自适应每个模型参数的学习率, 一个自然的问题是, 该选择哪种", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "24bc24ff-6cd5-4837-8429-0e1aaeb8d3b2", "label": "摘要85", "info": "遗憾的是，目前在这一点上没有达成共识。Schaul  et  al.  （2014）展示；了许多优化算法在大量学习任务上极具价值的比较。虽然结果表明，具；有自适应学习率（以RMSProp和AdaDelta为代表）的算法族表现得相当", "keywords": "虽然结果表明, 了许多优化算法在大量学习任务上极具价值的比较, 的算法族表现得相当, 有自适应学习率, 目前在这一点上没有达成共识", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "517bdae5-0a24-433c-9dfc-57c09ac34e24", "label": "摘要86", "info": "目前，最流行并且使用很高的优化算法包括SGD、具动量的SGD、；RMSProp、具动量的RMSProp、AdaDelta和Adam。此时，选择哪一个；算法似乎主要取决于使用者对算法的熟悉程度（以便调节超参数）。", "keywords": "具动量的, 选择哪一个, 以便调节超参数, 目前, 算法似乎主要取决于使用者对算法的熟悉程度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bf1adf8e-f2bf-47e9-b821-b0e68b2b5941", "label": "摘要87", "info": "8.5.1　AdaGrad", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "54a4ae6c-8cbd-4e5a-a3b3-58243cb2943a", "label": "摘要88", "info": "8.5.2　RMSProp", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b7e1f801-8ac6-44bb-9a9c-35187daf1a47", "label": "摘要89", "info": "8.5.3　Adam", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0a932af9-1f33-4a8a-b879-3839f6cb5e65", "label": "摘要90", "info": "8.5.4　选择正确的优化算；法", "keywords": "选择正确的优化算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "label": "8.6：二阶近似方法", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "191c25f7-c9a9-42e0-8b25-e44e33642d35", "label": "摘要1", "info": "8.6.1　牛顿法", "keywords": "牛顿法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "739a83bf-a224-4c4e-aa7e-856f3d149fb1", "label": "摘要2", "info": "8.6.2　共轭梯度", "keywords": "共轭梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "64aec55e-77a3-4fc0-8468-098f3e909614", "label": "摘要3", "info": "8.6.3　BFGS", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8602e2d7-ebdc-4699-b51b-8199eac558e6", "label": "摘要4", "info": "在本节中，我们会讨论训练深度神经网络的二阶方法。参考LeCun et al.；（1998a）了解该问题的早期处理方法。为表述简单起见，我们只考察；目标函数为经验风险：", "keywords": "参考, 我们会讨论训练深度神经网络的二阶方法, 在本节中, 目标函数为经验风险, 为表述简单起见", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d8d08228-75ba-44eb-88e2-6193fa2c3c1e", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；然而，我们在这里讨论的方法很容易扩展到更一般的目标函数，例如，；第7章讨论的包括参数正则项的函数。", "keywords": "章讨论的包括参数正则项的函数, 我们在这里讨论的方法很容易扩展到更一般的目标函数, 然而, 例如", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "db124520-cde3-478b-9fee-e055bedfc437", "label": "摘要6", "info": "8.6.1　牛顿法", "keywords": "牛顿法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "69c8e743-7777-41c3-bda1-fb156be35aba", "label": "摘要7", "info": "在第4.3节，我们介绍了二阶梯度方法。与一阶方法相比，二阶方法使；用二阶导数改进了优化。最广泛使用的二阶方法是牛顿法。我们现在更；详细地描述牛顿法，重点在其应用于神经网络的训练。", "keywords": "我们介绍了二阶梯度方法, 与一阶方法相比, 重点在其应用于神经网络的训练, 在第, 用二阶导数改进了优化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8d5a90a3-3204-4932-8b53-4e3c36a1c098", "label": "摘要8", "info": "牛顿法是基于二阶泰勒级数展开在某点  θ  0  附近来近似J  (  θ  )的优化方；法，其忽略了高阶导数：", "keywords": "牛顿法是基于二阶泰勒级数展开在某点, 的优化方, 其忽略了高阶导数, 附近来近似", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bb6475ee-ea1a-4b23-8f24-a23553c7f92d", "label": "摘要9", "info": "其中 H 是J相对于 θ 的Hessian矩阵在 θ  0  处的估计。如果我们再求解这；个函数的临界点，将得到牛顿参数更新规则：", "keywords": "处的估计, 如果我们再求解这, 相对于, 其中, 矩阵在", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5b7d4858-b31c-4bb6-9482-fcc6c197fe8e", "label": "摘要10", "info": "因此，对于局部的二次函数（具有正定的  H  ），用  H  -1  重新调整梯；度，牛顿法会直接跳到极小值。如果目标函数是凸的但非二次的（有高；阶项），该更新将是迭代的，得到和牛顿法相关的算法，如算法8.8所", "keywords": "对于局部的二次函数, 牛顿法会直接跳到极小值, 具有正定的, 因此, 有高", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "167f1f88-31dd-436d-92e5-398fbcde193b", "label": "摘要11", "info": "对于非二次的表面，只要Hessian矩阵保持正定，牛顿法能够迭代地应；用。这意味着一个两步迭代过程。首先，更新或计算Hessian逆（通过更；新二阶近似）。其次，根据式（8.27）更新参数。", "keywords": "其次, 对于非二次的表面, 矩阵保持正定, 牛顿法能够迭代地应, 这意味着一个两步迭代过程", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b292238a-f958-4ad5-a15b-2c5209d590f3", "label": "摘要12", "info": "算法8.8 　目标为", "keywords": "算法, 目标为", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5f1ea752-0b6b-4ad1-9495-da51b98ab58b", "label": "摘要13", "info": "的牛顿法。", "keywords": "的牛顿法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4821e48b-8c92-4fc2-9859-f2bbd917ed09", "label": "摘要14", "info": "Require： 初始参数 θ 0", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "56ed52cb-0f98-476b-ad2e-fe3e90b55858", "label": "摘要15", "info": "Require： 包含m个样本的训练集", "keywords": "包含, 个样本的训练集", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a5d5bff2-1a3c-4e26-a79e-85992a1b9fb0", "label": "摘要16", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6a29bfd1-5e7b-4582-b4f0-9a5061fce081", "label": "摘要17", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e39a94e1-07ef-4026-be9a-ba5fb3d029cc", "label": "摘要18", "info": "计算Hessian矩阵：", "keywords": "计算, 矩阵", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c1f859b5-3c33-4a99-a1bf-36f5d1105435", "label": "摘要19", "info": "计算Hessian逆：", "keywords": "计算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e24eaa59-17ef-4fbb-9f8d-a0ee568bca25", "label": "摘要20", "info": "计算更新：", "keywords": "计算更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8264844b-59ae-4765-b118-bf6a2bfcacd1", "label": "摘要21", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "40c73d4c-d2a8-4025-9241-9b39f19272aa", "label": "摘要22", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "86b8a11e-85e8-415d-a6a6-15a335a81491", "label": "摘要23", "info": "在第8.2.3节，我们讨论了牛顿法只适用于Hessian矩阵是正定的情况。在；深度学习中，目标函数的表面通常非凸（有很多特征），如鞍点。因此；使用牛顿法是有问题的。如果Hessian矩阵的特征值并不都是正的，例", "keywords": "如果, 我们讨论了牛顿法只适用于, 因此, 深度学习中, 使用牛顿法是有问题的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "253b5960-095b-4519-a234-f64f5ca19cda", "label": "摘要24", "info": "这个正则化策略用于牛顿法的近似，例如Levenberg-Marquardt算法；（Levenberg，1944；Marquardt，1963），只要Hessian矩阵的负特征值；仍然相对接近零，效果就会很好。在曲率方向更极端的情况下，α的值", "keywords": "算法, 效果就会很好, 例如, 这个正则化策略用于牛顿法的近似, 在曲率方向更极端的情况下", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5daed29d-babd-4e33-bd16-6674fcc5d82d", "label": "摘要25", "info": "除了目标函数的某些特征带来的挑战，如鞍点，牛顿法用于训练大型神；经网络还受限于其显著的计算负担。Hessian矩阵中元素数目是参数数量；的平方，因此，如果参数数目为k（甚至是在非常小的神经网络中k也可", "keywords": "经网络还受限于其显著的计算负担, 如果参数数目为, 因此, 牛顿法用于训练大型神, 也可", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "00e5aaef-5f4b-4bd9-9e7f-1ee30411cea1", "label": "摘要26", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；能是百万级别），牛顿法需要计算k×k矩阵的逆，计算复杂度为O(k；)。另外，由于参数将每次更新都会改变，每次训练迭代都需要计算", "keywords": "由于参数将每次更新都会改变, 牛顿法需要计算, 每次训练迭代都需要计算, 矩阵的逆, 能是百万级别", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b02da623-3638-474f-9d35-cf1367287b2e", "label": "摘要27", "info": "3", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b8e302ed-3209-4c9a-9ac8-13e7fb965d1c", "label": "摘要28", "info": "8.6.2　共轭梯度", "keywords": "共轭梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "85edf61c-97cb-4d03-8b55-73b2f33c0fef", "label": "摘要29", "info": "共轭梯度是一种通过迭代下降的共轭方向  （conjugate  directions）以有；效避免Hessian矩阵求逆计算的方法。这种方法的灵感来自对最速下降方；法弱点的仔细研究（详细信息请查看第4.3节），其中线搜索迭代地用", "keywords": "效避免, 详细信息请查看第, 共轭梯度是一种通过迭代下降的共轭方向, 法弱点的仔细研究, 以有", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7d31d8cb-5f06-4a65-9115-a23262fe247f", "label": "摘要30", "info": "图8.6　将最速下降法应用于二次代价表面。在每个步骤中，最速下降法沿着由初始点处的梯度；定义的线跳到最低代价的点。这解决了图4.6中使用固定学习率所遇到的一些问题，但即使使用；最佳步长，算法仍然朝最优方向曲折前进。根据定义，在沿着给定方向的目标最小值处，最终", "keywords": "最速下降法沿着由初始点处的梯度, 最终, 定义的线跳到最低代价的点, 但即使使用, 这解决了图", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3b5038cc-780d-4c80-b8fc-0f53bcd863d2", "label": "摘要31", "info": "假设上一个搜索方向是", "keywords": "假设上一个搜索方向是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0c9c7810-6e2d-485b-aab5-4bff28a364d8", "label": "摘要32", "info": "处的方向导数为零：", "keywords": "处的方向导数为零", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e0981c5f-19ef-4967-8f9b-7761073cd44d", "label": "摘要33", "info": "度定义了当前的搜索方向，", "keywords": "度定义了当前的搜索方向", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f217af67-dfba-4523-9171-17316e3913e2", "label": "摘要34", "info": "。因此方向   正交于", "keywords": "正交于, 因此方向", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "225bb416-aa03-4d61-ad81-90d7106221c4", "label": "摘要35", "info": "。在极小值处，线搜索终止，方向；。因为该点的梯；将不会贡献于方向", "keywords": "因为该点的梯, 在极小值处, 将不会贡献于方向, 方向, 线搜索终止", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "37264da2-88f3-4efd-a106-14129c3244bb", "label": "摘要36", "info": "和   之间的关系如图8.6所示。如图展示的那样，下降正交方；向的选择不会保持前一搜索方向上的最小值。这产生了锯齿形的过程。；在当前梯度方向下降到极小值，我们必须重新最小化之前梯度方向上的", "keywords": "之间的关系如图, 向的选择不会保持前一搜索方向上的最小值, 我们必须重新最小化之前梯度方向上的, 这产生了锯齿形的过程, 如图展示的那样", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8d20a82d-5500-44bf-8e5e-9457c58dbfff", "label": "摘要37", "info": "在共轭梯度法中，我们寻求一个和先前线搜索方向共轭 （conjugate）的；搜索方向，即它不会撤销该方向上的进展。在训练迭代t时，下一步的；搜索方向 d t 的形式如下：", "keywords": "的形式如下, 我们寻求一个和先前线搜索方向共轭, 下一步的, 搜索方向, 即它不会撤销该方向上的进展", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4620a938-4b7d-4d84-ae7d-4542c74c8da7", "label": "摘要38", "info": "其中，系数β  t  的大小控制我们应沿方向  d  t−1  加回多少到当前搜索方向；上。", "keywords": "加回多少到当前搜索方向, 其中, 系数, 的大小控制我们应沿方向", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cdbc38d1-f306-489f-9e51-3b679793c416", "label": "摘要39", "info": "如果", "keywords": "如果", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9ba5b0b7-d23a-4372-a415-7b1876182c68", "label": "摘要40", "info": "，其中  H  是Hessian矩阵，则两", "keywords": "则两, 矩阵, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3900cd58-14fb-446f-b686-91120b66ede5", "label": "摘要41", "info": "个方向 d t 和 d t−1 被称为共轭的。", "keywords": "个方向, 被称为共轭的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "3ed1d176-68b6-4d54-854a-04421fa44d55", "label": "摘要42", "info": "适应共轭的直接方法会涉及  H  特征向量的计算以选择β  t  。这将无法满；足我们的开发目标：寻找在大问题比牛顿法计算更加可行的方法。我们；能否不进行这些计算而得到共轭方向？幸运的是，这个问题的答案是肯", "keywords": "这个问题的答案是肯, 特征向量的计算以选择, 幸运的是, 我们, 能否不进行这些计算而得到共轭方向", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0dc65fae-22cf-4546-9a70-cca5ba6cb3d5", "label": "摘要43", "info": "两种用于计算β t 的流行方法是", "keywords": "两种用于计算, 的流行方法是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "66bd07e7-e9c0-4994-9d62-99b4cec59373", "label": "摘要44", "info": "（1）Fletcher-Reeves：", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d6bff36f-3187-4c6b-a5a0-f1c87a2f3018", "label": "摘要45", "info": "（2）Polak-Ribi`ere：", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6538e200-927d-42f5-820c-9ed89ab0b623", "label": "摘要46", "info": "对于二次曲面而言，共轭方向确保梯度沿着前一方向大小不变。因此，", "keywords": "共轭方向确保梯度沿着前一方向大小不变, 因此, 对于二次曲面而言", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6942ef44-6f1d-4b48-8949-333532c9d1c2", "label": "摘要47", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；我们在前一方向上仍然是极小值。其结果是，在k-维参数空间中，共轭；梯度只需要至多k次线搜索就能达到极小值。共轭梯度算法如算法8.9所", "keywords": "其结果是, 我们在前一方向上仍然是极小值, 次线搜索就能达到极小值, 共轭梯度算法如算法, 维参数空间中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f9d5c9c9-19a4-4d29-9c95-27a0783687c4", "label": "摘要48", "info": "算法8.9 　共轭梯度方法。", "keywords": "共轭梯度方法, 算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "51d9c436-2e7b-4368-b886-60e270a149f3", "label": "摘要49", "info": "Require： 初始参数 θ 0", "keywords": "初始参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "01ce8201-0b54-4004-8a3e-484872b8779d", "label": "摘要50", "info": "Require： 包含m个样本的训练集", "keywords": "包含, 个样本的训练集", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c0ee11df-0993-488d-93b3-cb75414673b7", "label": "摘要51", "info": "初始化 ρ 0 ＝0", "keywords": "初始化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b41df16e-a9a2-43d0-a8b3-712fac1c3157", "label": "摘要52", "info": "初始化g 0 ＝0", "keywords": "初始化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7b5283e8-02e6-47cf-9158-b9e0416b9fa5", "label": "摘要53", "info": "初始化t＝1", "keywords": "初始化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "226961f4-5015-4804-bc5c-aa6855ccf5cb", "label": "摘要54", "info": "while 没有达到停止准则do", "keywords": "没有达到停止准则", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "75eb7a7c-b9c0-4eb8-ad2a-ea0dadfe691c", "label": "摘要55", "info": "初始化梯度g t ＝0", "keywords": "初始化梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "31d9988e-32fc-4c3c-b75b-9a92337d2419", "label": "摘要56", "info": "计算梯度：", "keywords": "计算梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "823484c9-21b3-436e-8d1f-00b554e91ea7", "label": "摘要57", "info": "计算", "keywords": "计算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "06555872-bba6-4a7c-a461-bd0507be2ca7", "label": "摘要58", "info": "（非线性共轭梯度：视情况可重置β；时，如k＝5）", "keywords": "视情况可重置, 非线性共轭梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7a930c84-8f3e-495d-91e6-4e434001d09c", "label": "摘要59", "info": "t  为零，例如t是常数k的倍数", "keywords": "为零, 的倍数, 例如, 是常数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c8fe74f3-23ec-4ab1-b0cf-dbc8dcb60710", "label": "摘要60", "info": "计算搜索方向：", "keywords": "计算搜索方向", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "eef1ac03-537c-4c07-b63f-81e48d299dc9", "label": "摘要61", "info": "执行线搜索寻找：", "keywords": "执行线搜索寻找", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "09371340-ad71-48d6-ae0a-d124c02341ff", "label": "摘要62", "info": "（对于真正二次的代价函数，存在   的解析解，而无须显式地搜", "keywords": "对于真正二次的代价函数, 的解析解, 而无须显式地搜, 存在", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "54f4abc9-67c3-4c4b-9c18-6f2771d24c96", "label": "摘要63", "info": "索）", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "729abd36-3e6c-4da8-9ac2-c3123fb64120", "label": "摘要64", "info": "应用更新：", "keywords": "应用更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "092aaba0-8675-42a2-a4ad-8e741f42870f", "label": "摘要65", "info": "t←t＋1", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6fc7c502-a5a9-42ec-8dfc-8e0698800b20", "label": "摘要66", "info": "end while", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "df36945f-fa45-44ab-8856-1566fffcc8df", "label": "摘要67", "info": "非线性共轭梯度：  目前，我们已经讨论了用于二次目标函数的共轭梯；度法。当然，本章我们主要关注于探索训练神经网络和其他相关深度学；习模型的优化方法，其对应的目标函数比二次函数复杂得多。或许令人", "keywords": "本章我们主要关注于探索训练神经网络和其他相关深度学, 其对应的目标函数比二次函数复杂得多, 习模型的优化方法, 或许令人, 目前", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7d3dbd36-bcc5-4b1b-8c41-69f9a33c7b0b", "label": "摘要68", "info": "实践者报告，在实践中使用非线性共轭梯度算法训练神经网络是合理；的，尽管在开始非线性共轭梯度前使用随机梯度下降迭代若干步来初始；化效果更好。另外，尽管（非线性）共轭梯度算法传统上作为批方法，", "keywords": "共轭梯度算法传统上作为批方法, 实践者报告, 化效果更好, 在实践中使用非线性共轭梯度算法训练神经网络是合理, 非线性", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a4984c17-3cd0-4004-b3b5-05549db6d010", "label": "摘要69", "info": "8.6.3　BFGS", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "077d7893-4991-45d4-804a-8ba8d1562404", "label": "摘要70", "info": "Broyden-Fletcher-Goldfarb-Shanno（BFGS）  算法具有牛顿法的一些；优点，但没有牛顿法的计算负担。在这方面，BFGS和CG很像。然而，；BFGS使用了一个更直接的方法近似牛顿更新。回顾牛顿更新，由下式", "keywords": "回顾牛顿更新, 但没有牛顿法的计算负担, 然而, 优点, 使用了一个更直接的方法近似牛顿更新", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c6d7b0c0-0ffd-468a-b956-e63ceffb9e71", "label": "摘要71", "info": "其中， H 是J相对于  θ 的Hessian矩阵在 θ  0  处的估计。运用牛顿法的主；要计算难点在于计算Hessian逆 H  -1  。拟牛顿法所采用的方法（BFGS是；其中最突出的）是使用矩阵  M  t  近似逆，迭代地低秩更新精度以更好地", "keywords": "处的估计, 相对于, 拟牛顿法所采用的方法, 其中, 矩阵在", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "91613096-4314-4221-8973-7b8c3375b603", "label": "摘要72", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；近似 H -1 。", "keywords": "近似", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2c756682-29c4-4fd7-9e62-ba68c07735b9", "label": "摘要73", "info": "BFGS近似的说明和推导出现在很多关于优化的教科书中，包括；Luenberger（1984）。", "keywords": "包括, 近似的说明和推导出现在很多关于优化的教科书中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b4704ce2-2044-42d2-b6c1-ce52ceef7503", "label": "摘要74", "info": "当Hessian逆近似 M t 更新时，下降方向 ρ t 为 ρ t =M t g t 。该方向上的线；搜索用于决定该方向上的步长  。参数的最后更新为", "keywords": "参数的最后更新为, 更新时, 搜索用于决定该方向上的步长, 该方向上的线, 逆近似", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "bcfe25d7-7d83-4cd3-9aae-95a35c763e38", "label": "摘要75", "info": "和共轭梯度法相似，BFGS算法迭代一系列线搜索，其方向含二阶信；息。然而和共轭梯度不同的是，该方法的成功并不严重依赖于线搜索寻；找该方向上和真正极小值很近的一点。因此，相比于共轭梯度，BFGS", "keywords": "然而和共轭梯度不同的是, 算法迭代一系列线搜索, 相比于共轭梯度, 因此, 该方法的成功并不严重依赖于线搜索寻", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e2c4ec39-1efd-47f3-b450-bf88fe81ebac", "label": "摘要76", "info": "存储受限的BFGS（或L-BFGS）  　通过避免存储完整的Hessian逆近似；M  ，BFGS算法的存储代价可以显著降低。L-BFGS算法使用和BFGS算；法相同的方法计算  M  的近似，但起始假设是  M  (t−1)  是单位矩阵，而不", "keywords": "但起始假设是, 算法的存储代价可以显著降低, 的近似, 存储受限的, 是单位矩阵", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7bb2f54c-09fd-4665-9086-b32d5ec08225", "label": "摘要77", "info": "8.6.1　牛顿法", "keywords": "牛顿法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9741d575-ccd6-4bc1-83bc-c4b700515668", "label": "摘要78", "info": "8.6.2　共轭梯度", "keywords": "共轭梯度", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9fadce69-ef70-4b59-a023-327ef3bc3a3d", "label": "摘要79", "info": "8.6.3　BFGS", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "label": "8.7：优化策略和元算法", "level": 2, "group": "chapter-8", "type": "子章節"}, {"id": "eca2bb4e-e8bc-49b1-a972-c1f376aba63c", "label": "摘要1", "info": "8.7.1　批标准化", "keywords": "批标准化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f27404cd-fbb5-41ab-918a-03d87b75134c", "label": "摘要2", "info": "8.7.2　坐标下降", "keywords": "坐标下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "743f6505-29b1-4f5c-a1a8-8982cdd93fce", "label": "摘要3", "info": "8.7.3　Polyak平均", "keywords": "平均", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e2842942-ce8c-414e-a078-47a7213bd15a", "label": "摘要4", "info": "8.7.4　监督预训练", "keywords": "监督预训练", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2e8a764c-d346-4297-98c8-3a10b6e046cd", "label": "摘要5", "info": "8.7.5　设计有助于优化的模型", "keywords": "设计有助于优化的模型", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cff0b030-b022-4c1a-b454-0881e9e97b83", "label": "摘要6", "info": "8.7.6　延拓法和课程学习", "keywords": "延拓法和课程学习", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "8fbdd7cf-7eff-4b65-a5e7-40633ab52e90", "label": "摘要7", "info": "许多优化技术并非真正的算法，而是一般化的模板，可以特定地产生算；法，或是并入到很多不同的算法中。", "keywords": "而是一般化的模板, 可以特定地产生算, 或是并入到很多不同的算法中, 许多优化技术并非真正的算法", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "baebe870-83d1-427f-83f2-11fce326641f", "label": "摘要8", "info": "8.7.1　批标准化", "keywords": "批标准化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "1c746585-ce6d-4b25-8bbe-93d90a2832c5", "label": "摘要9", "info": "批标准化（Ioffe  and  Szegedy，2015）是优化深度神经网络中最激动人；心的最新创新之一。实际上它并不是一个优化算法，而是一个自适应的；重参数化的方法，试图解决训练非常深的模型的困难。", "keywords": "是优化深度神经网络中最激动人, 试图解决训练非常深的模型的困难, 实际上它并不是一个优化算法, 批标准化, 心的最新创新之一", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "33e03774-7df1-4054-bdce-2d6e6d310125", "label": "摘要10", "info": "非常深的模型会涉及多个函数或层组合。在其他层不改变的假设下，梯；度用于如何更新每一个参数。在实践中，我们同时更新所有层。当我们；进行更新时，可能会发生一些意想不到的结果，这是因为许多组合在一", "keywords": "这是因为许多组合在一, 进行更新时, 我们同时更新所有层, 可能会发生一些意想不到的结果, 度用于如何更新每一个参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d8d9746c-ddac-48d4-8161-46622f4e6d73", "label": "摘要11", "info": "。想想我们在更新；什么。近似   的一阶泰勒级数会预测   的值下降；望   下降0.1，那么梯度中的一阶信息表明我们应设置学习率   为", "keywords": "什么, 的值下降, 下降, 的一阶泰勒级数会预测, 近似", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b847978f-cfd0-42cc-8419-45bc285ece1f", "label": "摘要12", "info": "这个更新中所产生的一个二阶项示例是", "keywords": "这个更新中所产生的一个二阶项示例是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "25f402fc-23ed-4613-b5f8-1bd0564158f1", "label": "摘要13", "info": "。如果", "keywords": "如果", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "85203381-7ed3-4f47-9b86-cc65102d0fa9", "label": "摘要14", "info": "很小，那么该项可以忽略不计。而如果层3到层", "keywords": "而如果层, 那么该项可以忽略不计, 到层, 很小", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "20f85bf2-1f34-47be-a8a6-640a03c6f06e", "label": "摘要15", "info": "l的权重都比1大时，该项可能会指数级大。这使得我们很难选择一个合；适的学习率，因为某一层中参数更新的效果很大程度上取决于其他所有；层。二阶优化算法通过考虑二阶相互影响来解决这个问题，但我们可以", "keywords": "大时, 二阶优化算法通过考虑二阶相互影响来解决这个问题, 适的学习率, 的权重都比, 这使得我们很难选择一个合", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "39ab6ece-0abb-4bf3-8ee9-f48320f9d658", "label": "摘要16", "info": "批标准化提出了一种几乎可以重参数化所有深度网络的优雅方法。重参；数化显著减少了多层之间协调更新的问题。批标准化可应用于网络的任；何输入层或隐藏层。设  H  是需要标准化的某层的小批量激活函数，排", "keywords": "是需要标准化的某层的小批量激活函数, 重参, 何输入层或隐藏层, 批标准化提出了一种几乎可以重参数化所有深度网络的优雅方法, 数化显著减少了多层之间协调更新的问题", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0702d83c-440b-4719-9c57-d38235890795", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其中 µ 是包含每个单元均值的向量， σ 是包含每个单元标准差的向量。；此处的算术是基于广播向量  µ 和向量  σ  应用于矩阵  H  的每一行。在每", "keywords": "是包含每个单元均值的向量, 和向量, 其中, 应用于矩阵, 在每", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "31bf1c4b-ebdf-4769-b89a-eb2cdf47ce30", "label": "摘要18", "info": "在训练阶段，", "keywords": "在训练阶段", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "20cb3ec1-8ee9-4ef6-998d-e82322688216", "label": "摘要19", "info": "和", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a9bc96d1-d6e0-4fc7-a841-94d9f14fcaad", "label": "摘要20", "info": "其中δ是个很小的正值，比如10  −8  ，以强制避免遇到   的梯度在z＝0；处未定义的问题。至关重要的是，我们反向传播这些操作，来计算均值；和标准差，并应用它们于标准化  H  。这意味着，梯度不会再简单地增", "keywords": "和标准差, 是个很小的正值, 处未定义的问题, 以强制避免遇到, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "532716b3-d0f2-4bee-8791-04c7a795b3e6", "label": "摘要21", "info": "在测试阶段， µ 和 σ 可以被替换为训练阶段收集的运行均值。这使得模；型可以对单一样本评估，而无须使用定义于整个小批量的 µ 和 σ 。", "keywords": "型可以对单一样本评估, 可以被替换为训练阶段收集的运行均值, 在测试阶段, 这使得模, 而无须使用定义于整个小批量的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "e01d2d57-0120-4d4a-adcc-017b6091b9e2", "label": "摘要22", "info": "回顾例子；很大程度地解决学习这个模型的问题。假设x采样自一个单位高斯，那；么h  l−1 也是来自高斯，因为从x到h  l  的变换是线性的。然而，h  l−1  不再", "keywords": "然而, 采样自一个单位高斯, 不再, 也是来自高斯, 的变换是线性的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ed4c72d0-c450-43fe-bf87-eb7858aa1670", "label": "摘要23", "info": "，我们看到，可以通过标准化h  l−1", "keywords": "可以通过标准化, 我们看到", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "baafb005-d47a-4f61-abcb-89447f56a6cb", "label": "摘要24", "info": "了零均值和单位方差的特性。对于底层的几乎任意更新而言，；然保持着单位高斯。然后输出", "keywords": "了零均值和单位方差的特性, 然后输出, 对于底层的几乎任意更新而言, 然保持着单位高斯", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "376aaffa-a6b2-4d72-ba5e-de21712791ed", "label": "摘要25", "info": "仍；可以学习为一个简单的线性函数；。现在学习这个模型非常简单，因为低层的参数在大多数", "keywords": "因为低层的参数在大多数, 现在学习这个模型非常简单, 可以学习为一个简单的线性函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5dbdf199-690f-41b4-9ec1-02c74766d66f", "label": "摘要26", "info": "由于网络的最后一层能够学习线性变换，实际上我们可能希望移除一层；内单元之间的所有线性关系。事实上，这是Guillaume；Desjardins（2015）中采用的方法，为批标准化提供了灵感。令人遗憾", "keywords": "由于网络的最后一层能够学习线性变换, 事实上, 这是, 内单元之间的所有线性关系, 令人遗憾", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d510d492-6b3f-431d-bb9b-a0b8ab4a01eb", "label": "摘要27", "info": "，而不是简单地使用标准化的", "keywords": "而不是简单地使用标准化的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d610dec9-96ef-45d8-af3d-dbf555e4c8e3", "label": "摘要28", "info": "标准化一个单元的均值和标准差会降低包含该单元的神经网络的表达能；力。为了保持网络的表现力，通常会将批量隐藏单元激活  H  替换为；。变量γ和β是允许新变", "keywords": "标准化一个单元的均值和标准差会降低包含该单元的神经网络的表达能, 通常会将批量隐藏单元激活, 为了保持网络的表现力, 替换为, 是允许新变", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7bf4c94b-a2d9-4001-b147-4ad452d6f7f3", "label": "摘要29", "info": "大多数神经网络层会采取φ ( X W +b ) 的形式，其中φ是某个固定的非线；性激活函数，如整流线性变换。自然想到我们应该将批标准化应用于输；入 X 还是变换后的值 X W +b 。Ioffe and Szegedy（2015）推荐后者。更", "keywords": "如整流线性变换, 自然想到我们应该将批标准化应用于输, 其中, 大多数神经网络层会采取, 是某个固定的非线", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "5c5cc57e-abaf-4970-89e3-70cc1e28b68b", "label": "摘要30", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；具体地讲， X W +b 应替换为 X W 的标准化形式。偏置项应被忽略，因；为参数β  会加入批标准化重参数化，它是冗余的。一层的输入通常是前", "keywords": "具体地讲, 会加入批标准化重参数化, 的标准化形式, 偏置项应被忽略, 为参数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4f13c760-458b-4da8-8abf-03985082a9b6", "label": "摘要31", "info": "第9章所述的卷积网络，在特征映射中每个空间位置同样地标准化μ和σ；是很重要的，能使特征映射的统计量不因空间位置而保持相同。", "keywords": "在特征映射中每个空间位置同样地标准化, 能使特征映射的统计量不因空间位置而保持相同, 章所述的卷积网络, 是很重要的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9a10dca6-f93d-44b9-9ecf-1b62e37914a1", "label": "摘要32", "info": "8.7.2　坐标下降", "keywords": "坐标下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "39db2bee-8f4d-4265-b2e2-0d2535e8ed51", "label": "摘要33", "info": "在某些情况下，将一个优化问题分解成几个部分，可以更快地解决原问；题。如果我们相对于某个单一变量x i 最小化f( x )，然后相对于另一个变；量x j 等等，反复循环所有的变量，我们会保证到达（局部）极小值。这", "keywords": "如果我们相对于某个单一变量, 反复循环所有的变量, 局部, 然后相对于另一个变, 可以更快地解决原问", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "06dc75de-ee32-4872-a81a-5937503960dc", "label": "摘要34", "info": "当优化问题中的不同变量能够清楚地分成相对独立的组，或是当优化一；组变量明显比优化所有变量效率更高时，坐标下降最有意义。例如，考；虑代价函数", "keywords": "坐标下降最有意义, 例如, 当优化问题中的不同变量能够清楚地分成相对独立的组, 虑代价函数, 组变量明显比优化所有变量效率更高时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ead0899a-9fb6-49ac-9a18-d07efdec2ab4", "label": "摘要35", "info": "该函数描述了一种被称为稀疏编码的学习问题，其目标是寻求一个权重；矩阵 W ，可以线性解码激活值矩阵 H 以重构训练集 X 。稀疏编码的大；多数应用还涉及权重衰减或 W 列范数的约束，以避免极小 H 和极大 W", "keywords": "可以线性解码激活值矩阵, 稀疏编码的大, 列范数的约束, 和极大, 矩阵", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a2f1ee0e-353e-43e3-ae52-08e56c721821", "label": "摘要36", "info": "函数J不是凸的。然而，我们可以将训练算法的输入分成两个集合：字；典参数 W 和编码表示  H  。最小化关于这两者之一的任意一组变量的目；标函数都是凸问题。因此，块坐标下降允许我们使用高效的凸优化算", "keywords": "典参数, 标函数都是凸问题, 函数, 因此, 块坐标下降允许我们使用高效的凸优化算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b086e37d-4c54-4752-b894-1c3f6bb3f919", "label": "摘要37", "info": "当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是", "keywords": "坐标下降不是, 当一个变量的值很大程度地影响另一个变量的最优值时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "16d65c32-c844-43a1-b724-b34eb6e7019d", "label": "摘要38", "info": "一个很好的方法，如函数；中α是正值常数。第一项鼓励两个变量具有相似的值，而第二项鼓励它；们接近零。解是两者都为零。牛顿法可以一步解决这个问题，因为它是", "keywords": "们接近零, 因为它是, 牛顿法可以一步解决这个问题, 一个很好的方法, 是正值常数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2febfd03-f605-4e86-94e1-247fd29a4fed", "label": "摘要39", "info": "，其", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2498b696-451f-488c-bc4c-71cfedb9d893", "label": "摘要40", "info": "8.7.3　Polyak平均", "keywords": "平均", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "90a45177-2f35-40b7-a8a3-1f5c1108bfc7", "label": "摘要41", "info": "Polyak平均（Polyak  and  Juditsky，1992）会平均优化算法在参数空间访；，那；问轨迹中的几个点。如果t次迭代梯度下降访问了点", "keywords": "如果, 平均, 问轨迹中的几个点, 会平均优化算法在参数空间访, 次迭代梯度下降访问了点", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "faeef798-221c-49a6-8994-0d10e8556a52", "label": "摘要42", "info": "么Polyak平均算法的输出是", "keywords": "平均算法的输出是", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0766fb6a-d6e0-429c-8818-a0cfff42f6b8", "label": "摘要43", "info": "。在某些", "keywords": "在某些", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "2b294193-3c0d-4f42-b976-a9b271d44e97", "label": "摘要44", "info": "问题中，如梯度下降应用于凸问题时，这种方法具有较强的收敛保证。；当应用于神经网络时，其验证更多是启发式的，但在实践中表现良好。；基本想法是，优化算法可能会来回穿过山谷好几次而没经过山谷底部附", "keywords": "问题中, 但在实践中表现良好, 优化算法可能会来回穿过山谷好几次而没经过山谷底部附, 其验证更多是启发式的, 当应用于神经网络时", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cc76ada9-7511-4c2c-85eb-826f88ada00a", "label": "摘要45", "info": "在非凸问题中，优化轨迹的路径可以非常复杂，并且经过了许多不同的；区域。包括参数空间中遥远过去的点，可能与当前点在代价函数上相隔；很大的障碍，看上去不像一个有用的行为。其结果是，当应用Polyak平", "keywords": "当应用, 其结果是, 区域, 并且经过了许多不同的, 优化轨迹的路径可以非常复杂", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "6718b2a3-c704-40d3-a542-f9ab0cd5208e", "label": "摘要46", "info": "这个计算平均值的方法被用于大量数值应用中。最近的例子请查阅；Szegedy et al. （2015）。", "keywords": "这个计算平均值的方法被用于大量数值应用中, 最近的例子请查阅", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "03703dd3-b9d1-4532-8104-4dd080ce1e52", "label": "摘要47", "info": "8.7.4　监督预训练", "keywords": "监督预训练", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "67d7024a-97c6-4cc6-89b1-ab8f9ef0ef82", "label": "摘要48", "info": "有时，如果模型太复杂难以优化或是任务非常困难，直接训练模型来解；决特定任务的挑战可能太大。有时训练一个较简单的模型来求解问题，；然后使模型更复杂会更有效。训练模型来求解一个简化的问题，然后转", "keywords": "有时训练一个较简单的模型来求解问题, 如果模型太复杂难以优化或是任务非常困难, 训练模型来求解一个简化的问题, 有时, 直接训练模型来解", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "cbd7cac7-5be8-40a4-9bbb-2b7c63b13756", "label": "摘要49", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；贪心算法 （greedy algorithm）将问题分解成许多部分，然后独立地在每；个部分求解最优值。令人遗憾的是，结合各个最佳的部分不能保证得到", "keywords": "个部分求解最优值, 将问题分解成许多部分, 贪心算法, 然后独立地在每, 结合各个最佳的部分不能保证得到", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "225f0a28-4337-4449-a85c-b86f57318029", "label": "摘要50", "info": "预训练算法，特别是贪心预训练，在深度学习中是普遍存在的。在本节；中，我们会具体描述这些将监督学习问题分解成其他简化的监督学习问；题的预训练算法。这种方法被称为贪心监督预训练  （greedy  supervised", "keywords": "这种方法被称为贪心监督预训练, 我们会具体描述这些将监督学习问题分解成其他简化的监督学习问, 在深度学习中是普遍存在的, 题的预训练算法, 在本节", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "462254fa-6088-4e6c-b343-9d00159c6b06", "label": "摘要51", "info": "在贪心监督预训练的原始版本（Bengio et al.  ，2007c）中，每个阶段包；括一个仅涉及最终神经网络的子集层的监督学习训练任务。贪心监督预；训练的一个例子如图8.7所示，其中每个附加的隐藏层作为浅层监督多", "keywords": "括一个仅涉及最终神经网络的子集层的监督学习训练任务, 每个阶段包, 贪心监督预, 训练的一个例子如图, 在贪心监督预训练的原始版本", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "26f70d07-d099-421f-b71a-a27c81c6faa1", "label": "摘要52", "info": "图8.7　一种形式的贪心监督预训练的示意图（Bengio et al. ，2007a）。（a）我们从训练一个足；够浅的架构开始。（b）同一个架构的另一描绘。（c）我们只保留原始网络的输入到隐藏层，；并丢弃隐藏到输出层。我们将第一层隐藏层的输出作为输入发送到另一监督单隐层MLP（使用", "keywords": "同一个架构的另一描绘, 我们从训练一个足, 我们只保留原始网络的输入到隐藏层, 一种形式的贪心监督预训练的示意图, 我们将第一层隐藏层的输出作为输入发送到另一监督单隐层", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7c5e221b-20f9-4af1-a714-612112345f5d", "label": "摘要53", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（d）所得架构的另一种描绘，可视为前馈网络。为了进一步改进优化，我们可以联合地精调所；有层（仅在该过程的结束或者该过程的每个阶段）", "keywords": "为了进一步改进优化, 我们可以联合地精调所, 可视为前馈网络, 所得架构的另一种描绘, 仅在该过程的结束或者该过程的每个阶段", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f6485968-ade8-412f-8d9f-b343d5fa142e", "label": "摘要54", "info": "为什么贪心监督预训练会有帮助呢？最初由Bengio et al. （2007d）提出；的假说是，其有助于更好地指导深层结构的中间层的学习。一般情况；下，预训练对于优化和泛化都是有帮助的。", "keywords": "提出, 的假说是, 最初由, 为什么贪心监督预训练会有帮助呢, 一般情况", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "839368db-0340-4d64-926d-4c22f7df05a0", "label": "摘要55", "info": "另一个与监督预训练有关的方法扩展了迁移学习的想法：Yosinski  et  al.；（2014）在一组任务上预训练了8层权重的深度卷积网络（1000个；ImageNet对象类的子集），然而用该网络的前k层初始化同样规模的网", "keywords": "然而用该网络的前, 层初始化同样规模的网, 另一个与监督预训练有关的方法扩展了迁移学习的想法, 在一组任务上预训练了, 层权重的深度卷积网络", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c04d71bb-09d8-41bb-959d-3c6789f8916f", "label": "摘要56", "info": "另一条相关的工作线是FitNets （Romero et al. ，2015）方法。这种方法；始于训练深度足够低和宽度足够大（每层单元数），容易训练的网络。；然后，这个网络成为第二个网络（被指定为学生  ）的老师  。学生网络", "keywords": "每层单元数, 的老师, 这种方法, 容易训练的网络, 被指定为学生", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "872a5bdb-d092-4a2d-852f-76c271148313", "label": "摘要57", "info": "8.7.5　设计有助于优化的模型", "keywords": "设计有助于优化的模型", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "04a3cbcd-c77d-4db9-92c5-9aa5ead8137c", "label": "摘要58", "info": "改进优化的最好方法并不总是改进优化算法。相反，深度模型中优化的；许多改进来自设计易于优化的模型。", "keywords": "改进优化的最好方法并不总是改进优化算法, 许多改进来自设计易于优化的模型, 相反, 深度模型中优化的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "dabc31ee-d784-4f3e-b63f-9d4bddc970e0", "label": "摘要59", "info": "原则上，我们可以使用呈锯齿非单调模式上上下下的激活函数，但是，；这将使优化极为困难。在实践中，选择一族容易优化的模型比使用一个", "keywords": "但是, 在实践中, 原则上, 我们可以使用呈锯齿非单调模式上上下下的激活函数, 这将使优化极为困难", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "d12ce108-fbc9-4466-99c2-deaf193d614b", "label": "摘要60", "info": "强大的优化算法更重要。神经网络学习在过去30年的大多数进步主要来；自改变模型族，而非改变优化过程。20世纪80年代用于训练神经网络的；带动量的随机梯度下降，仍然是现代神经网络应用中的前沿算法。", "keywords": "世纪, 仍然是现代神经网络应用中的前沿算法, 年的大多数进步主要来, 年代用于训练神经网络的, 强大的优化算法更重要", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "59cc3e37-618d-441b-8c24-fde53485a1f7", "label": "摘要61", "info": "具体来说，现代神经网络的设计选择体现在层之间的线性变换，几乎处；处可导的激活函数，和大部分定义域都有明显的梯度。特别是，创新的；模型，如LSTM、整流线性单元和maxout单元都比先前的模型（如基于", "keywords": "创新的, 几乎处, 特别是, 和大部分定义域都有明显的梯度, 现代神经网络的设计选择体现在层之间的线性变换", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c3fba006-3a04-4163-b22e-c004d208154c", "label": "摘要62", "info": "其他的模型设计策略有助于使优化更简单。例如，层之间的线性路径或；是跳跃连接减少了从较低层参数到输出最短路径的长度，因而缓解了梯；度消失的问题（Srivastava  et  al.  ，2015）。一个和跳跃连接相关的想法", "keywords": "是跳跃连接减少了从较低层参数到输出最短路径的长度, 其他的模型设计策略有助于使优化更简单, 层之间的线性路径或, 度消失的问题, 因而缓解了梯", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "952e273d-9187-4a59-9c3b-3efaed69e0cf", "label": "摘要63", "info": "8.7.6　延拓法和课程学习", "keywords": "延拓法和课程学习", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7345a9e2-c099-4f06-a9a7-c85e5ca8bbea", "label": "摘要64", "info": "正如第8.2.7节探讨的，许多优化挑战都来自代价函数的全局结构，不能；仅通过局部更新方向上更好的估计来解决。解决这个问题的主要方法是；尝试初始化参数到某种区域内，该区域可以通过局部下降很快连接到参", "keywords": "许多优化挑战都来自代价函数的全局结构, 正如第, 节探讨的, 该区域可以通过局部下降很快连接到参, 仅通过局部更新方向上更好的估计来解决", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "b7c7622d-a8c1-499a-b929-de41802417c0", "label": "摘要65", "info": "延拓法  （continuation  method）是一族通过挑选初始点使优化更容易的；方法，以确保局部优化花费大部分时间在表现良好的空间。延拓法的背；后想法是构造一系列具有相同参数的目标函数。为了最小化代价函数", "keywords": "延拓法, 为了最小化代价函数, 后想法是构造一系列具有相同参数的目标函数, 是一族通过挑选初始点使优化更容易的, 以确保局部优化花费大部分时间在表现良好的空间", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "9c6efed6-7e7b-4c11-9ec0-347cf6273d3f", "label": "摘要66", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；，我们构建新的代价函数", "keywords": "我们构建新的代价函数", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "ea33d028-9190-40df-aada-17b19c1b63d7", "label": "摘要67", "info": "。这些代价函数的；难度逐步提高，其中J  (0)  是最容易最小化的，J  (n)  是最难的，真正的代；价函数驱动整个过程。当我们说J (i) 比J (i＋1) 更容易时，是指其在更多的", "keywords": "是最容易最小化的, 是指其在更多的, 价函数驱动整个过程, 真正的代, 其中", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "7ae94995-0965-4944-833d-69241d0c9c4d", "label": "摘要68", "info": "传统的延拓法（用于神经网络训练之前的延拓法）通常基于平滑目标函；数。读者可以查看Wu（1997）了解这类方法的示例，以及一些相关方；法的综述。延拓法也和参数中加入噪声的模拟退火紧密相关", "keywords": "法的综述, 延拓法也和参数中加入噪声的模拟退火紧密相关, 了解这类方法的示例, 通常基于平滑目标函, 读者可以查看", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "a852fe38-fcb8-4a6c-89ac-cae03f56a3df", "label": "摘要69", "info": "et", "keywords": "", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "00e082f9-ed2f-4f3f-9d12-91f2099015cf", "label": "摘要70", "info": "传统上，延拓法主要用来克服局部极小值的问题。具体地，它被设计用；来在有很多局部极小值的情况下，求解一个全局最小点。这些连续方法；会通过“模糊”原来的代价函数来构建更容易的代价函数。这些模糊操作", "keywords": "这些连续方法, 传统上, 这些模糊操作, 它被设计用, 求解一个全局最小点", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "53179275-fea9-464c-86be-d8fb3dbf1f31", "label": "摘要71", "info": "这个方法的直觉是有些非凸函数在模糊后会近似凸的。在许多情况下，；这种模糊保留了关于全局极小值的足够信息，我们可以通过逐步求解模；糊更少的问题来求解全局极小值。这种方法有三种可能失败的方式。首", "keywords": "这个方法的直觉是有些非凸函数在模糊后会近似凸的, 这种方法有三种可能失败的方式, 在许多情况下, 这种模糊保留了关于全局极小值的足够信息, 我们可以通过逐步求解模", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "be056972-575e-4f34-84c5-efb5d775acc3", "label": "摘要72", "info": "。其二，函数可能在模糊后是凸的，但模糊函数的最；小值可能会追踪到一个局部最小值，而非原始代价函数的全局最小值。", "keywords": "但模糊函数的最, 其二, 而非原始代价函数的全局最小值, 小值可能会追踪到一个局部最小值, 函数可能在模糊后是凸的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4ebcadab-f4e4-4df8-ae84-512221b73d14", "label": "摘要73", "info": "尽管延拓法最初用来解决局部最小值的问题，而局部最小值已不再认为；是神经网络优化中的主要问题了。幸运的是，延拓法仍然有所帮助。延；拓法引入的简化目标函数能够消除平坦区域，减少梯度估计的方差，提", "keywords": "拓法引入的简化目标函数能够消除平坦区域, 幸运的是, 是神经网络优化中的主要问题了, 尽管延拓法最初用来解决局部最小值的问题, 减少梯度估计的方差", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "c817b8b9-058b-420f-a3b6-db17907cf29f", "label": "摘要74", "info": "高Hessian矩阵的条件数，使局部更新更容易计算，或是改进局部更新方；向与朝向全局解方向之间的对应关系。", "keywords": "矩阵的条件数, 向与朝向全局解方向之间的对应关系, 或是改进局部更新方, 使局部更新更容易计算", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "351eabe0-59f6-4797-9211-3f6b249161da", "label": "摘要75", "info": "Bengio et al. （2009）指出被称为课程学习 （curriculum  learning）或者；塑造  （shaping）的方法可以被解释为延拓法。课程学习基于规划学习；过程的想法，首先学习简单的概念，然后逐步学习依赖于这些简化概念", "keywords": "过程的想法, 然后逐步学习依赖于这些简化概念, 首先学习简单的概念, 塑造, 或者", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f0996c90-fe77-45be-9d3d-ee71e9623a59", "label": "摘要76", "info": "课程学习研究的另一个重要贡献体现在训练循环神经网络捕获长期依；赖：Zaremba  and  Sutskever（2014）发现使用随机课程获得了更好的结；果，其中容易和困难的示例混合在一起，随机提供给学习者，更难示例", "keywords": "发现使用随机课程获得了更好的结, 其中容易和困难的示例混合在一起, 课程学习研究的另一个重要贡献体现在训练循环神经网络捕获长期依, 更难示例, 随机提供给学习者", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "77d65f4a-de6d-43db-93f8-268f608065f4", "label": "摘要77", "info": "现在我们已经介绍了一些基本的神经网络模型，以及如何进行正则化和；优化。在接下来的章节中，我们转向特化的神经网络家族，允许其扩展；到能够处理很大规模的数据和具有特殊结构的数据。在本章中讨论的优", "keywords": "以及如何进行正则化和, 现在我们已经介绍了一些基本的神经网络模型, 允许其扩展, 在接下来的章节中, 到能够处理很大规模的数据和具有特殊结构的数据", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "0c67d403-2a54-43e1-b367-1c82bda3e0d0", "label": "摘要78", "info": "8.7.1　批标准化", "keywords": "批标准化", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "fffebb4b-e67b-4674-89d8-9911c22f689f", "label": "摘要79", "info": "8.7.2　坐标下降", "keywords": "坐标下降", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "79a66e9a-4848-4a0a-9c2f-d85fb9aef929", "label": "摘要80", "info": "8.7.3　Polyak平均", "keywords": "平均", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "130b59f3-769d-4276-aae0-560db9e00788", "label": "摘要81", "info": "8.7.4　监督预训练", "keywords": "监督预训练", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "52305711-e4c3-4ea2-9fa3-589fc4c4c220", "label": "摘要82", "info": "8.7.5　设计有助于优化的；模型", "keywords": "模型, 设计有助于优化的", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "f80483b5-aae7-4182-baff-8e28a482efd8", "label": "摘要83", "info": "8.7.6　延拓法和课程学习", "keywords": "延拓法和课程学习", "level": 3, "group": "chapter-8", "type": "段落"}, {"id": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "label": "第9章：卷积网络", "level": 1, "group": "chapter-9", "type": "章節"}, {"id": "25d1522e-41b4-421e-ae7a-312858f67343", "label": "8.7：优化策略和元算法", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "7c18681b-a47e-45da-a064-b4bd6fed74f9", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；卷积网络 （convolutional network）（LeCun，1989），也叫作卷积神经；网络 （convolutional neural network，CNN），是一种专门用来处理具有", "keywords": "也叫作卷积神经, 卷积网络, 是一种专门用来处理具有, 网络", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "192e2667-7cd6-4388-b22d-37310fde7e96", "label": "摘要2", "info": "本章我们首先说明什么是卷积运算，接着会解释在神经网络中使用卷积；运算的动机，然后会介绍池化  （pooling）。池化是一种几乎所有的卷；积网络都会用到的操作。通常来说，卷积神经网络中用到的卷积运算和", "keywords": "积网络都会用到的操作, 通常来说, 然后会介绍池化, 运算的动机, 卷积神经网络中用到的卷积运算和", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "label": "9.1：卷积运算", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "18b5bde4-602d-4acc-9927-aacb32c5de84", "label": "摘要1", "info": "在通常形式中，卷积是对两个实变函数的一种数学运算 (1) 。为了给出卷；积的定义，我们从两个可能会用到的函数的例子出发。", "keywords": "卷积是对两个实变函数的一种数学运算, 积的定义, 我们从两个可能会用到的函数的例子出发, 为了给出卷, 在通常形式中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "8a3ee38a-ff9c-4a7d-b46e-57e8175aff06", "label": "摘要2", "info": "假设我们正在用激光传感器追踪一艘宇宙飞船的位置。我们的激光传感；器给出一个单独的输出x（t），表示宇宙飞船在时刻t的位置。x和t都是；实值的，这意味着我们可以在任意时刻从传感器中读出飞船的位置。", "keywords": "实值的, 的位置, 这意味着我们可以在任意时刻从传感器中读出飞船的位置, 我们的激光传感, 表示宇宙飞船在时刻", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fe13cf23-dd80-4cbe-bd59-23ebcb2833c5", "label": "摘要3", "info": "现在假设我们的传感器受到一定程度的噪声干扰。为了得到飞船位置的；低噪声估计，我们对得到的测量结果进行平均。显然，时间上越近的测", "keywords": "显然, 为了得到飞船位置的, 现在假设我们的传感器受到一定程度的噪声干扰, 低噪声估计, 我们对得到的测量结果进行平均", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9bbf444b-8865-4e94-99cf-d9c7a6006cf5", "label": "摘要4", "info": "量结果越相关，所以我们采用一种加权平均的方法，对于最近的测量结；果赋予更高的权重。我们可以采用一个加权函数w(a)来实现，其中a表；示测量结果距当前时刻的时间间隔。如果我们对任意时刻都采用这种加", "keywords": "量结果越相关, 对于最近的测量结, 我们可以采用一个加权函数, 如果我们对任意时刻都采用这种加, 所以我们采用一种加权平均的方法", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7314c2af-6544-4637-a94c-ba6946ffb2e1", "label": "摘要5", "info": "这种运算就叫作卷积 （convolution）。卷积运算通常用星号表示：", "keywords": "这种运算就叫作卷积, 卷积运算通常用星号表示", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "0ea605db-a016-4f4a-bf53-928a51b9fa8c", "label": "摘要6", "info": "在我们的例子中，w必须是一个有效的概率密度函数，否则输出就不再；是一个加权平均。另外，在参数为负值时，w的取值必须为0，否则它；会预测到未来，这不是我们能够推测得了的。但这些限制仅仅是对我们", "keywords": "这不是我们能够推测得了的, 在我们的例子中, 的取值必须为, 会预测到未来, 但这些限制仅仅是对我们", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "35a6271a-06d6-428e-94cf-21982b74d35c", "label": "摘要7", "info": "在卷积网络的术语中，卷积的第一个参数（在这个例子中，函数x）通；常叫作输入  （input），第二个参数（函数w）叫作核函数  （kernel；function）。输出有时被称作特征映射 （feature map）。", "keywords": "常叫作输入, 叫作核函数, 函数, 在这个例子中, 第二个参数", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ef53b742-b868-42c3-9e1e-2eeefc2d14eb", "label": "摘要8", "info": "在本例中，激光传感器在每个瞬间反馈测量结果的想法是不切实际的。；一般来讲，当我们用计算机处理数据时，时间会被离散化，传感器会定；期地反馈数据。所以在我们的例子中，假设传感器每秒反馈一次测量结", "keywords": "所以在我们的例子中, 当我们用计算机处理数据时, 在本例中, 期地反馈数据, 假设传感器每秒反馈一次测量结", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d5d1f4fa-35b6-4b50-86b6-68c75adae6fa", "label": "摘要9", "info": "在机器学习的应用中，输入通常是多维数组的数据，而核通常是由学习；算法优化得到的多维数组的参数。我们把这些多维数组叫作张量。因为；在输入与核中的每一个元素都必须明确地分开存储，我们通常假设在存", "keywords": "在机器学习的应用中, 因为, 我们把这些多维数组叫作张量, 而核通常是由学习, 我们通常假设在存", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2537c9f7-ec2f-4aa1-b532-ab2f4d2b7f5c", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最后，我们经常一次在多个维度上进行卷积运算。例如，如果把一张二；维的图像I作为输入，我们也许也想要使用一个二维的核K：", "keywords": "维的图像, 作为输入, 如果把一张二, 我们经常一次在多个维度上进行卷积运算, 例如", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a291bf5f-5a41-46f8-ba43-9071ecadd2f1", "label": "摘要11", "info": "卷积是可交换的（commutative），我们可以等价地写作：", "keywords": "卷积是可交换的, 我们可以等价地写作", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b5840cf1-9d4f-43dd-bd9a-85c0417317e6", "label": "摘要12", "info": "通常，下面的公式在机器学习库中实现更为简单，因为m和n的有效取；值范围相对较小。", "keywords": "因为, 通常, 下面的公式在机器学习库中实现更为简单, 值范围相对较小, 的有效取", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "601f7e50-e6fb-4db3-ba99-7a0816688135", "label": "摘要13", "info": "卷积运算可交换性的出现是因为我们将核相对输入进行了翻转；（flip），从m增大的角度来看，输入的索引在增大，但是核的索引在减；小。我们将核翻转的唯一目的是实现可交换性。尽管可交换性在证明时", "keywords": "尽管可交换性在证明时, 但是核的索引在减, 增大的角度来看, 我们将核翻转的唯一目的是实现可交换性, 卷积运算可交换性的出现是因为我们将核相对输入进行了翻转", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "0103fca9-4128-42b8-b386-1bd9555ed641", "label": "摘要14", "info": "许多机器学习的库实现的是互相关函数但是称之为卷积。在这本书中我；们遵循把两种运算都叫作卷积的这个传统，在与核翻转有关的上下文；中，我们会特别指明是否对核进行了翻转。在机器学习中，学习算法会", "keywords": "我们会特别指明是否对核进行了翻转, 学习算法会, 许多机器学习的库实现的是互相关函数但是称之为卷积, 在这本书中我, 们遵循把两种运算都叫作卷积的这个传统", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "999bb344-e4aa-4ed9-9e31-337332d14cad", "label": "摘要15", "info": "图9.1演示了一个在二维张量上的卷积运算（没有对核进行翻转）的例；子。", "keywords": "的例, 演示了一个在二维张量上的卷积运算, 没有对核进行翻转", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2a41d5a5-6a5f-4a4d-a94d-cd55683ea900", "label": "摘要16", "info": "图9.1　一个二维卷积的例子（没有对核进行翻转）。我们限制只对核完全处在图像中的位置进；行输出，在一些上下文中称为“有效”卷积。我们用画有箭头的盒子来说明输出张量的左上角元；素是如何通过对输入张量相应的左上角区域应用核进行卷积得到的", "keywords": "我们用画有箭头的盒子来说明输出张量的左上角元, 行输出, 在一些上下文中称为, 有效, 卷积", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d68d2811-c0ea-42cd-a2fe-339d0a4064be", "label": "摘要17", "info": "离散卷积可以看作矩阵的乘法，然而，这个矩阵的一些元素被限制为必；须和另外一些元素相等。例如对于单变量的离散卷积，矩阵每一行中的；元素都与上一行对应位置平移一个单位的元素相同。这种矩阵叫作", "keywords": "元素都与上一行对应位置平移一个单位的元素相同, 这种矩阵叫作, 然而, 例如对于单变量的离散卷积, 矩阵每一行中的", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f10fe3c5-fdd3-4ad5-8bb1-5e141de3ef4f", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；9.2　动机", "keywords": "动机", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "45f31da9-77e6-414f-b805-54f4e2f70aed", "label": "摘要19", "info": "卷积运算通过三个重要的思想来帮助改进机器学习系统：稀疏交互；（sparse；interactions）、参数共享  （parameter  sharing）、等变表示", "keywords": "参数共享, 等变表示, 稀疏交互, 卷积运算通过三个重要的思想来帮助改进机器学习系统", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "54893447-92e9-43aa-bd43-960299ec7dcf", "label": "摘要20", "info": "传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参；数矩阵中每一个单独的参数都描述了一个输入单元与一个输出单元间的；交互。这意味着每一个输出单元与每一个输入单元都产生交互。然而，", "keywords": "数矩阵中每一个单独的参数都描述了一个输入单元与一个输出单元间的, 传统的神经网络使用矩阵乘法来建立输入与输出的连接关系, 这意味着每一个输出单元与每一个输入单元都产生交互, 交互, 其中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3de37db2-a106-45b8-a644-8b750f7c7aa0", "label": "摘要21", "info": "图9.2　稀疏连接，对每幅图从下往上看。我们强调了一个输入单元x 3 以及在s中受该单元影响；的输出单元。（上）当s是由核宽度为3的卷积产生时，只有3个输出受到x的影响。（下）当s是；由矩阵乘法产生时，连接不再是稀疏的，所以所有的输出都会受到x 3 的影响", "keywords": "的输出单元, 我们强调了一个输入单元, 以及在, 的影响, 连接不再是稀疏的", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f9b0a3e3-f7eb-4033-871b-16a524461867", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图9.3　稀疏连接，对每幅图从上往下看。我们强调了一个输出单元s 3 以及x中影响该单元的输；入单元。这些单元被称为s 3 的接受域（receptive field）。（上）当s是由核宽度为3的卷积产生", "keywords": "的接受域, 入单元, 中影响该单元的输, 稀疏连接, 这些单元被称为", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "bdfeca41-9d76-47c2-9b5b-1a4537123348", "label": "摘要23", "info": "图9.4　处于卷积网络更深的层中的单元，它们的接受域要比处在浅层的单元的接受域更大。如；果网络还包含类似步幅卷积（见图9.12）或者池化（第9.3节）之类的结构特征，这种效应会加；强。这意味着在卷积网络中尽管直接连接都是很稀疏的，但处在更深的层中的单元可以间接地", "keywords": "这意味着在卷积网络中尽管直接连接都是很稀疏的, 处于卷积网络更深的层中的单元, 或者池化, 之类的结构特征, 这种效应会加", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "12d53ae2-1643-4357-b46b-a5ca647c89e2", "label": "摘要24", "info": "参数共享  （parameter  sharing）是指在一个模型的多个函数中使用相同；的参数。在传统的神经网络中，当计算一层的输出时，权重矩阵的每一；个元素只使用一次，当它乘以输入的一个元素后就再也不会用到了。作", "keywords": "参数共享, 的参数, 权重矩阵的每一, 个元素只使用一次, 当计算一层的输出时", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "52ab0a85-b073-4c62-af74-783f2f48c56c", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图9.5　参数共享。黑色箭头表示在两个不同的模型中使用了特殊参数的连接。（上）黑色箭头；表示在卷积模型中对3元素核的中间元素的使用。因为参数共享，这个单独的参数被用于所有的", "keywords": "元素核的中间元素的使用, 参数共享, 黑色箭头表示在两个不同的模型中使用了特殊参数的连接, 表示在卷积模型中对, 黑色箭头", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f2170fe8-51d2-4ee7-8f8a-da1ce24354bc", "label": "摘要26", "info": "作为前两条原则的一个实际例子，图9.6说明了稀疏连接和参数共享是；如何显著提高线性函数在一张图像上进行边缘检测的效率的。", "keywords": "如何显著提高线性函数在一张图像上进行边缘检测的效率的, 作为前两条原则的一个实际例子, 说明了稀疏连接和参数共享是", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "bc434004-f138-4171-9ec6-23d1ec847c40", "label": "摘要27", "info": "图9.6　边缘检测的效率。右边的图像是通过先获得原始图像中的每个像素，然后减去左边相邻；像素的值而形成的。这个操作给出了输入图像中所有垂直方向上的边缘的强度，对目标检测来；说是有用的。两个图像的高度均为280个像素。输入图像的宽度为320个像素，而输出图像的宽", "keywords": "边缘检测的效率, 输入图像的宽度为, 个像素, 右边的图像是通过先获得原始图像中的每个像素, 对目标检测来", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fd6c87b9-228f-41ef-b4f0-a2ea51c763d8", "label": "摘要28", "info": "度为319个像素。这个变换可以通过包含两个元素的卷积核来描述，使用卷积需要319×280×3＝；267 960次浮点运算（每个输出像素需要两次乘法和一次加法）。为了用矩阵乘法描述相同的变；换，需要一个包含320×280×319×280个或者说超过80亿个元素的矩阵，这使得卷积对于表示这", "keywords": "这个变换可以通过包含两个元素的卷积核来描述, 亿个元素的矩阵, 这使得卷积对于表示这, 个像素, 为了用矩阵乘法描述相同的变", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7d9d9636-cc23-41f3-a728-6329a8f29d29", "label": "摘要29", "info": "对于卷积，参数共享的特殊形式使得神经网络层具有对平移等变；（equivariance）的性质。如果一个函数满足输入改变，输出也以同样的；方式改变这一性质，我们就说它是等变（equivariant）的。特别的是，", "keywords": "我们就说它是等变, 如果一个函数满足输入改变, 输出也以同样的, 参数共享的特殊形式使得神经网络层具有对平移等变, 的性质", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d89f482d-1657-4b1e-89b2-ddf20e62a50b", "label": "摘要30", "info": "卷积对其他的一些变换并不是天然等变的，例如对于图像的放缩或者旋；转变换，需要其他的一些机制来处理这些变换。", "keywords": "卷积对其他的一些变换并不是天然等变的, 需要其他的一些机制来处理这些变换, 转变换, 例如对于图像的放缩或者旋", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d9b01406-6e74-4b20-b8f2-75038aad5fce", "label": "摘要31", "info": "最后，一些不能被传统的由（固定大小的）矩阵乘法定义的神经网络处；理的特殊数据，可能通过卷积神经网络来处理，我们将在第9.7节中进；行讨论。", "keywords": "理的特殊数据, 可能通过卷积神经网络来处理, 一些不能被传统的由, 矩阵乘法定义的神经网络处, 我们将在第", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "4b1440ea-dd26-406c-bdda-61695432587f", "label": "摘要32", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；9.3　池化", "keywords": "池化", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "609632a3-8d58-45b6-b80e-24de793abf08", "label": "摘要33", "info": "卷积网络中一个典型层包含三级（见图9.7）。在第一级中，这一层并；行地计算多个卷积产生一组线性激活响应。在第二级中，每一个线性激；活响应将会通过一个非线性的激活函数，例如整流线性激活函数。这一", "keywords": "在第一级中, 这一, 这一层并, 在第二级中, 行地计算多个卷积产生一组线性激活响应", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "50703611-a613-463e-ae36-52eacab3858a", "label": "摘要34", "info": "图9.7　一个典型卷积神经网络层的组件。有两组常用的术语用于描述这些层。（左）在这组术；语中，卷积网络被视为少量相对复杂的层，每层具有许多“级”。在这组术语中，核张量与网络；层之间存在一一对应关系。在本书中，我们通常使用这组术语。（右）在这组术语中，卷积网", "keywords": "卷积网络被视为少量相对复杂的层, 核张量与网络, 我们通常使用这组术语, 每层具有许多, 语中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "563a2094-b8b8-4346-8789-464b11727163", "label": "摘要35", "info": "池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置；的输出。例如，最大池化  （max  pooling）函数（Zhou  and  Chellappa，；1988）给出相邻矩形区域内的最大值。其他常用的池化函数包括相邻矩", "keywords": "的输出, 其他常用的池化函数包括相邻矩, 函数, 给出相邻矩形区域内的最大值, 例如", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b807b365-21b6-4cf8-930a-0a68c0311b39", "label": "摘要36", "info": "数。", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "447f782f-2ca4-48d2-82cd-771fafc1da1b", "label": "摘要37", "info": "不管采用什么样的池化函数，当输入做出少量平移时，池化能够帮助输；入的表示近似不变  （invariant）。平移的不变性是指当我们对输入进行；少量平移时，经过池化函数后的大多数输出并不会发生改变。图9.8用", "keywords": "入的表示近似不变, 少量平移时, 当输入做出少量平移时, 不管采用什么样的池化函数, 池化能够帮助输", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a42e2df9-865f-4dc0-9ac7-ced9f68e96b1", "label": "摘要38", "info": "图9.8　最大池化引入了不变性。（上）卷积层中间输出的视图。下面一行显示非线性的输出。；上面一行显示最大池化的输出，每个池的宽度为三个像素并且池化区域的步幅为一个像素。；（下）相同网络的视图，不过对输入右移了一个像素。下面一行的所有值都发生了改变，但上", "keywords": "不过对输入右移了一个像素, 卷积层中间输出的视图, 最大池化引入了不变性, 但上, 相同网络的视图", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "161ad59b-7167-4276-b31e-26b31b3ccf5e", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；使用池化可以看作增加了一个无限强的先验：这一层学得的函数必须具；有对少量平移的不变性。当这个假设成立时，池化可以极大地提高网络", "keywords": "这一层学得的函数必须具, 当这个假设成立时, 池化可以极大地提高网络, 使用池化可以看作增加了一个无限强的先验, 有对少量平移的不变性", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b54c0cab-8feb-48c2-840b-26bd6015f751", "label": "摘要40", "info": "对空间区域进行池化产生了平移不变性，但当我们对分离参数的卷积的；输出进行池化时，特征能够学得应该对于哪种变换具有不变性（见图；9.9）。", "keywords": "但当我们对分离参数的卷积的, 见图, 输出进行池化时, 特征能够学得应该对于哪种变换具有不变性, 对空间区域进行池化产生了平移不变性", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "bb8ea4bc-b91c-458c-bb67-a244816b7ab6", "label": "摘要41", "info": "图9.9　学习不变性的示例。使用分离的参数学得多个特征，再使用池化单元进行池化，可以学；得对输入的某些变换的不变性。这里我们展示了用三个学得的过滤器和一个最大池化单元可以；学得对旋转变换的不变性。这三个过滤器都旨在检测手写的数字5。每个过滤器尝试匹配稍微不", "keywords": "学得对旋转变换的不变性, 使用分离的参数学得多个特征, 再使用池化单元进行池化, 可以学, 这里我们展示了用三个学得的过滤器和一个最大池化单元可以", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7cb3194c-1f97-42c9-8b23-2fb6e6cd549a", "label": "摘要42", "info": "因为池化综合了全部邻居的反馈，这使得池化单元少于探测单元成为可；能，我们可以通过综合池化区域的k个像素的统计特征而不是单个像素；来实现。图9.10给出了一个例子。这种方法提高了网络的计算效率，因", "keywords": "因为池化综合了全部邻居的反馈, 我们可以通过综合池化区域的, 这种方法提高了网络的计算效率, 个像素的统计特征而不是单个像素, 这使得池化单元少于探测单元成为可", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "5c24d9f2-57c0-4f32-86a4-083e4ff45c9a", "label": "摘要43", "info": "图9.10　带有降采样的池化。这里我们使用最大池化，池的宽度为三并且池之间的步幅为二。；这使得表示的大小减少了一半，减轻了下一层的计算和统计负担。注意到最右边的池化区域尺；寸较小，但如果我们不想忽略一些探测单元，就必须包含这个区域", "keywords": "这里我们使用最大池化, 带有降采样的池化, 寸较小, 但如果我们不想忽略一些探测单元, 减轻了下一层的计算和统计负担", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b2237c3b-2a9f-47c7-8605-77cf6c8cc326", "label": "摘要44", "info": "在很多任务中，池化对于处理不同大小的输入具有重要作用。例如我们；想对不同大小的图像进行分类时，分类层的输入必须是固定的大小，而；这通常通过调整池化区域的偏置大小来实现，这样分类层总是能接收到", "keywords": "池化对于处理不同大小的输入具有重要作用, 在很多任务中, 例如我们, 这通常通过调整池化区域的偏置大小来实现, 这样分类层总是能接收到", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "412c3097-d6cb-422d-9441-c950b15650da", "label": "摘要45", "info": "一些理论工作对于在不同情况下应当使用哪种池化函数给出了一些指导；（Boureau et  al. ，2010）。将特征一起动态地池化也是可行的，例如，；对于感兴趣特征的位置运行聚类算法（Boureau et al. ，2011）。这种方", "keywords": "将特征一起动态地池化也是可行的, 例如, 对于感兴趣特征的位置运行聚类算法, 这种方, 一些理论工作对于在不同情况下应当使用哪种池化函数给出了一些指导", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "8ea2300c-81af-42ed-bd2b-5f1bbcb2d6f3", "label": "摘要46", "info": "池化可能会使得一些利用自顶向下信息的神经网络结构变得复杂，例如；玻尔兹曼机和自编码器。这些问题将在本书第3部分当我们遇到这些类；型的网络时进一步讨论。卷积玻尔兹曼机中的池化出现在第20.6节。一", "keywords": "部分当我们遇到这些类, 玻尔兹曼机和自编码器, 这些问题将在本书第, 例如, 池化可能会使得一些利用自顶向下信息的神经网络结构变得复杂", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "58ebb6be-1e8a-40b7-88a5-cb710094d430", "label": "摘要47", "info": "图9.11给出了一些使用卷积和池化操作的用于分类的完整卷积网络结构；的例子。", "keywords": "给出了一些使用卷积和池化操作的用于分类的完整卷积网络结构, 的例子", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "662a5cf2-1a2d-405a-bf16-f1a40e0c1b41", "label": "摘要48", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图9.11　卷积网络用于分类的结构示例。本图中使用的具体步幅和深度并不建议实际使用，因；为它们被设计得非常浅以适合页面。实际的卷积网络还常常涉及大量的分支，不同于这里为简", "keywords": "卷积网络用于分类的结构示例, 不同于这里为简, 实际的卷积网络还常常涉及大量的分支, 本图中使用的具体步幅和深度并不建议实际使用, 为它们被设计得非常浅以适合页面", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "28443ed6-e339-45a4-937d-cc06e198441a", "label": "9.4：卷积与池化作为一种无限强的先验", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "614543a4-6f71-4b91-96ac-7b95af5b633f", "label": "摘要1", "info": "回忆一下第5.2节中先验概率分布  （prior  probability  distribution）的概；念。这是一个模型参数的概率分布，它刻画了我们在看到数据之前认为", "keywords": "这是一个模型参数的概率分布, 它刻画了我们在看到数据之前认为, 节中先验概率分布, 回忆一下第, 的概", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7b437f2b-99d5-421c-8720-41e75ef0eab1", "label": "摘要2", "info": "什么样的模型是合理的信念。", "keywords": "什么样的模型是合理的信念", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d9eaefb2-9309-49c0-b19c-cd4ce2fc6ac0", "label": "摘要3", "info": "先验被认为是强或者弱取决于先验中概率密度的集中程度。弱先验具有；较高的熵值，例如方差很大的高斯分布。这样的先验允许数据对于参数；的改变具有或多或少的自由性。强先验具有较低的熵值，例如方差很小", "keywords": "例如方差很大的高斯分布, 弱先验具有, 这样的先验允许数据对于参数, 例如方差很小, 先验被认为是强或者弱取决于先验中概率密度的集中程度", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d5f51f10-70ad-467a-8d45-2f1e29df46db", "label": "摘要4", "info": "一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数；赋值，无论数据对于这些参数的值给出了多大的支持。", "keywords": "赋值, 无论数据对于这些参数的值给出了多大的支持, 一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9cb58e6c-405f-44be-b10a-94413d183090", "label": "摘要5", "info": "我们可以把卷积网络类比成全连接网络，但对于这个全连接网络的权重；有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须；和它邻居的权重相同，但可以在空间上移动。这个先验也要求除了那些", "keywords": "有一个无限强的先验, 这个先验也要求除了那些, 但对于这个全连接网络的权重, 我们可以把卷积网络类比成全连接网络, 但可以在空间上移动", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "12f2f109-c247-4627-8f38-08f07beca82b", "label": "摘要6", "info": "当然，把卷积神经网络当作一个具有无限强先验的全连接网络来实现会；导致极大的计算浪费。但把卷积神经网络想成具有无限强先验的全连接；网络可以帮助我们更好地洞察卷积神经网络是如何工作的。", "keywords": "网络可以帮助我们更好地洞察卷积神经网络是如何工作的, 但把卷积神经网络想成具有无限强先验的全连接, 把卷积神经网络当作一个具有无限强先验的全连接网络来实现会, 导致极大的计算浪费, 当然", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "8ebbfb4a-92bd-499c-b2bd-29d674079fd1", "label": "摘要7", "info": "其中一个关键的洞察是卷积和池化可能导致欠拟合。与任何其他先验类；似，卷积和池化只有当先验的假设合理且正确时才有用。如果一项任务；依赖于保存精确的空间信息，那么在所有的特征上使用池化将会增大训", "keywords": "卷积和池化只有当先验的假设合理且正确时才有用, 那么在所有的特征上使用池化将会增大训, 其中一个关键的洞察是卷积和池化可能导致欠拟合, 与任何其他先验类, 依赖于保存精确的空间信息", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "105bfe32-a2b3-4d8a-bc9d-9a4cef51cd7e", "label": "摘要8", "info": "另一个关键洞察是当我们比较卷积模型的统计学习表现时，只能以基准；中的其他卷积模型作为比较的对象。其他不使用卷积的模型即使我们把；图像中的所有像素点都置换后依然有可能进行学习。对于许多图像数据", "keywords": "只能以基准, 中的其他卷积模型作为比较的对象, 图像中的所有像素点都置换后依然有可能进行学习, 另一个关键洞察是当我们比较卷积模型的统计学习表现时, 其他不使用卷积的模型即使我们把", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f370b400-a30b-4e7e-8f46-839b7047fd29", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；一些是针对模型设计者将空间关系的知识植入了它们的模型。", "keywords": "一些是针对模型设计者将空间关系的知识植入了它们的模型", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "label": "9.5：基本卷积函数的变体", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "33ed60f4-24da-42ef-979d-482d8b97b00d", "label": "摘要1", "info": "当在神经网络的上下文中讨论卷积时，我们通常不是特指数学文献中使；用的那种标准的离散卷积运算。实际应用中的函数略有不同。这里我们；详细讨论一下这些差异，并且对神经网络中用到的函数的一些重要性质", "keywords": "我们通常不是特指数学文献中使, 并且对神经网络中用到的函数的一些重要性质, 用的那种标准的离散卷积运算, 详细讨论一下这些差异, 实际应用中的函数略有不同", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d533817f-a415-4d1d-9d5f-c0cecff8f300", "label": "摘要2", "info": "首先，当提到神经网络中的卷积时，我们通常是指由多个并行卷积组成；的运算。这是因为具有单个核的卷积只能提取一种类型的特征，尽管它；作用在多个空间位置上。我们通常希望网络的每一层能够在多个位置提", "keywords": "这是因为具有单个核的卷积只能提取一种类型的特征, 我们通常是指由多个并行卷积组成, 作用在多个空间位置上, 我们通常希望网络的每一层能够在多个位置提, 尽管它", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9850829a-16a7-430d-8d23-b41844cb16e9", "label": "摘要3", "info": "另外，输入通常也不仅仅是实值的网格，而是由一系列观测数据的向量；构成的网格。例如，一幅彩色图像在每一个像素点都会有红、绿、蓝三；种颜色的亮度。在多层的卷积网络中，第二层的输入是第一层的输出，", "keywords": "而是由一系列观测数据的向量, 构成的网格, 第二层的输入是第一层的输出, 例如, 输入通常也不仅仅是实值的网格", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "89364c03-bebc-4d8c-a422-fe348aa31bf1", "label": "摘要4", "info": "因为卷积网络通常使用多通道的卷积，所以即使使用了核翻转，也不一；定保证网络的线性运算是可交换的。只有当其中每个运算的输出和输入；具有相同的通道数时，这些多通道的运算才是可交换的。", "keywords": "因为卷积网络通常使用多通道的卷积, 只有当其中每个运算的输出和输入, 具有相同的通道数时, 定保证网络的线性运算是可交换的, 这些多通道的运算才是可交换的", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "add3ee5a-38d0-44d3-a8a6-c85771ea1d41", "label": "摘要5", "info": "假定我们有一个4维的核张量K ，它的每一个元素是 K i,j,k，l ，表示输出；中处于通道i的一个单元和输入中处于通道j中的一个单元的连接强度，；并且在输出单元和输入单元之间有k行l列的偏置。假定我们的输入由观", "keywords": "的一个单元和输入中处于通道, 假定我们的输入由观, 列的偏置, 表示输出, 假定我们有一个", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "29c5e28b-a829-4376-9c9a-3b25e93264c6", "label": "摘要6", "info": "这里对所有的l、m和n进行求和是对所有（在求和式中）有效的张量索；引的值进行求和。在线性代数中，向量的索引通常从1开始，这就是上；述公式中-1的由来。但是像C或Python这类编程语言索引通常从0开始，", "keywords": "这类编程语言索引通常从, 述公式中, 的由来, 在求和式中, 开始", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "1fc6d905-3ba0-4590-af26-cc0b68b699d2", "label": "摘要7", "info": "我们有时会希望跳过核中的一些位置来降低计算的开销（相应的代价是；提取特征没有先前那么好了）。我们可以把这一过程看作对全卷积函数；输出的下采样（downsampling）。如果只想在输出的每个方向上每间隔", "keywords": "相应的代价是, 提取特征没有先前那么好了, 如果只想在输出的每个方向上每间隔, 我们有时会希望跳过核中的一些位置来降低计算的开销, 我们可以把这一过程看作对全卷积函数", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "6ae4a247-bc62-4cc8-ba8e-df406bfc2e61", "label": "摘要8", "info": "我们把s称为下采样卷积的步幅  （stride）。当然也可以对每个移动方向；定义不同的步幅。图9.12演示了一个实例。", "keywords": "称为下采样卷积的步幅, 定义不同的步幅, 当然也可以对每个移动方向, 我们把, 演示了一个实例", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9b434f04-4779-4631-96b3-0ffc93b656d9", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图9.12　带有步幅的卷积。在这个例子中，我们的步幅为2。（上）在单个操作中实现的步幅为；2的卷积。（下）步幅大于一个像素的卷积在数学上等价于单位步幅的卷积随后降采样。显然，", "keywords": "显然, 我们的步幅为, 在单个操作中实现的步幅为, 带有步幅的卷积, 在这个例子中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c3f2b1db-a8e4-4df9-b35d-31cc91cab450", "label": "摘要10", "info": "在任何卷积网络的实现中都有一个重要性质，那就是能够隐含地对输；入V  用零进行填充（pad）使得它加宽。如果没有这个性质，表示的宽；度在每一层就会缩减，缩减的幅度是比核少一个像素这么多。对输入进", "keywords": "用零进行填充, 对输入进, 使得它加宽, 如果没有这个性质, 在任何卷积网络的实现中都有一个重要性质", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7d8edc6e-6efe-4406-b9f7-b26ddd26de2b", "label": "摘要11", "info": "图9.13　零填充对网络大小的影响。考虑一个卷积网络，每层有一个宽度为6的核。在这个例子；中，我们不使用任何池化，所以只有卷积操作本身缩小网络的大小。（上）在这个卷积网络；中，我们不使用任何隐含的零填充。这使得表示在每层缩小5个像素。从16个像素的输入开始，", "keywords": "考虑一个卷积网络, 我们不使用任何隐含的零填充, 所以只有卷积操作本身缩小网络的大小, 个像素, 在这个卷积网络", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ec05419c-521d-44e8-9420-709330a4f06d", "label": "摘要12", "info": "有三种零填充设定的情况值得注意。第一种是无论怎样都不使用零填充；的极端情况，并且卷积核只允许访问那些图像中能够完全包含整个核的；位置。在MATLAB的术语中，这称为有效  （valid）卷积。在这种情况", "keywords": "这称为有效, 的极端情况, 第一种是无论怎样都不使用零填充, 的术语中, 在这种情况", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "e80e7cbe-f594-45e7-845a-726b209563c3", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；硬件支持，网络就能包含任意多的卷积层，这是因为卷积运算不改变下；一层的结构。然而，输入像素中靠近边界的部分相比于中间部分对于输", "keywords": "输入像素中靠近边界的部分相比于中间部分对于输, 硬件支持, 一层的结构, 然而, 这是因为卷积运算不改变下", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b2467ec7-cebf-4327-a4c4-60d29604b8ef", "label": "摘要14", "info": "在一些情况下，我们并不是真的想使用卷积，而是想用一些局部连接的；网络层（LeCun，1986，1989）。在这种情况下，我们的多层感知机对；应的邻接矩阵是相同的，但每一个连接都有它自己的权重，用一个6维", "keywords": "我们的多层感知机对, 应的邻接矩阵是相同的, 我们并不是真的想使用卷积, 在这种情况下, 网络层", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b1a6bf6e-0a5b-4c86-aa3c-41f81bd0c32f", "label": "摘要15", "info": "这有时也被称为非共享卷积 （unshared convolution），因为它和具有一；个小核的离散卷积运算很像，但并不横跨位置来共享参数。图9.14比较；了局部连接、卷积和全连接的区别。", "keywords": "个小核的离散卷积运算很像, 卷积和全连接的区别, 比较, 了局部连接, 因为它和具有一", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b1ba9223-c432-47af-8650-b3f0ed638232", "label": "摘要16", "info": "图9.14　局部连接，卷积和全连接的比较。（上）每一小片（接受域）有两个像素的局部连接；层。每条边用唯一的字母标记，来显示每条边都有自身的权重参数。（中）核宽度为两个像素；的卷积层。该模型与局部连接层具有完全相同的连接。区别不在于哪些单元相互交互，而在于", "keywords": "来显示每条边都有自身的权重参数, 区别不在于哪些单元相互交互, 的卷积层, 接受域, 卷积和全连接的比较", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d22c7e23-fa66-417b-8e29-dc0aeba85cfb", "label": "摘要17", "info": "当我们知道每一个特征都是一小块空间的函数并且相同的特征不会出现；在所有的空间上时，局部连接层是很有用的。例如，如果想要辨别一张；图片是否是人脸图像，我们只需要去寻找嘴是否在图像下半部分即可。", "keywords": "局部连接层是很有用的, 图片是否是人脸图像, 例如, 在所有的空间上时, 当我们知道每一个特征都是一小块空间的函数并且相同的特征不会出现", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f2d4322e-eaaf-481c-9184-84bedfe12ece", "label": "摘要18", "info": "使用那些连接被更进一步限制的卷积或者局部连接层也是有用的，例", "keywords": "使用那些连接被更进一步限制的卷积或者局部连接层也是有用的", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9abeb4d4-9b1e-4e33-9362-d61357815712", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；如，限制每一个输出的通道i仅仅是输入通道l的一部分的函数时。实现；这种情况的一种通用方法是使输出的前m个通道仅仅连接到输入的前n", "keywords": "个通道仅仅连接到输入的前, 仅仅是输入通道, 实现, 的一部分的函数时, 限制每一个输出的通道", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "54af9ab8-4138-4118-bb7f-745d20b71c34", "label": "摘要20", "info": "图9.15　卷积网络的前两个输出通道只和前两个输入通道相连，随后的两个输出通道只和随后；的两个输入通道相连", "keywords": "卷积网络的前两个输出通道只和前两个输入通道相连, 的两个输入通道相连, 随后的两个输出通道只和随后", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "12c2b588-a8ba-43fe-b590-8c66bc0483bb", "label": "摘要21", "info": "平铺卷积 （tiled convolution）（Gregor and LeCun，2010a；Le et al. ，；2010）对卷积层和局部连接层进行了折衷。这里并不是对每一个空间位", "keywords": "对卷积层和局部连接层进行了折衷, 这里并不是对每一个空间位, 平铺卷积", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ebe36ec3-faf5-47a2-b06e-62a7e23858ef", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；置的权重集合进行学习，我们学习一组核使得当我们在空间移动时它们；可以循环利用。这意味着在近邻的位置上拥有不同的过滤器，就像局部", "keywords": "我们学习一组核使得当我们在空间移动时它们, 置的权重集合进行学习, 可以循环利用, 这意味着在近邻的位置上拥有不同的过滤器, 就像局部", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ce90a964-ea36-433d-bb85-0881c41ed0c8", "label": "摘要23", "info": "图9.16　局部连接层、平铺卷积和标准卷积的比较。当使用相同大小的核时，这三种方法在单；元之间具有相同的连接。此图是对使用两个像素宽的核的说明。这三种方法之间的区别在于它；们如何共享参数。（上）局部连接层根本没有共享参数。我们对每个连接使用唯一的字母标", "keywords": "们如何共享参数, 局部连接层, 我们对每个连接使用唯一的字母标, 平铺卷积和标准卷积的比较, 当使用相同大小的核时", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b7b7a0bb-7a66-45d7-8564-2373810bd70a", "label": "摘要24", "info": "为“a”和“b”的边的核", "keywords": "的边的核", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a25a6196-ae43-4ec4-b25f-622cde692d3c", "label": "摘要25", "info": "为了用代数的方法定义平铺卷积，令K 是一个6维的张量  (3)  ，其中的两；维对应着输出映射中的不同位置。K  在这里并没有对输出映射中的每一；个位置使用单独的索引，输出的位置在每个方向上在t个不同的核组成", "keywords": "其中的两, 为了用代数的方法定义平铺卷积, 维的张量, 个不同的核组成, 输出的位置在每个方向上在", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "1f601877-7b3f-449c-9e65-954cd07b4b1a", "label": "摘要26", "info": "这里百分号是取模运算，它的性质包括t%t＝0，(t+1)%t＝1等。在每一；维上使用不同的t可以很容易对这个方程进行扩展。", "keywords": "在每一, 这里百分号是取模运算, 可以很容易对这个方程进行扩展, 维上使用不同的, 它的性质包括", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "41ee0e21-8d88-4ca5-9e56-f244313a76a8", "label": "摘要27", "info": "局部连接层与平铺卷积层都和最大池化有一些有趣的关联：这些层的探；测单元都是由不同的过滤器驱动的。如果这些过滤器能够学会探测相同；隐含特征的不同变换形式，那么最大池化的单元对于学得的变换就具有", "keywords": "那么最大池化的单元对于学得的变换就具有, 局部连接层与平铺卷积层都和最大池化有一些有趣的关联, 测单元都是由不同的过滤器驱动的, 隐含特征的不同变换形式, 这些层的探", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "126b6ad9-1d74-4383-bffe-f1d9dce2d082", "label": "摘要28", "info": "实现卷积网络时，通常也需要除卷积以外的其他运算。为了实现学习，；必须在给定输出的梯度时能够计算核的梯度。在一些简单情况下，这种；运算可以通过卷积来实现，但在很多我们感兴趣的情况下，包括步幅大", "keywords": "通常也需要除卷积以外的其他运算, 为了实现学习, 但在很多我们感兴趣的情况下, 运算可以通过卷积来实现, 实现卷积网络时", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "99f24d80-49b3-4a58-90ef-3c7dc679af7a", "label": "摘要29", "info": "回忆一下，卷积是一种线性运算，所以可以表示成矩阵乘法的形式（如；果我们首先把输入张量变形为一个扁平的向量）。其中包含的矩阵是关；于卷积核的函数。这个矩阵是稀疏的，并且核的每个元素都复制给矩阵", "keywords": "回忆一下, 其中包含的矩阵是关, 所以可以表示成矩阵乘法的形式, 并且核的每个元素都复制给矩阵, 于卷积核的函数", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "73af0c9c-a9e4-4b3d-ad28-c388bd7219f6", "label": "摘要30", "info": "通过卷积定义的矩阵转置的乘法就是这样一种运算。这种运算用于在卷；积层反向传播误差的导数，所以它在训练多于一个隐藏层的卷积网络时；是必要的。如果我们想要从隐藏层单元重构可视化单元时，同样的运算", "keywords": "是必要的, 积层反向传播误差的导数, 同样的运算, 通过卷积定义的矩阵转置的乘法就是这样一种运算, 所以它在训练多于一个隐藏层的卷积网络时", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9d275c17-c97c-44cb-b823-d366d1b49616", "label": "摘要31", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；向传播过程相协调。转置运算返回的输出的大小取决于三个方面：零填；充的策略、前向传播运算的步幅以及前向传播的输出映射的大小。在一", "keywords": "转置运算返回的输出的大小取决于三个方面, 充的策略, 在一, 零填, 前向传播运算的步幅以及前向传播的输出映射的大小", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "0faa3384-8706-4f40-b905-7a21cffef89d", "label": "摘要32", "info": "这三种运算——卷积、从输出到权重的反向传播和从输出到输入的反向；传播——对于训练任意深度的前馈卷积网络，以及训练带有（基于卷积；的转置的）重构函数的卷积网络，这三种运算都足以计算它们所需的所", "keywords": "基于卷积, 重构函数的卷积网络, 这三种运算, 对于训练任意深度的前馈卷积网络, 卷积", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "0154fe71-b8e8-4fb1-9853-9d47c3520913", "label": "摘要33", "info": "假设我们想要训练这样一个卷积网络，它包含步幅为s的步幅卷积，该；卷积的核为K  ，作用于多通道的图像V  ，定义为c(K；,s)，就像式", "keywords": "的步幅卷积, 定义为, 就像式, 它包含步幅为, 卷积的核为", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f35f9804-00df-4475-a99e-8c3af5c6fcdd", "label": "摘要34", "info": ",V", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fa2e4162-d51e-4a9a-a88f-c3e87bb7394d", "label": "摘要35", "info": "满足", "keywords": "满足", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3f0a009e-83e2-4580-96e3-ae42cb1f408d", "label": "摘要36", "info": "。", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c0722288-0d70-42ba-8d8a-fefed39a0ccb", "label": "摘要37", "info": "为了训练网络，我们需要对核中的权重求导。为了实现这个目的，我们；可以使用一个函数", "keywords": "可以使用一个函数, 为了训练网络, 我们需要对核中的权重求导, 为了实现这个目的, 我们", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "0025d13e-c825-4a8f-ac2c-05e80dfb882a", "label": "摘要38", "info": "如果这一层不是网络的底层，我们需要对V  求梯度来使得误差进一步反；向传播。我们可以使用如下的函数", "keywords": "向传播, 我们需要对, 如果这一层不是网络的底层, 我们可以使用如下的函数, 求梯度来使得误差进一步反", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "e3613415-1c53-48cd-8f07-f95df0a41a53", "label": "摘要39", "info": "第14章描述的自编码器网络，是一些被训练成把输入拷贝到输出的前馈；网络。一个简单的例子是PCA算法，将输入  x  拷贝到一个近似的重构值；来实现。使用权重矩阵转置的乘法，就像PCA", "keywords": "网络, 章描述的自编码器网络, 算法, 使用权重矩阵转置的乘法, 将输入", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a46e506b-642b-49a9-b36e-271c28903f40", "label": "摘要40", "info": "算法这种，在一般的自编码器中是很常见的。为了使这些模型卷积化，；我们可以用函数h来实现卷积运算的转置。假定我们有和Z  相同形式的；隐藏单元H ，并且我们定义一种重构运算", "keywords": "隐藏单元, 假定我们有和, 并且我们定义一种重构运算, 在一般的自编码器中是很常见的, 算法这种", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "6f7f6f20-c28f-4fbb-860e-ea42309eca4d", "label": "摘要41", "info": "为了训练自编码器，我们会得到关于R  的梯度，表示为一个张量E  。为；了训练解码器，我们需要获得对于K 的梯度，这通过g(H ,E ,s)来得到。；为了训练编码器，我们需要获得对于H  的梯度，这通过c(K  ,E  ,s)来得", "keywords": "为了训练自编码器, 我们需要获得对于, 这通过, 来得到, 了训练解码器", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "561dc114-5a6d-4fe5-87d7-74670a0e4dc8", "label": "摘要42", "info": "一般来说，在卷积层从输入到输出的变换中我们不仅仅只用线性运算。；我们一般也会在进行非线性运算前，对每个输出加入一些偏置项。这样；就产生了如何在偏置项中共享参数的问题。对于局部连接层，很自然地", "keywords": "在卷积层从输入到输出的变换中我们不仅仅只用线性运算, 很自然地, 一般来说, 对每个输出加入一些偏置项, 对于局部连接层", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "label": "9.6：结构化输出", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "35ca46c7-9aa6-42cd-a396-c1d9876d5b3a", "label": "摘要1", "info": "卷积神经网络可以用于输出高维的结构化对象，而不仅仅是预测分类任；务的类标签或回归任务的实数值。通常这个对象只是一个张量，由标准；卷积层产生。例如，模型可以产生张量S ，其中S  i,j,k 是网络的输入像素", "keywords": "模型可以产生张量, 由标准, 卷积层产生, 通常这个对象只是一个张量, 其中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b08507ff-f8ce-418e-963f-6dc47aeb5aad", "label": "摘要2", "info": "经常出现的一个问题是输出平面可能比输入平面要小，如图9.13所示。；用于对图像中单个对象分类的常用结构中，网络空间维数的最大减少来；源于使用大步幅的池化层。为了产生与输入大小相似的输出映射，我们", "keywords": "经常出现的一个问题是输出平面可能比输入平面要小, 网络空间维数的最大减少来, 所示, 用于对图像中单个对象分类的常用结构中, 我们", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a403deac-3134-4000-8418-ecef8dc2463c", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；生一张低分辨率的标签网格（Pinheiro and Collobert，2014，2015）。最；后，原则上可以使用具有单位步幅的池化操作。", "keywords": "生一张低分辨率的标签网格, 原则上可以使用具有单位步幅的池化操作", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "abae668e-3b80-4a43-a2ae-d1a484713dcc", "label": "摘要4", "info": "对图像逐个像素标记的一种策略是先产生图像标签的原始猜测，然后使；用相邻像素之间的交互来修正该原始猜测。重复这个修正步骤数次对应；于在每一步使用相同的卷积，该卷积在深层网络的最后几层之间共享权", "keywords": "用相邻像素之间的交互来修正该原始猜测, 然后使, 对图像逐个像素标记的一种策略是先产生图像标签的原始猜测, 该卷积在深层网络的最后几层之间共享权, 于在每一步使用相同的卷积", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3266084e-369e-4dfc-97f4-251a4bba6451", "label": "摘要5", "info": "图9.17　用于像素标记的循环卷积网络的示例。输入是图像张量X，它的轴对应图像的行、列和；，它遵循每个像素的标签的概率分布。该张量的轴对；通道（红、绿、蓝）。目标是输出标签", "keywords": "通道, 目标是输出标签, 它遵循每个像素的标签的概率分布, 输入是图像张量, 列和", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "e699a410-42ac-4353-8751-ccec2b78eb58", "label": "摘要6", "info": "进行卷积来提供隐", "keywords": "进行卷积来提供隐", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "1e48cd0d-d13f-4b42-b69b-d3154c1ceb79", "label": "摘要7", "info": "藏层的输入。在第一步中，此项由零代替。因为每一步使用相同的参数，所以这是一个循环网；络的例子，如第10章所述", "keywords": "藏层的输入, 此项由零代替, 络的例子, 如第, 在第一步中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f96c85c2-9def-4fc1-ab41-f2559e5183f2", "label": "摘要8", "info": "一旦对每个像素都进行了预测，我们就可以使用各种方法来进一步处理；这些预测，以便获得图像在区域上的分割（Briggman  et  al.  ，2009；；Turaga et al. ，2010；Farabet et al. ，2013）。一般的想法是假设大片相", "keywords": "我们就可以使用各种方法来进一步处理, 一般的想法是假设大片相, 以便获得图像在区域上的分割, 一旦对每个像素都进行了预测, 这些预测", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "label": "9.7：数据类型", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "a77ccdf1-42d1-4abc-b17f-d716db522cf0", "label": "摘要1", "info": "卷积网络使用的数据通常包含多个通道，每个通道是时间上或空间中某；一点的不同观测量。参考表9.1来了解具有不同维数和通道数的数据类；型的例子。", "keywords": "卷积网络使用的数据通常包含多个通道, 每个通道是时间上或空间中某, 一点的不同观测量, 参考表, 来了解具有不同维数和通道数的数据类", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "cce80d4a-2208-4488-8bff-4a7c710e50b8", "label": "摘要2", "info": "表9.1　用于卷积网络的不同数据格式的示例", "keywords": "用于卷积网络的不同数据格式的示例", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c1bf8532-c298-4bdc-b6ed-e076636a8c51", "label": "摘要3", "info": "单通道", "keywords": "单通道", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "9a8e1e66-ccc4-48cb-bfb6-e2d0690c4e14", "label": "摘要4", "info": "一；维", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "e4c70af9-7976-4e3d-a4ec-7b4cc2940fe2", "label": "摘要5", "info": "音频波形：卷积的轴对应于时间。我；们将时间离散化并且在每个时间点测；量一次波形的振幅", "keywords": "音频波形, 量一次波形的振幅, 们将时间离散化并且在每个时间点测, 卷积的轴对应于时间", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "34a74bda-766a-472d-962e-9c8d1b4f2a6a", "label": "摘要6", "info": "多通道", "keywords": "多通道", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7f1a421f-3b90-4c63-a2ee-58bbf8cac1ae", "label": "摘要7", "info": "骨架动画（skeleton；animation）数据：计算机渲；染的三维角色动画是通过随", "keywords": "计算机渲, 染的三维角色动画是通过随, 数据, 骨架动画", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ff71a1c0-e52c-4f00-b6b9-937260ac7f0c", "label": "摘要8", "info": "已经使用傅里叶变换预处理过的音频；数据：我们可以将音频波形变换成二；维张量，不同的行对应不同的频率，", "keywords": "已经使用傅里叶变换预处理过的音频, 数据, 不同的行对应不同的频率, 我们可以将音频波形变换成二, 维张量", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b3f5b79e-041b-4317-aff1-1c1e2213d573", "label": "摘要9", "info": "二；维", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7d4d86fc-00d6-48ad-8217-2de769eff8ba", "label": "摘要10", "info": "彩色图像数据：其中一个；通道包含红色像素，另一个；包含绿色像素，最后一个包", "keywords": "最后一个包, 其中一个, 彩色图像数据, 包含绿色像素, 通道包含红色像素", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "cebbd400-b726-4a9b-a2e5-7d068262c899", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；等效于在频率上移动，这使得在不同；八度音阶中播放的相同旋律产生相同", "keywords": "这使得在不同, 等效于在频率上移动, 八度音阶中播放的相同旋律产生相同", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "167f28ff-8536-4d94-8b9e-4687afedbab9", "label": "摘要12", "info": "赋予了两个方向上平移等变；性", "keywords": "赋予了两个方向上平移等变", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "403d7e33-3f53-4acf-a75c-0e423d872992", "label": "摘要13", "info": "三；维", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "001802bf-4e02-4b0e-a4b0-e20cdea6e941", "label": "摘要14", "info": "体积数据：这种数据一般来源于医学；成像技术，例如CT扫描等", "keywords": "扫描等, 例如, 这种数据一般来源于医学, 体积数据, 成像技术", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "acce5934-2d69-44f2-ba07-c6bc3484ecef", "label": "摘要15", "info": "彩色视频数据：其中一个；轴对应着时间，另一个轴对；应着视频帧的高度，最后一", "keywords": "应着视频帧的高度, 其中一个, 轴对应着时间, 彩色视频数据, 另一个轴对", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d51e95cc-9a3c-4151-9563-488cfab2e875", "label": "摘要16", "info": "卷积网络用于视频的例子，可以参考Chen et al. （2010）。", "keywords": "可以参考, 卷积网络用于视频的例子", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7b6127bc-e562-407f-a665-931bac3764b8", "label": "摘要17", "info": "到目前为止，我们仅讨论了训练和测试数据中的每个样例都有相同的空；间维度的情况。卷积网络的一个优点是它们还可以处理具有可变的空间；尺度的输入。这些类型的输入不能用传统的基于矩阵乘法的神经网络来", "keywords": "间维度的情况, 尺度的输入, 我们仅讨论了训练和测试数据中的每个样例都有相同的空, 到目前为止, 这些类型的输入不能用传统的基于矩阵乘法的神经网络来", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3d138843-4209-4583-9fb5-488aef444916", "label": "摘要18", "info": "例如，考虑一组图像的集合，其中每个图像具有不同的高度和宽度。目；前还不清楚如何用固定大小的权重矩阵对这样的输入进行建模。卷积就；可以很直接地应用；核依据输入的大小简单地被使用不同次，并且卷积", "keywords": "前还不清楚如何用固定大小的权重矩阵对这样的输入进行建模, 可以很直接地应用, 并且卷积, 例如, 卷积就", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "673fb7cf-0ac0-4e17-8f73-1f8df8ded864", "label": "摘要19", "info": "注意，使用卷积处理可变尺寸的输入，仅对输入是因为包含对同种事物；的不同量的观察（时间上不同长度的记录，空间上不同宽度的观察等）；而导致的尺寸变化这种情况才有意义。如果输入是因为它可以选择性地", "keywords": "而导致的尺寸变化这种情况才有意义, 空间上不同宽度的观察等, 注意, 仅对输入是因为包含对同种事物, 时间上不同长度的记录", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c08d0f94-2139-4f68-914c-aeb39548c99f", "label": "摘要20", "info": "成绩特征和测试分数特征进行卷积是没有意义的。", "keywords": "成绩特征和测试分数特征进行卷积是没有意义的", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "51f62548-da2e-4f14-a365-86e9360952c1", "label": "9.8：高效的卷积算法", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "e6705c77-b93c-406b-8f13-fa85185d49f0", "label": "摘要1", "info": "现代卷积网络的应用通常需要包含超过百万个单元的网络。利用并行计；算资源的强大实现是很关键的，如第12.1节中所描述的。然而，在很多；情况下，也可以通过选择适当的卷积算法来加速卷积。", "keywords": "节中所描述的, 也可以通过选择适当的卷积算法来加速卷积, 情况下, 然而, 现代卷积网络的应用通常需要包含超过百万个单元的网络", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "8b37b8c8-09e0-4609-9416-fe1b7f114fd7", "label": "摘要2", "info": "卷积等效于使用傅里叶变换将输入与核都转换到频域、执行两个信号的；逐点相乘，再使用傅里叶逆变换转换回时域。对于某些问题的规模，这；种算法可能比离散卷积的朴素实现更快。", "keywords": "对于某些问题的规模, 逐点相乘, 执行两个信号的, 卷积等效于使用傅里叶变换将输入与核都转换到频域, 再使用傅里叶逆变换转换回时域", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "bdb40a5b-524b-44e3-93a5-dcdd3b8acb5a", "label": "摘要3", "info": "当一个d维的核可以表示成d个向量（每一维一个向量）的外积时，该核；被称为可分离的 （separable）。当核可分离时，朴素的卷积是低效的。；它等价于组合d个一维卷积，每个卷积使用这些向量中的一个。组合方", "keywords": "维的核可以表示成, 的外积时, 当一个, 当核可分离时, 每个卷积使用这些向量中的一个", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c4c031e3-bdc2-43cd-b8d5-665d649d5a99", "label": "摘要4", "info": "设计更快的执行卷积或近似卷积，而不损害模型准确性的方法，是一个；活跃的研究领域。甚至仅提高前向传播效率的技术也是有用的，因为在；商业环境中，通常部署网络比训练网络还要耗资源。", "keywords": "因为在, 活跃的研究领域, 商业环境中, 通常部署网络比训练网络还要耗资源, 而不损害模型准确性的方法", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "label": "9.9：随机或无监督的特征", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "a8841753-2004-4784-bc74-399d8b807610", "label": "摘要1", "info": "通常，卷积网络训练中最昂贵的部分是学习特征。输出层的计算代价通；常相对不高，因为在通过若干层池化之后作为该层输入的特征的数量较；少。当使用梯度下降执行监督训练时，每步梯度计算需要完整地运行整", "keywords": "通常, 因为在通过若干层池化之后作为该层输入的特征的数量较, 当使用梯度下降执行监督训练时, 每步梯度计算需要完整地运行整, 输出层的计算代价通", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b9f24062-82b0-4a70-8b82-23c031d5b239", "label": "摘要2", "info": "有三种基本策略可以不通过监督训练而得到卷积核。其中一种是简单地；随机初始化它们。另一种是手动设计它们，例如设置每个核在一个特定；的方向或尺度来检测边缘。最后，可以使用无监督的标准来学习核。例", "keywords": "例如设置每个核在一个特定, 有三种基本策略可以不通过监督训练而得到卷积核, 另一种是手动设计它们, 的方向或尺度来检测边缘, 可以使用无监督的标准来学习核", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "034de583-1031-4522-bfa2-878d2063c1ae", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；如，Coates  et  al.  （2011）将k均值聚类算法应用于小图像块，然后使用；每个学得的中心作为卷积核。本书第3部分描述了更多的无监督学习方", "keywords": "然后使用, 均值聚类算法应用于小图像块, 本书第, 每个学得的中心作为卷积核, 部分描述了更多的无监督学习方", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "604027ff-6ddc-44fa-af19-63b9cf4f3842", "label": "摘要4", "info": "随机过滤器经常在卷积网络中表现得出乎意料得好Jarrett；al.；（2009b）；Saxe  et  al.  （2011）；Pinto  et  al.  （2011）；Cox  and", "keywords": "随机过滤器经常在卷积网络中表现得出乎意料得好", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "6a8660cf-f03a-4b19-837e-2661edfbc31f", "label": "摘要5", "info": "et", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c437f528-2381-4453-8c4d-df53a62d497d", "label": "摘要6", "info": "一个中间方法是学习特征，但是使用那种不需要在每个梯度计算步骤中；都进行完整的前向和反向传播的方法。与多层感知机一样，我们使用贪；心逐层预训练，单独训练第一层，然后一次性地从第一层提取所有特", "keywords": "一个中间方法是学习特征, 心逐层预训练, 与多层感知机一样, 然后一次性地从第一层提取所有特, 单独训练第一层", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d3074a10-d91a-47bf-bdee-b46402f48a42", "label": "摘要7", "info": "与其他无监督预训练的方法一样，使用这种方法的一些好处仍然难以说；清。无监督预训练可以提供一些相对于监督训练的正则化，或者它可以；简单地允许我们训练更大的结构，因为它的学习规则降低了计算成本。", "keywords": "无监督预训练可以提供一些相对于监督训练的正则化, 简单地允许我们训练更大的结构, 使用这种方法的一些好处仍然难以说, 或者它可以, 因为它的学习规则降低了计算成本", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "label": "9.10：卷积网络的神经科学基础", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "ab5841ab-2d57-4258-973b-5f2b2b13658f", "label": "摘要1", "info": "卷积网络也许是生物学启发人工智能的最为成功的案例。虽然卷积网络；也经过许多其他领域的指导，但是神经网络的一些关键设计原则来自神；经科学。", "keywords": "经科学, 虽然卷积网络, 也经过许多其他领域的指导, 卷积网络也许是生物学启发人工智能的最为成功的案例, 但是神经网络的一些关键设计原则来自神", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d3c316df-9967-4558-b0a5-46011880bbbd", "label": "摘要2", "info": "卷积网络的历史始于神经科学实验，远早于相关计算模型的发展。为了；确定关于哺乳动物视觉系统如何工作的许多最基本的事实，神经生理学；家David  Hubel和Torsten  Wiesel合作多年（Hubel  and  Wiesel，1959，", "keywords": "为了, 确定关于哺乳动物视觉系统如何工作的许多最基本的事实, 远早于相关计算模型的发展, 卷积网络的历史始于神经科学实验, 神经生理学", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fdf665b8-1996-4989-9e25-d522c03f98da", "label": "摘要3", "info": "他们的工作有助于表征大脑功能的许多方面，这些方面超出了本书的范；围。从深度学习的角度来看，我们可以专注于简化的、草图形式的大脑；功能视图。", "keywords": "我们可以专注于简化的, 草图形式的大脑, 从深度学习的角度来看, 功能视图, 他们的工作有助于表征大脑功能的许多方面", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3aa6d283-b169-4534-a675-49cae7d765b7", "label": "摘要4", "info": "在这个简化的视图中，我们关注被称为V1的大脑的一部分，也称为初；级视觉皮层 （primary visual cortex）。V1是大脑对视觉输入开始执行显；著高级处理的第一个区域。在该草图视图中，图像是由光到达眼睛并刺", "keywords": "图像是由光到达眼睛并刺, 著高级处理的第一个区域, 我们关注被称为, 在该草图视图中, 的大脑的一部分", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2ab5213d-f182-4f13-929f-55e9c4482594", "label": "摘要5", "info": "卷积网络层被设计为描述V1的三个性质：", "keywords": "卷积网络层被设计为描述, 的三个性质", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "ad4f0287-22c0-40a1-a3ee-0bd7c4bfed84", "label": "摘要6", "info": "（1）V1可以进行空间映射。它实际上具有二维结构来反映视网膜中的；图像结构。例如，到达视网膜下半部的光仅影响V1相应的一半。卷积；网络通过用二维映射定义特征的方式来描述该特性。", "keywords": "相应的一半, 图像结构, 它实际上具有二维结构来反映视网膜中的, 可以进行空间映射, 例如", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "102f11f7-ce02-405f-8e2d-6dd62dc48c1c", "label": "摘要7", "info": "（2）V1包含许多简单细胞  （simple  cell）。简单细胞的活动在某种程", "keywords": "包含许多简单细胞, 简单细胞的活动在某种程", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b3524a68-fca8-4c05-a310-c4bd59143927", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；度上可以概括为在一个小的空间位置感受野内的图像的线性函数。卷积；网络的检测器单元被设计为模拟简单细胞的这些性质。", "keywords": "度上可以概括为在一个小的空间位置感受野内的图像的线性函数, 卷积, 网络的检测器单元被设计为模拟简单细胞的这些性质", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "db363827-841e-4eea-8879-668313e18692", "label": "摘要9", "info": "（3）V1还包括许多复杂细胞 （complex cell）。这些细胞响应类似于由；简单细胞检测的那些特征，但是复杂细胞对于特征的位置微小偏移具有；不变性。这启发了卷积网络的池化单元。复杂细胞对于照明中的一些变", "keywords": "还包括许多复杂细胞, 复杂细胞对于照明中的一些变, 这启发了卷积网络的池化单元, 这些细胞响应类似于由, 不变性", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "8f356fa9-ecf8-4ad0-bae7-744fd83eb614", "label": "摘要10", "info": "虽然我们最了解V1，但是一般认为相同的基本原理也适用于视觉系统；的其他区域。在视觉系统的草图视图中，当我们逐渐深入大脑时，遵循；池化的基本探测策略被反复执行。当穿过大脑的多个解剖层时，我们最", "keywords": "在视觉系统的草图视图中, 池化的基本探测策略被反复执行, 当我们逐渐深入大脑时, 当穿过大脑的多个解剖层时, 的其他区域", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f660d9a3-0760-441e-beef-4321f1dfde85", "label": "摘要11", "info": "这些祖母细胞已经被证明确实存在于人脑中，在一个被称为内侧颞叶的；区域（Quiroga et  al.  ，2005）。研究人员测试了单个神经元是否会响应；名人的照片。他们发现了后来被称为“Halle  Berry神经元”的神经元：由", "keywords": "在一个被称为内侧颞叶的, 区域, 名人的照片, 他们发现了后来被称为, 神经元", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "4bc7b80a-2557-4e27-b108-fac83013e9e5", "label": "摘要12", "info": "这些内侧颞叶神经元比现代卷积网络更通用一些，这些网络在读取名称；时不会自动联想到识别人或对象。与卷积网络的最后一层在特征上最接；近的类比是称为颞下皮质（IT）的脑区。当查看一个对象时，信息从视", "keywords": "近的类比是称为颞下皮质, 与卷积网络的最后一层在特征上最接, 这些内侧颞叶神经元比现代卷积网络更通用一些, 这些网络在读取名称, 当查看一个对象时", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "d8912bd1-7883-4dc2-9008-46ed2a823aa2", "label": "摘要13", "info": "类似（DiCarlo，2013）。", "keywords": "类似", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "4ae2849b-ecbb-4f66-8e58-778123107b0f", "label": "摘要14", "info": "话虽如此，卷积网络和哺乳动物的视觉系统之间还是有许多区别。这些；区别有一些是计算神经科学家所熟知的，但超出了本书的范围。还有一；些区别尚未知晓，因为关于哺乳动物视觉系统如何工作的许多基本问题", "keywords": "这些, 话虽如此, 因为关于哺乳动物视觉系统如何工作的许多基本问题, 区别有一些是计算神经科学家所熟知的, 些区别尚未知晓", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "aa00ac38-8891-4e3d-ba07-e360455334bb", "label": "摘要15", "info": "人眼大部分是非常低的分辨率，除了一个被称为中央凹  （fovea）；的小块。中央凹仅观察在手臂长度距离内一块拇指大小的区域。虽；然我们觉得自己可以看到高分辨率的整个场景，但这是由大脑的潜", "keywords": "除了一个被称为中央凹, 的小块, 人眼大部分是非常低的分辨率, 然我们觉得自己可以看到高分辨率的整个场景, 中央凹仅观察在手臂长度距离内一块拇指大小的区域", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "fa5ba3e9-511f-4759-a4fd-860f0917fd7b", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；还值得一提的是，神经科学很少告诉我们该如何训练卷积网络。具有跨；多个空间位置的参数共享的模型结构，可以追溯到早期关于视觉的联结", "keywords": "可以追溯到早期关于视觉的联结, 神经科学很少告诉我们该如何训练卷积网络, 多个空间位置的参数共享的模型结构, 具有跨, 还值得一提的是", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c3b33694-acb2-4cde-9390-2576f2c04898", "label": "摘要17", "info": "Lang  and  Hinton（1988）引入反向传播来训练时延神经网络  （time；delay  neural network，TDNN）。使用当代术语来说，TDNN是用于时间；序列的一维卷积网络。用于这些模型的反向传播不受任何神经科学观察", "keywords": "序列的一维卷积网络, 使用当代术语来说, 是用于时间, 用于这些模型的反向传播不受任何神经科学观察, 引入反向传播来训练时延神经网络", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3b4aad49-5b1b-439b-a1e3-7fcba878fbfc", "label": "摘要18", "info": "到目前为止，我们已经描述了简单细胞对于某些特征是如何呈现粗略的；线性和选择性，复杂细胞是如何更加非线性，并且对于这些简单细胞特；征的某些变换具有不变性，以及在选择性和不变性之间交替放置的层可", "keywords": "征的某些变换具有不变性, 复杂细胞是如何更加非线性, 我们已经描述了简单细胞对于某些特征是如何呈现粗略的, 线性和选择性, 到目前为止", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "bdfeb90d-e3a8-4a75-ba5a-38dd6e454fb5", "label": "摘要19", "info": "反向相关向我们表明，大多数的V1细胞具有由Gabor函数；（Gabor；function）所描述的权重。Gabor函数描述在图像中的二维点处的权重。", "keywords": "反向相关向我们表明, 函数, 所描述的权重, 大多数的, 细胞具有由", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "15c56c38-e503-4e46-8093-b490dff044a2", "label": "摘要20", "info": "特别地，w(x,y)采用Gabor函数的形式：", "keywords": "函数的形式, 采用, 特别地", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b531b209-d463-4b76-80e1-26e741db4c1a", "label": "摘要21", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "826905d3-7254-4e00-8bf1-17345b1d3892", "label": "摘要22", "info": "以及", "keywords": "以及", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7a405f60-43f9-489c-9ffd-c86a22201823", "label": "摘要23", "info": "这里α、β  x  、β  y  、f、φ、x  0  、y  0  、τ都是控制Gabor函数性质的参数。；图9.18给出了Gabor函数在不同参数集上的一些例子。", "keywords": "这里, 函数在不同参数集上的一些例子, 给出了, 函数性质的参数, 都是控制", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "aa09e8c1-11b8-4382-b5e4-df5c594a8601", "label": "摘要24", "info": "图9.18　具有各种参数设置的Gabor函数。白色表示绝对值大的正权重，黑色表示绝对值大的负；权重，背景灰色对应于零权重。（左）控制坐标系的参数具有不同值的Gabor函数，这些参数包；括：x 0 、y 0 和γ。在该网格中的每个Gabor函数被赋予和它在网格中的位置成比例的x 0 和y 0", "keywords": "具有各种参数设置的, 黑色表示绝对值大的负, 背景灰色对应于零权重, 函数, 在该网格中的每个", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "05714f45-d690-499e-a13e-00da2d2b36c4", "label": "摘要25", "info": "参数x  0  、y  0  和τ定义坐标系。我们平移和旋转x和y来得到x′和y′。具体；地，简单细胞会响应以点(x 0 ，y 0 )为中心的图像特征，并且当我们沿着；从水平方向旋转τ弧度的线移动时，简单细胞将响应亮度的变化。", "keywords": "我们平移和旋转, 参数, 具体, 并且当我们沿着, 从水平方向旋转", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "a5068bf8-8354-43d5-aad7-ada6847e2c92", "label": "摘要26", "info": "作为x′和y′的函数，函数w会响应当我们沿着x′移动时的亮度变化。它有；两个重要的因子：一个是高斯函数，另一个是余弦函数。", "keywords": "一个是高斯函数, 作为, 两个重要的因子, 函数, 会响应当我们沿着", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "89da3557-5c44-428c-9dd2-c94826478799", "label": "摘要27", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；高斯因子αexp(-β x x '2 -β  y  y  '2 )可以被视为阈值项，用于保证简单细胞仅；对接近x′和y′都为零点处的值响应，换句话说，接近细胞接受域的中", "keywords": "都为零点处的值响应, 高斯因子, 接近细胞接受域的中, 换句话说, 可以被视为阈值项", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "95983ef5-d7e7-4a74-b8cf-d7660c796c13", "label": "摘要28", "info": "余弦因子cos(fx′+φ)控制简单细胞如何响应延x′轴的亮度改变。参数f控；制余弦的频率，φ控制它的相位偏移。", "keywords": "参数, 余弦因子, 控制简单细胞如何响应延, 控制它的相位偏移, 制余弦的频率", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2b62da72-8ec9-4011-b9fb-f5b0e6c812ec", "label": "摘要29", "info": "合在一起，简单细胞的这个草图视图意味着，简单细胞对在特定位置；处、特定方向上、特定空间频率的亮度进行响应。当图像中的光波与细；胞的权重具有相同的相位时，简单细胞是最兴奋的。这种情况发生在当", "keywords": "简单细胞的这个草图视图意味着, 特定方向上, 合在一起, 简单细胞是最兴奋的, 简单细胞对在特定位置", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "3673e625-d651-4edd-8b8d-d68c42a662e6", "label": "摘要30", "info": "复杂细胞的草图视图是它计算包含两个简单细胞响应的二维向量的L；2；。一个重要的特殊情况是当s 1 和s  0  具有", "keywords": "一个重要的特殊情况是当, 复杂细胞的草图视图是它计算包含两个简单细胞响应的二维向量的, 具有", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "2bb37786-8e54-4941-ad29-d773c71924e3", "label": "摘要31", "info": "神经科学和机器学习之间最显著的对应关系，是从视觉上比较机器学习；模型学得的特征与使用V1得到的特征。Olshausen  and  Field（1996）说；明，一个简单的无监督学习算法——稀疏编码，学习的特征具有与简单", "keywords": "学习的特征具有与简单, 模型学得的特征与使用, 稀疏编码, 是从视觉上比较机器学习, 神经科学和机器学习之间最显著的对应关系", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "30d81765-ec79-4602-8a87-4c38d941d269", "label": "摘要32", "info": "（Hyvärinen et al. ，2009）来获得自然图像统计领域的综述。", "keywords": "来获得自然图像统计领域的综述", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "18793ed8-de52-43da-932c-7a167ff06a6c", "label": "摘要33", "info": "图9.19　许多机器学习算法在应用于自然图像时，会学习那些用来检测边缘或边缘的特定颜色；的特征。这些特征检测器使人联想到已知存在于初级视觉皮层中的Gabor函数。（左）通过应用；于小图像块的无监督学习算法（尖峰和平板稀疏编码）学得的权重。（右）由完全监督的卷积", "keywords": "会学习那些用来检测边缘或边缘的特定颜色, 的特征, 由完全监督的卷积, 这些特征检测器使人联想到已知存在于初级视觉皮层中的, 学得的权重", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "label": "9.11：卷积网络与深度学习的历史", "level": 2, "group": "chapter-9", "type": "子章節"}, {"id": "21dd5170-8006-4c93-9031-1c423edd4bee", "label": "摘要1", "info": "卷积网络在深度学习的历史中发挥了重要作用。它们是将研究大脑获得；的深刻理解成功用于机器学习应用的关键例子。它们也是第一个表现良；好的深度模型之一，远远早于任意深度模型被认为是可行的。卷积网络", "keywords": "好的深度模型之一, 远远早于任意深度模型被认为是可行的, 卷积网络, 它们也是第一个表现良, 的深刻理解成功用于机器学习应用的关键例子", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "f4671ee1-dfac-4c1d-9fbc-3faaabe1b977", "label": "摘要2", "info": "卷积网络也被用作在许多比赛中的取胜手段。当前对深度学习的商业兴；趣的热度始于Krizhevsky  et  al.  （2012a）赢得了ImageNet对象识别挑；战，但是在那之前，卷积网络也已经被用于赢得前些年影响较小的其他", "keywords": "赢得了, 对象识别挑, 卷积网络也被用作在许多比赛中的取胜手段, 卷积网络也已经被用于赢得前些年影响较小的其他, 但是在那之前", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7138764e-d3d4-4dcd-85f0-277bbadb1bb7", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；卷积网络是第一批能使用反向传播有效训练的的深度网络之一。现在仍；不完全清楚为什么卷积网络在一般的反向传播网络被认为已经失败时反", "keywords": "现在仍, 不完全清楚为什么卷积网络在一般的反向传播网络被认为已经失败时反, 卷积网络是第一批能使用反向传播有效训练的的深度网络之一", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "b9385d62-dd73-4438-9f09-98bdd8915a00", "label": "摘要4", "info": "卷积网络提供了一种方法来特化神经网络，使其能够处理具有清楚的网；格结构拓扑的数据，以及将这样的模型扩展到非常大的规模。这种方法；在二维图像拓扑上是最成功的。为了处理一维序列数据，我们接下来转", "keywords": "使其能够处理具有清楚的网, 这种方法, 我们接下来转, 格结构拓扑的数据, 卷积网络提供了一种方法来特化神经网络", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "e0d7e4a0-9d57-4099-b1b9-d3aca14d5e8d", "label": "摘要5", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "7effec9f-3623-48cf-a31d-a1eed9609bce", "label": "摘要6", "info": "(1)  译者注：本书中operation视语境有时翻译成“运算”，有时翻译成“操作”。", "keywords": "操作, 有时翻译成, 运算, 译者注, 本书中", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "98574e89-2ffa-48f9-bc22-3b69ecea7d84", "label": "摘要7", "info": "(2)  译者注：原文将此处误写成了I′。", "keywords": "译者注, 原文将此处误写成了", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "00673808-b921-433b-a7ec-460d80a0963b", "label": "摘要8", "info": "(3)  译者注：原文将 K 误写成了k。", "keywords": "误写成了, 原文将, 译者注", "level": 3, "group": "chapter-9", "type": "段落"}, {"id": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "label": "第10章：序列建模：循环和递归网络", "level": 1, "group": "chapter-10", "type": "章節"}, {"id": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "label": "9.11：卷积网络与深度学习的历史", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "bd41ef74-46f3-4858-afa9-d4c05fe76d97", "label": "摘要1", "info": "循环神经网络  （recurrent  neural  network）或RNN（Rumelhart  et  al.  ，；1986c）是一类用于处理序列数据的神经网络。就像卷积网络是专门用；于处理网格化数据X  （如一个图像）的神经网络，循环神经网络是专门", "keywords": "就像卷积网络是专门用, 是一类用于处理序列数据的神经网络, 循环神经网络, 于处理网格化数据, 如一个图像", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "122dfbb3-4a5f-431d-b7aa-ec8f33853e40", "label": "摘要2", "info": "从多层网络出发到循环网络，我们需要利用20世纪80年代机器学习和统", "keywords": "我们需要利用, 从多层网络出发到循环网络, 年代机器学习和统, 世纪", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f7d5a2e9-8151-4fb0-a537-9749e789681a", "label": "摘要3", "info": "计模型早期思想的优点：在模型的不同部分共享参数。参数共享使得模；型能够扩展到不同形式的样本（这里指不同长度的样本）并进行泛化。；如果我们在每个时间点都有一个单独的参数，不但不能泛化到训练时没", "keywords": "计模型早期思想的优点, 并进行泛化, 这里指不同长度的样本, 如果我们在每个时间点都有一个单独的参数, 不但不能泛化到训练时没", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7f5104fd-0b93-4c60-a2e5-b9966a860b5e", "label": "摘要4", "info": "一个相关的想法是在一维时间序列上使用卷积。这种卷积方法是时延神；经网络的基础（Lang  and  Hinton，1988；Waibel  et  al.  ，1989；Lang  et；al.  ，1990）。卷积操作允许网络跨时间共享参数，但是浅层的。卷积", "keywords": "经网络的基础, 但是浅层的, 卷积, 一个相关的想法是在一维时间序列上使用卷积, 卷积操作允许网络跨时间共享参数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8a0ab510-9d36-4eff-b5ae-4e0c53039b03", "label": "摘要5", "info": "为简单起见，我们说的RNN是指在序列上的操作，并且该序列在时刻；t（从1到τ）包含向量 x (t) 。在实际情况中，循环网络通常在序列的小批；量上操作，并且小批量的每项具有不同序列长度τ。我们省略了小批量", "keywords": "量上操作, 包含向量, 我们说的, 并且小批量的每项具有不同序列长度, 循环网络通常在序列的小批", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f4557b2a-2763-4d42-bd84-4d05155736b0", "label": "摘要6", "info": "本章将计算图的思想扩展到包括循环。这些周期代表变量自身的值在未；来某一时间步对自身值的影响。这样的计算图允许我们定义循环神经网；络。然后，我们描述许多构建、训练和使用循环神经网络的不同方式。", "keywords": "这样的计算图允许我们定义循环神经网, 我们描述许多构建, 来某一时间步对自身值的影响, 训练和使用循环神经网络的不同方式, 本章将计算图的思想扩展到包括循环", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "786df9ee-a760-45c2-9863-f0f942143b67", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；本章将简要介绍循环神经网络，为获取更多详细信息，我们建议读者参；考Graves（2012）的著作。", "keywords": "为获取更多详细信息, 的著作, 本章将简要介绍循环神经网络, 我们建议读者参", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "label": "10.1：展开计算图", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "ddd3e465-9568-4fa3-bf24-64a5620e3742", "label": "摘要1", "info": "计算图是形式化一组计算结构的方式，如那些涉及将输入和参数映射到；输出和损失的计算。综合的介绍请参考第6.5.1节。本节，我们对展开；（unfolding）递归或循环计算得到的重复结构进行解释，这些重复结构", "keywords": "这些重复结构, 递归或循环计算得到的重复结构进行解释, 如那些涉及将输入和参数映射到, 综合的介绍请参考第, 计算图是形式化一组计算结构的方式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "581fa6d9-3b35-4106-8df0-06bec530d321", "label": "摘要2", "info": "例如，考虑动态系统的经典形式：", "keywords": "考虑动态系统的经典形式, 例如", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "3103a4cf-5f41-437a-ba03-8f96fdc04a14", "label": "摘要3", "info": "其中 s (t) 称为系统的状态。", "keywords": "称为系统的状态, 其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e2a145c8-c336-49ea-a0b7-bf1034d477af", "label": "摘要4", "info": "s  在时刻t的定义需要参考时刻t-1时同样的定义，因此式（10.1）是循环；的。", "keywords": "在时刻, 时同样的定义, 因此式, 的定义需要参考时刻, 是循环", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b9864278-eab8-415d-83df-2d90b14b2f43", "label": "摘要5", "info": "对有限时间步τ，τ-1次应用这个定义可以展开这个图。例如τ＝3，我们；对式（10.1）展开，可以得到", "keywords": "展开, 可以得到, 次应用这个定义可以展开这个图, 例如, 我们", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b1a9efeb-606d-495d-8b3c-75b84ab7136b", "label": "摘要6", "info": "以这种方式重复应用定义，展开等式，就能得到不涉及循环的表达。现；在我们可以使用传统的有向无环计算图呈现这样的表达。", "keywords": "在我们可以使用传统的有向无环计算图呈现这样的表达, 以这种方式重复应用定义, 就能得到不涉及循环的表达, 展开等式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "efc6020c-8080-4624-915a-c6ff8eaf28b2", "label": "摘要7", "info": "式（10.1）和式（10.3）的展开计算图如图10.1所示。", "keywords": "所示, 的展开计算图如图, 和式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a99a2fc0-e3e6-440e-8ac0-9d70268e34c5", "label": "摘要8", "info": "图10.1　将式（10.1）描述的经典动态系统表示为展开的计算图。每个节点表示在某个时刻t的；状态，并且函数f将t处的状态映射到t+1处的状态。所有时间步都使用相同的参数（用于参数化f", "keywords": "描述的经典动态系统表示为展开的计算图, 处的状态, 用于参数化, 状态, 所有时间步都使用相同的参数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9882456a-7176-49e7-a7a3-9dffd42cfadc", "label": "摘要9", "info": "的相同 θ 值）", "keywords": "的相同", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "80e92f3d-9599-40e1-97ca-1cdb49594928", "label": "摘要10", "info": "作为另一个例子，让我们考虑由外部信号 x (t) 驱动的动态系统，", "keywords": "让我们考虑由外部信号, 作为另一个例子, 驱动的动态系统", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5017280d-68ef-442a-bb65-3a7b7076c7c7", "label": "摘要11", "info": "我们可以看到，当前状态包含了整个过去序列的信息。", "keywords": "当前状态包含了整个过去序列的信息, 我们可以看到", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0d58dc08-59eb-40f5-810c-49d5cc5b00d1", "label": "摘要12", "info": "循环神经网络可以通过许多不同的方式建立。就像几乎所有函数都可以；被认为是前馈网络，本质上任何涉及循环的函数都可以视为一个循环神；经网络。", "keywords": "本质上任何涉及循环的函数都可以视为一个循环神, 被认为是前馈网络, 就像几乎所有函数都可以, 循环神经网络可以通过许多不同的方式建立, 经网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "622d75de-4346-4fc4-8929-07d510c75920", "label": "摘要13", "info": "很多循环神经网络使用式（10.5）或类似的公式定义隐藏单元的值。为；了表明状态是网络的隐藏单元，我们使用变量；h  代表状态重写式", "keywords": "或类似的公式定义隐藏单元的值, 很多循环神经网络使用式, 代表状态重写式, 了表明状态是网络的隐藏单元, 我们使用变量", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fe30e68c-b9f0-4860-878d-acd4aaa6cfa3", "label": "摘要14", "info": "如图10.2所示，典型RNN会增加额外的架构特性，如读取状态信息 h  进；行预测的输出层。", "keywords": "行预测的输出层, 会增加额外的架构特性, 典型, 所示, 如图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e6c118b5-b8bf-4038-ac70-d4b7899ebce3", "label": "摘要15", "info": "图10.2　没有输出的循环网络。此循环网络只处理来自输入 x 的信息，将其合并到经过时间向前；传播的状态 h 。（左）回路原理图。黑色方块表示单个时间步的延迟。（右）同一网络被视为；展开的计算图，其中每个节点现在与一个特定的时间实例相关联", "keywords": "同一网络被视为, 将其合并到经过时间向前, 没有输出的循环网络, 展开的计算图, 回路原理图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "1cb77ede-89d7-4ffa-a47e-56c07523bd2a", "label": "摘要16", "info": "当训练循环网络根据过去预测未来时，网络通常要学会使用 h  (t)  作为过；去序列（直到t）与任务相关方面的有损摘要。此摘要一般而言一定是；有损的，因为其映射任意长度的序列( x (t) , x （t-1） , x （t-2） ,…, x (2) , x (1)", "keywords": "因为其映射任意长度的序列, 与任务相关方面的有损摘要, 去序列, 直到, 此摘要一般而言一定是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9dea42da-0c38-4a9e-93d4-4757459614bb", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；入序列中的所有信息；而仅仅存储足够预测句子其余部分的信息。最苛；刻的情况是我们要求  h  (t)  足够丰富，并能大致恢复输入序列，如自编码", "keywords": "并能大致恢复输入序列, 如自编码, 而仅仅存储足够预测句子其余部分的信息, 入序列中的所有信息, 刻的情况是我们要求", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "223232c8-843c-42f0-84cd-0850a9937b95", "label": "摘要18", "info": "式（10.5）可以用两种不同的方式绘制。一种方法是为可能在模型的物；理实现中存在的部分赋予一个节点，如生物神经网络。在这个观点下，；网络定义了实时操作的回路，如图10.2的左侧，其当前状态可以影响其", "keywords": "理实现中存在的部分赋予一个节点, 的左侧, 网络定义了实时操作的回路, 其当前状态可以影响其, 可以用两种不同的方式绘制", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7aaa882a-3cdd-44e8-8bfe-3f09180d9340", "label": "摘要19", "info": "我们可以用一个函数g (t) 代表经t步展开后的循环：", "keywords": "代表经, 我们可以用一个函数, 步展开后的循环", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "05295715-263d-4da6-9322-baa5c4637ad5", "label": "摘要20", "info": "函数g (t) 将全部的过去序列( x (t) , x (t-1) , x (t-2) ,…, x (2) , x  (1)  )作为输入来；生成当前状态，但是展开的循环架构允许我们将g  (t)  分解为函数f的重复；应用。因此，展开过程引入两个主要优点：", "keywords": "分解为函数, 的重复, 函数, 因此, 展开过程引入两个主要优点", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9370267e-3d3a-49d1-bebb-b8beb09bf551", "label": "摘要21", "info": "（1）无论序列的长度，学成的模型始终具有相同的输入大小，因为它；指定的是从一种状态到另一种状态的转移，而不是在可变长度的历史状；态上操作。", "keywords": "无论序列的长度, 而不是在可变长度的历史状, 指定的是从一种状态到另一种状态的转移, 态上操作, 学成的模型始终具有相同的输入大小", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "53ea5cd9-5ce7-4cb1-80d8-09d7ad1ea999", "label": "摘要22", "info": "（2）我们可以在每个时间步使用相同参数的相同转移函数f。", "keywords": "我们可以在每个时间步使用相同参数的相同转移函数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d9023208-cfb8-4311-ac0e-050e2b79b559", "label": "摘要23", "info": "这两个因素使得学习在所有时间步和所有序列长度上操作单一的模型f；是可能的，而不需要在所有可能时间步学习独立的模型g  (t)  。学习单一；的共享模型允许泛化到没有见过的序列长度（没有出现在训练集中），", "keywords": "是可能的, 学习单一, 没有出现在训练集中, 这两个因素使得学习在所有时间步和所有序列长度上操作单一的模型, 而不需要在所有可能时间步学习独立的模型", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cd3d6f3f-c315-4871-8af6-1c8812bd90ef", "label": "摘要24", "info": "无论是循环图还是展开图，都有其用途。循环图简洁。展开图能够明确", "keywords": "都有其用途, 无论是循环图还是展开图, 展开图能够明确, 循环图简洁", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a57acc55-03c3-4219-bea8-88677d60380f", "label": "摘要25", "info": "描述其中的计算流程。展开图还通过显式的信息流动路径帮助说明信息；在时间上向前（计算输出和损失）和向后（计算梯度）的思想。", "keywords": "描述其中的计算流程, 的思想, 在时间上向前, 展开图还通过显式的信息流动路径帮助说明信息, 和向后", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "label": "10.2：循环神经网络", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "7d042eb4-8352-4aa4-bf4d-c5bbe9480d58", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；10.2.1　导师驱动过程和输出循环网络", "keywords": "导师驱动过程和输出循环网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "920b176b-4931-479e-a192-84b646b016bc", "label": "摘要2", "info": "10.2.2　计算循环神经网络的梯度", "keywords": "计算循环神经网络的梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4f8045d1-862c-4485-baea-0fbc8ac04740", "label": "摘要3", "info": "10.2.3　作为有向图模型的循环网络", "keywords": "作为有向图模型的循环网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ae5dca6d-3d7a-4854-b49c-eacd89ef21db", "label": "摘要4", "info": "10.2.4　基于上下文的RNN序列建模", "keywords": "基于上下文的, 序列建模", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "41b8c722-ab20-4e5a-834e-59d2563ea4c6", "label": "摘要5", "info": "基于第10.1节中的图展开和参数共享的思想，我们可以设计各种循环神；经网络。", "keywords": "我们可以设计各种循环神, 节中的图展开和参数共享的思想, 经网络, 基于第", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "eafff8c1-8ad9-4a57-b0c8-a30f773ad0c5", "label": "摘要6", "info": "循环神经网络中一些重要的设计模式包括以下几种：", "keywords": "循环神经网络中一些重要的设计模式包括以下几种", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "062d71bc-e8ce-4e7c-94d8-1031c42c7e4a", "label": "摘要7", "info": "（1）每个时间步都有输出，并且隐藏单元之间有循环连接的循环网；络，如图10.3所示。", "keywords": "如图, 所示, 并且隐藏单元之间有循环连接的循环网, 每个时间步都有输出", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9aa6ee96-25f0-4d90-9a97-40618f1ffd2c", "label": "摘要8", "info": "图10.3　计算循环网络（将 x 值的输入序列映射到输出值 o 的对应序列）训练损失的计算图。损；失 L 衡量每个 o 与相应的训练目标 y 的距离。当使用softmax输出时，我们假设 o 是未归一化的对；，并将其与目标 y 比较。RNN输入到隐藏的连接", "keywords": "输出时, 比较, 衡量每个, 输入到隐藏的连接, 训练损失的计算图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "92b4f19b-021e-4575-af38-690142701d75", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（2）每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的；隐藏单元之间有循环连接的循环网络，如图10.4所示。", "keywords": "隐藏单元之间有循环连接的循环网络, 所示, 只有当前时刻的输出到下个时刻的, 如图, 每个时间步都产生一个输出", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "769de0b9-1109-4257-a1be-5ade63b9a7d4", "label": "摘要10", "info": "图10.4　此类RNN的唯一循环是从输出到隐藏层的反馈连接。在每个时间步t，输入为 x t ，隐藏；层激活为 h (t) ，输出为 o (t) ，目标为 y (t) ，损失为 L (t) 。（左）回路原理图。（右）展开的计；算图。这样的RNN没有图10.3表示的RNN那样强大（只能表示更小的函数集合）。图10.3中的", "keywords": "中的, 那样强大, 此类, 回路原理图, 只能表示更小的函数集合", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "93d7291e-17d5-4b5b-8be3-f8e74acfdbd7", "label": "摘要11", "info": "（3）隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的；循环网络，如图10.5所示。", "keywords": "所示, 隐藏单元之间存在循环连接, 循环网络, 但读取整个序列后产生单个输出的, 如图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a2a9bd2e-bdf8-405c-89f3-1a2c670c955e", "label": "摘要12", "info": "图10.5　关于时间展开的循环神经网络，在序列结束时具有单个输出。这样的网络可以用于概；括序列并产生用于进一步处理的固定大小的表示。在结束处可能存在目标（如此处所示），或；者通过更下游模块的反向传播来获得输出 o (t) 上的梯度", "keywords": "者通过更下游模块的反向传播来获得输出, 这样的网络可以用于概, 如此处所示, 在结束处可能存在目标, 在序列结束时具有单个输出", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "76025110-87e5-4756-a3ff-edd27a13b23e", "label": "摘要13", "info": "图10.3是非常具有代表性的例子，我们将会在本章大部分涉及这个例；子。", "keywords": "是非常具有代表性的例子, 我们将会在本章大部分涉及这个例", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4b1b3cb3-61d0-4e71-a9d2-0e5fb883ecbc", "label": "摘要14", "info": "任何图灵可计算的函数都可以通过这样一个有限维的循环网络计算，在；这个意义上图10.3和式（10.8）的循环神经网络是万能的。RNN经过若；干时间步后读取输出，这与由图灵机所用的时间步是渐近线性的，与输", "keywords": "任何图灵可计算的函数都可以通过这样一个有限维的循环网络计算, 干时间步后读取输出, 这个意义上图, 与输, 的循环神经网络是万能的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8c147073-b878-4201-8aa7-148a02bd94e9", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；现在我们研究图10.3中RNN的前向传播公式。这个图没有指定隐藏单元；的激活函数。假设使用双曲正切激活函数。此外，图中没有明确指定何", "keywords": "现在我们研究图, 的激活函数, 这个图没有指定隐藏单元, 此外, 图中没有明确指定何", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b46aba95-3b83-49cf-8c30-1c2217c4e431", "label": "摘要16", "info": "其中的参数的偏置向量 b 和 c 连同权重矩阵 U 、 V 和 W ，分别对应于；输入到隐藏、隐藏到输出和隐藏到隐藏的连接。这个循环网络将一个输；入序列映射到相同长度的输出序列。与 x 序列配对的 y 的总损失就是所", "keywords": "隐藏到输出和隐藏到隐藏的连接, 入序列映射到相同长度的输出序列, 的总损失就是所, 连同权重矩阵, 这个循环网络将一个输", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5c335d74-73e5-411f-85d7-dd0dbf6bc7f8", "label": "摘要17", "info": "其中p model (y (t) ｜{ x (1) ,…, x (t) })需要读取模型输出向量  中对应于y；(t)  的项。关于各个参数计算这个损失函数的梯度是计算成本很高的操；作。梯度计算涉及执行一次前向传播（如在图10.3展开图中从左到右的", "keywords": "关于各个参数计算这个损失函数的梯度是计算成本很高的操, 如在图, 梯度计算涉及执行一次前向传播, 展开图中从左到右的, 其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ab8672e1-80ff-4cc2-a67a-46184e21e42c", "label": "摘要18", "info": "。应用于展开图且代价为", "keywords": "应用于展开图且代价为", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0a558b67-e40c-4f42-9302-e9b969eded72", "label": "摘要19", "info": "10.2.1　导师驱动过程和输出循环网络", "keywords": "导师驱动过程和输出循环网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d9992062-3253-4213-abaf-30171d697695", "label": "摘要20", "info": "仅在一个时间步的输出和下一个时间步的隐藏单元间存在循环连接的网；络（见图10.4）确实没有那么强大（因为缺乏隐藏到隐藏的循环连；接）。例如，它不能模拟通用图灵机。因为这个网络缺少隐藏到隐藏的", "keywords": "仅在一个时间步的输出和下一个时间步的隐藏单元间存在循环连接的网, 它不能模拟通用图灵机, 例如, 确实没有那么强大, 见图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4b644a0a-92ec-4af1-bcb2-895a6d8bef4c", "label": "摘要21", "info": "由输出反馈到模型而产生循环连接的模型可用导师驱动过程  （teacher；forcing）进行训练。训练模型时，导师驱动过程不再使用最大似然准；则，而在时刻t+1接收真实值y  (t)  作为输入。我们可以通过检查两个时间", "keywords": "作为输入, 导师驱动过程不再使用最大似然准, 我们可以通过检查两个时间, 而在时刻, 进行训练", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a6260b85-895e-4590-bd4e-1ace55e3b05a", "label": "摘要22", "info": "在这个例子中，同时给定迄今为止的 x 序列和来自训练集的前一 y 值，；我们可以看到在时刻t＝2时，模型被训练为最大化  y  (2)  的条件概率。因；此最大似然在训练时指定正确反馈，而不是将自己的输出反馈到模型，", "keywords": "模型被训练为最大化, 我们可以看到在时刻, 同时给定迄今为止的, 在这个例子中, 的条件概率", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "966aea9e-7238-44bc-9d4d-d697bf9f6674", "label": "摘要23", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图10.6　导师驱动过程的示意图。导师驱动过程是一种训练技术，适用于输出与下一时间步的；隐藏状态存在连接的RNN。（左）训练时，我们将训练集中正确的输出 y (t) 反馈到 h （t+1） 。", "keywords": "隐藏状态存在连接的, 反馈到, 导师驱动过程的示意图, 训练时, 导师驱动过程是一种训练技术", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ce8ee095-c4a4-4925-8284-03baa906cfe0", "label": "摘要24", "info": "我们使用导师驱动过程的最初动机是为了在缺乏隐藏到隐藏连接的模型；中避免通过时间反向传播。只要模型一个时间步的输出与下一时间步计；算的值存在连接，导师驱动过程仍然可以应用到这些存在隐藏到隐藏连", "keywords": "算的值存在连接, 只要模型一个时间步的输出与下一时间步计, 中避免通过时间反向传播, 我们使用导师驱动过程的最初动机是为了在缺乏隐藏到隐藏连接的模型, 导师驱动过程仍然可以应用到这些存在隐藏到隐藏连", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0c426b8a-0e1a-4d46-a12a-9bfb790e97b1", "label": "摘要25", "info": "如果之后网络在开环  （open-loop）模式下使用，即网络输出（或输出；分布的样本）反馈作为输入，那么完全使用导师驱动过程进行训练的缺；点就会出现。在这种情况下，训练期间该网络看到的输入与测试时看到", "keywords": "或输出, 那么完全使用导师驱动过程进行训练的缺, 点就会出现, 训练期间该网络看到的输入与测试时看到, 在这种情况下", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "de3ea796-f2ab-497a-b91f-ed8b57942c5c", "label": "摘要26", "info": "自由运行的输入进行训练，例如在展开循环的输出到输入路径上预测几；个步骤的正确目标值。通过这种方式，网络可以学会考虑在训练时没有；接触到的输入条件（如自由运行模式下，自身生成自身），以及将状态", "keywords": "个步骤的正确目标值, 自身生成自身, 例如在展开循环的输出到输入路径上预测几, 如自由运行模式下, 通过这种方式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fed92cb8-0e74-415f-8b7c-0bdf71f4a096", "label": "摘要27", "info": "10.2.2　计算循环神经网络的梯度", "keywords": "计算循环神经网络的梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f1cd506e-2e1d-4283-b696-5c01c2f35d09", "label": "摘要28", "info": "计算循环神经网络的梯度是容易的。我们可以简单地将第6.5.6节中的推；广反向传播算法应用于展开的计算图，而不需要特殊化的算法。由反向；传播计算得到的梯度，并结合任何通用的基于梯度的技术就可以训练", "keywords": "传播计算得到的梯度, 由反向, 计算循环神经网络的梯度是容易的, 我们可以简单地将第, 广反向传播算法应用于展开的计算图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9bab2775-9657-4b80-8f78-7947f79b61f4", "label": "摘要29", "info": "为了获得BPTT算法行为的一些直观理解，我们举例说明如何通过BPTT；计算上述RNN公式（式（10.8）和式（10.12））的梯度。计算图的节点；包括参数 U 、 V 、 W 、 b 和 c ，以及以t为索引的节点序列 x (t) 、 h (t)", "keywords": "公式, 算法行为的一些直观理解, 为了获得, 为索引的节点序列, 计算上述", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "122f7c6a-4119-43c2-9a04-acbf69090466", "label": "摘要30", "info": "在这个导数中，假设输出  o；(t)  作为softmax函数的参数，我们可以从；softmax函数可以获得关于输出概率的向量   。我们也假设损失是迄今", "keywords": "在这个导数中, 假设输出, 作为, 函数可以获得关于输出概率的向量, 我们可以从", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a271a1d2-fd63-4d69-b772-a0bc7f64bb53", "label": "摘要31", "info": "如下：", "keywords": "如下", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f8a85ff6-80e9-4b1b-881e-59329a969775", "label": "摘要32", "info": "我们从序列的末尾开始，反向进行计算。在最后的时间步τ， h (τ) 只有 o；(τ) 作为后续节点，因此这个梯度很简单：", "keywords": "在最后的时间步, 因此这个梯度很简单, 反向进行计算, 作为后续节点, 我们从序列的末尾开始", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cd8ea698-361b-420d-a7d8-463efe95b83b", "label": "摘要33", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；然后，我们可以从时刻t＝τ-1到t＝1反向迭代，通过时间反向传播梯；度，注意 h (t) (t＜τ)同时具有 o (t) 和 h (t+1) 两个后续节点。因此，它的梯", "keywords": "我们可以从时刻, 两个后续节点, 反向迭代, 通过时间反向传播梯, 同时具有", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a6634ba3-336e-4b4e-8fee-4de23347424f", "label": "摘要34", "info": "其中；时刻t+1与隐藏单元i关联的双曲正切的Jacobian。", "keywords": "时刻, 其中, 关联的双曲正切的, 与隐藏单元", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fa2646be-41f2-4087-8777-8828ba753591", "label": "摘要35", "info": "表示包含元素", "keywords": "表示包含元素", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f372df22-3487-41a3-a504-7f2af6a755aa", "label": "摘要36", "info": "的对角矩阵。这是关于", "keywords": "的对角矩阵, 这是关于", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "52dd415d-0dbf-425d-9515-4e007d1f501a", "label": "摘要37", "info": "一旦获得了计算图内部节点的梯度，我们就可以得到关于参数节点的梯；度。因为参数在许多时间步共享，我们必须在表示这些变量的微积分操；作时谨慎对待。我们希望实现的等式使用第6.5.6节中的bprop方法计算", "keywords": "方法计算, 我们希望实现的等式使用第, 我们必须在表示这些变量的微积分操, 节中的, 我们就可以得到关于参数节点的梯", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "447896b7-57b7-422e-9db1-4c0440051c09", "label": "摘要38", "info": "表示权重在时间步t对梯度的贡献。", "keywords": "表示权重在时间步, 对梯度的贡献", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9911153f-7872-4570-9b74-52c1db6011c2", "label": "摘要39", "info": "使用这个表示，关于剩下参数的梯度可以由式（10.22）～式（10.28）；给出：", "keywords": "使用这个表示, 给出, 关于剩下参数的梯度可以由式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "05a6091d-8d18-4db8-b37c-7ab2dc89a5ee", "label": "摘要40", "info": "因为计算图中定义的损失的任何参数都不是训练数据 x  (t)  的父节点，所；以我们不需要计算关于它的梯度。", "keywords": "以我们不需要计算关于它的梯度, 因为计算图中定义的损失的任何参数都不是训练数据, 的父节点", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e9bf6d85-7c6d-4145-bc83-f9c9f5e483d4", "label": "摘要41", "info": "10.2.3　作为有向图模型的循环网络", "keywords": "作为有向图模型的循环网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b671dd49-56d4-4491-84b4-09fabffa7054", "label": "摘要42", "info": "目前为止，我们接触的循环网络例子中损失L  (t)  是训练目标  y  (t)  和输出；o  (t)  之间的交叉熵。与前馈网络类似，原则上循环网络几乎可以使用任；何损失。但必须根据任务来选择损失。如前馈网络，通常我们希望将", "keywords": "与前馈网络类似, 我们接触的循环网络例子中损失, 如前馈网络, 原则上循环网络几乎可以使用任, 何损失", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "70074d7d-6aa2-4998-9ba9-81946c99de37", "label": "摘要43", "info": "当使用一个预测性对数似然的训练目标，如式（10.12），我们将RNN；训练为能够根据之前的输入估计下一个序列元素 y  (t)  的条件分布。这可；能意味着，我们最大化对数似然", "keywords": "如式, 我们将, 当使用一个预测性对数似然的训练目标, 能意味着, 我们最大化对数似然", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d4680de0-f5c9-4390-9a7b-3c1b1aca51ff", "label": "摘要44", "info": "或者，如果模型包括来自一个时间步的输出到下一个时间步的连接，", "keywords": "如果模型包括来自一个时间步的输出到下一个时间步的连接, 或者", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e7312ede-2f92-48b0-af9e-1c6c2cc79139", "label": "摘要45", "info": "将整个序列 y  的联合分布分解为一系列单步的概率预测是捕获关于整个；序列完整联合分布的一种方法。如果我们不把过去的 y  值反馈给下一步；作为预测的条件，那么有向图模型不包含任何从过去 y  (i) 到当前 y  (t)  的", "keywords": "作为预测的条件, 将整个序列, 如果我们不把过去的, 到当前, 值反馈给下一步", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "773e2861-1f4c-4829-9440-403e041d413f", "label": "摘要46", "info": "举一个简单的例子，让我们考虑对标量随机变量序列   ＝{y  (1)  ,…,y；(τ)  }建模的RNN，也没有额外的输入x。在时间步t的输入仅仅是时间步t-", "keywords": "在时间步, 的输入仅仅是时间步, 也没有额外的输入, 建模的, 举一个简单的例子", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d6d53e1b-9ef0-4247-b10b-87f859aa66d6", "label": "摘要47", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；1的输出。该RNN定义了关于y变量的有向图模型。我们使用链式法则；（用于条件概率的（3.6））参数化这些观察值的联合分布：", "keywords": "的输出, 用于条件概率的, 定义了关于, 我们使用链式法则, 变量的有向图模型", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f58e551d-44f1-4398-aed1-a1b434be064d", "label": "摘要48", "info": "其中当t＝1时竖杠右侧显然为空。因此，根据这样一个模型，一组值{y；(1) ,…,y (τ) }的负对数似然为", "keywords": "因此, 一组值, 其中当, 时竖杠右侧显然为空, 根据这样一个模型", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4330a38c-63a4-4bca-8feb-32e632971248", "label": "摘要49", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5824d3ec-bd69-4195-92aa-f84d56941e37", "label": "摘要50", "info": "图模型中的边表示哪些变量直接依赖于其他变量。许多图模型的目标是；省略不存在强相互作用的边以实现统计和计算的效率。例如，我们通常；可以作Markov假设，即图模型应该只包含从{y  (t-k)  ,…,y  (t-1)  }到y  (t)  的", "keywords": "许多图模型的目标是, 图模型中的边表示哪些变量直接依赖于其他变量, 例如, 省略不存在强相互作用的边以实现统计和计算的效率, 我们通常", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "aaf18eeb-897d-432c-a4fd-e625d31bf7dc", "label": "摘要51", "info": "解释RNN作为图模型的一种方法是将RNN视为定义一个结构为完全图；的图模型，且能够表示任何一对y值之间的直接联系。图10.7是关于y值；且具有完全图结构的图模型。该RNN完全图的解释基于排除并忽略模型", "keywords": "的图模型, 是关于, 完全图的解释基于排除并忽略模型, 解释, 值之间的直接联系", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "afaa33dd-0f06-406a-9c44-af0bbce8b27c", "label": "摘要52", "info": "图10.7　序列y (1) ，y (2) ,…,y (t) ，· · ·的全连接图模型。给定先前的值，每个过去的观察值y；(i) 可以影响一些y (t) (t＞i)的条件分布。当序列中每个元素的输入和参数的数目越来越多，根据；此图直接参数化图模型（如式（10.6）中）可能是非常低效的。RNN可以通过高效的参数化获", "keywords": "可以影响一些, 给定先前的值, 根据, 如式, 可能是非常低效的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cc6daa10-a630-45c6-996c-9bda9db3c2f5", "label": "摘要53", "info": "更有趣的是，将隐藏单元 h (t)  视为随机变量，从而产生RNN的图模型结；构 (1) 。在图模型中包括隐藏单元预示RNN能对观测的联合分布提供非常；有效的参数化。假设我们用表格表示法来表示离散值上任意的联合分", "keywords": "视为随机变量, 将隐藏单元, 有效的参数化, 能对观测的联合分布提供非常, 假设我们用表格表示法来表示离散值上任意的联合分", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7acb7570-01bd-4250-a67b-aeac81f6d601", "label": "摘要54", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图10.8　在RNN图模型中引入状态变量，尽管它是输入的确定性函数，但它有助于我们根据式；（10.5）获得非常高效的参数化。序列中的每个阶段（对于 h (t) 和 y (t) ）使用相同的结构（每", "keywords": "但它有助于我们根据式, 获得非常高效的参数化, 图模型中引入状态变量, 对于, 序列中的每个阶段", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "64e3289f-7841-4d82-87d2-5d9502a57821", "label": "摘要55", "info": "即便使用高效参数化的图模型，某些操作在计算上仍然具有挑战性。例；如，难以预测序列中缺少的值。", "keywords": "某些操作在计算上仍然具有挑战性, 即便使用高效参数化的图模型, 难以预测序列中缺少的值", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b50a430c-bdd8-4fe2-a931-c6c14f157659", "label": "摘要56", "info": "循环网络为减少的参数数目付出的代价是优化参数可能变得困难。", "keywords": "循环网络为减少的参数数目付出的代价是优化参数可能变得困难", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c25d979a-c79a-4d17-939c-f68f35a6fb0b", "label": "摘要57", "info": "在循环网络中使用的参数共享的前提是相同参数可用于不同时间步的假；设。也就是说，假设给定时刻t的变量后，时刻t+1变量的条件概率分布；是平稳的  （stationary），这意味着之前的时间步与下个时间步之间的", "keywords": "的变量后, 是平稳的, 变量的条件概率分布, 这意味着之前的时间步与下个时间步之间的, 时刻", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "96998db1-db98-4ff9-a604-ad8fa9f89e40", "label": "摘要58", "info": "为了完整描述将RNN作为图模型的观点，我们必须描述如何从模型采；样。我们需要执行的主要操作是简单地从每一时间步的条件分布采样。；然而，这会导致额外的复杂性。RNN必须有某种机制来确定序列的长", "keywords": "我们需要执行的主要操作是简单地从每一时间步的条件分布采样, 这会导致额外的复杂性, 我们必须描述如何从模型采, 然而, 作为图模型的观点", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "773150d5-3fc3-4a66-9a83-7eb0b42e7b6c", "label": "摘要59", "info": "在当输出是从词汇表获取的符号的情况下，我们可以添加一个对应于序；列末端的特殊符号（Schmidhuber，2012）。当产生该符号时，采样过；程停止。在训练集中，我们将该符号作为序列的一个额外成员，即紧跟", "keywords": "当产生该符号时, 我们可以添加一个对应于序, 在当输出是从词汇表获取的符号的情况下, 我们将该符号作为序列的一个额外成员, 即紧跟", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "480f5b43-1e33-493c-abb0-a3612442aaee", "label": "摘要60", "info": "另一种选择是在模型中引入一个额外的Bernoulli输出，表示在每个时间；步决定继续生成或停止生成。相比向词汇表增加一个额外符号，这种方；法更普遍，因为它适用于任何RNN，而不仅仅是输出符号序列的", "keywords": "而不仅仅是输出符号序列的, 另一种选择是在模型中引入一个额外的, 法更普遍, 步决定继续生成或停止生成, 相比向词汇表增加一个额外符号", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f7d7b2c4-6b17-45a9-8da6-87326b0c4702", "label": "摘要61", "info": "RNN。例如，它可以应用于一个产生实数序列的RNN。新的输出单元；通常使用sigmoid单元，并通过交叉熵训练。在这种方法中，sigmoid被；训练为最大化正确预测的对数似然，即在每个时间步序列决定结束或继", "keywords": "在这种方法中, 例如, 训练为最大化正确预测的对数似然, 新的输出单元, 它可以应用于一个产生实数序列的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e455647d-6857-4e07-b05b-dbcc3c1ee28a", "label": "摘要62", "info": "确定序列长度τ的另一种方法是将一个额外的输出添加到模型并预测整；数τ本身。模型可以采出τ的值，然后采τ步有价值的数据。这种方法需；要在每个时间步的循环更新中增加一个额外输入，使得循环更新知道它", "keywords": "的另一种方法是将一个额外的输出添加到模型并预测整, 本身, 使得循环更新知道它, 模型可以采出, 要在每个时间步的循环更新中增加一个额外输入", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fa4142b0-6965-4de0-a564-6660de7bafe9", "label": "摘要63", "info": "直接预测τ的例子见Goodfellow et al. （2014d）。", "keywords": "直接预测, 的例子见", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f3be88b5-0742-4610-a5ea-be1101b313c4", "label": "摘要64", "info": "10.2.4　基于上下文的RNN序列建模", "keywords": "基于上下文的, 序列建模", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cb11916a-d093-41ed-998b-c1fdcdf272ee", "label": "摘要65", "info": "上一节描述了没有输入 x  时，关于随机变量序列y  (t)  的RNN如何对应于；有向图模型。当然，如式（10.8）所示的RNN包含一个输入序列 x  (1)  ，；x (2) ,…, x  (τ) 。一般情况下，RNN允许将图模型的观点扩展到不仅代表y", "keywords": "上一节描述了没有输入, 包含一个输入序列, 如式, 有向图模型, 所示的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d00ac444-dc28-484a-8854-ab8deec1ae8e", "label": "摘要66", "info": "之前，我们已经讨论了将t＝1,…,τ的向量  x  (t)  序列作为输入的RNN。另；一种选择是只使用单个向量  x  作为输入。当  x  是一个固定大小的向量；时，我们可以简单地将其看作产生 y 序列RNN的额外输入。将额外输入", "keywords": "作为输入, 序列作为输入的, 我们已经讨论了将, 将额外输入, 的额外输入", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5cfa4154-238f-439d-9d39-f75026230ae0", "label": "摘要67", "info": "（1）在每个时刻作为一个额外输入，或", "keywords": "在每个时刻作为一个额外输入", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a5cb063c-bc9f-4216-8e78-a2c54e5938c2", "label": "摘要68", "info": "（2）作为初始状态 h (0) ，或", "keywords": "作为初始状态", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7125ac11-97eb-4e31-91cc-7166afe3efd0", "label": "摘要69", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（3）结合两种方式。", "keywords": "结合两种方式", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "53c049d2-6269-4164-93de-79268707ecee", "label": "摘要70", "info": "第一个也是最常用的方法如图10.9所示。输入  x  和每个隐藏单元向量  h；(t)  之间的相互作用是通过新引入的权重矩阵  R  参数化的，这是只包含y；在每个时间步作为隐藏单元", "keywords": "在每个时间步作为隐藏单元, 和每个隐藏单元向量, 第一个也是最常用的方法如图, 参数化的, 所示", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "42db0bee-b762-4d2e-a960-94615c05d8ca", "label": "摘要71", "info": "图10.9　将固定长度的向量 x 映射到序列 Y 上分布的RNN。这类RNN适用于很多任务（如图；注），其中单个图像作为模型的输入，然后产生描述图像的词序列。观察到的输出序列的每个；元素 y (t) 同时用作输入（对于当前时间步）和训练期间的目标（对于前一时间步）", "keywords": "适用于很多任务, 观察到的输出序列的每个, 对于当前时间步, 这类, 同时用作输入", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "da502558-58df-47ba-b810-d508962f0a76", "label": "摘要72", "info": "RNN可以接收向量序列 x (t) 作为输入，而不是仅接收单个向量 x 作为输；入。式（10.8）描述的RNN对应条件分布P( y (1) ,…, y (τ) ｜ x  (1)  ,…,  x  (τ)；)，并在条件独立的假设下这个分布分解为", "keywords": "可以接收向量序列, 而不是仅接收单个向量, 作为输入, 作为输, 并在条件独立的假设下这个分布分解为", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "19d19c9d-383a-4819-992e-2337fc1ca61d", "label": "摘要73", "info": "为去掉条件独立的假设，我们可以在时刻t的输出到时刻t+1的隐藏单元；添加连接，如图10.10所示。该模型就可以代表关于 y 序列的任意概率分；布。这种给定一个序列表示另一个序列分布的模型的还是有一个限制，", "keywords": "这种给定一个序列表示另一个序列分布的模型的还是有一个限制, 的隐藏单元, 所示, 添加连接, 序列的任意概率分", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7e66825e-9949-465c-b9be-aa1eafb125ae", "label": "摘要74", "info": "图10.10　将可变长度的 x 值序列映射到相同长度的 y 值序列上分布的条件循环神经网络。对比；图10.3，此RNN包含从前一个输出到当前状态的连接。这些连接允许此RNN对给定 x 的序列后；相同长度的 y 序列上的任意分布建模。图10.3的RNN仅能表示在给定 x 值的情况下， y 值彼此条", "keywords": "包含从前一个输出到当前状态的连接, 仅能表示在给定, 对比, 值序列上分布的条件循环神经网络, 的序列后", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9c3aabb1-601f-45ec-bf01-312552975c4a", "label": "摘要75", "info": "10.2.1　导师驱动过程和；输出循环网络", "keywords": "输出循环网络, 导师驱动过程和", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "3dc57ce9-8965-4d4f-a28e-4612a5cf3aa5", "label": "摘要76", "info": "10.2.2　计算循环神经网；络的梯度", "keywords": "计算循环神经网, 络的梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5f3caac9-da98-48e4-b7d4-ff99e5c8dadd", "label": "摘要77", "info": "10.2.3　作为有向图模型；的循环网络", "keywords": "的循环网络, 作为有向图模型", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "47dfc76a-f34a-4cba-ad6b-0ebffd1871c2", "label": "摘要78", "info": "10.2.4　基于上下文的；RNN序列建模", "keywords": "基于上下文的, 序列建模", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fce5e349-256c-4d2c-b978-977bd5ba3cc3", "label": "摘要79", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；10.3　双向RNN", "keywords": "双向", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "00a82921-a13e-44ed-98b8-3e215ab8f981", "label": "10.3：双向RNN", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "5d4ab3ae-3d27-4af1-9682-6d2b30054735", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；目前为止，我们考虑的所有循环神经网络有一个“因果”结构，意味着在；时刻t的状态只能从过去的序列 x (1) ,…, x (t-1) 以及当前的输入 x (t) 捕获信", "keywords": "我们考虑的所有循环神经网络有一个, 意味着在, 目前为止, 因果, 捕获信", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c0430a76-a743-4cd9-b8e2-4aa82fafcd6a", "label": "摘要2", "info": "然而，在许多应用中，我们要输出的 y  (t)  的预测可能依赖于整个输入序；列。例如，在语音识别中，由于协同发音，当前声音作为音素的正确解；释可能取决于未来几个音素，甚至潜在的可能取决于未来的几个词，因", "keywords": "在语音识别中, 然而, 由于协同发音, 例如, 的预测可能依赖于整个输入序", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e99e174d-fb8d-436f-beed-dfac5a2f2965", "label": "摘要3", "info": "双向循环神经网络（或双向RNN）为满足这种需要而发明（Schuster；Paliwal，1997）。它们在需要双向信息的应用中非常成功；and", "keywords": "双向循环神经网络, 它们在需要双向信息的应用中非常成功, 或双向, 为满足这种需要而发明", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b4923386-8c91-4517-ad9f-dff477f04435", "label": "摘要4", "info": "顾名思义，双向RNN结合时间上从序列起点开始移动的RNN和另一个；时间上从序列末尾开始移动的RNN。图10.11展示了典型的双向RNN，；其中 h (t) 代表通过时间向前移动的子RNN的状态， g (t) 代表通过时间向", "keywords": "代表通过时间向前移动的子, 代表通过时间向, 展示了典型的双向, 时间上从序列末尾开始移动的, 其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b99ff8da-b9f3-4401-9ea4-92b45a11ad21", "label": "摘要5", "info": "图10.11　典型的双向循环神经网络中的计算，意图学习将输入序列 x 映射到目标序列 y （在每；个步骤t具有损失L (t) ）。循环性 h 在时间上向前传播信息（向右），而循环性 g 在时间上向后", "keywords": "在时间上向前传播信息, 循环性, 个步骤, 典型的双向循环神经网络中的计算, 具有损失", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "3b3651ff-c865-4888-9304-1b7d97939eae", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；传播信息（向左）。因此在每个点t，输出单元 o (t) 可以受益于输入 h (t) 中关于过去的相关概要；以及输入 g (t) 中关于未来的相关概要", "keywords": "以及输入, 向左, 传播信息, 中关于未来的相关概要, 中关于过去的相关概要", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9fd7a3a3-9fb8-4a46-8983-544c4196de73", "label": "摘要7", "info": "这个想法可以自然地扩展到二维输入，如图像，由4个RNN组成，每一；个沿着4个方向中的一个计算：上、下、左、右。如果RNN能够学习到；承载长期信息，那在二维网格每个点（i,j）的输出O  i,j  就能计算一个能", "keywords": "每一, 组成, 个方向中的一个计算, 如果, 承载长期信息", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e7f352de-0275-4986-8780-d4e9e94c0c77", "label": "10.4：基于编码-解码的序列到序列架构", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "381201ac-7de2-47e3-a9a8-5b051d286ef9", "label": "摘要1", "info": "我们已经在图10.5看到RNN如何将输入序列映射成固定大小的向量，在；图10.9中看到RNN如何将固定大小的向量映射成一个序列，在图10.3、；图10.4、图10.10和图10.11中看到RNN如何将一个输入序列映射到等长", "keywords": "如何将输入序列映射成固定大小的向量, 在图, 如何将一个输入序列映射到等长, 和图, 中看到", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b1a936e0-d228-4dff-a8fa-29e2e262edf8", "label": "摘要2", "info": "本节我们讨论如何训练RNN，使其将输入序列映射到不一定等长的输出；序列。这在许多场景中都有应用，如语音识别、机器翻译或问答，其中；训练集的输入和输出序列的长度通常不相同（虽然它们的长度可能相", "keywords": "如语音识别, 其中, 机器翻译或问答, 训练集的输入和输出序列的长度通常不相同, 使其将输入序列映射到不一定等长的输出", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0dcf16b3-ab7c-48d3-8072-b9b50c54f2f5", "label": "摘要3", "info": "我们经常将RNN的输入称为“上下文”。我们希望产生此上下文的表示；C。这个上下文C可能是一个概括输入序列 X ＝( x  (1)  ,…,；或者向量序列。", "keywords": "的输入称为, 或者向量序列, 可能是一个概括输入序列, 这个上下文, 我们经常将", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c1c9e437-67d7-4949-b4f7-317cfd1fb004", "label": "摘要4", "info": ")的向量", "keywords": "的向量", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f0e51a2c-d6e2-42c7-989c-9e681301f025", "label": "摘要5", "info": "用于映射可变长度序列到另一可变长度序列最简单的RNN架构最初由；Cho  et  al.  （2014a）提出，之后不久由Sutskever  et  al.  （2014）独立开；发，并且第一个使用这种方法获得翻译的最好结果。前一系统是对另一", "keywords": "架构最初由, 提出, 独立开, 前一系统是对另一, 并且第一个使用这种方法获得翻译的最好结果", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5d6eac67-1fd2-485d-9bcd-f6d479eadb3a", "label": "摘要6", "info": "（input）RNN处理输入序列。编码器输出上下文；（reader）或输入；C（通常是最终隐藏状态的简单函数）。（2）解码器  （decoder）或写", "keywords": "或输入, 编码器输出上下文, 处理输入序列, 通常是最终隐藏状态的简单函数, 或写", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d8bc66c4-371a-4a24-a52d-b896977af581", "label": "摘要7", "info": "图10.12　在给定输入序列", "keywords": "在给定输入序列", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "063ef1d7-7e1e-4aad-a9b0-37dde9f69800", "label": "摘要8", "info": "的情况下学习生成输出序列", "keywords": "的情况下学习生成输出序列", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b867b3f2-9624-4a56-b7c3-5e121ffec795", "label": "摘要9", "info": "的编码器-解码器或序列到序列的RNN架构的示例。它由读取输入序", "keywords": "解码器或序列到序列的, 它由读取输入序, 的编码器, 架构的示例", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "e5265d5a-20c6-4914-9fc2-8fb95725e26d", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；列的编码器RNN以及生成输出序列（或计算给定输出序列的概率）的解码器RNN组成。编码器；RNN的最终隐藏状态用于计算一般为固定大小的上下文变量C，C表示输入序列的语义概要并且", "keywords": "组成, 或计算给定输出序列的概率, 表示输入序列的语义概要并且, 列的编码器, 编码器", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "96cebccf-36ed-46a6-aeb6-396054af8315", "label": "摘要11", "info": "如果上下文C是一个向量，则编码器RNN只是在第10.2.4节描述的向量；到序列RNN。正如我们所见，向量到序列RNN至少有两种接受输入的；方法。输入可以被提供为RNN的初始状态，或连接到每个时间步中的隐", "keywords": "正如我们所见, 至少有两种接受输入的, 的初始状态, 如果上下文, 或连接到每个时间步中的隐", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "979ad605-f2d7-4832-9814-61faaae380bd", "label": "摘要12", "info": "这里并不强制要求编码器与解码器的隐藏层具有相同的大小。", "keywords": "这里并不强制要求编码器与解码器的隐藏层具有相同的大小", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "087642e6-7f32-4ec7-ba03-4bb1ebe06ae7", "label": "摘要13", "info": "此架构的一个明显不足是，编码器RNN输出的上下文C的维度太小而难；以适当地概括一个长序列。这种现象由Bahdanau  et  al.  （2015）在机器；翻译中观察到。他们提出让C成为可变长度的序列，而不是一个固定大", "keywords": "输出的上下文, 而不是一个固定大, 成为可变长度的序列, 的维度太小而难, 此架构的一个明显不足是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "label": "10.5：深度循环网络", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "8a25b9df-ee33-4de9-9235-d3b98ff04544", "label": "摘要1", "info": "大多数RNN中的计算可以分解成3块参数及其相关的变换：", "keywords": "块参数及其相关的变换, 中的计算可以分解成, 大多数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fa6673dd-3391-4be5-b084-60653bc5caa1", "label": "摘要2", "info": "（1）从输入到隐藏状态。", "keywords": "从输入到隐藏状态", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ab05b32f-d8e7-48e8-9aaf-4ee9886b707e", "label": "摘要3", "info": "（2）从前一隐藏状态到下一隐藏状态。", "keywords": "从前一隐藏状态到下一隐藏状态", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f0e14aec-3acc-4a8e-9ed8-b2cb2caf6c6b", "label": "摘要4", "info": "（3）从隐藏状态到输出。", "keywords": "从隐藏状态到输出", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a06185c8-493c-4122-a45d-d5f8881a8efa", "label": "摘要5", "info": "根据图10.3中的RNN架构，这3个块都与单个权重矩阵相关联。换句话；说，当网络被展开时，每个块对应一个浅的变换。能通过深度MLP内单；个层来表示的变换称为浅变换。通常，这是由学成的仿射变换和一个固", "keywords": "能通过深度, 这是由学成的仿射变换和一个固, 当网络被展开时, 通常, 内单", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4dd9c960-adc3-4b72-9370-108737528313", "label": "摘要6", "info": "图10.13　循环神经网络可以通过许多方式变得更深（Pascanu et al. ，2014a）。（a）隐藏循环；状态可以被分解为具有层次的组。（b）可以向输入到隐藏、隐藏到隐藏以及隐藏到输出的部分；引入更深的计算（如MLP）。这可以延长链接不同时间步的最短路径。（c）可以引入跳跃连接", "keywords": "状态可以被分解为具有层次的组, 可以向输入到隐藏, 这可以延长链接不同时间步的最短路径, 隐藏循环, 循环神经网络可以通过许多方式变得更深", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "54d56086-f7ef-4f0c-a06a-65150c912d12", "label": "摘要7", "info": "在这些操作中引入深度会有利吗？实验证据（Graves  et  al.  ，2013；；Pascanu  et  al.  ，2014a）强烈暗示理应如此。实验证据与我们需要足够；的深度以执行所需映射的想法一致。读者可以参考", "keywords": "强烈暗示理应如此, 的深度以执行所需映射的想法一致, 实验证据, 实验证据与我们需要足够, 在这些操作中引入深度会有利吗", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "bb595bc0-f228-467d-8f20-bc25dc3f877e", "label": "摘要8", "info": "Graves  et  al.  （2013）第一个展示了将RNN的状态分为多层的显著好；处，如图10.13（a）所示。我们可以认为，在图10.13（a）所示层次结；构中较低的层起到了将原始输入转化为对更高层的隐藏状态更合适表示", "keywords": "在图, 所示, 所示层次结, 第一个展示了将, 如图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "93d74c45-ebe6-45d4-abfd-7cdfc378e274", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；优化困难而损害学习效果。在一般情况下，更容易优化较浅的架构，加；入图10.13（b）的额外深度导致从时间步t的变量到时间步t+1的最短路", "keywords": "优化困难而损害学习效果, 更容易优化较浅的架构, 的最短路, 在一般情况下, 入图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "label": "10.6：递归神经网络", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "fbbe8a4d-8963-443d-b03c-13acfd70e66c", "label": "摘要1", "info": "递归神经网络 (2) 代表循环网络的另一个扩展，它被构造为深的树状结构；而不是RNN的链状结构，因此是不同类型的计算图。递归网络的典型计；算图如图10.14所示。递归神经网络由Pollack（1990）引入，而", "keywords": "因此是不同类型的计算图, 递归神经网络由, 递归神经网络, 的链状结构, 它被构造为深的树状结构", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0f6753ea-0783-4e9f-9398-802271e7be90", "label": "摘要2", "info": "递归网络的一个明显优势是，对于具有相同长度τ的序列，深度（通过；非线性操作的组合数量来衡量）可以急剧地从τ减小为O（logτ），这可；能有助于解决长期依赖。一个悬而未决的问题是如何以最佳的方式构造", "keywords": "一个悬而未决的问题是如何以最佳的方式构造, 对于具有相同长度, 这可, 能有助于解决长期依赖, 递归网络的一个明显优势是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "534ed38d-351b-4cb7-ae9e-e70b5d477671", "label": "摘要3", "info": "图10.14　递归网络将循环网络的链状计算图推广到树状计算图。可变大小的序列 x (1) ， x (2) ,；…, x (t) 可以通过固定的参数集合（权重矩阵 U ， V ， W ）映射到固定大小的表示（输出 o ）。；该图展示了监督学习的情况，其中提供了一些与整个序列相关的目标 y", "keywords": "输出, 权重矩阵, 可变大小的序列, 该图展示了监督学习的情况, 递归网络将循环网络的链状计算图推广到树状计算图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "abfaa454-cf61-4f3e-bbac-fe83a2770e15", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；al.  （1997）和；递归网络想法的变种存在很多。例如，Frasconi", "keywords": "递归网络想法的变种存在很多, 例如", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "eace84b0-4a37-43e0-9b1b-568607856056", "label": "摘要5", "info": "al.", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8d445061-a650-49e8-83df-d4dfa5a2fb16", "label": "摘要6", "info": "et", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d2365770-536b-438a-8375-9fdc10cdf263", "label": "摘要7", "info": "et", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "label": "10.7：长期依赖的挑战", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "5888c076-ea82-4411-80fc-5cd694f9933f", "label": "摘要1", "info": "学习循环网络长期依赖的数学挑战在第8.2.5节中引入。根本问题是，经；过许多阶段传播后的梯度倾向于消失（大部分情况）或爆炸（很少，但；对优化过程影响很大）。即使我们假设循环网络是参数稳定的（可存储", "keywords": "对优化过程影响很大, 很少, 即使我们假设循环网络是参数稳定的, 过许多阶段传播后的梯度倾向于消失, 节中引入", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "33428521-8250-46b9-b98c-48f8018235c4", "label": "摘要2", "info": "循环网络涉及相同函数的多次组合，每个时间步一次。这些组合可以导；致极端非线性行为，如图10.15所示。", "keywords": "循环网络涉及相同函数的多次组合, 所示, 致极端非线性行为, 每个时间步一次, 这些组合可以导", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b9dee598-50c3-48b8-a543-544c3f557c01", "label": "摘要3", "info": "图10.15　重复组合函数。当组合许多非线性函数（如这里所示的线性tanh层）时，结果是高度；非线性的，通常大多数值与微小的导数相关联，也有一些具有大导数的值，以及在增加和减小；之间的多次交替。此处，我们绘制从100维隐藏状态降到单个维度的线性投影，绘制于y轴上。x", "keywords": "结果是高度, 也有一些具有大导数的值, 轴上, 绘制于, 重复组合函数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "67d39096-44de-4332-8424-9f72bf7811cd", "label": "摘要4", "info": "特别的是，循环神经网络所使用的函数组合有点像矩阵乘法。我们可以；认为，循环联系", "keywords": "循环神经网络所使用的函数组合有点像矩阵乘法, 认为, 我们可以, 循环联系, 特别的是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "6faa38c0-3a12-4209-aa0c-d07541ecb24a", "label": "摘要5", "info": "是一个非常简单的、缺少非线性激活函数和输入 x 的循环神经网络。如；第8.2.5节描述，这种递推关系本质上描述了幂法。它可以被简化为", "keywords": "节描述, 缺少非线性激活函数和输入, 它可以被简化为, 这种递推关系本质上描述了幂法, 是一个非常简单的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4ba8396a-acea-4b79-a349-ed56d82c69d5", "label": "摘要6", "info": "而当 W 符合下列形式的特征分解", "keywords": "符合下列形式的特征分解, 而当", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ee3dd8f8-9171-4193-8819-04b4df1275c1", "label": "摘要7", "info": "其中 Q 正交，循环性可进一步简化为", "keywords": "正交, 其中, 循环性可进一步简化为", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8600c9dd-0131-467b-b849-03fca48652fd", "label": "摘要8", "info": "特征值提升到t次后，导致幅值不到一的特征值衰减到零，而幅值大于；一的就会激增。任何不与最大特征向量对齐的  h  (0)  的部分将最终被丢；弃。", "keywords": "特征值提升到, 次后, 而幅值大于, 任何不与最大特征向量对齐的, 一的就会激增", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "54292f43-3cd1-4245-82f4-eeca665f58b4", "label": "摘要9", "info": "这个问题是针对循环网络的。在标量情况下，想象多次乘一个权重w。；该乘积w t 消失还是爆炸取决于w的幅值。然而，如果每个时刻使用不同；权重w  (t)  的非循环网络，情况就不同了。如果初始状态给定为1，那么", "keywords": "消失还是爆炸取决于, 如果每个时刻使用不同, 情况就不同了, 这个问题是针对循环网络的, 的幅值", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "64f66af2-b12c-4803-8b34-eddf905f66c1", "label": "摘要10", "info": "RNN梯度消失和爆炸问题是由不同研究人员独立发现（Hochreiter，；1991a；Bengio  et  al.  ，1993，1994b）。有人可能会希望通过简单地停；留在梯度不消失或爆炸的参数空间来避免这个问题。不幸的是，为了储", "keywords": "留在梯度不消失或爆炸的参数空间来避免这个问题, 梯度消失和爆炸问题是由不同研究人员独立发现, 有人可能会希望通过简单地停, 不幸的是, 为了储", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "629c01fc-701f-4cf9-b7f9-6c296b78c8e7", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；依赖时，长期相互作用的梯度幅值就会变得指数小（相比短期相互作用；的梯度幅值）。这并不意味着这是不可能学习的，由于长期依赖关系的", "keywords": "的梯度幅值, 依赖时, 这并不意味着这是不可能学习的, 由于长期依赖关系的, 相比短期相互作用", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "75d03d04-dc8b-4d98-8fd4-d892c599af4b", "label": "摘要12", "info": "将循环网络作为动力系统更深入探讨的资料见Doya（1993）；Bengio  et；al.  （1994b）；Siegel-mann  and  Sontag（1995）及Pascanu  et  al.；（2013b）的回顾。本章的其余部分将讨论目前已经提出的降低学习长", "keywords": "将循环网络作为动力系统更深入探讨的资料见, 本章的其余部分将讨论目前已经提出的降低学习长, 的回顾", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "label": "10.8：回声状态网络", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "83ba9c35-75d7-4346-94dd-4667ca23cd8e", "label": "摘要1", "info": "从 h (t-1) 到 h (t) 的循环权重映射以及从 x (t) 到 h (t) 的输入权重映射是循环；网络中最难学习的参数。研究者（Jaeger，2003；Maass  et  al.  ，2002；；Jaeger  and  Haas，2004；Jaeger，2007b）提出避免这种困难的方法是设", "keywords": "研究者, 的输入权重映射是循环, 网络中最难学习的参数, 的循环权重映射以及从, 提出避免这种困难的方法是设", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "915ce7c5-74e2-43b2-80a4-d6ee3a0d76f4", "label": "摘要2", "info": "（reservoir", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8dfdebc4-d3d0-455c-841d-0f39f91599e3", "label": "摘要3", "info": "储层计算循环网络类似于核机器，这是思考它们的一种方式：它们将任；意长度的序列（到时刻t的输入历史）映射为一个长度固定的向量（循；环状态  h  (t)  ），之后可以施加一个线性预测算子（通常是一个线性回", "keywords": "的输入历史, 之后可以施加一个线性预测算子, 储层计算循环网络类似于核机器, 环状态, 通常是一个线性回", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b0f8778d-9347-4685-add2-d8a3c1870606", "label": "摘要4", "info": "因此，重要的问题是：如何设置输入和循环权重，才能让一组丰富的历", "keywords": "如何设置输入和循环权重, 因此, 才能让一组丰富的历, 重要的问题是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7c8d84d6-6de2-4b97-ae48-c3299837bdb8", "label": "摘要5", "info": "史可以在循环神经网络的状态中表示？储层计算研究给出的答案是将循；环网络视为动态系统，并设定让动态系统接近稳定边缘的输入和循环权；重。", "keywords": "并设定让动态系统接近稳定边缘的输入和循环权, 环网络视为动态系统, 储层计算研究给出的答案是将循, 史可以在循环神经网络的状态中表示", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "09300c62-04ed-4dcf-a265-76fd66adcf26", "label": "摘要6", "info": "最初的想法是使状态到状态转换函数的Jacobian矩阵的特征值接近1。如；第8.2.5节解释，循环网络的一个重要特征就是Jacobian矩阵的特征值谱", "keywords": "循环网络的一个重要特征就是, 矩阵的特征值接近, 节解释, 矩阵的特征值谱, 最初的想法是使状态到状态转换函数的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "15220e42-0946-47c5-8d4c-e5a7d7532b4c", "label": "摘要7", "info": "。特别重要的是，  J  (t)  的谱半径  （spectral", "keywords": "的谱半径, 特别重要的是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "79a3b016-c45b-458d-8a92-97e9ca479a04", "label": "摘要8", "info": "radius）定义为特征值的最大绝对值。", "keywords": "定义为特征值的最大绝对值", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "6759c189-2b4c-42e2-bec7-0248cdb7bc1c", "label": "摘要9", "info": "为了解谱半径的影响，可以考虑反向传播中Jacobian矩阵  J  不随t改变的；简单情况。例如当网络是纯线性时，会发生这种情况。假设  J  特征值λ；对应的特征向量为 ν  。考虑当我们通过时间向后传播梯度向量时会发生", "keywords": "对应的特征向量为, 可以考虑反向传播中, 特征值, 矩阵, 会发生这种情况", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7d9ec8c6-acb1-4b99-ae13-3539df4e81ac", "label": "摘要10", "info": "当｜λ｜＞1，偏差δ｜λ｜  n  就会指数增长。当｜λ｜＜1，偏差就会变得；指数减小。", "keywords": "指数减小, 偏差就会变得, 偏差, 就会指数增长", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a929d99f-d62f-47e7-a2d9-031a5eb6e18f", "label": "摘要11", "info": "当然，这个例子假定Jacobian矩阵在每个时间步是相同的，即对应于没；有非线性循环网络。当非线性存在时，非线性的导数将在许多时间步后；接近零，并有助于防止因过大的谱半径而导致的爆炸。事实上，关于回", "keywords": "这个例子假定, 当非线性存在时, 事实上, 即对应于没, 有非线性循环网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "6c59ddd0-693a-4715-942f-00d6159f851a", "label": "摘要12", "info": "我们已经说过多次，通过反复矩阵乘法的反向传播同样适用于没有非线；性的正向传播的网络，其状态为", "keywords": "我们已经说过多次, 通过反复矩阵乘法的反向传播同样适用于没有非线, 其状态为, 性的正向传播的网络", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "dcebb07b-cce2-48f6-8761-b5f691c1557e", "label": "摘要13", "info": "。", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "91aa6f68-718d-44ff-9184-708e298d533f", "label": "摘要14", "info": "如果线性映射", "keywords": "如果线性映射", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "61418106-8d86-4459-adca-f35ce7ef820b", "label": "摘要15", "info": "在L 2 范数的测度下总是缩小 h ，那么我们说这个映", "keywords": "那么我们说这个映, 范数的测度下总是缩小", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "42b34602-4626-4c10-9365-2c839ba0672f", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；射是收缩（contractive）的。当谱半径小于一，则从 h (t) 到 h (t+1) 的映射；是收缩的，因此小变化在每个时间步后变得更小。当我们使用有限精度", "keywords": "则从, 是收缩的, 的映射, 射是收缩, 因此小变化在每个时间步后变得更小", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "d10d3933-bbba-47e6-b84f-b448a6657f4a", "label": "摘要17", "info": "Jacobian矩阵告诉我们  h  (t)  一个微小的变化如何向前一步传播，或等价；地， h (t+1) 的梯度如何向后一步传播。需要注意的是， W 和 J 都不需要；是对称的（尽管它们是实方阵），因此它们可能有复的特征值和特征向", "keywords": "需要注意的是, 是对称的, 或等价, 尽管它们是实方阵, 因此它们可能有复的特征值和特征向", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "53224200-498d-4674-816f-975da5ae7184", "label": "摘要18", "info": "非线性映射情况时，Jacobian会在每一步任意变化。因此，动态量变得；更加复杂。然而，一个小的初始变化多步之后仍然会变成一个大的变；化。纯线性和非线性情况的一个不同之处在于使用压缩非线性（如", "keywords": "非线性映射情况时, 因此, 纯线性和非线性情况的一个不同之处在于使用压缩非线性, 然而, 更加复杂", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c7068e5a-5926-48c7-9577-022c66338f95", "label": "摘要19", "info": "回声状态网络的策略是简单地固定权重，使其具有一定的谱半径如3，；其中信息通过时间前向传播，但会由于饱和非线性单元（如tanh）的稳；定作用而不会爆炸。", "keywords": "但会由于饱和非线性单元, 定作用而不会爆炸, 回声状态网络的策略是简单地固定权重, 其中信息通过时间前向传播, 使其具有一定的谱半径如", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c2bd26ea-4343-4d0e-a28e-e494fa6b86fd", "label": "摘要20", "info": "最近，已经有研究表明，用于设置ESN权重的技术可以用来初始化完全；可训练的循环网络的权重（通过时间反向传播来训练隐藏到隐藏的循环；et  al.  ，", "keywords": "已经有研究表明, 用于设置, 权重的技术可以用来初始化完全, 最近, 可训练的循环网络的权重", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "label": "10.9：渗漏单元和其他多时间尺度的策略", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "9e796374-c705-4497-a523-5f16e388b374", "label": "摘要1", "info": "10.9.1　时间维度的跳跃连接", "keywords": "时间维度的跳跃连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f3a48789-0132-4dc9-997b-fbc2409b4548", "label": "摘要2", "info": "10.9.2　渗漏单元和一系列不同时间尺度", "keywords": "渗漏单元和一系列不同时间尺度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5be72b70-5cbb-4c61-b8f4-9f694cfcdd47", "label": "摘要3", "info": "10.9.3　删除连接", "keywords": "删除连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "930c0970-4f25-49a9-bc52-301e373693e4", "label": "摘要4", "info": "处理长期依赖的一种方法是设计工作在多个时间尺度的模型，使模型的；某些部分在细粒度时间尺度上操作并能处理小细节，而其他部分在粗时", "keywords": "某些部分在细粒度时间尺度上操作并能处理小细节, 而其他部分在粗时, 处理长期依赖的一种方法是设计工作在多个时间尺度的模型, 使模型的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5e8ddd26-863c-459a-8e23-caa54186d157", "label": "摘要5", "info": "间尺度上操作并能把遥远过去的信息更有效地传递过来。存在多种同时；构建粗细时间尺度的策略。这些策略包括在时间轴增加跳跃连接，“渗；漏单元”使用不同时间常数整合信号，并去除一些用于建模细粒度时间", "keywords": "构建粗细时间尺度的策略, 使用不同时间常数整合信号, 漏单元, 并去除一些用于建模细粒度时间, 存在多种同时", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "15047d56-d50e-4476-8849-1f68368196b3", "label": "摘要6", "info": "10.9.1　时间维度的跳跃连接", "keywords": "时间维度的跳跃连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "88883b88-da99-4f00-8361-3ed09a1ce338", "label": "摘要7", "info": "增加从遥远过去的变量到目前变量的直接连接是得到粗时间尺度的一种；方法。使用这样跳跃连接的想法可以追溯到Lin et al. （1996），紧接是；向前馈网络引入延迟的想法（Lang  and  Hinton，1988）。在普通的循环", "keywords": "使用这样跳跃连接的想法可以追溯到, 方法, 紧接是, 在普通的循环, 增加从遥远过去的变量到目前变量的直接连接是得到粗时间尺度的一种", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9428b702-fc46-4147-afcd-98ac31751598", "label": "摘要8", "info": "正如我们在第8.2.5节看到，梯度可能关于时间步数呈指数消失或爆炸。；（Lin  et  al.  ，1996）引入了d延时的循环连接以减轻这个问题。现在导", "keywords": "延时的循环连接以减轻这个问题, 现在导, 梯度可能关于时间步数呈指数消失或爆炸, 节看到, 引入了", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "6c82666e-fd4a-4e29-bed4-ec0ebf4ecdb6", "label": "摘要9", "info": "数指数减小的速度与   相关而不是τ。既然同时存在延迟和单步连", "keywords": "数指数减小的速度与, 相关而不是, 既然同时存在延迟和单步连", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0717d5d8-1646-4e3a-a4ed-4a37872fef05", "label": "摘要10", "info": "接，梯度仍可能成t指数爆炸。这允许学习算法捕获更长的依赖性，但；不是所有的长期依赖都能在这种方式下良好地表示。", "keywords": "不是所有的长期依赖都能在这种方式下良好地表示, 梯度仍可能成, 这允许学习算法捕获更长的依赖性, 指数爆炸", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "1de54d3b-f32a-4b10-9b71-4e4dd3892808", "label": "摘要11", "info": "10.9.2　渗漏单元和一系列不同时间尺度", "keywords": "渗漏单元和一系列不同时间尺度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ec49b187-87bf-4415-b528-ea77555eba83", "label": "摘要12", "info": "获得导数乘积接近1的另一方式是设置线性自连接单元，并且这些连接；的权重接近1。", "keywords": "并且这些连接, 的另一方式是设置线性自连接单元, 获得导数乘积接近, 的权重接近", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "04aed686-a948-43d9-b66b-5d18281fabc1", "label": "摘要13", "info": "我们对某些ν值应用更新µ (t) ←αµ  (t-1)  +(1-α)ν  (t) 累积一个滑动平均值µ  (t)；，其中α是一个从µ  (t-1)  到µ  (t)  线性自连接的例子。当α接近1时，滑动平；均值能记住过去很长一段时间的信息，而当α接近0，关于过去的信息被", "keywords": "而当, 其中, 线性自连接的例子, 均值能记住过去很长一段时间的信息, 关于过去的信息被", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cb2d365a-cab5-4926-bc4a-00808d356878", "label": "摘要14", "info": "d时间步的跳跃连接可以确保单元总能被d个时间步前的那个值影响。使；用权重接近1的线性自连接是确保该单元可以访问过去值的不同方式。；线性自连接通过调节实值α更平滑灵活地调整这种效果，而不是调整整", "keywords": "时间步的跳跃连接可以确保单元总能被, 用权重接近, 线性自连接通过调节实值, 个时间步前的那个值影响, 更平滑灵活地调整这种效果", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "76d827d9-6c7c-4d6a-9083-ed22c9092331", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；这个想法由Mozer（1992）和El  Hihi  and  Bengio（1996）提出。在回声；状态网络中，渗漏单元也被发现很有用（Jaeger et al. ，2007）。", "keywords": "在回声, 提出, 状态网络中, 渗漏单元也被发现很有用, 这个想法由", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "89198d3c-f373-4735-973c-e0ad3f55b09d", "label": "摘要16", "info": "我们可以通过两种基本策略设置渗漏单元使用的时间常数。一种策略是；手动将其固定为常数，例如在初始化时从某些分布采样它们的值。另一；种策略是使时间常数成为自由变量，并学习出来。在不同时间尺度使用", "keywords": "并学习出来, 在不同时间尺度使用, 种策略是使时间常数成为自由变量, 例如在初始化时从某些分布采样它们的值, 一种策略是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "39fbeb9e-eca9-4c34-87a6-47ff98abf8a1", "label": "摘要17", "info": "10.9.3　删除连接", "keywords": "删除连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "4fc12d92-9dbf-4e59-bbd5-f9f11ae18dda", "label": "摘要18", "info": "处理长期依赖的另一种方法是在多个时间尺度组织RNN状态的想法（El；Hihi  and  Bengio，1996），信息在较慢的时间尺度上更容易长距离流；动。", "keywords": "处理长期依赖的另一种方法是在多个时间尺度组织, 信息在较慢的时间尺度上更容易长距离流, 状态的想法", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "89ef190e-f49e-4ffe-96dd-185f3ae5c823", "label": "摘要19", "info": "这个想法与之前讨论的时间维度上的跳跃连接不同，因为它涉及主动删；除长度为一的连接并用更长的连接替换它们。以这种方式修改的单元被；迫在长时间尺度上运作。而通过时间跳跃连接是添加边。收到这种新连", "keywords": "这个想法与之前讨论的时间维度上的跳跃连接不同, 因为它涉及主动删, 收到这种新连, 迫在长时间尺度上运作, 而通过时间跳跃连接是添加边", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5fff3b75-6456-440c-8ac6-3359481c8707", "label": "摘要20", "info": "强制一组循环单元在不同时间尺度上运作有不同的方式。一种选择是使；循环单元变成渗漏单元，但不同的单元组关联不同的固定时间尺度。这；由Mozer（1992）提出，并被成功应用于Pascanu et al.  （2013a）。另一", "keywords": "但不同的单元组关联不同的固定时间尺度, 强制一组循环单元在不同时间尺度上运作有不同的方式, 提出, 另一, 并被成功应用于", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f7e2fc23-44c6-4c4c-b2bf-6c240b2c57ff", "label": "摘要21", "info": "10.9.1　时间维度的跳跃；连接", "keywords": "时间维度的跳跃, 连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a5bc7ea6-27b0-47ed-8ee0-5f9cda1e821d", "label": "摘要22", "info": "10.9.2　渗漏单元和一系；列不同时间尺度", "keywords": "渗漏单元和一系, 列不同时间尺度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ead33b56-1052-46fa-b613-3b765f05f0a1", "label": "摘要23", "info": "10.9.3　删除连接", "keywords": "删除连接", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8f269230-fe09-48e8-8d18-c64513858db0", "label": "10.10：长短期记忆和其他门控RNN", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "d5c32f3b-7f38-4718-bb27-a2791f83c05a", "label": "摘要1", "info": "10.10.1　LSTM", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "233448fa-7ea5-4aef-8ee0-79e5ffba1b09", "label": "摘要2", "info": "10.10.2　其他门控RNN", "keywords": "其他门控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "82dc351f-efea-4ab4-bc0c-5fcf04c46a12", "label": "摘要3", "info": "本书撰写之时，实际应用中最有效的序列模型称为门控RNN  （gated；RNN）。包括基于长短期记忆  （long  short-term  memory）和基于门控；循环单元 （gated recurrent unit）的网络。", "keywords": "本书撰写之时, 的网络, 循环单元, 和基于门控, 包括基于长短期记忆", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f426ce1a-1d41-41c7-9685-5c04ab34181b", "label": "摘要4", "info": "像渗漏单元一样，门控RNN想法也是基于生成通过时间的路径，其中导；数既不消失也不发生爆炸。渗漏单元通过手动选择常量的连接权重或参", "keywords": "数既不消失也不发生爆炸, 其中导, 想法也是基于生成通过时间的路径, 像渗漏单元一样, 门控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "65c48901-fce8-4151-b2bf-5b7c676230bb", "label": "摘要5", "info": "数化的连接权重来达到这一目的。门控RNN将其推广为在每个时间步都；可能改变的连接权重。", "keywords": "将其推广为在每个时间步都, 门控, 数化的连接权重来达到这一目的, 可能改变的连接权重", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "08f10adc-8b5a-4f0d-865b-02713413b083", "label": "摘要6", "info": "渗漏单元允许网络在较长持续时间内积累信息（诸如用于特定特征或类；的线索）。然而，一旦该信息被使用，让神经网络遗忘旧的状态可能是；有用的。例如，如果一个序列是由子序列组成，我们希望渗漏单元能在", "keywords": "渗漏单元允许网络在较长持续时间内积累信息, 如果一个序列是由子序列组成, 我们希望渗漏单元能在, 有用的, 然而", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "dab1039b-9976-4d59-879c-044d06d4bc43", "label": "摘要7", "info": "10.10.1　LSTM", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "59c38535-16a4-474f-978e-fb674f87fc11", "label": "摘要8", "info": "引入自循环的巧妙构思，以产生梯度长时间持续流动的路径是初始长短；期记忆 （long short-term memory，LSTM）模型的核心贡献（Hochreiter；and  Schmidhuber，1997）。其中一个关键扩展是使自循环的权重视上下", "keywords": "期记忆, 引入自循环的巧妙构思, 其中一个关键扩展是使自循环的权重视上下, 模型的核心贡献, 以产生梯度长时间持续流动的路径是初始长短", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5538cc5a-cca2-4c57-b4c5-7b5bd0ff3f67", "label": "摘要9", "info": "LSTM块如图10.16所示。在浅循环网络的架构下，相应的前向传播公式；如下。更深的架构也被成功应用（Graves et al. ，2013；Pascanu et al. ，；2014a）。LSTM循环网络除了外部的RNN循环外，还具有内部", "keywords": "块如图, 循环网络除了外部的, 循环外, 还具有内部, 如下", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f88ec4bc-c152-4225-b73b-eca1afdfac65", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图10.16　 LSTM循环网络“细胞”的框图。细胞彼此循环连接，代替一般循环网络中普通的隐藏；单元。这里使用常规的人工神经元计算输入特征。如果sigmoid输入门允许，它的值可以累加到", "keywords": "如果, 这里使用常规的人工神经元计算输入特征, 的框图, 循环网络, 细胞", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b3311787-09fd-461f-b00b-0c0bcaf3b469", "label": "摘要11", "info": "其中 x  (t) 是当前输入向量，  h  t  是当前隐藏层向量， h  t  包含所有LSTM；细胞的输出。 b f 、 U f 、 W f 分别是偏置、输入权重和遗忘门的循环权；重。因此LSTM细胞内部状态以如下方式更新，其中有一个条件的自环", "keywords": "是当前隐藏层向量, 其中有一个条件的自环, 细胞的输出, 因此, 其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "51ce0f99-92bd-4f1d-bed4-ce0b3648235d", "label": "摘要12", "info": "其中  b  、  U  、  W  分别是LSTM细胞中的偏置、输入权重和遗忘门的循；环权重。外部输入门  （external  input  gate）单元   以类似遗忘门（使；用sigmoid获得一个0和1之间的值）的方式更新，但有自身的参数：", "keywords": "细胞中的偏置, 之间的值, 以类似遗忘门, 外部输入门, 其中", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "15a1b708-6bc7-46d3-8d7b-43b5d0b1e199", "label": "摘要13", "info": "LSTM细胞的输出   也可以由输出门  （output  gate）   关闭（使用；sigmoid单元作为门控）：", "keywords": "也可以由输出门, 单元作为门控, 细胞的输出, 关闭, 使用", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "193cc973-122d-4d04-9a2d-51a8a1c72a10", "label": "摘要14", "info": "其中 b o 、 U o 、 W o 分别是偏置、输入权重和遗忘门的循环权重。在这；些变体中，可以选择使用细胞状态   作为额外的输入（及其权重），；输入到第i个单元的3个门，如图10.16所示。这将需要3个额外的参数。", "keywords": "些变体中, 输入权重和遗忘门的循环权重, 在这, 作为额外的输入, 及其权重", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "fd12598c-f6bc-4c49-b537-867c85014ca0", "label": "摘要15", "info": "LSTM网络比简单的循环架构更易于学习长期依赖，先是用于测试长期；依赖学习能力的人工数据集（Bengio  et  al.  ，1994c；Hochreiter  and；Schmidhuber，1997；Hochreiter et al. ，2001），然后是在具有挑战性的", "keywords": "网络比简单的循环架构更易于学习长期依赖, 先是用于测试长期, 然后是在具有挑战性的, 依赖学习能力的人工数据集", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ed372949-08df-46fd-84bf-b87169b3c77b", "label": "摘要16", "info": "10.10.2　其他门控RNN", "keywords": "其他门控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "33ea9ab2-4152-4c48-9711-60f3a0b1e721", "label": "摘要17", "info": "LSTM架构中哪些部分是真正必需的？还可以设计哪些其他成功架构允；许网络动态地控制时间尺度和不同单元的遗忘行为？", "keywords": "架构中哪些部分是真正必需的, 许网络动态地控制时间尺度和不同单元的遗忘行为, 还可以设计哪些其他成功架构允", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0f93cbb0-4c3d-4405-ae59-942e17318e4f", "label": "摘要18", "info": "最近关于门控RNN的工作给出了这些问题的某些答案，其单元也被称为；门控循环单元或GRU（Cho  et  al.  ，2014c；Chung  et  al.  ，2014，；2015a；Jozefowicz  et  al.  ，2015；Chrupala  et  al.  ，2015）。与LSTM的", "keywords": "门控循环单元或, 其单元也被称为, 的工作给出了这些问题的某些答案, 最近关于门控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "15ce8687-f545-459e-8599-6bffeddc1139", "label": "摘要19", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其中 u 代表“更新”门， r 表示“复位”门。它们的值就如通常所定义的：", "keywords": "表示, 代表, 更新, 其中, 它们的值就如通常所定义的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "abac8236-3013-459a-8d3f-87388ad36e34", "label": "摘要20", "info": "和", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b99c6e23-98de-47d8-a195-c4f9ca149f2b", "label": "摘要21", "info": "复位和更新门能独立地“忽略”状态向量的一部分。更新门像条件渗漏累；积器一样可以线性门控任意维度，从而选择将它复制（在sigmoid的一；个极端）或完全由新的“目标状态”值（朝向渗漏累积器的收敛方向）替", "keywords": "复位和更新门能独立地, 忽略, 积器一样可以线性门控任意维度, 从而选择将它复制, 目标状态", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ca3f48e9-84dc-4953-b0cf-a0a052dd70ba", "label": "摘要22", "info": "围绕这一主题可以设计更多的变种。例如复位门（或遗忘门）的输出可；以在多个隐藏单元间共享。或者，全局门的乘积（覆盖一整组的单元，；例如整一层）和一个局部门（每单元）可用于结合全局控制和局部控", "keywords": "以在多个隐藏单元间共享, 围绕这一主题可以设计更多的变种, 例如整一层, 每单元, 可用于结合全局控制和局部控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ff721f71-cae0-4210-a1e2-ac1d1e3a804c", "label": "摘要23", "info": "10.10.1　LSTM", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "074c2394-82d0-41f8-ab53-26d96cf1c970", "label": "摘要24", "info": "10.10.2　其他门控RNN", "keywords": "其他门控", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "label": "10.11：优化长期依赖", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "51fde2f0-69ba-4fc8-a577-66a34735b0b9", "label": "摘要1", "info": "10.11.1　截断梯度", "keywords": "截断梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ffa77c64-525d-44bf-a1ba-91413281ec77", "label": "摘要2", "info": "10.11.2　引导信息流的正则化", "keywords": "引导信息流的正则化", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "39001db7-65cd-4fa3-98bf-9dc8ad08a89d", "label": "摘要3", "info": "我们已经在第8.2.5节和第10.7节中描述过在许多时间步上优化RNN时发；生的梯度消失和爆炸的问题。", "keywords": "节和第, 节中描述过在许多时间步上优化, 时发, 生的梯度消失和爆炸的问题, 我们已经在第", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "6f3cdb2e-5ee1-4a54-ac3f-bdfe58a22940", "label": "摘要4", "info": "由Martens and Sutskever（2011）提出了一个有趣的想法是，二阶导数可；能在一阶导数消失的同时消失。二阶优化算法可以大致被理解为将一阶；导数除以二阶导数（在更高维数，由梯度乘以Hessian的逆）。如果二阶", "keywords": "提出了一个有趣的想法是, 二阶导数可, 的逆, 能在一阶导数消失的同时消失, 如果二阶", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "f4df8d6d-d639-495e-b562-256aa62c809a", "label": "摘要5", "info": "导数与一阶导数以类似的速率收缩，那么一阶和二阶导数的比率可保持；相对恒定。不幸的是，二阶方法有许多缺点，包括高的计算成本、需要；一个大的小批量并且倾向于被吸引到鞍点。Martens", "keywords": "二阶方法有许多缺点, 一个大的小批量并且倾向于被吸引到鞍点, 导数与一阶导数以类似的速率收缩, 相对恒定, 那么一阶和二阶导数的比率可保持", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b2742078-0b83-4643-8d5f-760f6ea10202", "label": "摘要6", "info": "10.11.1　截断梯度", "keywords": "截断梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7f5da94b-184e-449e-9fdc-fe397b427064", "label": "摘要7", "info": "如第8.2.4节讨论，强非线性函数（如由许多时间步计算的循环网络）往；往倾向于非常大或非常小幅度的梯度。如图8.3和图10.17所示，我们可；以看到，目标函数（作为参数的函数）存在一个伴随“悬崖”的“地形”：", "keywords": "目标函数, 我们可, 和图, 强非线性函数, 所示", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "90c8e1fd-2a59-424b-a91e-769bf68aaac0", "label": "摘要8", "info": "这导致的困难是，当参数梯度非常大时，梯度下降的参数更新可以将参；数抛出很远，进入目标函数较大的区域，到达当前解所做的努力变成了；无用功。梯度告诉我们，围绕当前参数的无穷小区域内最速下降的方", "keywords": "这导致的困难是, 无用功, 数抛出很远, 梯度告诉我们, 当参数梯度非常大时", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "99c23c1b-4e31-403e-913b-d811090efc89", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图10.17　梯度截断在有两个参数 w 和 b 的循环网络中的效果示例。梯度截断可以使梯度下降在；极陡峭的悬崖附近更合理地执行。这些陡峭的悬崖通常发生在循环网络中，位于循环网络近似", "keywords": "梯度截断在有两个参数, 这些陡峭的悬崖通常发生在循环网络中, 极陡峭的悬崖附近更合理地执行, 梯度截断可以使梯度下降在, 的循环网络中的效果示例", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "13bc2a9e-96ea-4ba1-ade0-5eefd4a61faf", "label": "摘要10", "info": "一个简单的解决方案已被从业者使用多年：截断梯度  （clipping；gradient）。此想法有不同实例（Mikolov，2012；Pascanu；2013a）。一种选择是在参数更新之前，逐元素地截断小批量产生的参", "keywords": "一个简单的解决方案已被从业者使用多年, 此想法有不同实例, 截断梯度, 一种选择是在参数更新之前, 逐元素地截断小批量产生的参", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b25ebd9e-684f-49a5-bb9f-4af4f745d7f1", "label": "摘要11", "info": "the；et  al.  ，", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "be9d3979-69ee-4606-ac08-4b8e6c86c026", "label": "摘要12", "info": "其中ν是范数上界，  g  用来更新参数。因为所有参数（包括不同的参数；组，如权重和偏置）的梯度被单个缩放因子联合重整化，所以后一方法；具有的优点是保证了每个步骤仍然是在梯度方向上的，但实验表明两种", "keywords": "的梯度被单个缩放因子联合重整化, 具有的优点是保证了每个步骤仍然是在梯度方向上的, 所以后一方法, 其中, 因为所有参数", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9fa8809f-fe27-4f8b-ba5c-f905513e21d5", "label": "摘要13", "info": "10.11.2　引导信息流的正则化", "keywords": "引导信息流的正则化", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9a4a5e5e-ea7c-43c9-affa-da834f16e930", "label": "摘要14", "info": "梯度截断有助于处理爆炸的梯度，但它无助于消失的梯度。为了解决消；失的梯度问题并更好地捕获长期依赖，我们讨论了如下想法：在展开循；环架构的计算图中，沿着与弧边相关联的梯度乘积接近1的部分创建路", "keywords": "我们讨论了如下想法, 梯度截断有助于处理爆炸的梯度, 环架构的计算图中, 沿着与弧边相关联的梯度乘积接近, 的部分创建路", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7f0033ad-72d2-49ca-9a68-9519b10ca4c9", "label": "摘要15", "info": "与", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "db2c219b-0f08-4a92-b8d9-2f44495806c3", "label": "摘要16", "info": "一样大。在这个目标下，Pascanu et al. （2013a）提出以下正则项：", "keywords": "一样大, 提出以下正则项, 在这个目标下", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "da8960a0-bd00-49a0-9633-e0f672bddd20", "label": "摘要17", "info": "计算这一梯度的正则项可能会出现困难，但Pascanu  et  al.  （2013a）提；出可以将后向传播向量；考虑为恒值作为近似（为了计算正则化", "keywords": "考虑为恒值作为近似, 为了计算正则化, 出可以将后向传播向量, 计算这一梯度的正则项可能会出现困难", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "5cacd1ab-8ed3-4196-ab7e-666f182263d4", "label": "摘要18", "info": "这种方法的一个主要弱点是，在处理数据冗余的任务时如语言模型，它；并不像LSTM一样有效。", "keywords": "这种方法的一个主要弱点是, 在处理数据冗余的任务时如语言模型, 并不像, 一样有效", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "10fbaa82-93a8-4d9c-a89e-fe99612722b2", "label": "摘要19", "info": "10.11.1　截断梯度", "keywords": "截断梯度", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "33b8e447-0929-41ee-8ce7-0fd2a4d5cbbd", "label": "摘要20", "info": "10.11.2　引导信息流的正；则化", "keywords": "引导信息流的正, 则化", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "label": "10.12：外显记忆", "level": 2, "group": "chapter-10", "type": "子章節"}, {"id": "93e6472a-ca02-48ce-83db-f01b90363503", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；智能需要知识并且可以通过学习获取知识，这已促使大型深度架构的发；展。然而，知识是不同的并且种类繁多。有些知识是隐含的、潜意识的", "keywords": "然而, 潜意识的, 知识是不同的并且种类繁多, 有些知识是隐含的, 这已促使大型深度架构的发", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "29f72e75-f76e-4cd1-9da0-a121e26ae014", "label": "摘要2", "info": "神经网络擅长存储隐性知识，但是它们很难记住事实。被存储在神经网；络参数中之前，随机梯度下降需要多次提供相同的输入，即使如此，该；输入也不会被特别精确地存储。Graves  et  al.  （2014）推测这是因为神", "keywords": "络参数中之前, 随机梯度下降需要多次提供相同的输入, 即使如此, 被存储在神经网, 推测这是因为神", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "b63dbe01-a180-4ce7-bc17-c8475677615a", "label": "摘要3", "info": "为了解决这一难题，Weston  et  al.  （2014）引入了记忆网络  （memory；network），其中包括一组可以通过寻址机制来访问的记忆单元。记忆；网络原本需要监督信号指示它们如何使用自己的记忆单元。Graves et al.", "keywords": "记忆, 网络原本需要监督信号指示它们如何使用自己的记忆单元, 引入了记忆网络, 其中包括一组可以通过寻址机制来访问的记忆单元, 为了解决这一难题", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a7232479-0a71-49c6-92c6-f69503c4a26b", "label": "摘要4", "info": "每个记忆单元可以被认为是LSTM和GRU中记忆单元的扩展。不同的；是，网络输出一个内部状态来选择从哪个单元读取或写入，正如数字计；算机读取或写入到特定地址的内存访问。", "keywords": "正如数字计, 中记忆单元的扩展, 网络输出一个内部状态来选择从哪个单元读取或写入, 算机读取或写入到特定地址的内存访问, 每个记忆单元可以被认为是", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ec737d70-a317-4f8a-8b69-3ce4cbb1725c", "label": "摘要5", "info": "产生确切整数地址的函数很难优化。为了缓解这一问题，NTM实际同；时从多个记忆单元写入或读取。读取时，它们采取许多单元的加权平均；值。写入时，它们对多个单元修改不同的数值。用于这些操作的系数被", "keywords": "写入时, 用于这些操作的系数被, 时从多个记忆单元写入或读取, 产生确切整数地址的函数很难优化, 它们采取许多单元的加权平均", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "a032d43f-2366-4898-a567-17a50711e78d", "label": "摘要6", "info": "选择为集中在一个小数目的单元，如通过softmax函数产生它们。使用；这些具有非零导数的权重允许函数控制访问存储器，从而能使用梯度下；降法优化。关于这些系数的梯度指示着其中每个参数是应该增加还是减", "keywords": "选择为集中在一个小数目的单元, 关于这些系数的梯度指示着其中每个参数是应该增加还是减, 如通过, 降法优化, 这些具有非零导数的权重允许函数控制访问存储器", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0798fd94-e396-4cf6-8751-7d40a2b2d34b", "label": "摘要7", "info": "这些记忆单元通常扩充为包含向量，而不是由LSTM或GRU存储单元所；存储的单个标量。增加记忆单元大小的原因有两个。原因之一是，我们；已经增加了访问记忆单元的成本。我们为产生用于许多单元的系数付出", "keywords": "这些记忆单元通常扩充为包含向量, 已经增加了访问记忆单元的成本, 我们, 增加记忆单元大小的原因有两个, 存储的单个标量", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "cf6cb56c-2d9a-49e6-aa19-f604f8017918", "label": "摘要8", "info": "如果一个存储单元的内容在大多数时间步上会被复制（不被忘记），则；它包含的信息可以在时间上向前传播，随时间向后传播的梯度也不会消；失或爆炸。", "keywords": "不被忘记, 如果一个存储单元的内容在大多数时间步上会被复制, 随时间向后传播的梯度也不会消, 失或爆炸, 它包含的信息可以在时间上向前传播", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "ed26ca57-9217-46a4-b4ba-57e0242e1997", "label": "摘要9", "info": "外显记忆的方法在图10.18说明，其中我们可以看到与存储器耦接的“任；务神经网络”。虽然这一任务神经网络可以是前馈或循环的，但整个系；统是一个循环网络。任务网络可以选择读取或写入的特定内存地址。外", "keywords": "但整个系, 其中我们可以看到与存储器耦接的, 任务网络可以选择读取或写入的特定内存地址, 务神经网络, 外显记忆的方法在图", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "0fab2def-15b8-4a94-bc51-87e8dffb687d", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图10.18　具有外显记忆网络的示意图，具备神经网络图灵机的一些关键设计元素。在此图中，；我们将模型的“表示”部分（“任务网络”，这里是底部的循环网络）与存储事实的模型（记忆单", "keywords": "表示, 部分, 我们将模型的, 记忆单, 与存储事实的模型", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "182473fe-a2f7-4630-a216-d7a898d05a4f", "label": "摘要11", "info": "作为存储器单元的加权平均值反向传播的替代，我们可以将存储器寻址；系数解释为概率，并随机从一个单元读取（Zaremba  and  Sutskever，；2015）。优化离散决策的模型需要专门的优化算法，这将在第20.9.1节", "keywords": "作为存储器单元的加权平均值反向传播的替代, 我们可以将存储器寻址, 这将在第, 并随机从一个单元读取, 优化离散决策的模型需要专门的优化算法", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "99c7462c-83a2-42fb-a10e-2e89cae7a1fe", "label": "摘要12", "info": "无论是软（允许反向传播）或随机硬性的，用于选择一个地址的机制与；先前在机器翻译的背景下引入的注意力机制形式相同（Bahdanau  et  al.；，2015），这在第12.4.5.1节中也有讨论。甚至更早之前，注意力机制", "keywords": "用于选择一个地址的机制与, 无论是软, 节中也有讨论, 或随机硬性的, 甚至更早之前", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "1cf75c6c-0143-4c5c-9f40-2bb63e36f049", "label": "摘要13", "info": "循环神经网络提供了将深度学习扩展到序列数据的一种方法。它们是我；们的深度学习工具箱中最后一个主要的工具。现在我们的讨论将转移到；如何选择和使用这些工具，以及如何在真实世界的任务中应用这些工", "keywords": "现在我们的讨论将转移到, 如何选择和使用这些工具, 以及如何在真实世界的任务中应用这些工, 循环神经网络提供了将深度学习扩展到序列数据的一种方法, 它们是我", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "9d553273-229e-40fe-97ba-6a7eab2cc013", "label": "摘要14", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "8d79ca66-8a86-4f39-8fa6-fe599923ec43", "label": "摘要15", "info": "(1)    给定这些变量的父变量，其条件分布是确定性的。尽管设计具有这样确定性的隐藏单元的；图模型是很少见的，但这是完全合理的。", "keywords": "图模型是很少见的, 其条件分布是确定性的, 尽管设计具有这样确定性的隐藏单元的, 给定这些变量的父变量, 但这是完全合理的", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "c28ddcb5-d478-4038-aa2a-524f6b5ca46c", "label": "摘要16", "info": "(2)  我们建议不要将“递归神经网络”缩写为“RNN”，以免与“循环神经网络”混淆。", "keywords": "循环神经网络, 缩写为, 递归神经网络, 混淆, 以免与", "level": 3, "group": "chapter-10", "type": "段落"}, {"id": "7d0f807b-d203-4b94-b42f-8b12602938ec", "label": "第11章：实践方法论", "level": 1, "group": "chapter-11", "type": "章節"}, {"id": "823e55f4-5cc1-4794-afc7-d45361131bff", "label": "10.12：外显记忆", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "d80b691b-7ed2-48a5-b1a0-75b809924d7c", "label": "摘要1", "info": "要成功地使用深度学习技术，仅仅知道存在哪些算法和解释它们为何有；效的原理是不够的。一个优秀的机器学习实践者还需要知道如何针对具；体应用挑选一个合适的算法以及如何监控，并根据实验反馈改进机器学", "keywords": "要成功地使用深度学习技术, 一个优秀的机器学习实践者还需要知道如何针对具, 体应用挑选一个合适的算法以及如何监控, 仅仅知道存在哪些算法和解释它们为何有, 效的原理是不够的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "d2b345aa-befe-4230-aa50-f8b22d1d364a", "label": "摘要2", "info": "本书的大部分内容都是关于不同的机器学习模型、训练算法和目标函；数，这可能给人一种印象——成为机器学习专家的最重要因素是了解各；种各样的机器学习技术，并熟悉各种不同的数学。在实践中，正确使用", "keywords": "这可能给人一种印象, 正确使用, 训练算法和目标函, 成为机器学习专家的最重要因素是了解各, 种各样的机器学习技术", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "2e2b61f2-0b2f-4dd5-a581-02618b9e24a7", "label": "摘要3", "info": "我们建议参考以下几个实践设计流程：", "keywords": "我们建议参考以下几个实践设计流程", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "def3c4e5-26cb-4aa7-b526-6b2b1f1a39ca", "label": "摘要4", "info": "确定目标——使用什么样的误差度量，并为此误差度量指定目标；值。这些目标和误差度量取决于该应用旨在解决的问题。；尽快建立一个端到端的工作流程，包括估计合适的性能度量。", "keywords": "使用什么样的误差度量, 尽快建立一个端到端的工作流程, 确定目标, 这些目标和误差度量取决于该应用旨在解决的问题, 包括估计合适的性能度量", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "41323104-8841-43db-b19d-13781e658b1b", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；根据具体观察反复地进行增量式的改动，如收集新数据、调整超参；数或改进算法。", "keywords": "如收集新数据, 数或改进算法, 调整超参, 根据具体观察反复地进行增量式的改动", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c954b69d-692a-4f79-841d-395c8e7cdf05", "label": "摘要6", "info": "我们将使用街景地址号码转录系统（Goodfellow et  al.  ，2014d）作为一；个运行示例。该应用的目标是将建筑物添加到谷歌地图。街景车拍摄建；筑物，并记录与每张建筑照片相关的GPS坐标。卷积网络识别每张照片", "keywords": "筑物, 街景车拍摄建, 卷积网络识别每张照片, 坐标, 并记录与每张建筑照片相关的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0925d1ef-ebde-4146-955a-de9fdec48e6d", "label": "摘要7", "info": "我们现在描述这个过程中的每一个步骤。", "keywords": "我们现在描述这个过程中的每一个步骤", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "label": "11.1：性能度量", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "c64fb5f2-ade7-4d1d-b4d5-25330c47b3c0", "label": "摘要1", "info": "确定目标，即使用什么误差度量，是必要的第一步，因为误差度量将指；导接下来的所有工作。同时我们也应该了解大概能得到什么级别的目标；性能。", "keywords": "因为误差度量将指, 性能, 即使用什么误差度量, 导接下来的所有工作, 确定目标", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0fd36442-e1f4-4719-bb1a-799777c25dbf", "label": "摘要2", "info": "值得注意的是，对于大多数应用而言，不可能实现绝对零误差。即使你；有无限的训练数据，并且恢复了真正的概率分布，贝叶斯误差仍定义了；能达到的最小错误率。这是因为输入特征可能无法包含输出变量的完整", "keywords": "对于大多数应用而言, 不可能实现绝对零误差, 值得注意的是, 能达到的最小错误率, 有无限的训练数据", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0a0ff11a-cec7-4788-a30d-2425368abb69", "label": "摘要3", "info": "训练数据的数量会因为各种原因受到限制。当目标是打造现实世界中最；好的产品或服务时，我们通常需要收集更多的数据，但必须确定进一步；减少误差的价值，并与收集更多数据的成本做权衡。数据收集会耗费时", "keywords": "并与收集更多数据的成本做权衡, 数据收集会耗费时, 好的产品或服务时, 当目标是打造现实世界中最, 训练数据的数量会因为各种原因受到限制", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c2ba843d-ef3a-421d-af61-617fd8fe6280", "label": "摘要4", "info": "如何确定合理的性能期望？在学术界，通常我们可以根据先前公布的基；准结果来估计预期错误率。在现实世界中，一个应用的错误率有必要是；安全的、具有成本效益的或吸引消费者的。一旦你确定了想要达到的错", "keywords": "准结果来估计预期错误率, 安全的, 一旦你确定了想要达到的错, 通常我们可以根据先前公布的基, 在学术界", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "263f0f7d-4b24-49d0-b472-f75db4dfd18a", "label": "摘要5", "info": "除了需要考虑性能度量之外，另一个需要考虑的是度量的选择。我们有", "keywords": "除了需要考虑性能度量之外, 我们有, 另一个需要考虑的是度量的选择", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "9837a129-828c-4a08-bb49-eb002d27f415", "label": "摘要6", "info": "几种不同的性能度量，可以用来度量一个含有机器学习组件的完整应用；的有效性。这些性能度量通常不同于训练模型的代价函数。如第5.1.2节；所述，我们通常会度量一个系统的准确率，或等价地，错误率。", "keywords": "可以用来度量一个含有机器学习组件的完整应用, 这些性能度量通常不同于训练模型的代价函数, 的有效性, 或等价地, 所述", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3e15d852-7b50-45bc-8310-e6ef2969e20b", "label": "摘要7", "info": "然而，许多应用需要更高级的度量。", "keywords": "许多应用需要更高级的度量, 然而", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "02d0f43d-f78f-4463-973f-075bf4944c48", "label": "摘要8", "info": "有时，一种错误可能会比另一种错误更严重。例如，垃圾邮件检测系统；会有两种错误：将正常邮件错误地归为垃圾邮件，将垃圾邮件错误地归；为正常邮件。阻止正常消息比允许可疑消息通过糟糕得多。我们希望度", "keywords": "将正常邮件错误地归为垃圾邮件, 将垃圾邮件错误地归, 垃圾邮件检测系统, 有时, 一种错误可能会比另一种错误更严重", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "57944078-5548-4e0c-8b48-9b2c96d150ff", "label": "摘要9", "info": "有时，我们需要训练检测某些罕见事件的二元分类器。例如，我们可能；会为一种罕见疾病设计医疗测试。假设每一百万人中只有一人患病。我；们只需要让分类器一直报告没有患者，就能轻易地在检测任务上实现", "keywords": "会为一种罕见疾病设计医疗测试, 就能轻易地在检测任务上实现, 有时, 我们需要训练检测某些罕见事件的二元分类器, 例如", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "2bde2acc-3fa1-472d-b7ca-d6952b3ad0cd", "label": "摘要10", "info": "x", "keywords": "", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0884b1f5-a441-44d4-ba82-ba35f0eb7b21", "label": "摘要11", "info": "另一种方法是报告PR曲线下方的总面积。", "keywords": "曲线下方的总面积, 另一种方法是报告", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "aa2ad3ab-4e84-44b5-8d6a-ff3fa9a1132b", "label": "摘要12", "info": "在一些应用中，机器学习系统可能会拒绝作出判断。如果机器学习算法", "keywords": "如果机器学习算法, 机器学习系统可能会拒绝作出判断, 在一些应用中", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "f34b031f-f409-4030-8b57-a7c6b3f85613", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；能够估计所作判断的置信度，这将会非常有用，特别是在错误判断会导；致严重危害，而人工操作员能够偶尔接管的情况下。街景转录系统可以", "keywords": "而人工操作员能够偶尔接管的情况下, 能够估计所作判断的置信度, 致严重危害, 这将会非常有用, 特别是在错误判断会导", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e4f77e5e-8cc5-4ae3-b1df-bef6c15045b9", "label": "摘要14", "info": "还有许多其他的性能度量。例如，我们可以度量点击率、收集用户满意；度调查等。许多专业的应用领域也有特定的标准。", "keywords": "许多专业的应用领域也有特定的标准, 我们可以度量点击率, 例如, 还有许多其他的性能度量, 度调查等", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "00f9e75a-bafe-4536-bce1-ca881584ab00", "label": "摘要15", "info": "最重要的是首先要确定改进哪个性能度量，然后专心提高性能度量。如；果没有明确的目标，那么我们很难判断机器学习系统上的改动是否有所；改进。", "keywords": "最重要的是首先要确定改进哪个性能度量, 然后专心提高性能度量, 那么我们很难判断机器学习系统上的改动是否有所, 改进, 果没有明确的目标", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "label": "11.2：默认的基准模型", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "cf6202bc-c31f-4ce8-bbd3-ca5b8fd70ba7", "label": "摘要1", "info": "确定性能度量和目标后，任何实际应用的下一步是尽快建立一个合理的；端到端的系统。在本节中，我们提供了关于不同情况下使用哪种算法作；为第一基准方法的推荐。值得注意的是，深度学习研究进展迅速，所以", "keywords": "在本节中, 端到端的系统, 任何实际应用的下一步是尽快建立一个合理的, 深度学习研究进展迅速, 我们提供了关于不同情况下使用哪种算法作", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "14f9c7ce-be5b-4fd2-9913-ed7d9a7740bb", "label": "摘要2", "info": "根据问题的复杂性，项目开始时可能无须使用深度学习。如果只需正确；地选择几个线性权重就可能解决问题，那么项目可以开始于一个简单的；统计模型，如逻辑回归。", "keywords": "地选择几个线性权重就可能解决问题, 统计模型, 如逻辑回归, 如果只需正确, 项目开始时可能无须使用深度学习", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e7df469c-95dc-4f75-9735-aebc875dcd32", "label": "摘要3", "info": "如果问题属于“AI-完全”类的，如对象识别、语音识别、机器翻译等，；那么项目开始于一个合适的深度学习模型，效果会比较好。", "keywords": "语音识别, 效果会比较好, 完全, 那么项目开始于一个合适的深度学习模型, 机器翻译等", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c332c0d3-5945-440a-b73c-3476ade786ca", "label": "摘要4", "info": "首先，根据数据的结构选择一类合适的模型。如果项目是以固定大小的", "keywords": "首先, 根据数据的结构选择一类合适的模型, 如果项目是以固定大小的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5b0375fc-00b2-42f0-bf7b-482be19d5116", "label": "摘要5", "info": "向量作为输入的监督学习，那么可以使用全连接的前馈网络。如果输入；已知的拓扑结构（例如，输入的是图像），那么可以使用卷积网络。在；这些情况下，刚开始可以使用某些分段线性单元（ReLU或者其扩展，", "keywords": "刚开始可以使用某些分段线性单元, 这些情况下, 输入的是图像, 那么可以使用卷积网络, 例如", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "fb80b30e-2aef-47cd-b837-12d9b5fec5aa", "label": "摘要6", "info": "具有衰减学习率以及动量的SGD是优化算法一个合理的选择（流行的衰；减方法有，衰减到固定最低学习率的线性衰减、指数衰减，或每次发生；验证错误停滞时将学习率降低2～10倍，这些衰减方法在不同问题上好", "keywords": "是优化算法一个合理的选择, 这些衰减方法在不同问题上好, 减方法有, 衰减到固定最低学习率的线性衰减, 验证错误停滞时将学习率降低", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e728e893-f7ba-4ce2-9e22-43bff4d8e114", "label": "摘要7", "info": "除非训练集包含数千万以及更多的样本，否则项目应该在一开始就包含；一些温和的正则化。提前终止也被普遍采用。Dropout也是一个很容易；实现，且兼容很多模型和训练算法的出色正则化项。批标准化有时也能", "keywords": "一些温和的正则化, 批标准化有时也能, 也是一个很容易, 实现, 除非训练集包含数千万以及更多的样本", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "10923666-5337-4060-ad08-59b052beacd6", "label": "摘要8", "info": "如果我们的任务和另一个被广泛研究的任务相似，那么通过复制先前研；究中已知性能良好的模型和算法，可能会得到很好的效果，甚至可以从；该任务中复制一个训练好的模型。例如，通常会使用在ImageNet上训练", "keywords": "该任务中复制一个训练好的模型, 可能会得到很好的效果, 甚至可以从, 通常会使用在, 如果我们的任务和另一个被广泛研究的任务相似", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "a0bbe250-796d-4c20-9d50-cd5dd6396ebc", "label": "摘要9", "info": "一个常见问题是项目开始时是否使用无监督学习，我们将在第三部分进；一步探讨这个问题。这个问题和特定领域有关。在某些领域，比如自然；语言处理，能够大大受益于无监督学习技术，如学习无监督词嵌入。在", "keywords": "我们将在第三部分进, 比如自然, 这个问题和特定领域有关, 如学习无监督词嵌入, 语言处理", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3903b2d9-e8f9-4006-98b7-a003105d73c7", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；11.3　决定是否收集更多数据", "keywords": "决定是否收集更多数据", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "4521f28a-adcb-410c-8ed1-b5e0aa86b252", "label": "摘要11", "info": "在建立第一个端到端的系统后，就可以度量算法性能并决定如何改进算；法。许多机器学习新手都忍不住尝试很多不同的算法来进行改进。然；而，收集更多的数据往往比改进学习算法要有用得多。", "keywords": "许多机器学习新手都忍不住尝试很多不同的算法来进行改进, 收集更多的数据往往比改进学习算法要有用得多, 在建立第一个端到端的系统后, 就可以度量算法性能并决定如何改进算", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "6fe7786b-32bd-4a57-814e-3afdda7cbe64", "label": "摘要12", "info": "怎样判断是否要收集更多的数据？首先，确定训练集上的性能是否可接；受。如果模型在训练集上的性能就很差，学习算法都不能在训练集上学；习出良好的模型，那么就没必要收集更多的数据。反之，可以尝试增加", "keywords": "如果模型在训练集上的性能就很差, 怎样判断是否要收集更多的数据, 确定训练集上的性能是否可接, 学习算法都不能在训练集上学, 习出良好的模型", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "d49cdd20-c9e5-4d3d-9fd0-b9767c7a31e6", "label": "摘要13", "info": "如果训练集上的性能是可接受的，那么我们开始度量测试集上的性能。；如果测试集上的性能也是可以接受的，那么就顺利完成了。如果测试集；上的性能比训练集的要差得多，那么收集更多的数据是最有效的解决方", "keywords": "那么我们开始度量测试集上的性能, 上的性能比训练集的要差得多, 如果训练集上的性能是可接受的, 那么收集更多的数据是最有效的解决方, 如果测试集", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e620c703-c57f-4d91-808b-6207ada8f9ec", "label": "摘要14", "info": "在决定是否收集更多的数据时，也需要确定收集多少数据。如图5.4所；示，绘制曲线显示训练集规模和泛化误差之间的关系是很有帮助的。根；据走势延伸曲线，可以预测还需要多少训练数据来达到一定的性能。通", "keywords": "也需要确定收集多少数据, 据走势延伸曲线, 可以预测还需要多少训练数据来达到一定的性能, 如图, 绘制曲线显示训练集规模和泛化误差之间的关系是很有帮助的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3e70dde3-f062-4558-b974-1f04b745cd30", "label": "摘要15", "info": "如果收集更多的数据是不可行的，那么改进泛化误差的唯一方法是改进；学习算法本身。这属于研究领域，并非对应用实践者的建议。", "keywords": "这属于研究领域, 学习算法本身, 那么改进泛化误差的唯一方法是改进, 如果收集更多的数据是不可行的, 并非对应用实践者的建议", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "label": "11.4：选择超参数", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "e7382623-1e88-424f-8648-b5c1dbc31ec9", "label": "摘要1", "info": "11.4.1　手动调整超参数", "keywords": "手动调整超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "13e40ed1-917d-4f50-ab99-0e45474d76a9", "label": "摘要2", "info": "11.4.2　自动超参数优化算法", "keywords": "自动超参数优化算法", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c3f5812e-4c3a-4182-a9b7-2381330e73d2", "label": "摘要3", "info": "11.4.3　网格搜索", "keywords": "网格搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "861af66e-3b0c-4b77-94d0-e3b1f9049e2e", "label": "摘要4", "info": "11.4.4　随机搜索", "keywords": "随机搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "cb9367f0-3aee-4223-a009-e9e74cbb3672", "label": "摘要5", "info": "11.4.5　基于模型的超参数优化", "keywords": "基于模型的超参数优化", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "fab6990b-0f3e-4238-99d5-31224c8472f7", "label": "摘要6", "info": "大部分深度学习算法都有许多超参数来控制不同方面的算法表现。有些；超参数会影响算法运行的时间和存储成本，有些超参数会影响学习到的；模型质量以及在新输入上推断正确结果的能力。", "keywords": "超参数会影响算法运行的时间和存储成本, 模型质量以及在新输入上推断正确结果的能力, 有些超参数会影响学习到的, 大部分深度学习算法都有许多超参数来控制不同方面的算法表现, 有些", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "19eacf3a-1971-47b7-8216-78fa2bce06f0", "label": "摘要7", "info": "有两种选择超参数的基本方法：手动选择和自动选择。手动选择超参数；需要了解超参数做了些什么，以及机器学习模型如何才能取得良好的泛；化。自动选择超参数算法大大减少了了解这些想法的需要，但它们往往", "keywords": "自动选择超参数算法大大减少了了解这些想法的需要, 手动选择和自动选择, 以及机器学习模型如何才能取得良好的泛, 需要了解超参数做了些什么, 手动选择超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "cb326093-9422-40b4-a621-4f88a79c70e7", "label": "摘要8", "info": "11.4.1　手动调整超参数", "keywords": "手动调整超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "28f7bb2b-213e-43f3-a7e7-8fc4e9f14da6", "label": "摘要9", "info": "手动设置超参数，我们必须了解超参数、训练误差、泛化误差和计算资；源（内存和运行时间）之间的关系。这需要切实了解一个学习算法有效；容量的基础概念，如第5章所描述的。", "keywords": "训练误差, 手动设置超参数, 容量的基础概念, 内存和运行时间, 章所描述的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "a631bed8-88c8-4550-987a-b66490923648", "label": "摘要10", "info": "手动搜索超参数的目标通常是最小化受限于运行时间和内存预算的泛化；误差。我们不去探讨如何确定各种超参数对运行时间和内存的影响，因；为这高度依赖于平台。", "keywords": "手动搜索超参数的目标通常是最小化受限于运行时间和内存预算的泛化, 为这高度依赖于平台, 误差, 我们不去探讨如何确定各种超参数对运行时间和内存的影响", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3330d8fe-027d-4855-8cbf-ab832bf6493e", "label": "摘要11", "info": "手动搜索超参数的主要目标是调整模型的有效容量以匹配任务的复杂；性。有效容量受限于3个因素：模型的表示容量、学习算法成功最小化；训练模型代价函数的能力，以及代价函数和训练过程正则化模型的程", "keywords": "以及代价函数和训练过程正则化模型的程, 训练模型代价函数的能力, 手动搜索超参数的主要目标是调整模型的有效容量以匹配任务的复杂, 个因素, 有效容量受限于", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "1828b3ec-fdab-4b20-99ca-ff22bfe4e225", "label": "摘要12", "info": "当泛化误差以某个超参数为变量，作为函数绘制出来时，通常会表现为；U形曲线，如图5.3所示。在某个极端情况下，超参数对应着低容量，并；且泛化误差由于训练误差较大而很高。这便是欠拟合的情况。另一种极", "keywords": "通常会表现为, 超参数对应着低容量, 在某个极端情况下, 且泛化误差由于训练误差较大而很高, 这便是欠拟合的情况", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "75d4b810-2ab1-4654-bebd-e73929f03b52", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；之间的差距较大而很高。最优的模型容量位于曲线中间的某个位置，能；够达到最低可能的泛化误差，由某个中等的泛化误差和某个中等的训练", "keywords": "由某个中等的泛化误差和某个中等的训练, 够达到最低可能的泛化误差, 最优的模型容量位于曲线中间的某个位置, 之间的差距较大而很高", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "1681e834-b5fb-4551-880f-a7b179c361ad", "label": "摘要14", "info": "对于某些超参数，当超参数数值太大时，会发生过拟合。例如中间层隐；藏单元的数量，增加数量能提高模型的容量，容易发生过拟合。对于某；些超参数，当超参数数值太小时，也会发生过拟合。例如，最小的权重", "keywords": "当超参数数值太大时, 会发生过拟合, 些超参数, 例如, 最小的权重", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "482442ff-cb66-4767-94f0-0834763ac30b", "label": "摘要15", "info": "并非每个超参数都能对应着完整的U形曲线。很多超参数是离散的，如；中间层单元数目或是maxout单元中线性元件的数目，这种情况只能沿曲；线探索一些点。有些超参数是二值的。通常这些超参数用来指定是否使", "keywords": "单元中线性元件的数目, 很多超参数是离散的, 这种情况只能沿曲, 线探索一些点, 通常这些超参数用来指定是否使", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "bfcc885c-69c0-4bd3-b26a-8932be322ee3", "label": "摘要16", "info": "学习率可能是最重要的超参数。如果你只有时间调整一个超参数，那就；调整学习率。相比其他超参数，它以一种更复杂的方式控制模型的有效；容量——当学习率适合优化问题时，模型的有效容量最高，此时学习率", "keywords": "相比其他超参数, 它以一种更复杂的方式控制模型的有效, 那就, 容量, 调整学习率", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3a6b7f94-1ac2-45e1-b558-fdef9fec4273", "label": "摘要17", "info": "图11.1　训练误差和学习率之间的典型关系。注意，当学习率大于最优值时，误差会有显著的；提升。此图针对固定的训练时间，越小的学习率有时候可以以一个正比于学习率减小量的因素；来减慢训练过程。泛化误差也会得到类似的曲线，由于正则项作用在学习率过大或过小处比较", "keywords": "由于正则项作用在学习率过大或过小处比较, 来减慢训练过程, 注意, 当学习率大于最优值时, 提升", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "18739d63-e96c-47f2-9732-f9887b2559c9", "label": "摘要18", "info": "调整学习率外的其他参数时，需要同时监测训练误差和测试误差，以判；断模型是否过拟合或欠拟合，然后适当调整其容量。", "keywords": "调整学习率外的其他参数时, 然后适当调整其容量, 断模型是否过拟合或欠拟合, 需要同时监测训练误差和测试误差, 以判", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0f60df97-3292-4c4e-806f-6345a951b96d", "label": "摘要19", "info": "如果训练集错误率大于目标错误率，那么只能增加模型容量以改进模；型。如果没有使用正则化，并且确信优化算法正确运行，那么有必要添；加更多的网络层或隐藏单元。然而，令人遗憾的是，这增加了模型的计", "keywords": "那么有必要添, 加更多的网络层或隐藏单元, 这增加了模型的计, 然而, 那么只能增加模型容量以改进模", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5d14298d-5d2b-4617-b9ea-6b07408c5989", "label": "摘要20", "info": "如果测试集错误率大于目标错误率，那么可以采取两个方法。测试误差；是训练误差和测试误差之间差距与训练误差的总和。寻找最佳的测试误；差需要权衡这些数值。当训练误差较小（因此容量较大），测试误差主", "keywords": "当训练误差较小, 寻找最佳的测试误, 差需要权衡这些数值, 测试误差, 测试误差主", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3a6005d2-da44-4e9e-9d2a-741af3eb9ea2", "label": "摘要21", "info": "效果最好。此时目标是缩小这一差距，使训练误差的增长速率不快于差；距减小的速率。要减少这个差距，我们可以改变正则化超参数，以减少；有效的模型容量，如添加Dropout或权重衰减策略。通常，最佳性能来", "keywords": "此时目标是缩小这一差距, 通常, 如添加, 有效的模型容量, 以减少", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "6d1aef64-c3cb-4a52-925b-8e63d6db0b53", "label": "摘要22", "info": "大部分超参数可以通过推理其是否增加或减少模型容量来设置。部分示；例如表11.1所示。", "keywords": "大部分超参数可以通过推理其是否增加或减少模型容量来设置, 所示, 例如表, 部分示", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "141b7c7c-b597-44ba-a7d0-9af5e5fafb66", "label": "摘要23", "info": "表11.1　各种超参数对模型容量的影响", "keywords": "各种超参数对模型容量的影响", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "ceb31084-c73b-46aa-a5fc-49002861fb81", "label": "摘要24", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；注意事项", "keywords": "注意事项", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "dbb59bc5-059b-4f20-8862-08cee23f617c", "label": "摘要25", "info": "几乎模型每个操作；所需的时间和内存代；价都会随隐藏单元数", "keywords": "所需的时间和内存代, 价都会随隐藏单元数, 几乎模型每个操作", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "528b608b-288e-4838-81d5-045b6b66b9aa", "label": "摘要26", "info": "较宽的卷积核导致；较窄的输出尺寸，除；非使用隐式零填充减", "keywords": "较窄的输出尺寸, 非使用隐式零填充减, 较宽的卷积核导致", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "42602539-5e05-4636-b921-4c51c151e6c4", "label": "摘要27", "info": "大多数操作的时间；和内存代价会增加", "keywords": "和内存代价会增加, 大多数操作的时间", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "ed33ecd2-5184-4890-958d-70c2b1dd033f", "label": "摘要28", "info": "超参数", "keywords": "超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "8fd946aa-9797-41cc-ad35-001ba1b26753", "label": "摘要29", "info": "容量何时增；加", "keywords": "容量何时增", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "13987dd0-25bc-4ca7-8359-8071a14cf8e1", "label": "摘要30", "info": "原因", "keywords": "原因", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "8a2e198a-c6be-4954-b726-85e9374c6f5c", "label": "摘要31", "info": "隐藏单元数；量", "keywords": "隐藏单元数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "72ee88db-abd4-4660-bc77-e23f536ec03a", "label": "摘要32", "info": "增加", "keywords": "增加", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "fa026691-0c0c-43ee-89e5-6ae48b4158a0", "label": "摘要33", "info": "学习率", "keywords": "学习率", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "f5436098-8b87-41d3-8f2b-55aa7d0033db", "label": "摘要34", "info": "调至最优", "keywords": "调至最优", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "eea4696d-135c-4b34-b387-06f83d9fa2c3", "label": "摘要35", "info": "增加隐藏单元数量；会增加模型的表示能；力", "keywords": "会增加模型的表示能, 增加隐藏单元数量", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "1091f5ff-d27d-4d9b-bc78-a052501735f8", "label": "摘要36", "info": "不正确的学习速；率，不管是太高还是；太低都会由于优化失", "keywords": "不管是太高还是, 不正确的学习速, 太低都会由于优化失", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "35e5a490-545b-42df-9b02-5356536cfb6b", "label": "摘要37", "info": "卷积核宽度     增加", "keywords": "卷积核宽度, 增加", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "094433f4-1d61-4495-bff8-87ed32b3ff49", "label": "摘要38", "info": "增加卷积核宽度会；增加模型的参数数；量", "keywords": "增加模型的参数数, 增加卷积核宽度会", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3b962399-429f-4598-b7f5-d3fd038d6356", "label": "摘要39", "info": "隐式零填充     增加", "keywords": "隐式零填充, 增加", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5f373b2d-1917-4b7b-8ea8-f523534ec0aa", "label": "摘要40", "info": "权重衰减系；数", "keywords": "权重衰减系", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "7d5420ad-0e3d-4859-9505-64c75b5f2383", "label": "摘要41", "info": "降低", "keywords": "降低", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "a93213ef-197c-4ba2-a1f8-c71e7db9d24e", "label": "摘要42", "info": "Dropout比", "keywords": "", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c120a75f-368d-469f-a186-8ddab7306e56", "label": "摘要43", "info": "率", "keywords": "", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "aeaa0e50-99cb-400d-baec-4667a823d2f5", "label": "摘要44", "info": "降低", "keywords": "降低", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "98b6a530-7f54-4c67-b1ad-76ea73e39e1e", "label": "摘要45", "info": "在卷积之前隐式添；加零能保持较大尺寸；的表示", "keywords": "的表示, 在卷积之前隐式添, 加零能保持较大尺寸", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c13695c6-f3aa-4679-8005-b937ace7de09", "label": "摘要46", "info": "手动调整超参数时，不要忘记最终目标：提升测试集性能。加入正则化；只是实现这个目标的一种方法。只要训练误差低，随时都可以通过收集", "keywords": "只要训练误差低, 随时都可以通过收集, 手动调整超参数时, 只是实现这个目标的一种方法, 加入正则化", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "cf7b285e-0b7a-45f8-b1ae-3b11ad4e1558", "label": "摘要47", "info": "更多的训练数据来减少泛化误差。实践中能够确保学习有效的暴力方法；就是不断提高模型容量和训练集的大小，直到解决问题。这种做法增加；了训练和推断的计算代价，所以只有在拥有足够资源时才是可行的。原", "keywords": "就是不断提高模型容量和训练集的大小, 所以只有在拥有足够资源时才是可行的, 更多的训练数据来减少泛化误差, 实践中能够确保学习有效的暴力方法, 直到解决问题", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "71afdd2f-9df6-49fd-9f7e-dfab431f0192", "label": "摘要48", "info": "11.4.2　自动超参数优化算法", "keywords": "自动超参数优化算法", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "f26ddda1-53c9-468f-a1b3-23731121be4c", "label": "摘要49", "info": "理想的学习算法应该是只需要输入一个数据集，就可以输出学习的函；数，而不需要手动调整超参数。一些流行的学习算法，如逻辑回归和支；持向量机，流行的部分原因是这类算法只有一到两个超参数需要调整，", "keywords": "理想的学习算法应该是只需要输入一个数据集, 而不需要手动调整超参数, 流行的部分原因是这类算法只有一到两个超参数需要调整, 就可以输出学习的函, 如逻辑回归和支", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "57c16dcf-68a5-4b52-8370-0dc9d996a359", "label": "摘要50", "info": "如果仔细想想使用者搜索学习算法合适超参数的方式，我们会意识到这；其实是一种优化：我们在试图寻找超参数来优化目标函数，例如验证误；差，有时还会有一些约束（如训练时间、内存或识别时间的预算）。因", "keywords": "我们在试图寻找超参数来优化目标函数, 我们会意识到这, 其实是一种优化, 如训练时间, 有时还会有一些约束", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "6b98a7a1-6d44-4f1e-b110-86f73f91df3f", "label": "摘要51", "info": "11.4.3　网格搜索", "keywords": "网格搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "33154fe0-7723-454e-8011-7c7d6cc811e7", "label": "摘要52", "info": "当有3个或更少的超参数时，常见的超参数搜索方法是网格搜索  （grid；search）。对于每个超参数，使用者选择一个较小的有限值集去探索。；然后，这些超参数笛卡儿乘积得到一组组超参数，网格搜索使用每组超", "keywords": "个或更少的超参数时, 这些超参数笛卡儿乘积得到一组组超参数, 使用者选择一个较小的有限值集去探索, 当有, 对于每个超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "03eca012-e51f-4e93-be48-40e46e47d15f", "label": "摘要53", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；11.2所示是超参数值的网络。", "keywords": "所示是超参数值的网络", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "b17be1f1-51ab-4a7c-b31a-f1341a4bd555", "label": "摘要54", "info": "图11.2　网格搜索和随机搜索的比较。为了便于说明，我们只展示两个超参数的例子，但是我；们关注的问题中超参数个数通常会更多。（左）为了实现网格搜索，我们为每个超参数提供了；一个值的集合。搜索算法对每一种在这些集合的交叉积中的超参数组合进行训练。（右）为了", "keywords": "我们为每个超参数提供了, 但是我, 为了, 搜索算法对每一种在这些集合的交叉积中的超参数组合进行训练, 我们只展示两个超参数的例子", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "55bc6fa9-c269-4ff1-b131-13facbb91a19", "label": "摘要55", "info": "应该如何选择搜索集合的范围呢？在超参数是数值（有序）的情况下，；每个列表的最小和最大的元素可以基于先前相似实验的经验保守地挑选；出来，以确保最优解非常可能在所选范围内。通常，网格搜索大约会在", "keywords": "有序, 通常, 网格搜索大约会在, 每个列表的最小和最大的元素可以基于先前相似实验的经验保守地挑选, 应该如何选择搜索集合的范围呢", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5d8edb63-91af-409f-85a2-aec8fd463cbf", "label": "摘要56", "info": "通常重复进行网格搜索时，效果会最好。例如，假设我们在集合{-1，；0，1}上网格搜索超参数α。如果找到的最佳值是1，那么说明我们低估；了最优值α所在的范围，应该改变搜索格点，例如在集合{1，2，3}中搜", "keywords": "例如在集合, 假设我们在集合, 通常重复进行网格搜索时, 了最优值, 所在的范围", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "541619cf-3288-47ba-bf29-21c768c6847c", "label": "摘要57", "info": "网格搜索带来的一个明显问题是，计算代价会随着超参数数量呈指数级", "keywords": "网格搜索带来的一个明显问题是, 计算代价会随着超参数数量呈指数级", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "a2a4f9dd-99d1-4ba2-867c-79987dad2843", "label": "摘要58", "info": "增长。如果有m个超参数，每个最多取n个值，那么训练和估计所需的；试验数将是O(n  m  )。我们可以并行地进行实验，并且并行要求十分宽松；（进行不同搜索的机器之间几乎没有必要进行通信）。令人遗憾的是，", "keywords": "试验数将是, 我们可以并行地进行实验, 那么训练和估计所需的, 如果有, 并且并行要求十分宽松", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "cf7524ba-8689-4102-85b2-2062230c91e5", "label": "摘要59", "info": "11.4.4　随机搜索", "keywords": "随机搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "156f62d1-2957-4e0e-8f88-06c473cc2292", "label": "摘要60", "info": "幸运的是，有一个替代网格搜索的方法，并且编程简单，使用更方便，；能更快地收敛到超参数的良好取值——随机搜索（Bergstra；and", "keywords": "能更快地收敛到超参数的良好取值, 随机搜索, 并且编程简单, 幸运的是, 使用更方便", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "9e81ab9e-5e51-42da-8bef-c950aba34956", "label": "摘要61", "info": "随机搜索过程如下。首先，我们为每个超参数定义一个边缘分布，例；如，Bernoulli分布或范畴分布（分别对应着二元超参数或离散超参；数），或者对数尺度上的均匀分布（对应着正实值超参数）。例如，", "keywords": "或者对数尺度上的均匀分布, 例如, 分布或范畴分布, 对应着正实值超参数, 随机搜索过程如下", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0d3ba0ad-9a69-404a-9eb3-aad0ee55e9ba", "label": "摘要62", "info": "其中，u(a,b)表示区间(a,b)上均匀采样的样本。类似；地，log_number_of_hidden_units 可以从u(log(50),log(2000))上采样。", "keywords": "上采样, 其中, 类似, 可以从, 上均匀采样的样本", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "658456ca-6cbc-4a3c-b10b-5c87b08643cc", "label": "摘要63", "info": "与网格搜索不同，我们不需要离散化超参数的值。这允许我们在一个更；大的集合上进行搜索，而不产生额外的计算代价。实际上，如图11.2所；示，当有几个超参数对性能度量没有显著影响时，随机搜索相比于网格", "keywords": "我们不需要离散化超参数的值, 这允许我们在一个更, 而不产生额外的计算代价, 大的集合上进行搜索, 随机搜索相比于网格", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "81a8ab75-f358-4e93-ba39-c1736aa75b64", "label": "摘要64", "info": "与网格搜索一样，我们通常会重复运行不同版本的随机搜索，以基于前；一次运行的结果改进下一次搜索。", "keywords": "以基于前, 一次运行的结果改进下一次搜索, 与网格搜索一样, 我们通常会重复运行不同版本的随机搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "03d60dd9-6284-45d5-a453-4bd9b3ef8a0c", "label": "摘要65", "info": "随机搜索能比网格搜索更快地找到良好超参数的原因是，没有浪费的实；验，不像网格搜索有时会对一个超参数的两个不同值（给定其他超参数；值不变）给出相同结果。在网格搜索中，其他超参数将在这两次实验中", "keywords": "没有浪费的实, 值不变, 随机搜索能比网格搜索更快地找到良好超参数的原因是, 在网格搜索中, 给定其他超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "d62529df-c917-45a3-ab4b-dbb876dcf635", "label": "摘要66", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；果这两个值的变化所对应的验证集误差没有明显区别的话，网格搜索没；有必要重复两个等价的实验，而随机搜索仍然会对其他超参数进行两次", "keywords": "网格搜索没, 有必要重复两个等价的实验, 果这两个值的变化所对应的验证集误差没有明显区别的话, 而随机搜索仍然会对其他超参数进行两次", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "289329b1-3a50-4f30-9bc4-88dca8907c96", "label": "摘要67", "info": "11.4.5　基于模型的超参数优化", "keywords": "基于模型的超参数优化", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "38bb54cb-d3b0-4c1a-9b99-927fb4991979", "label": "摘要68", "info": "超参数搜索问题可以转化为一个优化问题，决策变量是超参数，优化的；代价是超参数训练出来的模型在验证集上的误差。在简化的设定下，可；以计算验证集上可导误差函数关于超参数的梯度，然后我们遵循这个梯", "keywords": "代价是超参数训练出来的模型在验证集上的误差, 优化的, 超参数搜索问题可以转化为一个优化问题, 然后我们遵循这个梯, 决策变量是超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "23f8be6d-770f-4759-8e1a-591d8e9ca7ad", "label": "摘要69", "info": "为了弥补梯度的缺失，我们可以对验证集误差建模，然后通过优化该模；型来提出新的超参数猜想。大部分基于模型的超参数搜索算法，都是使；用贝叶斯回归模型来估计每个超参数的验证集误差期望和该期望的不确", "keywords": "都是使, 为了弥补梯度的缺失, 型来提出新的超参数猜想, 然后通过优化该模, 用贝叶斯回归模型来估计每个超参数的验证集误差期望和该期望的不确", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5dbd1ebb-50be-44ca-bb71-c4e0658e9686", "label": "摘要70", "info": "et", "keywords": "", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c4440fe1-fc46-467c-93ac-6a4bf9111fe4", "label": "摘要71", "info": "目前，我们无法明确确定，贝叶斯超参数优化是否是一个能够实现更好；深度学习结果或是能够事半功倍的成熟工具。贝叶斯超参数优化有时表；现得像人类专家，能够在有些问题上取得很好的效果，但有时又会在某", "keywords": "贝叶斯超参数优化有时表, 我们无法明确确定, 目前, 深度学习结果或是能够事半功倍的成熟工具, 能够在有些问题上取得很好的效果", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "40d1ffe6-5d12-4fb6-9742-6093fca9e801", "label": "摘要72", "info": "大部分超参数优化算法比随机搜索更复杂，并且具有一个共同的缺点，；在它们能够从实验中提取任何信息之前，它们需要运行完整的训练实；验。相比于人类实践者手动搜索，考虑实验早期可以收集的信息量，这", "keywords": "它们需要运行完整的训练实, 大部分超参数优化算法比随机搜索更复杂, 相比于人类实践者手动搜索, 考虑实验早期可以收集的信息量, 并且具有一个共同的缺点", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "8d280c82-4c37-4286-a8a4-5e1fda9c197d", "label": "摘要73", "info": "的早期版本算法。在不同的时间点，超参数优化算法可以选择开启一个；新实验，“冻结”正在运行但希望不大的实验，或是“解冻”并恢复早期被；冻结的，但现在根据更多信息后又有希望的实验。", "keywords": "在不同的时间点, 解冻, 但现在根据更多信息后又有希望的实验, 新实验, 的早期版本算法", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "401233c4-3922-44bf-b1dc-4fe1fdd7f7ab", "label": "摘要74", "info": "11.4.1　手动调整超参数", "keywords": "手动调整超参数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0cc17194-1584-4055-a934-84c02040cb82", "label": "摘要75", "info": "11.4.2　自动超参数优化；算法", "keywords": "自动超参数优化, 算法", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "49d8c4f0-4dea-4351-a770-c50d8f21213a", "label": "摘要76", "info": "11.4.3　网格搜索", "keywords": "网格搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "cbbe32ac-32a7-4cdd-b73b-8785a18ce17c", "label": "摘要77", "info": "11.4.4　随机搜索", "keywords": "随机搜索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "6d70d521-3bb5-4ad3-869a-5a31258c3a82", "label": "摘要78", "info": "11.4.5　基于模型的超参；数优化", "keywords": "基于模型的超参, 数优化", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "label": "11.5：调试策略", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "f9fb85d3-523b-4b00-8609-1c98b4a5ed49", "label": "摘要1", "info": "当一个机器学习系统效果不好时，通常很难判断效果不好的原因是算法；本身，还是算法实现错误。由于各种原因，机器学习系统很难调试。", "keywords": "本身, 通常很难判断效果不好的原因是算法, 由于各种原因, 机器学习系统很难调试, 还是算法实现错误", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "980c8b10-5235-497f-ace8-b6d406c4b2a0", "label": "摘要2", "info": "在大多数情况下，我们不能提前知道算法的行为。事实上，使用机器学；习的整个出发点是，它会发现一些我们自己无法发现的有用行为。如果；我们在一个新的分类任务上训练一个神经网络，它达到5％的测试误", "keywords": "它会发现一些我们自己无法发现的有用行为, 如果, 我们在一个新的分类任务上训练一个神经网络, 在大多数情况下, 事实上", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "284ce3ad-a338-49f5-a9c6-2e4646372ce8", "label": "摘要3", "info": "另一个难点是，大部分机器学习模型有多个自适应的部分。如果一个部；分失效了，其他部分仍然可以自适应，并获得大致可接受的性能。例；如，假设我们正在训练多层神经网络，其中参数为权重  W  和偏置  b  。", "keywords": "和偏置, 另一个难点是, 假设我们正在训练多层神经网络, 其中参数为权重, 其他部分仍然可以自适应", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3c7bdcad-6dcf-46e9-a0e3-3176a225664d", "label": "摘要4", "info": "其中α是学习率。这个错误更新没有使用梯度。它会导致偏置在整个学；习中不断变为负值，对于一个学习算法来说这显然是错误的。然而只是；检查模型输出的话，该错误可能并不是显而易见的。根据输入的分布，", "keywords": "习中不断变为负值, 这个错误更新没有使用梯度, 它会导致偏置在整个学, 其中, 根据输入的分布", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e64e4b00-a838-4dd1-9094-4ca87275ef96", "label": "摘要5", "info": "大部分神经网络的调试策略都是解决这两个难题中的一个或两个。我们；可以设计一种足够简单的情况，能够提前得到正确结果，判断模型预测；是否与之相符；我们也可以设计一个测试，独立检查神经网络实现的各", "keywords": "能够提前得到正确结果, 是否与之相符, 我们, 我们也可以设计一个测试, 可以设计一种足够简单的情况", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0ac70b38-1f70-4d94-9d23-43065aa4be21", "label": "摘要6", "info": "一些重要的调试检测如下所述。", "keywords": "一些重要的调试检测如下所述", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "9bcbf268-e09c-4eda-bf58-0ef451f1558e", "label": "摘要7", "info": "可视化计算中模型的行为：当训练模型检测图像中的对象时，查看一些；模型检测到部分重叠的图像。在训练语音生成模型时，试听一些生成的", "keywords": "查看一些, 当训练模型检测图像中的对象时, 试听一些生成的, 在训练语音生成模型时, 可视化计算中模型的行为", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "b732237e-717d-44bf-a2d2-2c3b1f8eb759", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；语音样本。这似乎是显而易见的，但在实际中很容易只注意量化性能度；量，如准确率或对数似然。直接观察机器学习模型运行其任务，有助于", "keywords": "语音样本, 但在实际中很容易只注意量化性能度, 如准确率或对数似然, 直接观察机器学习模型运行其任务, 这似乎是显而易见的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "a83f1767-bd6a-4105-8095-0a0f4393490e", "label": "摘要9", "info": "可视化最严重的错误：大多数模型能够输出运行任务时的某种置信度；量。例如，基于softmax函数输出层的分类器给每个类分配一个概率。；因此，分配给最有可能的类的概率给出了模型在其分类决定上的置信估", "keywords": "函数输出层的分类器给每个类分配一个概率, 大多数模型能够输出运行任务时的某种置信度, 因此, 例如, 分配给最有可能的类的概率给出了模型在其分类决定上的置信估", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "849b5f1a-5cc9-42f0-a534-d6a221c5dff8", "label": "摘要10", "info": "根据训练和测试误差检测软件：我们往往很难确定底层软件是否正确实；现。训练和测试误差能够提供一些线索。如果训练误差较低，但是测试；误差较高，那么很有可能训练过程是在正常运行，但模型由于算法原因", "keywords": "但模型由于算法原因, 根据训练和测试误差检测软件, 如果训练误差较低, 那么很有可能训练过程是在正常运行, 训练和测试误差能够提供一些线索", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "d7bd1674-c968-4608-b8f8-fd74efdc87f6", "label": "摘要11", "info": "拟合极小的数据集：当训练集上有很大的误差时，我们需要确定问题是；真正的欠拟合，还是软件错误。通常，即使是小模型也可以保证很好地；拟合一个足够小的数据集。例如，只有一个样本的分类数据可以通过正", "keywords": "只有一个样本的分类数据可以通过正, 真正的欠拟合, 通常, 拟合极小的数据集, 例如", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "9bce36f6-e00a-42db-9d14-318b314a33bc", "label": "摘要12", "info": "比较反向传播导数和数值导数：如果读者正在使用一个需要实现梯度计；算的软件框架，或者在添加一个新操作到求导库中，必须定义它的；bprop  方法，那么常见的错误原因是没能正确地实现梯度表达。验证这", "keywords": "那么常见的错误原因是没能正确地实现梯度表达, 比较反向传播导数和数值导数, 验证这, 算的软件框架, 必须定义它的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "c9683920-2510-43bf-a693-9e6b31bed485", "label": "摘要13", "info": "我们可以使用小的、有限的  近似导数：", "keywords": "我们可以使用小的, 有限的, 近似导数", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "00494658-b138-4dac-93ed-cbe86aa3bc9c", "label": "摘要14", "info": "我们可以使用中心差分 （centered difference）提高近似的准确率：", "keywords": "我们可以使用中心差分, 提高近似的准确率", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "5c0fc8f1-9bba-40b4-8569-d03504324a94", "label": "摘要15", "info": "扰动大小   必须足够大，以确保该扰动不会由于数值计算的有限精度；问题产生舍入误差。", "keywords": "必须足够大, 扰动大小, 问题产生舍入误差, 以确保该扰动不会由于数值计算的有限精度", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "4432bf75-55d4-4cce-9061-eaf9364a5c2a", "label": "摘要16", "info": "通常，我们会测试向量值函数；的梯度或Jacobian矩；阵。令人遗憾的是，有限差分只允许我们每次计算一个导数。我们可以", "keywords": "我们可以, 通常, 我们会测试向量值函数, 的梯度或, 令人遗憾的是", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "0906ffa1-1ab0-44f6-b8c6-353f15db2d8d", "label": "摘要17", "info": "如果我们可以在复数上进行数值计算，那么使用复数作为函数的输入会；有非常高效的数值方法估算梯度（Squire  and  Trapp，1998）。该方法基；于如下观察：", "keywords": "如果我们可以在复数上进行数值计算, 那么使用复数作为函数的输入会, 于如下观察, 有非常高效的数值方法估算梯度, 该方法基", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "25055bc8-4b8b-4596-94c7-f87c777105dc", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其中；我们对f在不同点上计", "keywords": "我们对, 在不同点上计, 其中", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "ce4f07d5-c3e9-41a9-9d76-36e96ca2118d", "label": "摘要19", "info": "。和上面的实值情况不同，这里不存在消除影响，因为", "keywords": "因为, 这里不存在消除影响, 和上面的实值情况不同", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "628c2f23-31c7-4e4c-ba34-edddd66ae912", "label": "摘要20", "info": "算差分。因此我们可以使用很小的   ，比如   ＝10  -150  ，其中误差", "keywords": "比如, 算差分, 因此我们可以使用很小的, 其中误差", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "bc5c803a-6a4c-4043-867e-2c0a955cb4a9", "label": "摘要21", "info": "对所有实用目标都是微不足道的。", "keywords": "对所有实用目标都是微不足道的", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e04be5cd-92a4-4361-8ada-bffe9c4c3a31", "label": "摘要22", "info": "监控激活函数值和梯度的直方图：可视化神经网络在大量训练迭代后；（也许是一个轮）收集到的激活函数值和梯度的统计量往往是有用的。；隐藏单元的预激活值可以告诉我们该单元是否饱和，或者它们饱和的频", "keywords": "监控激活函数值和梯度的直方图, 收集到的激活函数值和梯度的统计量往往是有用的, 或者它们饱和的频, 可视化神经网络在大量训练迭代后, 也许是一个轮", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e65ed23f-027a-41c1-be31-440f516f58e0", "label": "摘要23", "info": "最后，许多深度学习算法为每一步产生的结果提供了某种保证。例如，；在第3部分，我们将看到一些使用代数解决优化问题的近似推断算法。；通常，这些可以通过测试它们的每个保", "keywords": "许多深度学习算法为每一步产生的结果提供了某种保证, 这些可以通过测试它们的每个保, 部分, 通常, 我们将看到一些使用代数解决优化问题的近似推断算法", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "63253922-1c52-4f24-a98f-ca39b737ef4d", "label": "摘要24", "info": "证来调试。某些优化算法提供的保证包括，目标函数值在算法的迭代步；中不会增加，某些变量的导数在算法的每一步中都是零，所有变量的梯；度在收敛时会变为零。通常，由于舍入误差，这些条件不会在数字计算", "keywords": "通常, 这些条件不会在数字计算, 证来调试, 目标函数值在算法的迭代步, 中不会增加", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "e87b12b6-96d3-4839-900a-0c89794a69c9", "label": "11.6：示例：多位数字识别", "level": 2, "group": "chapter-11", "type": "子章節"}, {"id": "46110ac0-bf61-4ce9-a48a-87ae898af352", "label": "摘要1", "info": "为了端到端地说明如何在实践中应用我们的设计方法论，我们从设计深；度学习组件出发，简单地介绍一下街景转录系统。显然，整个系统的许", "keywords": "显然, 整个系统的许, 度学习组件出发, 为了端到端地说明如何在实践中应用我们的设计方法论, 简单地介绍一下街景转录系统", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "1fcf278e-e09d-407c-bbac-6a217c6a81d2", "label": "摘要2", "info": "多其他组件，如街景车、数据库设施等，也是极其重要的。", "keywords": "也是极其重要的, 如街景车, 多其他组件, 数据库设施等", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "adb34331-8cd2-4a0c-8728-9f9cc40d1e39", "label": "摘要3", "info": "从机器学习任务的视角出发，首先这个过程要采集数据。街景车收集原；始数据，然后操作员手动提供标签。转录任务开始前有大量的数据处理；工作，包括在转录前使用其他机器学习技术探测房屋号码。", "keywords": "然后操作员手动提供标签, 首先这个过程要采集数据, 转录任务开始前有大量的数据处理, 包括在转录前使用其他机器学习技术探测房屋号码, 始数据", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "de7a0075-9ff7-468b-8cbe-e6f560fc3e50", "label": "摘要4", "info": "转录项目开始于性能度量的选择和对这些度量的期望值。一个重要的总；原则是度量的选择要符合项目的业务目标。因为地图只有是高准确率时；才有用，所以为这个项目设置高准确率的要求非常重要。具体地，目标", "keywords": "原则是度量的选择要符合项目的业务目标, 转录项目开始于性能度量的选择和对这些度量的期望值, 目标, 因为地图只有是高准确率时, 才有用", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "14e7eadf-d8c1-4d91-bec5-122edf82bde5", "label": "摘要5", "info": "在选择量化目标后，我们推荐方法的下一步是要快速建立一个合理的基；准系统。对于视觉任务而言，基准系统是带有整流线性单元的卷积网；络。转录项目开始于一个这样的模型。当时，使用卷积网络输出预测序", "keywords": "准系统, 对于视觉任务而言, 转录项目开始于一个这样的模型, 使用卷积网络输出预测序, 在选择量化目标后", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "ffaec40a-55cc-4374-b567-4194fc3e17a9", "label": "摘要6", "info": "我们建议反复细化这些基准，并测试每个变化是否都有改进。街景转录；系统的第一个变化受激励于覆盖指标的理论理解和数据结构。具体地，；当输出序列的概率低于某个值t即p( y ｜ x )＜t时，网络拒绝为输入 x 分", "keywords": "系统的第一个变化受激励于覆盖指标的理论理解和数据结构, 网络拒绝为输入, 并测试每个变化是否都有改进, 当输出序列的概率低于某个值, 我们建议反复细化这些基准", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "f604f76b-588d-4db0-a88a-662a46aa4cbe", "label": "摘要7", "info": "此时，覆盖仍低于90％，但该方法没有明显的理论问题了。因此，我们；的方法论建议综合训练集和测试集性能，以确定问题是否欠拟合或过拟；合。在这种情况下，训练和测试集误差几乎是一样的。事实上，这个项", "keywords": "训练和测试集误差几乎是一样的, 事实上, 因此, 的方法论建议综合训练集和测试集性能, 在这种情况下", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "369a2b2b-42d5-43c4-81d3-d59f528b6f1b", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的错误。在这种情况下，这意味着可视化不正确而模型给了最高置信度；的训练集转录结果。结果显示，主要是输入图像裁剪得太紧，有些和地", "keywords": "这意味着可视化不正确而模型给了最高置信度, 的错误, 在这种情况下, 有些和地, 主要是输入图像裁剪得太紧", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "1538443e-ead3-4cb3-bd9f-979980b59cfc", "label": "摘要9", "info": "最后，性能提升的最后几个百分点来自调整超参数。这主要包括在保持；一些计算代价限制的同时加大模型的规模。因为训练误差和测试误差保；持几乎相等，所以明确表明性能不足是由欠拟合造成的，数据集本身也", "keywords": "所以明确表明性能不足是由欠拟合造成的, 性能提升的最后几个百分点来自调整超参数, 持几乎相等, 这主要包括在保持, 数据集本身也", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "70b90957-8ed9-4ebb-994c-2a9050efa75e", "label": "摘要10", "info": "总体来说，转录项目是非常成功的，可以比人工速度更快、代价更低地；转录数以亿计的地址。", "keywords": "转录项目是非常成功的, 可以比人工速度更快, 总体来说, 转录数以亿计的地址, 代价更低地", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "d32e11d9-7588-4265-b0aa-7650b6a75289", "label": "摘要11", "info": "我们希望本章中介绍的设计原则能带来其他更多类似的成功。", "keywords": "我们希望本章中介绍的设计原则能带来其他更多类似的成功", "level": 3, "group": "chapter-11", "type": "段落"}, {"id": "3b17aede-7732-46af-9458-e5bb104b5d9f", "label": "第12章：应用", "level": 1, "group": "chapter-12", "type": "章節"}, {"id": "a9a3c265-aedd-469c-8bad-1184eac25c54", "label": "11.6：示例：多位数字识别", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "3eb24b43-cecb-4ca7-a0e9-45e860df6daf", "label": "摘要1", "info": "在本章中，我们将介绍如何使用深度学习来解决计算机视觉、语音识；别、自然语言处理以及其他商业领域中的应用。首先我们将讨论在许多；最重要的AI应用中所需的大规模神经网络的实现。接着，我们将回顾深", "keywords": "我们将介绍如何使用深度学习来解决计算机视觉, 最重要的, 我们将回顾深, 语音识, 接着", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "label": "12.1：大规模深度学习", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "2501e958-dea4-49a2-8d92-e07c5ee3c3fb", "label": "摘要1", "info": "12.1.1　快速的CPU实现", "keywords": "实现, 快速的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6645cf43-f986-43d4-83f3-7e375f917804", "label": "摘要2", "info": "12.1.2　GPU实现", "keywords": "实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b6d6cc5b-1dd7-4274-aa11-2472928966ad", "label": "摘要3", "info": "12.1.3　大规模的分布式实现", "keywords": "大规模的分布式实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8cae0b6a-cc2f-47f6-9cb7-76e651929bb7", "label": "摘要4", "info": "12.1.4　模型压缩", "keywords": "模型压缩", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b4199f77-beb2-441b-a356-6c00943af93c", "label": "摘要5", "info": "12.1.5　动态结构", "keywords": "动态结构", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "46315e26-e8b8-4981-97cd-5a59f2f48708", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；12.1.6　深度网络的专用硬件实现", "keywords": "深度网络的专用硬件实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2953b79c-b8c1-4430-bb14-62005a6e86c0", "label": "摘要7", "info": "深度学习的基本思想基于联结主义：尽管机器学习模型中单个生物性的；神经元或者说是单个特征不是智能的，但是大量的神经元或者特征作用；在一起往往能够表现出智能。我们必须着重强调神经元数量必须很大这", "keywords": "但是大量的神经元或者特征作用, 我们必须着重强调神经元数量必须很大这, 在一起往往能够表现出智能, 神经元或者说是单个特征不是智能的, 尽管机器学习模型中单个生物性的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "370f6838-f0dc-444c-9b86-5d498051f2e3", "label": "摘要8", "info": "个事实。相比20世纪80年代，如今神经网络的精度以及处理任务的复杂；度都有一定提升，其中一个关键的因素就是网络规模的巨大提升。正如；我们在第1.2.3节中看到的一样，在过去的30年内，网络规模是以指数级", "keywords": "我们在第, 个事实, 在过去的, 世纪, 其中一个关键的因素就是网络规模的巨大提升", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "91fc3a21-5394-4877-8412-0d2e673f6db8", "label": "摘要9", "info": "由于规模的大小对于神经网络来说至关重要，因此深度学习需要高性能；的硬件设施和软件实现。", "keywords": "由于规模的大小对于神经网络来说至关重要, 因此深度学习需要高性能, 的硬件设施和软件实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0134f9b7-6574-493d-8f04-6fea77723ecc", "label": "摘要10", "info": "12.1.1　快速的CPU实现", "keywords": "实现, 快速的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "21598b3f-237d-40c4-a97d-0da6b37f2710", "label": "摘要11", "info": "传统的神经网络是用单台机器的CPU来训练的。如今，这种做法通常被；视为是不可取的。现在，我们通常使用GPU或者许多台机器的CPU连接；在一起进行计算。在使用这种昂贵配置之前，为论证CPU无法承担神经", "keywords": "视为是不可取的, 连接, 无法承担神经, 或者许多台机器的, 传统的神经网络是用单台机器的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7b62c179-64d2-496b-a7be-a316cf5cc1bf", "label": "摘要12", "info": "描述如何实现高效的数值CPU代码已经超出了本书的讨论范围，但是我；们在这里还是要强调通过设计一些特定的CPU上的操作可以大大提升效；率。例如，在2011年，最好的CPU在训练神经网络时使用定点运算能够", "keywords": "但是我, 在训练神经网络时使用定点运算能够, 上的操作可以大大提升效, 最好的, 例如", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "50c0ee26-aca2-45c8-8208-04d364021f01", "label": "摘要13", "info": "12.1.2　GPU实现", "keywords": "实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "27bfce55-ec4e-4274-bb61-3b9bcebe2e34", "label": "摘要14", "info": "许多现代神经网络的实现基于图形处理器  （Graphics  Processing  Unit，；GPU）。图形处理器最初是为图形应用而开发的专用硬件组件。视频游；戏系统的消费市场刺激了图形处理硬件的发展。GPU为视频游戏所设计", "keywords": "图形处理器最初是为图形应用而开发的专用硬件组件, 为视频游戏所设计, 戏系统的消费市场刺激了图形处理硬件的发展, 许多现代神经网络的实现基于图形处理器, 视频游", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "986260c4-6537-4686-a55e-0ebd1feb9975", "label": "摘要15", "info": "视频游戏的渲染要求许多操作能够快速并行地执行。环境和角色模型通", "keywords": "环境和角色模型通, 视频游戏的渲染要求许多操作能够快速并行地执行", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d803b778-96e6-42a6-bc57-b475f8db57b4", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；过一系列顶点的3D坐标确定。为了将大量的3D坐标转化为2D显示器上；的坐标，显卡必须并行地对许多顶点执行矩阵乘法与除法。之后，显卡", "keywords": "之后, 的坐标, 显示器上, 坐标转化为, 过一系列顶点的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "36dfe828-c966-4072-b0db-8dc78d3d61d6", "label": "摘要17", "info": "与上述的实时图形算法相比，神经网络算法所需要的性能特性是相同；的。神经网络算法通常涉及大量参数、激活值、梯度值的缓冲区，其中；每个值在每一次训练迭代中都要被完全更新。这些缓冲太大，会超出传", "keywords": "神经网络算法所需要的性能特性是相同, 每个值在每一次训练迭代中都要被完全更新, 神经网络算法通常涉及大量参数, 这些缓冲太大, 其中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "871653cd-7ca1-4ab3-a4a2-0317b2ec4517", "label": "摘要18", "info": "GPU硬件最初专为图形任务而设计。随着时间的推移，GPU也变得更灵；活，允许定制的子程序处理转化顶点坐标或者计算像素颜色的任务。原；则上，GPU不要求这些像素值实际基于渲染任务。只要将计算的输出值", "keywords": "也变得更灵, 硬件最初专为图形任务而设计, 则上, 允许定制的子程序处理转化顶点坐标或者计算像素颜色的任务, 不要求这些像素值实际基于渲染任务", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ebceb7d9-3328-4e97-a497-1d8a73f5a22f", "label": "摘要19", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0ac36377-a9c1-486c-8e88-c906c7532023", "label": "摘要20", "info": "在通用GPU发布以后，使用显卡训练神经网络的热度开始爆炸性地增；长。这种通用GPU可以执行任意的代码，而并非仅仅渲染子程序。；NVIDIA的CUDA编程语言使得我们可以用一种像C一样的语言实现任意", "keywords": "发布以后, 这种通用, 编程语言使得我们可以用一种像, 而并非仅仅渲染子程序, 使用显卡训练神经网络的热度开始爆炸性地增", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "dd7c6265-0ddd-4c12-bb50-83d65fa2371e", "label": "摘要21", "info": "2009b；Ciresan et al. ，2010）。", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9cb4ab11-856e-4f2a-add0-888316829e46", "label": "摘要22", "info": "如何在通用GPU上写高效的代码依然是一个难题。在GPU上获得良好表；现所需的技术与CPU上的技术非常不同。比如说，基于CPU的良好代码；通常被设计为尽可能从高速缓存中读取更多的信息。然而在GPU中，大", "keywords": "上写高效的代码依然是一个难题, 如何在通用, 基于, 比如说, 通常被设计为尽可能从高速缓存中读取更多的信息", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1e939b1a-d818-41f1-9622-03f62f563ef8", "label": "摘要23", "info": "由于实现高效GPU代码的困难性，研究人员应该组织好他们的工作流；程，避免对每一个新的模型或算法都编写新的GPU代码。通常来讲，人；们会选择建立一个包含高效操作（如卷积和矩阵乘法）的软件库解决这", "keywords": "的软件库解决这, 代码的困难性, 由于实现高效, 避免对每一个新的模型或算法都编写新的, 们会选择建立一个包含高效操作", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6a7321ed-1235-4db9-8f0c-39fce9716472", "label": "摘要24", "info": "12.1.3　大规模的分布式实现", "keywords": "大规模的分布式实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2f26bcc5-8436-4b4e-a593-32d8f8dd8aae", "label": "摘要25", "info": "在许多情况下，单个机器的计算资源是有限的。因此，我们希望把训练；或者推断的任务分摊到多个机器上进行。", "keywords": "在许多情况下, 因此, 或者推断的任务分摊到多个机器上进行, 单个机器的计算资源是有限的, 我们希望把训练", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f1db2a02-1d18-43f8-be4c-a4c80eda1959", "label": "摘要26", "info": "分布式的推断是容易实现的，因为每一个输入的样本都可以在单独的机", "keywords": "因为每一个输入的样本都可以在单独的机, 分布式的推断是容易实现的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ca8e096b-b157-44cd-976c-d22387ebce50", "label": "摘要27", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；器上运行。这也被称为数据并行 （data parallelism）。", "keywords": "这也被称为数据并行, 器上运行", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9771647b-62ca-4f8a-9069-0e9cd0ac01b2", "label": "摘要28", "info": "同样地，模型并行  （model  parallelism）也是可行的，其中多个机器共；同运行一个数据点，每一个机器负责模型的一个部分。对于推断和训；练，这都是可行的。", "keywords": "模型并行, 每一个机器负责模型的一个部分, 这都是可行的, 也是可行的, 同样地", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "92501ca1-6b8b-48cc-bf4f-7e5bce6a06ab", "label": "摘要29", "info": "在训练过程中，数据并行从某种程度上来说更加困难。对于随机梯度下；降的单步来说，我们可以增加小批量的大小，但是从优化性能的角度来；说，我们得到的回报通常并不会线性增长。使用多个机器并行地计算多", "keywords": "使用多个机器并行地计算多, 我们得到的回报通常并不会线性增长, 降的单步来说, 我们可以增加小批量的大小, 在训练过程中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ac6bd262-1606-4623-a72e-cf0837d15717", "label": "摘要30", "info": "这个问题可以使用异步随机梯度下降  （Asynchoronous；Stochasitc；Gradient Descent）（Bengio et al. ，2001b；Recht et al. ，2011）解决。", "keywords": "这个问题可以使用异步随机梯度下降, 解决", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "48968f29-ae8f-409e-88c6-e24eba8716a0", "label": "摘要31", "info": "12.1.4　模型压缩", "keywords": "模型压缩", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0f433e34-2608-4b8f-867e-a19ff715feb7", "label": "摘要32", "info": "在许多商业应用的机器学习模型中，一个时间和内存开销较小的推断算；法比一个时间和内存开销较小的训练算法要更为重要。对于那些不需要；个性化设计的应用来说，我们只需要一次性地训练模型，然后它就可以", "keywords": "一个时间和内存开销较小的推断算, 我们只需要一次性地训练模型, 法比一个时间和内存开销较小的训练算法要更为重要, 然后它就可以, 个性化设计的应用来说", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8610a9ff-a92d-4a22-8762-042ae48c8b66", "label": "摘要33", "info": "减少推断所需开销的一个关键策略是模型压缩  （model  compression）；（Buciluă  et  al.  ，2006）。模型压缩的基本思想是用一个更小的模型取；代替原始耗时的模型，从而使得用来存储与评估所需的内存与运行时间", "keywords": "减少推断所需开销的一个关键策略是模型压缩, 模型压缩的基本思想是用一个更小的模型取, 代替原始耗时的模型, 从而使得用来存储与评估所需的内存与运行时间", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1e24eb92-4444-41c6-bc56-b0d847bd1d01", "label": "摘要34", "info": "当原始模型的规模很大，且我们需要防止过拟合时，模型压缩就可以起；到作用。在许多情况下，拥有最小泛化误差的模型往往是多个独立训练；而成的模型的集成。评估所有n个集成成员的成本很高。有时候，当单", "keywords": "当原始模型的规模很大, 而成的模型的集成, 个集成成员的成本很高, 在许多情况下, 模型压缩就可以起", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "62a0385e-ed7f-453b-b49e-2f3afb233b94", "label": "摘要35", "info": "这些巨大的模型能够学习到某个函数f( x )，但选用的参数数量超过了任；务所需的参数数量。只是因为训练样本数是有限的，所以模型的规模才；变得必要。只要我们拟合了这个函数f(  x  )，我们就可以通过将f作用于", "keywords": "我们就可以通过将, 所以模型的规模才, 但选用的参数数量超过了任, 只要我们拟合了这个函数, 这些巨大的模型能够学习到某个函数", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2d3d4e25-b2cd-43de-a8ee-1fb921b4d100", "label": "摘要36", "info": "此外，我们还可以仅在原始训练数据上训练一个更小的模型，但只是为；了复制模型的其他特征，比如在不正确的类上的后验分布（Hinton et al.；，2014，2015）。", "keywords": "但只是为, 了复制模型的其他特征, 此外, 我们还可以仅在原始训练数据上训练一个更小的模型, 比如在不正确的类上的后验分布", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f3cef828-57a8-49a2-98df-0269c03b3ef6", "label": "摘要37", "info": "12.1.5　动态结构", "keywords": "动态结构", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "52cd8cb9-1950-448a-b4e9-e3ae9c4ca1d7", "label": "摘要38", "info": "一般来说，加速数据处理系统的一种策略是构造一个系统，这个系统用；动态结构  （dynamic  structure）描述图中处理输入所需的计算过程。在；给定一个输入的情况中，数据处理系统可以动态地决定运行神经网络系", "keywords": "数据处理系统可以动态地决定运行神经网络系, 给定一个输入的情况中, 描述图中处理输入所需的计算过程, 加速数据处理系统的一种策略是构造一个系统, 这个系统用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "22d2d20e-b15f-4274-9151-2bd4452261b2", "label": "摘要39", "info": "动态结构计算是一种基础的计算机科学方法，广泛应用于软件工程项", "keywords": "广泛应用于软件工程项, 动态结构计算是一种基础的计算机科学方法", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7ed8d4e6-724e-47b3-9744-573f81fd4d5e", "label": "摘要40", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；目。应用于神经网络的最简单的动态结构基于决定神经网络（或者其他；机器学习模型）中的哪些子集需要应用于特定的输入。", "keywords": "机器学习模型, 中的哪些子集需要应用于特定的输入, 或者其他, 应用于神经网络的最简单的动态结构基于决定神经网络", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7cafa3a0-c546-45d1-b260-40f5d7e6ad77", "label": "摘要41", "info": "在分类器中加速推断的可行策略是使用级联  （cascade）的分类器。当；目标是检测罕见对象（或事件）是否存在时，可以应用级联策略。要确；定对象是否存在，我们必须使用具有高容量、运行成本高的复杂分类", "keywords": "我们必须使用具有高容量, 可以应用级联策略, 运行成本高的复杂分类, 或事件, 的分类器", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0f2900f2-b915-42a8-a778-739b41b4c9c9", "label": "摘要42", "info": "决策树本身是动态结构的一个例子，因为树中的每个节点决定应该使用；哪个子树来评估输入。一个结合深度学习和动态结构的简单方法是训练；一个决策树，其中每个节点使用神经网络作出决策（Guo  and  Gelfand，", "keywords": "其中每个节点使用神经网络作出决策, 一个决策树, 哪个子树来评估输入, 决策树本身是动态结构的一个例子, 因为树中的每个节点决定应该使用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b3fde2af-1ca8-480a-a926-04046007f5fe", "label": "摘要43", "info": "类似地，我们可以使用称为选通器  （gater）的神经网络来选择在给定；当前输入的情况下将使用几个专家网络  （expert  network）中的哪一个；来计算输出。这个想法的第一个版本被称为专家混合体  （mixture  of", "keywords": "中的哪一个, 来计算输出, 我们可以使用称为选通器, 的神经网络来选择在给定, 这个想法的第一个版本被称为专家混合体", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "80966402-84d7-43ea-aefa-7f9b86c47158", "label": "摘要44", "info": "专家输出一个概率或权重（通过非线性的softmax函数获得），并且最；终输出由各个专家输出的加权组合获得。在这种情况下，使用选通器不；会降低计算成本，但如果每个样本的选通器选择单个专家，我们就会获", "keywords": "通过非线性的, 并且最, 在这种情况下, 但如果每个样本的选通器选择单个专家, 专家输出一个概率或权重", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b046bc4a-5140-4946-805c-6fe70cea60e5", "label": "摘要45", "info": "另一种动态结构是开关，其中隐藏单元可以根据具体情况从不同单元接；收输入。这种动态路由方法可以理解为注意力机制；（attention", "keywords": "收输入, 这种动态路由方法可以理解为注意力机制, 另一种动态结构是开关, 其中隐藏单元可以根据具体情况从不同单元接", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d8f9db9f-f157-4716-986b-03af31012683", "label": "摘要46", "info": "使用动态结构化系统的主要障碍是由于系统针对不同输入的不同代码分；支导致的并行度降低。这意味着网络中只有很少的操作可以被描述为对；样本小批量的矩阵乘法或批量卷积。我们可以写更多的专用子程序，用", "keywords": "我们可以写更多的专用子程序, 使用动态结构化系统的主要障碍是由于系统针对不同输入的不同代码分, 样本小批量的矩阵乘法或批量卷积, 这意味着网络中只有很少的操作可以被描述为对, 支导致的并行度降低", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3f3e114f-4be7-43eb-91ef-33bf683842bc", "label": "摘要47", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；12.1.6　深度网络的专用硬件实现", "keywords": "深度网络的专用硬件实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9bf48d45-46de-417b-b346-a5dabf66bc2b", "label": "摘要48", "info": "自从早期的神经网络研究以来，硬件设计者就已经致力于可以加速神经；网络算法的训练和/或推断的专用硬件实现。读者可以查看早期的和更；近的专用硬件深度网络的评论（Lindsey and Lindblad，1994；Beiu et al.", "keywords": "网络算法的训练和, 自从早期的神经网络研究以来, 硬件设计者就已经致力于可以加速神经, 或推断的专用硬件实现, 近的专用硬件深度网络的评论", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "757151d2-df3c-4d34-b3a9-2d68f5b2ff4d", "label": "摘要49", "info": "不同形式的专用硬件（Graf and Jackel，1989；Mead and Ismail，2012；；Kim et al. ，2009；Pham et al. ，2012；Chen et al. ，2014b，a）的研究；已经持续了好几十年，比如专用集成电路", "keywords": "的研究, 比如专用集成电路, 已经持续了好几十年, 不同形式的专用硬件", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "abb1f435-dc49-4247-8262-f2f8fc657637", "label": "摘要50", "info": "虽然CPU和GPU上的软件实现通常使用32位或64位的精度来表示浮点；数，但是长期以来使用较低的精度在更短的时间内完成推断也是可行的；（Holt and Baker，1991；Holi and Hwang，1993；Presley and Haggard，", "keywords": "上的软件实现通常使用, 虽然, 位的精度来表示浮点, 但是长期以来使用较低的精度在更短的时间内完成推断也是可行的, 位或", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "fd062895-759d-47b5-ac40-011d2e951209", "label": "摘要51", "info": "最近对基于反向传播神经网络的低精度实现的工作（Vanhoucke et al. ，；2011；Courbariaux et al. ，2015；Gupta et al. ，2015）表明，8位和16位；之间的精度足以满足使用或训练基于反向传播的深度神经网络的要求。", "keywords": "之间的精度足以满足使用或训练基于反向传播的深度神经网络的要求, 最近对基于反向传播神经网络的低精度实现的工作, 位和, 表明", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "de2e8ef5-8e1b-4443-b028-f3f3b3a26cdf", "label": "摘要52", "info": "形式的动态定点表示能够减少每个数需要的存储空间。传统的定点数被；限制在一个固定范围之内（其对应于浮点表示中的给定指数）。而动态；定点表示在一组数字（例如一个层中的所有权重）之间共享该范围。使", "keywords": "之间共享该范围, 形式的动态定点表示能够减少每个数需要的存储空间, 其对应于浮点表示中的给定指数, 限制在一个固定范围之内, 而动态", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d27928b8-c26e-4a5f-810d-9931f1a4f756", "label": "摘要53", "info": "12.1.1　快速的CPU实现", "keywords": "实现, 快速的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0f331c70-af0f-4f86-9141-9e185f291eaf", "label": "摘要54", "info": "12.1.2　GPU实现", "keywords": "实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "34fca34d-9df9-417a-bbc7-9bf985f39428", "label": "摘要55", "info": "12.1.3　大规模的分布式；实现", "keywords": "大规模的分布式, 实现", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "331324af-632a-4248-bf1a-14d524ed3e56", "label": "摘要56", "info": "12.1.4　模型压缩", "keywords": "模型压缩", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "aadd2e86-5525-4ff1-8335-9cdd9775c0bf", "label": "摘要57", "info": "12.1.5　动态结构", "keywords": "动态结构", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f89a48a3-45c2-4498-9c40-6edf86d2bddb", "label": "摘要58", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；12.1.6　深度网络的专用；硬件实现", "keywords": "硬件实现, 深度网络的专用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "label": "12.2：计算机视觉", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "453f2dff-b180-4bb7-8b35-51957d5ca849", "label": "摘要1", "info": "12.2.1　预处理", "keywords": "预处理", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7e966893-2f3f-4df8-a417-7d67c89ae727", "label": "摘要2", "info": "12.2.2　数据集增强", "keywords": "数据集增强", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "eb2de971-b819-4909-9ab9-1c1540936fe4", "label": "摘要3", "info": "长久以来，计算机视觉就是深度学习应用中几个最活跃的研究方向之；一。因为视觉是一个对人类以及许多动物毫不费力，但对计算机却充满；挑战的任务（Ballard  et  al.  ，1983）。深度学习中许多流行的标准基准", "keywords": "长久以来, 但对计算机却充满, 因为视觉是一个对人类以及许多动物毫不费力, 挑战的任务, 深度学习中许多流行的标准基准", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "669df274-0737-4d76-b5f0-acbd781fd72d", "label": "摘要4", "info": "计算机视觉是一个非常广阔的发展领域，其中包括多种多样的处理图片；的方式以及应用方向。计算机视觉的应用广泛：从复现人类视觉能力；（比如识别人脸）到创造全新的视觉能力。举个后者的例子，近期一个", "keywords": "到创造全新的视觉能力, 举个后者的例子, 计算机视觉是一个非常广阔的发展领域, 近期一个, 其中包括多种多样的处理图片", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0361f461-abde-4027-8f54-953ebc63e758", "label": "摘要5", "info": "12.2.1　预处理", "keywords": "预处理", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b530fbba-e6c4-445f-a94b-3fbd60df0032", "label": "摘要6", "info": "由于原始输入往往以深度学习架构难以表示的形式出现，许多应用领域；需要复杂精细的预处理。计算机视觉通常只需要相对少的这种预处理。；图像应该被标准化，从而使得它们的像素都在相同并且合理的范围内，", "keywords": "图像应该被标准化, 需要复杂精细的预处理, 由于原始输入往往以深度学习架构难以表示的形式出现, 计算机视觉通常只需要相对少的这种预处理, 从而使得它们的像素都在相同并且合理的范围内", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "db7b6c3f-05e7-4192-92f1-35edfc9918ca", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图像混合，通常会导致失败。将图像格式化为具有相同的比例，严格上；说是唯一一种必要的预处理。许多计算机视觉架构需要标准尺寸的图", "keywords": "许多计算机视觉架构需要标准尺寸的图, 说是唯一一种必要的预处理, 图像混合, 将图像格式化为具有相同的比例, 严格上", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b73a177d-c1bd-4f17-874a-34ac57dda078", "label": "摘要8", "info": "数据集增强可以被看作一种只对训练集做预处理的方式。数据集增强是；减少大多数计算机视觉模型泛化误差的一种极好方法。在测试时可用的；一个相关想法是将同一输入的许多不同版本传给模型（例如，在稍微不", "keywords": "在稍微不, 在测试时可用的, 减少大多数计算机视觉模型泛化误差的一种极好方法, 数据集增强可以被看作一种只对训练集做预处理的方式, 数据集增强是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4311cce0-3265-45fb-907f-495b89293050", "label": "摘要9", "info": "其他种类的预处理需要同时应用于训练集和测试集，其目的是将每个样；本置于更规范的形式，以便减少模型需要考虑的变化量。减少数据中的；变化量既能够减少泛化误差，也能够减小拟合训练集所需模型的大小。", "keywords": "其他种类的预处理需要同时应用于训练集和测试集, 本置于更规范的形式, 也能够减小拟合训练集所需模型的大小, 变化量既能够减少泛化误差, 减少数据中的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "86e9e588-d33f-46eb-b51a-b45b4bf897df", "label": "摘要10", "info": "12.2.1.1　对比度归一化", "keywords": "对比度归一化", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1f666764-cc06-4b93-8ea2-6da550249644", "label": "摘要11", "info": "在许多任务中，对比度是能够安全移除的最为明显的变化源之一。简单；地说，对比度指的是图像中亮像素和暗像素之间差异的大小。量化图像；对比度有许多方式。在深度学习中，对比度通常指的是图像或图像区域", "keywords": "对比度通常指的是图像或图像区域, 地说, 简单, 对比度是能够安全移除的最为明显的变化源之一, 对比度有许多方式", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9480fb6d-18dc-4265-9979-ae5e84b7c899", "label": "摘要12", "info": "其中X 是整个图片的平均强度，满足", "keywords": "满足, 是整个图片的平均强度, 其中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "508f0f69-9c17-4522-80fa-e40f84b0a848", "label": "摘要13", "info": "全局对比度归一化  （global  contrast  normalization，GCN）旨在通过从；每个图像中减去其平均值，然后重新缩放使其像素上的标准差等于某个；常数s来防止图像具有变化的对比度。这种方法非常复杂，因为没有缩", "keywords": "因为没有缩, 旨在通过从, 每个图像中减去其平均值, 常数, 全局对比度归一化", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "180644d3-0ed4-415d-9448-b5485a5ac746", "label": "摘要14", "info": "从大图像中剪切感兴趣的对象所组成的数据集不可能包含任何强度几乎；恒定的图像。在这些情况下，通过设置λ＝0来忽略小分母问题是安全；的，并且在非常罕见的情况下为了避免除以0，通过将   设置为一个非", "keywords": "恒定的图像, 来忽略小分母问题是安全, 并且在非常罕见的情况下为了避免除以, 通过将, 设置为一个非", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e70ff614-0cf9-4031-902b-f748c00d8823", "label": "摘要15", "info": "尺度参数s通常可以设置为1（如Coates et al. （2011）所采用的），或选；择使所有样本上每个像素的标准差接近1（如Goodfellow；al.", "keywords": "所采用的, 择使所有样本上每个像素的标准差接近, 通常可以设置为, 尺度参数, 或选", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2477d79b-13be-4ebd-8881-457d0cfbc80f", "label": "摘要16", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "96e8db47-0df1-4031-a905-7efabc9593e2", "label": "摘要17", "info": "式（12.3）中的标准差仅仅是对图片L 2 范数的重新缩放（假设图像的平；2  范数来定义；均值已经被移除）。我们更偏向于根据标准差而不是L", "keywords": "中的标准差仅仅是对图片, 我们更偏向于根据标准差而不是, 均值已经被移除, 范数的重新缩放, 假设图像的平", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "91794426-0ba8-4373-8f0f-176cea9b0977", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；GCN，因为标准差包括除以像素数量这一步，从而基于标准差的GCN；能够使用与图像大小无关的固定的s。然而，观察到L  2  范数与标准差成", "keywords": "因为标准差包括除以像素数量这一步, 能够使用与图像大小无关的固定的, 然而, 从而基于标准差的, 观察到", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "98b8c4d7-6ce6-4cc7-ad55-ccb97c5e28ab", "label": "摘要19", "info": "图12.1　 GCN将样本投影到一个球上。（左）原始的输入数据可能拥有任意的范数。（中）λ＝；＝10 -8 。由于我们；0时，GCN可以完美地将所有的非零样本投影到球上。这里我们令s＝1，", "keywords": "原始的输入数据可能拥有任意的范数, 可以完美地将所有的非零样本投影到球上, 将样本投影到一个球上, 由于我们, 这里我们令", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "52d2b874-5215-4a70-ad48-ebad295a6569", "label": "摘要20", "info": "与直觉相反的是，存在被称为sphering  的预处理操作，并且它不同于；GCN。sphering并不会使数据位于球形壳上，而是将主成分重新缩放以；具有相等方差，使得PCA使用的多变量正态分布具有球形等高线。", "keywords": "与直觉相反的是, 并且它不同于, 具有相等方差, 的预处理操作, 而是将主成分重新缩放以", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e1d56df9-5880-48d3-905b-d828718579d3", "label": "摘要21", "info": "全局对比度归一化常常不能突出我们想要突出的图像特征，例如边缘和；角。如果我们有一个场景，包含了一个大的黑暗区域和一个大的明亮区；域（例如一个城市广场有一半的区域处于建筑物的阴影之中），则全局", "keywords": "包含了一个大的黑暗区域和一个大的明亮区, 全局对比度归一化常常不能突出我们想要突出的图像特征, 例如一个城市广场有一半的区域处于建筑物的阴影之中, 如果我们有一个场景, 则全局", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c8ddeedf-02b1-4535-b5f0-c19d789ef6df", "label": "摘要22", "info": "这催生了局部对比度归一化  （local  contrast  normalization，LCN）。局", "keywords": "这催生了局部对比度归一化", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6705feef-d534-4958-93ae-444fee2e207d", "label": "摘要23", "info": "部对比度归一化确保对比度在每个小窗口上被归一化，而不是作为整体；在图像上被归一化。关于局部对比度归一化和全局对比度归一化的比较；可以参考图12.2。", "keywords": "在图像上被归一化, 关于局部对比度归一化和全局对比度归一化的比较, 可以参考图, 而不是作为整体, 部对比度归一化确保对比度在每个小窗口上被归一化", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "50c7c84e-97de-4c0b-a852-0d94aa40f705", "label": "摘要24", "info": "图12.2　全局对比度归一化和局部对比度归一化的比较。直观上说，全局对比度归一化的效果；很巧妙。它使得所有图片的尺度都差不多，这减轻了学习算法处理多个尺度的负担。局部对比；度归一化更多地改变了图像，丢弃了所有相同强度的区域。这使模型能够只关注于边缘。较好", "keywords": "它使得所有图片的尺度都差不多, 这使模型能够只关注于边缘, 丢弃了所有相同强度的区域, 直观上说, 局部对比", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "eccc80a1-b43c-456a-8e45-8cb214c8892b", "label": "摘要25", "info": "局部对比度归一化的各种定义都是可行的。在所有情况下，我们可以通；过减去邻近像素的平均值并除以邻近像素的标准差来修改每个像素。在；一些情况下，要计算以当前要修改的像素为中心的矩形窗口中所有像素", "keywords": "过减去邻近像素的平均值并除以邻近像素的标准差来修改每个像素, 我们可以通, 局部对比度归一化的各种定义都是可行的, 在所有情况下, 要计算以当前要修改的像素为中心的矩形窗口中所有像素", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7fbe1c03-0ec9-49fa-8c1a-81580abaccd5", "label": "摘要26", "info": "局部对比度归一化通常可以通过使用可分离卷积（参考第9.8节）来计；算特征映射的局部平均值和局部标准差，然后在不同的特征映射上使用；逐元素的减法和除法。", "keywords": "逐元素的减法和除法, 参考第, 算特征映射的局部平均值和局部标准差, 然后在不同的特征映射上使用, 局部对比度归一化通常可以通过使用可分离卷积", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "849fc0ac-e1b9-4add-887d-4eeecc303aa6", "label": "摘要27", "info": "局部对比度归一化是可微分的操作，并且还可以作为一种非线性作用应；用于网络隐藏层，以及应用于输入的预处理操作。", "keywords": "并且还可以作为一种非线性作用应, 用于网络隐藏层, 以及应用于输入的预处理操作, 局部对比度归一化是可微分的操作", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a1bb57d8-8199-4c2a-b7b2-41cd9b9e70fd", "label": "摘要28", "info": "与全局对比度归一化一样，我们通常需要正则化局部对比度归一化来避；免出现除以零的情况。事实上，因为局部对比度归一化通常作用于较小", "keywords": "免出现除以零的情况, 事实上, 我们通常需要正则化局部对比度归一化来避, 因为局部对比度归一化通常作用于较小, 与全局对比度归一化一样", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9c5a7389-3043-4bdd-be18-31c27bf2e217", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的窗口，所以正则化更加重要。较小的窗口更可能包含彼此几乎相同的；值，因此更可能具有零标准差。", "keywords": "较小的窗口更可能包含彼此几乎相同的, 因此更可能具有零标准差, 所以正则化更加重要, 的窗口", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0721539d-395a-47c5-abb5-cedbcf748caf", "label": "摘要30", "info": "12.2.2　数据集增强", "keywords": "数据集增强", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d81006bc-aa65-4d6a-9fae-ac08f074fe95", "label": "摘要31", "info": "如第7.4节中讲到的一样，我们很容易通过增加训练集的额外副本来增；加训练集的大小，进而改进分类器的泛化能力。这些额外副本可以通过；对原始图像进行一些变化来生成，但是并不改变其类别。对象识别这个", "keywords": "进而改进分类器的泛化能力, 但是并不改变其类别, 加训练集的大小, 对原始图像进行一些变化来生成, 我们很容易通过增加训练集的额外副本来增", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "abea3476-2954-4eff-b189-3f2775c28d7d", "label": "摘要32", "info": "12.2.1　预处理", "keywords": "预处理", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "95a13075-ef52-4d89-bdaf-f464ba234312", "label": "摘要33", "info": "12.2.2　数据集增强", "keywords": "数据集增强", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f0301b62-1763-4765-9bac-b86eafc0191d", "label": "12.3：语音识别", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "84f282f1-b66c-476f-b3d4-42a3216d0853", "label": "摘要1", "info": "语音识别任务是将一段包括了自然语言发音的声学信号投影到对应说话；人的词序列上。令 X ＝( x (1) , x (2) ,…, x (T) )表示语音的输入向量（传统；做法以20ms为一帧分割信号）。许多语音识别的系统通过特殊的手工设", "keywords": "表示语音的输入向量, 语音识别任务是将一段包括了自然语言发音的声学信号投影到对应说话, 为一帧分割信号, 传统, 许多语音识别的系统通过特殊的手工设", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3f607ac0-318c-40f7-9584-2679f0487844", "label": "摘要2", "info": "recognition，ASR）任务指的是构造一个函数；，使得它能够在给定声学序列 X 的情况下计算最有可能的语言序", "keywords": "的情况下计算最有可能的语言序, 任务指的是构造一个函数, 使得它能够在给定声学序列", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "643e6d31-1fa3-44a4-b046-21aedd035e64", "label": "摘要3", "info": "列 y ：", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "dc7319c4-8e38-4fc4-af23-8845ad8b8114", "label": "摘要4", "info": "其中P * 是给定输入值 X 时对应目标 y 的真实条件分布。", "keywords": "时对应目标, 其中, 是给定输入值, 的真实条件分布", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0cbf0637-9cac-47f5-8cc7-cbc783b7bdc5", "label": "摘要5", "info": "从20世纪80年代直到2009～2012年，最先进的语音识别系统是隐马尔可；夫模型  （hidden  markov  model，HMM）和高斯混合模型  （gaussian；mixture  model，GMM）的结合。GMM对声学特征和音素  （phoneme）", "keywords": "的结合, 对声学特征和音素, 世纪, 夫模型, 最先进的语音识别系统是隐马尔可", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e30a4081-ce07-4f24-8ed1-8ccf9d4f675d", "label": "摘要6", "info": "HMM模型将语音信号视作由如下过程生成：首先，一个HMM生成了一；个音素的序列以及离散的子音素状态（比如每一个音素的开始、中间、；结尾），然后GMM把每一个离散的状态转化为一个简短的声音信号。", "keywords": "把每一个离散的状态转化为一个简短的声音信号, 个音素的序列以及离散的子音素状态, 模型将语音信号视作由如下过程生成, 比如每一个音素的开始, 中间", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "08876ad2-e02f-48b2-8790-ab7fcda03b6a", "label": "摘要7", "info": "之后，随着更大更深的模型以及更大的数据集的出现，通过使用神经网；络代替GMM来实现将声学特征转化为音素（或者子音素状态）的过程；可以大大地提高识别的精度。从2009年开始，语音识别的研究者们将一", "keywords": "之后, 的过程, 络代替, 通过使用神经网, 或者子音素状态", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "06c60be8-14e5-463c-82ba-8b7a61ecc21d", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；发展到了使用诸如整流线性单元和Dropout这样的技术（Zeiler  et  al.  ，；2013；Dahl  et  al.  ，2013）。从那时开始，工业界的几个语音研究组开", "keywords": "从那时开始, 发展到了使用诸如整流线性单元和, 这样的技术, 工业界的几个语音研究组开", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9d691697-e5b7-4337-af20-40a10e3de1c9", "label": "摘要9", "info": "随后，当研究组使用了越来越大的带标签的数据集，加入了各种初始；化、训练方法以及调试深度神经网络的结构之后，他们发现这种无监督；的预训练方式是没有必要的，或者说不能带来任何显著的改进。", "keywords": "当研究组使用了越来越大的带标签的数据集, 加入了各种初始, 随后, 或者说不能带来任何显著的改进, 的预训练方式是没有必要的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "548fde31-58f9-4fed-a53f-b9f7c09cf973", "label": "摘要10", "info": "用语音识别中词错误率来衡量，在语音识别性能上的这些突破是史无前；例的（大约30％的提高）。在这之前的长达十年左右的时间内，尽管数；据集的规模是随时间增长的（见Deng  and  Yu（2014）的图2.4），但基", "keywords": "但基, 据集的规模是随时间增长的, 例的, 尽管数, 在这之前的长达十年左右的时间内", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8adb2128-e935-4cee-82bf-0df3363e9ad9", "label": "摘要11", "info": "其中的一个创新点是卷积网络的应用（Sainath  et  al.  ，2013）。卷积网；络在时域与频域上复用了权重，改进了之前的仅在时域上使用重复权值；的时延神经网络。这种新的二维卷积模型并不是将输入的频谱当作一个", "keywords": "其中的一个创新点是卷积网络的应用, 的时延神经网络, 这种新的二维卷积模型并不是将输入的频谱当作一个, 卷积网, 改进了之前的仅在时域上使用重复权值", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9c708d73-6798-4404-8094-115ce579a2c9", "label": "摘要12", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1664c124-7853-48fd-b3cc-28c2483d09ed", "label": "摘要13", "info": "完全抛弃HMM并转向研究端到端的深度学习语音识别系统是至今仍然；活跃的另一个重要推动。这个领域第一个主要突破是Graves；（2013），他训练了一个深度的长短期记忆循环神经网络（见第10.10", "keywords": "活跃的另一个重要推动, 这个领域第一个主要突破是, 完全抛弃, 他训练了一个深度的长短期记忆循环神经网络, 并转向研究端到端的深度学习语音识别系统是至今仍然", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1a35d2c5-e61b-4dd2-93e2-e1d4a539fd02", "label": "摘要14", "info": "al.", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "768c2170-7b59-489d-9f43-6389430c7ab5", "label": "摘要15", "info": "另一个端到端深度学习语音识别方向的最新方法是，让系统学习如何利；用语音（phonetic）层级的信息“排列”声学；（acoustic）层级的信息", "keywords": "层级的信息, 让系统学习如何利, 声学, 另一个端到端深度学习语音识别方向的最新方法是, 排列", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "495ceafe-4a02-45e2-b8bc-c0088a7b2e6c", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；12.4　自然语言处理", "keywords": "自然语言处理", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "87a80d84-6f1e-4a15-8109-b73874637be4", "label": "摘要17", "info": "自然语言处理  （natural  language  processing，NLP）是让计算机能够使；用人类语言，例如英语或法语。为了让简单的程序能够高效明确地解；析，计算机程序通常读取和发出特殊化的语言。而自然语言通常是模糊", "keywords": "是让计算机能够使, 自然语言处理, 例如英语或法语, 为了让简单的程序能够高效明确地解, 计算机程序通常读取和发出特殊化的语言", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ff66aaa1-631d-4983-af70-3b6533dc9c8b", "label": "摘要18", "info": "与本章讨论的其他应用一样，非常通用的神经网络技术可以成功地应用；于自然语言处理。然而，为了实现卓越的性能并扩展到大型应用程序，；一些领域特定的策略也很重要。为了构建自然语言的有效模型，通常必", "keywords": "与本章讨论的其他应用一样, 为了实现卓越的性能并扩展到大型应用程序, 通常必, 为了构建自然语言的有效模型, 然而", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8b66c8d1-9983-4e32-9096-d29fd9e7396a", "label": "摘要19", "info": "12.4.1　n-gram", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3200c3b3-2e65-4c31-8578-60138c0d187e", "label": "摘要20", "info": "语言模型  （language  model）定义了自然语言中标记序列的概率分布。；根据模型的设计，标记可以是词、字符甚至是字节。标记总是离散的实；体。最早成功的语言模型基于固定长度序列的标记模型，称为n-gram。", "keywords": "标记总是离散的实, 称为, 标记可以是词, 字符甚至是字节, 最早成功的语言模型基于固定长度序列的标记模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "dcc466c5-7b6b-4652-b356-ac98b98f7772", "label": "摘要21", "info": "基于n-gram的模型定义一个条件概率——给定前n-1个标记后的第n个标；记的条件概率。该模型使用这些条件分布的乘积定义较长序列的概率分；布：", "keywords": "给定前, 的模型定义一个条件概率, 个标, 记的条件概率, 该模型使用这些条件分布的乘积定义较长序列的概率分", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c292d517-7497-4f21-9bd7-858ad3009876", "label": "摘要22", "info": "这个分解可以由概率的链式法则证明。初始序列P(x 1 ,…,x  n-1 )的概率分；布可以通过带有较小n值的不同模型建模。", "keywords": "初始序列, 这个分解可以由概率的链式法则证明, 的概率分, 值的不同模型建模, 布可以通过带有较小", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f951627c-3d35-417e-b762-1f76123b6128", "label": "摘要23", "info": "训练n-gram模型是简单的，因为最大似然估计可以通过简单地统计每个；可能的n-gram在训练集中出现的次数来获得。几十年来，基于n-gram的；模型都是统计语言模型的核心模块（Jelinek  and  Mercer，1980；Katz，", "keywords": "训练, 在训练集中出现的次数来获得, 模型都是统计语言模型的核心模块, 可能的, 基于", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "39686b63-d8c1-463b-979a-aa1e51de9f3d", "label": "摘要24", "info": "对于小的n值，模型有特定的名称：n＝1称为一元语法  （unigram），n；＝2称为二元语法 （bigram），n＝3称为三元语法  （trigram）。这些名；称源于相应数字的拉丁前缀和希腊后缀“-gram”，分别表示所写之物。", "keywords": "分别表示所写之物, 称为三元语法, 模型有特定的名称, 称为二元语法, 对于小的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d0922492-e3a6-43de-bb0f-d5774c577b1f", "label": "摘要25", "info": "通常我们同时训练n-gram模型和n-1  gram模型。这使得下式可以简单地；通过查找两个存储的概率来计算。", "keywords": "这使得下式可以简单地, 通常我们同时训练, 模型, 通过查找两个存储的概率来计算, 模型和", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "eac920e1-3b2b-4693-8713-93dd2bd33ced", "label": "摘要26", "info": "为了在P  n  中精确地再现推断，我们训练P  n-1  时必须省略每个序列最后；一个字符。", "keywords": "一个字符, 为了在, 时必须省略每个序列最后, 中精确地再现推断, 我们训练", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e850d737-5c9f-41a5-92ce-e3c155166da4", "label": "摘要27", "info": "举个例子，我们演示三元模型如何计算句子“THE DOG RAN AWAY．；”的概率。句子的第一个词不能通过上述条件概率的公式计算，因为句；子的开头没有上下文。取而代之，在句子的开头我们必须使用词的边缘", "keywords": "取而代之, 在句子的开头我们必须使用词的边缘, 因为句, 举个例子, 句子的第一个词不能通过上述条件概率的公式计算", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "027e4a1f-7dd5-44ff-94e2-2c6165791dee", "label": "摘要28", "info": "n-gram模型最大似然的基本限制是，在许多情况下从训练集计数估计得；到的P n 很可能为零（即使元组(x t-n+1 ,…,x t )可能出现在测试集中）。这；可能会导致两种不同的灾难性后果。当P  n-1  为零时，该比率是未定义", "keywords": "模型最大似然的基本限制是, 到的, 该比率是未定义, 可能会导致两种不同的灾难性后果, 很可能为零", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7567685b-43b7-4dd4-921a-33575646d016", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；先验的贝叶斯推断。另一个非常流行的想法是包含高阶和低阶n-gram模；型的混合模型，其中高阶模型提供更多的容量，而低阶模型尽可能地避", "keywords": "先验的贝叶斯推断, 其中高阶模型提供更多的容量, 型的混合模型, 而低阶模型尽可能地避, 另一个非常流行的想法是包含高阶和低阶", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0ed6bbc7-607c-428f-ac0c-fde47894e706", "label": "摘要30", "info": "经典的n-gram模型特别容易引起维数灾难。因为存在；可能的n-；gram，而且   通常很大。即使有大量训练数据和适当的n，大多数n-", "keywords": "即使有大量训练数据和适当的, 因为存在, 大多数, 而且, 模型特别容易引起维数灾难", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "fece62d5-2318-403d-9cca-f2f3c90c4d03", "label": "摘要31", "info": "为了提高n-gram模型的统计效率，基于类的语言模型；（class-based；language model）（Brown et al. ，1992；Ney and Kneser，1993；Niesler", "keywords": "基于类的语言模型, 为了提高, 模型的统计效率", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "aaffbb17-761c-4b4c-b356-bc15fa24ca5b", "label": "摘要32", "info": "12.4.2　神经语言模型", "keywords": "神经语言模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c30629ff-ce0c-46d6-943b-91072c1ad9a3", "label": "摘要33", "info": "神经语言模型  （neural  language  model，NLM）是一类用来克服维数灾；难的语言模型，它使用词的分布式表示对自然语言序列建模（Bengio  et；al.  ，2001b）。不同于基于类的n-gram模型，神经语言模型在能够识别", "keywords": "它使用词的分布式表示对自然语言序列建模, 是一类用来克服维数灾, 神经语言模型在能够识别, 神经语言模型, 模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0cd1d35f-c88d-430e-9439-07f6ad59faaf", "label": "摘要34", "info": "性的表示，则包含词cat  的句子可以告知模型对包含词dog  的句子做出；预测，反之亦然。因为这样的属性很多，所以存在许多泛化的方式，可；以将信息从每个训练语句传递到指数数量的语义相关语句。维数灾难需", "keywords": "维数灾难需, 反之亦然, 的句子做出, 性的表示, 因为这样的属性很多", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6cb32279-4c31-42f8-a6f4-2bcc0feb942e", "label": "摘要35", "info": "我们有时将这些词表示称为词嵌入  （word  embedding）。在这个解释；下，我们将原始符号视为维度等于词表大小的空间中的点。词表示将这；些点嵌入到较低维的特征空间中。在原始空间中，每个词由一个one-hot", "keywords": "在这个解释, 我们有时将这些词表示称为词嵌入, 些点嵌入到较低维的特征空间中, 词表示将这, 在原始空间中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7dc2f734-63f0-4a64-a747-9602587eeef2", "label": "摘要36", "info": "图12.3　从神经机器翻译模型获得的词嵌入的二维可视化（Bahdanau et al. ，2015）。此图在语；义相关词的特定区域放大，它们具有彼此接近的嵌入向量。国家在左图，数字在右图。注意，；这些嵌入是为了可视化才表示为二维。在实际应用中，嵌入通常具有更高的维度并且可以同时", "keywords": "从神经机器翻译模型获得的词嵌入的二维可视化, 数字在右图, 嵌入通常具有更高的维度并且可以同时, 注意, 在实际应用中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a9076d16-1659-408f-b14d-6ce45eafc941", "label": "摘要37", "info": "其他领域的神经网络也可以定义嵌入。例如，卷积网络的隐藏层提；供“图像嵌入”。因为自然语言最初不在实值向量空间上，所以NLP从业；者通常对嵌入的这个想法更感兴趣。隐藏层在表示数据的方式上提供了", "keywords": "其他领域的神经网络也可以定义嵌入, 例如, 从业, 者通常对嵌入的这个想法更感兴趣, 所以", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e439d57c-e7ba-471d-bd22-f6c5f7a84c29", "label": "摘要38", "info": "使用分布式表示来改进自然语言处理模型的基本思想不必局限于神经网；络。它还可以用于图模型，其中分布式表示是多个潜变量的形式（Mnih", "keywords": "它还可以用于图模型, 其中分布式表示是多个潜变量的形式, 使用分布式表示来改进自然语言处理模型的基本思想不必局限于神经网", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e7a82ba6-0661-4de6-a623-3c3d39e4a5f1", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；and Hinton，2007）。", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "902f4ed4-bb10-40c6-a4a1-fa7bf7bd2075", "label": "摘要40", "info": "12.4.3　高维输出", "keywords": "高维输出", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "28b5f0e8-5cb8-4499-b93b-f2af5f3490a0", "label": "摘要41", "info": "在许多自然语言应用中，通常希望我们的模型产生词（而不是字符）作；为输出的基本单位。对于大词汇表，由于词汇量很大，在词的选择上表；示输出分布的计算成本可能非常高。在许多应用中，   包含数十万", "keywords": "为输出的基本单位, 示输出分布的计算成本可能非常高, 对于大词汇表, 而不是字符, 包含数十万", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1d7942cb-6d6f-4156-87b4-e998dd82eab5", "label": "摘要42", "info": "假设 h 是用于预测输出概率  的顶部隐藏层。如果我们使用学到的权重；W  和学到的偏置 b  参数化从  h  到   的变换，则仿射softmax输出层执行；以下计算：", "keywords": "如果我们使用学到的权重, 是用于预测输出概率, 输出层执行, 和学到的偏置, 的顶部隐藏层", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d8396137-f0d3-4a33-9707-ac8f7b94ea4f", "label": "摘要43", "info": "。在n  h  为数千；如果 h 包含n h 个元素，则上述操作复杂度是；和  数十万的情况下，这个操作占据了神经语言模型的大多数计算。", "keywords": "如果, 则上述操作复杂度是, 包含, 数十万的情况下, 这个操作占据了神经语言模型的大多数计算", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "059a4928-aa0c-4cc9-90b8-531f81175794", "label": "摘要44", "info": "12.4.3.1　使用短列表", "keywords": "使用短列表", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ba58c9d7-b4a0-446a-9423-2c4566f84e19", "label": "摘要45", "info": "第一个神经语言模型（Bengio et al. ，2001b，2003）通过将词汇量限制；为10  000或20  000来减轻大词汇表上softmax的高成本。Schwenk  and；Gauvain（2002）和Schwenk（2007）在这种方法的基础上建立新的方", "keywords": "的高成本, 来减轻大词汇表上, 在这种方法的基础上建立新的方, 第一个神经语言模型, 通过将词汇量限制", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7eacb75a-d264-4547-ab7b-410289b22eb5", "label": "摘要46", "info": "分为最常见词汇（由神经网络处理）的短列表；式，将词汇表；（shortlist）   和较稀有词汇的尾列表", "keywords": "和较稀有词汇的尾列表, 分为最常见词汇, 将词汇表, 由神经网络处理, 的短列表", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9cf4131e-296a-46d3-9d4b-3eacf2b4a11e", "label": "摘要47", "info": "实现这个预测。额外输出则可以用来估计   中所有词", "keywords": "额外输出则可以用来估计, 实现这个预测, 中所有词", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "22dec105-c707-4d65-8076-4e9ae232107d", "label": "摘要48", "info": "的概率分布，如下：", "keywords": "的概率分布, 如下", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d46d400d-937a-47e5-9072-f7bb94b1d9cf", "label": "摘要49", "info": "其中；由n-gram模型提供。稍作修改，这种方法也可以在神经语言模型模型的；softmax层中使用额外的输出值，而不是单独的sigmoid单元。", "keywords": "稍作修改, 这种方法也可以在神经语言模型模型的, 模型提供, 其中, 层中使用额外的输出值", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e0cee287-d656-49e0-bf14-4e27ee7a0455", "label": "摘要50", "info": "由神经语言模型提供", "keywords": "由神经语言模型提供", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "faa7dd00-0503-4e23-8aa3-5e98c6a444d9", "label": "摘要51", "info": "短列表方法的一个明显缺点是，神经语言模型的潜在泛化优势仅限于最；常用的词，这大概是最没用的。这个缺点引发了处理高维输出替代方法；的探索，如下所述。", "keywords": "的探索, 短列表方法的一个明显缺点是, 如下所述, 神经语言模型的潜在泛化优势仅限于最, 这个缺点引发了处理高维输出替代方法", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "59ed7c79-8d66-4559-8e0b-8d41198354f3", "label": "摘要52", "info": "12.4.3.2　分层Softmax", "keywords": "分层", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "db121a84-5e79-4417-b0c9-7be7f412b289", "label": "摘要53", "info": "上高维输出层计算负担的经典方法（Goodman，；减少大词汇表；一样低，而无须", "keywords": "一样低, 上高维输出层计算负担的经典方法, 减少大词汇表, 而无须", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "80f39b90-0f63-4f58-a9a8-361bc7aea532", "label": "摘要54", "info": "我们可以认为这种层次结构是先建立词的类别，然后是词类别的类别，；然后是词类别的类别的类别等。这些嵌套类别构成一棵树，其叶子为；词。在平衡树中，树的深度为log", "keywords": "其叶子为, 然后是词类别的类别, 我们可以认为这种层次结构是先建立词的类别, 这些嵌套类别构成一棵树, 树的深度为", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9de13580-6b44-4a5c-8496-1422d5fe785d", "label": "摘要55", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图12.4　词类别简单层次结构的示意图，其中8个词w 0 ,…,w 7 组织成三级层次结构。树的叶子；表示实际特定的词。内部节点表示词的组别。任何节点都可以通过二值决策序列（0＝左，1＝", "keywords": "个词, 任何节点都可以通过二值决策序列, 树的叶子, 内部节点表示词的组别, 其中", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "166e22a8-6373-42c5-b25d-e2b7e6c5a1b7", "label": "摘要56", "info": "次操作（从根开始的路径上的每个节点一次操作）。在该", "keywords": "次操作, 在该, 从根开始的路径上的每个节点一次操作", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ef967c9e-fa4d-43f0-aa16-615d397892f4", "label": "摘要57", "info": "的对数同阶：从", "keywords": "的对数同阶", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2c4e8e26-1ca1-41d1-994c-d0d07e0789e0", "label": "摘要58", "info": "为了预测树的每个节点所需的条件概率，我们通常在树的每个节点处使；用逻辑回归模型，并且为所有这些模型提供与输入相同的上下文C。因；为正确的输出编码在训练集中，我们可以使用监督学习训练逻辑回归模", "keywords": "我们可以使用监督学习训练逻辑回归模, 为了预测树的每个节点所需的条件概率, 用逻辑回归模型, 为正确的输出编码在训练集中, 我们通常在树的每个节点处使", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1315ef38-4465-4cfd-bdca-d252ce73d2b8", "label": "摘要59", "info": "因为可以高效地计算输出对数似然（低至log", "keywords": "低至, 因为可以高效地计算输出对数似然", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "92868e96-bdf8-4565-815a-2fddb4060704", "label": "摘要60", "info": "而不是  ），所以也", "keywords": "所以也, 而不是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "42274555-8d8a-4ef9-ac9c-d4e03df6c293", "label": "摘要61", "info": "可以高效地计算梯度。这不仅包括关于输出参数的梯度，而且还包括关；于隐藏层激活的梯度。", "keywords": "可以高效地计算梯度, 于隐藏层激活的梯度, 这不仅包括关于输出参数的梯度, 而且还包括关", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "cc30a13c-07b8-4cde-9e1b-dd7769c5d59e", "label": "摘要62", "info": "优化树结构最小化期望的计算数量是可能的，但通常不切实际。给定词；的相对频率，信息理论的工具可以指定如何选择最佳的二进制编码。为；此，我们可以构造树，使得与词相关联的位数量近似等于该词频率的对", "keywords": "的相对频率, 优化树结构最小化期望的计算数量是可能的, 给定词, 信息理论的工具可以指定如何选择最佳的二进制编码, 但通常不切实际", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c1902fdc-cce3-448d-bd5d-5093ab1ed16d", "label": "摘要63", "info": "，而输出计算增长为O(n h n b )。只要n b ≤ln h ，我们可以通过收；缩n h 比收缩n b 减少更多的计算量。事实上，n  b  通常很小。因为词汇表；的大小很少超过一百万，而", "keywords": "通常很小, 事实上, 的大小很少超过一百万, 而输出计算增长为, 比收缩", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "da9462fe-fcc6-4b27-a9e2-0d6c290cffdd", "label": "摘要64", "info": "一个仍然有点开放的问题是如何最好地定义这些词类，或者如何定义一；般的词层次结构。早期工作使用现有的层次结构（Morin  and  Bengio，；2005），但也可以理想地与神经语言模型联合学习层次结构。学习层次", "keywords": "但也可以理想地与神经语言模型联合学习层次结构, 或者如何定义一, 学习层次, 早期工作使用现有的层次结构, 一个仍然有点开放的问题是如何最好地定义这些词类", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "79816a8f-7f8a-4931-a31f-b752b98ae5d4", "label": "摘要65", "info": "分层softmax的一个重要优点是，它在训练期间和测试期间（如果在测；试时我们想计算特定词的概率）都带来了计算上的好处。", "keywords": "的一个重要优点是, 都带来了计算上的好处, 分层, 它在训练期间和测试期间, 如果在测", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "bf63c2ca-ec5a-476f-85bf-1c5b3b94613c", "label": "摘要66", "info": "当然即使使用分层softmax，计算所有  个词概率的成本仍是很高的。；另一个重要的操作是在给定上下文中选择最可能的词。不幸的是，树结；构不能为这个问题提供高效精确的解决方案。", "keywords": "另一个重要的操作是在给定上下文中选择最可能的词, 树结, 构不能为这个问题提供高效精确的解决方案, 个词概率的成本仍是很高的, 不幸的是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "92589ae3-9cf0-44ec-aa32-d734dfecbd8b", "label": "摘要67", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；其缺点是在实践中，分层softmax倾向于更差的测试结果（相对基于采；样的方法），我们将在下文描述。这可能是因为词类选择得不好。", "keywords": "我们将在下文描述, 倾向于更差的测试结果, 样的方法, 分层, 相对基于采", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "71695424-1863-449e-94f5-2f3b4033be2a", "label": "摘要68", "info": "12.4.3.3　重要采样", "keywords": "重要采样", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e2415ff5-51e4-42a8-b9fc-6b63809eb1cd", "label": "摘要69", "info": "加速神经语言模型训练的一种方式是，避免明确地计算所有未出现在下；一位置的词对梯度的贡献。每个不正确的词在此模型下具有低概率。枚；举所有这些词的计算成本可能会很高。相反，我们可以仅采样词的子", "keywords": "加速神经语言模型训练的一种方式是, 避免明确地计算所有未出现在下, 举所有这些词的计算成本可能会很高, 我们可以仅采样词的子, 每个不正确的词在此模型下具有低概率", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "581602a1-52b9-432e-b0ac-cfe1c218c114", "label": "摘要70", "info": "phase）项，推动a", "keywords": "推动", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "432b9f63-d434-4d96-a9df-e94007e2321b", "label": "摘要71", "info": "其中  a  是presoftmax激活（或得分）向量，每个词对应一个元素。第一；y  向上；而第二项是负相；项是正相  （positive", "keywords": "向上, 而第二项是负相, 或得分, 第一, 激活", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "5e11aa4e-ba83-4549-8bb9-0387058c03e7", "label": "摘要72", "info": "and", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "89634f5c-4243-4bad-a73f-e817d09716b1", "label": "摘要73", "info": "我们可以从另一个分布中采样，而不是从模型中采样，这个分布称为提；议分布 （proposal distribution）（记为q），并通过适当的权重校正从错；误分布采样引入的偏差（Bengio", "keywords": "记为, 议分布, 这个分布称为提, 我们可以从另一个分布中采样, 并通过适当的权重校正从错", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "25eb8fdd-d977-4165-bfc2-41f0c59b3c85", "label": "摘要74", "info": "Sénécal，2003；Bengio", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a635b459-a100-4d1c-9e9f-b0d1d1f9a3c2", "label": "摘要75", "info": "这些权重用于对来自q的m个负样本给出适当的重要性，以形成负相估；计对梯度的贡献：", "keywords": "个负样本给出适当的重要性, 计对梯度的贡献, 以形成负相估, 这些权重用于对来自", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "5c28a17e-01d1-476a-892b-c0a451a9c5aa", "label": "摘要76", "info": "一元语法或二元语法分布与提议分布q工作得一样好。从数据估计这种；分布的参数是很容易。在估计参数之后，也可以非常高效地从这样的分；布采样。", "keywords": "一元语法或二元语法分布与提议分布, 也可以非常高效地从这样的分, 布采样, 从数据估计这种, 分布的参数是很容易", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a8128647-becf-43e3-a1c4-2991538f152a", "label": "摘要77", "info": "重要采样 （Importance Sampling）不仅可以加速具有较大softmax输出的；模型。更一般地，它可以加速具有大稀疏输出层的训练，其中输出是稀；疏向量而不是n选1。其中一个例子是词袋  （bag  of  words）。词袋具有", "keywords": "其中一个例子是词袋, 疏向量而不是, 更一般地, 不仅可以加速具有较大, 它可以加速具有大稀疏输出层的训练", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "176c0c1e-e2e9-486a-854a-c47451fc8d92", "label": "摘要78", "info": "在所有这些情况下，输出层梯度估计的计算复杂度被减少为与负样本数；量成比例，而不是与输出向量的大小成比例。", "keywords": "输出层梯度估计的计算复杂度被减少为与负样本数, 量成比例, 在所有这些情况下, 而不是与输出向量的大小成比例", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "206d3d56-7624-4463-86c4-b041dd69bd6b", "label": "摘要79", "info": "12.4.3.4　噪声对比估计和排名损失", "keywords": "噪声对比估计和排名损失", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2c907a23-1a11-45be-92fd-c839757efc1c", "label": "摘要80", "info": "为减少训练大词汇表的神经语言模型的计算成本，研究者也提出了其他；基于采样的方法。早期的例子是Collobert  and  Weston（2008a）提出的；排名损失，将神经语言模型每个词的输出视为一个得分，并试图使正确", "keywords": "将神经语言模型每个词的输出视为一个得分, 基于采样的方法, 研究者也提出了其他, 排名损失, 早期的例子是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "44c36d71-b761-4eda-8d19-2f088c75d4fc", "label": "摘要81", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；词的得分a y 比其他词a i 排名更高。提出的排名损失则是", "keywords": "比其他词, 排名更高, 提出的排名损失则是, 词的得分", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "75850b40-0e96-4e20-b17e-81167472d91e", "label": "摘要82", "info": "如果观察到词的得分a y 远超过负词的得分a i （相差大于1），则第i项梯；度为零。这个准则的一个问题是它不提供估计的条件概率，条件概率在；很多应用中是有用的，包括语音识别和文本生成（包括诸如翻译的条件", "keywords": "则第, 项梯, 度为零, 包括语音识别和文本生成, 相差大于", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "19774c11-5644-40c2-be61-46dab244ca27", "label": "摘要83", "info": "最近用于神经语言模型的训练目标是噪声对比估计，将在第18.6节中介；绍。这种方法已成功应用于神经语言模型（Mnih  and  Teh，2012；Mnih；and Kavukcuoglu，2013）。", "keywords": "将在第, 这种方法已成功应用于神经语言模型, 节中介, 最近用于神经语言模型的训练目标是噪声对比估计", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "dfb80145-423e-46cb-9bd2-9290c56ff844", "label": "摘要84", "info": "12.4.4　结合n-gram和神经语言模型", "keywords": "和神经语言模型, 结合", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7603f833-395a-467a-b756-7db8f38fdc09", "label": "摘要85", "info": "n-gram模型相对神经网络的主要优点是n-gram模型具有更高的模型容量；（通过存储非常多的元组的频率），并且处理样本只需非常少的计算量；（通过查找只匹配当前上下文的几个元组）。如果我们使用哈希表或树", "keywords": "模型相对神经网络的主要优点是, 并且处理样本只需非常少的计算量, 模型具有更高的模型容量, 通过查找只匹配当前上下文的几个元组, 如果我们使用哈希表或树", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d5e08240-b7e3-4a93-af37-faf531c4cc09", "label": "摘要86", "info": "因此，增加容量的一种简单方法是将两种方法结合，由神经语言模型和；n-gram语言模型组成集成（Bengio et al. ，2001b，2003）。", "keywords": "由神经语言模型和, 因此, 语言模型组成集成, 增加容量的一种简单方法是将两种方法结合", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "14b4cd53-594d-488a-adb1-9818afbd8f40", "label": "摘要87", "info": "对于任何集成，如果集成成员产生独立的错误，这种技术可以减少测试；误差。集成学习领域提供了许多方法来组合集成成员的预测，包括统一；加权和在验证集上选择权重。Mikolov  et  al.  （2011a）扩展了集成，不", "keywords": "这种技术可以减少测试, 包括统一, 如果集成成员产生独立的错误, 对于任何集成, 加权和在验证集上选择权重", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1380094d-c78a-4e8b-b7c9-d7e8d1e28822", "label": "摘要88", "info": "接到模型的任何其他部分。额外输入是输入上下文中特定n-gram是否存；在的指示器，因此这些变量是非常高维且非常稀疏的。", "keywords": "在的指示器, 接到模型的任何其他部分, 额外输入是输入上下文中特定, 因此这些变量是非常高维且非常稀疏的, 是否存", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "77287d48-56d1-46c8-8c83-5157bdc1a2e4", "label": "摘要89", "info": "模型容量的增加是巨大的（架构的新部分包含高达｜sV｜  n  个参数），；但是处理输入所需的额外计算量是很小的（因为额外输入非常稀疏）。", "keywords": "但是处理输入所需的额外计算量是很小的, 因为额外输入非常稀疏, 个参数, 模型容量的增加是巨大的, 架构的新部分包含高达", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "015cbb03-b5a0-4553-85a7-438e42900b65", "label": "摘要90", "info": "12.4.5　神经机器翻译", "keywords": "神经机器翻译", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4ae50f99-38a3-4b5f-bfb1-737bb20daa43", "label": "摘要91", "info": "机器翻译以一种自然语言读取句子并产生等同含义的另一种语言的句；子。机器翻译系统通常涉及许多组件。在高层次，一个组件通常会提出；许多候选翻译。由于语言之间的差异，这些翻译中的许多翻译是不符合", "keywords": "机器翻译以一种自然语言读取句子并产生等同含义的另一种语言的句, 这些翻译中的许多翻译是不符合, 一个组件通常会提出, 机器翻译系统通常涉及许多组件, 在高层次", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a3a65f28-a529-4677-805e-5aa6ea2ddb84", "label": "摘要92", "info": "最早的机器翻译神经网络探索中已经纳入了编码器和解码器的想法；（Allen  1987；Chris-man  1991；Forcada  and  Ñeco  1997），而翻译中神；经网络的第一个大规模有竞争力的用途是通过神经语言模型升级翻译系", "keywords": "最早的机器翻译神经网络探索中已经纳入了编码器和解码器的想法, 经网络的第一个大规模有竞争力的用途是通过神经语言模型升级翻译系, 而翻译中神", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e7949ab4-1cdc-48ba-bd8e-ade72a78ece1", "label": "摘要93", "info": "and", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "63050b7d-c4d6-4219-9ac2-9a333df9733e", "label": "摘要94", "info": "传统语言模型仅仅报告自然语言句子的概率。因为机器翻译涉及给定输；入句子产生输出句子，所以将自然语言模型扩展为条件的是有意义的。；如第6.2.1.1节所述，可以直接地扩展一个模型，该模型定义某些变量的", "keywords": "因为机器翻译涉及给定输, 可以直接地扩展一个模型, 如第, 节所述, 入句子产生输出句子", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "25257bba-f0dc-414a-ba6f-afaf0194fd08", "label": "摘要95", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；基于MLP方法的缺点是需要将序列预处理为固定长度。为了使翻译更加；灵活，我们希望模型允许可变的输入长度和输出长度。RNN具备这种能", "keywords": "我们希望模型允许可变的输入长度和输出长度, 方法的缺点是需要将序列预处理为固定长度, 为了使翻译更加, 灵活, 具备这种能", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "460e0034-55a7-4495-86a4-71d2db838af7", "label": "摘要96", "info": "图12.5　编码器-解码器架构在直观表示（例如词序列或图像）和语义表示之间来回映射。使用；来自一种模态数据的编码器输出（例如从法语句子到捕获句子含义的隐藏表示的编码器映射）；作为用于另一模态的解码器输入（如解码器将捕获句子含义的隐藏表示映射到英语），我们可", "keywords": "例如从法语句子到捕获句子含义的隐藏表示的编码器映射, 解码器架构在直观表示, 作为用于另一模态的解码器输入, 来自一种模态数据的编码器输出, 我们可", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "334d6ec8-3e00-4da7-8060-5806a8c46d84", "label": "摘要97", "info": "为生成以源句为条件的整句，模型必须具有表示整个源句的方式。早期", "keywords": "为生成以源句为条件的整句, 早期, 模型必须具有表示整个源句的方式", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "058e46c0-6644-49a1-a5ff-4d5fbed7ad97", "label": "摘要98", "info": "模型只能表示单个词或短语。从表示学习的观点来看，具有相同含义的；句子具有类似表示是有用的，无论它们是以源语言还是以目标语言书；写。研究者首先使用卷积和RNN的组合探索该策略（Kalchbrenner", "keywords": "研究者首先使用卷积和, 无论它们是以源语言还是以目标语言书, 句子具有类似表示是有用的, 从表示学习的观点来看, 具有相同含义的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d2f920ee-96ed-4c50-9d2b-dbc9cf30f4e4", "label": "摘要99", "info": "12.4.5.1　使用注意力机制并对齐数据片段", "keywords": "使用注意力机制并对齐数据片段", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4292c978-c77e-4318-bc92-2bc144470f2c", "label": "摘要100", "info": "使用固定大小的表示概括非常长的句子（例如60个词）的所有语义细节；是非常困难的。这需要使用足够大的RNN，并且用足够长的时间训练得；很好才能实现，如Cho et al. （2014b）和Sutskever et al. （2014）所表明", "keywords": "个词, 这需要使用足够大的, 例如, 使用固定大小的表示概括非常长的句子, 的所有语义细节", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a6311c8b-1e83-43cc-a125-49a0d681a295", "label": "摘要101", "info": "图12.6　由Bahdanau et al. （2015）引入的现代注意力机制，本质上是加权平均。注意力机制对；具有权重α (t) 的特征向量 h (t) 进行加权平均形成上下文向量 c 。在一些应用中，特征向量 h 是神", "keywords": "注意力机制对, 进行加权平均形成上下文向量, 特征向量, 具有权重, 引入的现代注意力机制", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b9a0b28a-1515-4d65-b605-b7d427d2e403", "label": "摘要102", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；经网络的隐藏单元，但它们也可以是模型的原始输入。权重α (t) 由模型本身产生。它们通常是；区间［0，1］中的值，并且旨在仅仅集中在单个 h (t) 周围，使得加权平均精确地读取接近一个", "keywords": "由模型本身产生, 周围, 中的值, 并且旨在仅仅集中在单个, 经网络的隐藏单元", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "47f81844-88c7-4069-a81d-fe034090bb18", "label": "摘要103", "info": "我们可以认为基于注意力机制的系统有三个组件：", "keywords": "我们可以认为基于注意力机制的系统有三个组件", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0d6af05b-0ab8-4150-a93d-916637349911", "label": "摘要104", "info": "读取器读取原始数据（例如源语句中的源词）并将其转换为分布式；表示，其中一个特征向量与每个词的位置相关联。；存储器存储读取器输出的特征向量列表。这可以被理解为包含事实", "keywords": "表示, 读取器读取原始数据, 其中一个特征向量与每个词的位置相关联, 存储器存储读取器输出的特征向量列表, 并将其转换为分布式", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d3a2f85e-938b-4f7f-b199-a12d7681c7cf", "label": "摘要105", "info": "第三组件可以生成翻译语句。", "keywords": "第三组件可以生成翻译语句", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "28d1c936-d9e7-4e7f-b67a-a7f0d964756c", "label": "摘要106", "info": "当用一种语言书写的句子中的词与另一种语言的翻译语句中的相应词对；齐时，可以使对应的词嵌入相关联。早期的工作表明，我们可以学习将；一种语言中的词嵌入与另一种语言中的词嵌入相关联的翻译矩阵", "keywords": "我们可以学习将, 一种语言中的词嵌入与另一种语言中的词嵌入相关联的翻译矩阵, 当用一种语言书写的句子中的词与另一种语言的翻译语句中的相应词对, 早期的工作表明, 齐时", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2ebc3dad-3e49-4863-a3c9-5a40c68fee19", "label": "摘要107", "info": "12.4.6　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8fded51a-1890-427c-82b3-47ced103e754", "label": "摘要108", "info": "在对反向传播的第一次探索中，Rumelhart et al. （1986a）等人提出了分；布式表示符号的思想，其中符号对应于族成员的身份，而神经网络捕获；族成员之间的关系，训练样本形成三元组如（Colin、Mother、", "keywords": "等人提出了分, 布式表示符号的思想, 在对反向传播的第一次探索中, 训练样本形成三元组如, 而神经网络捕获", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3c54038a-a1c4-4ec6-893d-7fdfee069261", "label": "摘要109", "info": "母亲。", "keywords": "母亲", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "02e0521c-8dda-46e0-85db-e0f16c6d3f65", "label": "摘要110", "info": "Deerwester et al. （1990）将符号嵌入的想法扩展到对词的嵌入。这些嵌；入使用SVD学习。之后，嵌入将通过神经网络学习。", "keywords": "之后, 嵌入将通过神经网络学习, 学习, 将符号嵌入的想法扩展到对词的嵌入, 入使用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4edc5ee5-79ac-455a-a404-c6e63602943e", "label": "摘要111", "info": "自然语言处理的历史是由流行表示（对模型输入不同方式的表示）的变；化为标志的。在早期对符号和词建模的工作之后，神经网络在NLP上一；些最早的应用（Miikkulainen  and  Dyer，1991；Schmidhuber，1996）将", "keywords": "对模型输入不同方式的表示, 些最早的应用, 上一, 自然语言处理的历史是由流行表示, 在早期对符号和词建模的工作之后", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "0cf6a5a5-ee47-483f-86f6-4aff292a32f4", "label": "摘要112", "info": "Bengio et al. （2001b）将焦点重新引到对词建模并引入神经语言模型，；能产生可解释的词嵌入。这些神经模型已经从在一小组符号上的定义表；示（20世纪80年代）扩展到现代应用中的数百万字（包括专有名词和拼", "keywords": "能产生可解释的词嵌入, 将焦点重新引到对词建模并引入神经语言模型, 世纪, 扩展到现代应用中的数百万字, 年代", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d0b14a0f-1bda-4954-b3a2-a3b22df8e558", "label": "摘要113", "info": "最初，使用词作为语言模型的基本单元可以改进语言建模的性能；（Bengio et al.  ，2001b）。而今，新技术不断推动基于字符（Sutskever；et  al. ，2011）和基于词的模型向前发展，最近的工作（Gillick  et  al.  ，", "keywords": "使用词作为语言模型的基本单元可以改进语言建模的性能, 最近的工作, 新技术不断推动基于字符, 和基于词的模型向前发展, 最初", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ef9a61c8-ff21-4183-ad34-e168e82507dd", "label": "摘要114", "info": "神经语言模型背后的思想已经扩展到多个自然语言处理应用，如解析；（Henderson，2003，2004；Collobert，2011）、词性标注、语义角色标；注、分块等，有时使用共享词嵌入的单一多任务学习架构（Collobert", "keywords": "语义角色标, 有时使用共享词嵌入的单一多任务学习架构, 词性标注, 分块等, 神经语言模型背后的思想已经扩展到多个自然语言处理应用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "e159edbd-3a3f-409a-b44c-396fc52c4387", "label": "摘要115", "info": "随着t-SNE降维算法的发展（van  der  Maaten  and  Hinton，2008）以及；Joseph  Turian在2009年引入的专用于可视化词嵌入的应用，用于分析语；言模型嵌入的二维可视化成为一种流行的工具。", "keywords": "用于分析语, 言模型嵌入的二维可视化成为一种流行的工具, 随着, 以及, 降维算法的发展", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "label": "12.4：自然语言处理", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "33401eff-a5fb-40ac-bbc4-701568bc2c45", "label": "摘要1", "info": "12.4.1　n-gram", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8748b37c-f6c4-44b6-9556-6ea21db7b8a5", "label": "摘要2", "info": "12.4.2　神经语言模型", "keywords": "神经语言模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "76b003d9-55db-47a1-b0d8-5ccd2e5d807a", "label": "摘要3", "info": "12.4.3　高维输出", "keywords": "高维输出", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "93eb67c4-1a4f-4a58-bf75-fd3ed0fbfaa0", "label": "摘要4", "info": "12.4.4　结合n-gram和神经语言模型", "keywords": "和神经语言模型, 结合", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "cf8700d9-2f4f-4778-b34f-7134b1d9f341", "label": "摘要5", "info": "12.4.5　神经机器翻译", "keywords": "神经机器翻译", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "cddeac6e-4179-4216-b1b1-4231b9dc4541", "label": "摘要6", "info": "12.4.6　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "04e5b763-d5f7-4c24-aee8-0a43f9f3332f", "label": "摘要7", "info": "12.4.1　n-gram", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4f7c2ddc-340c-4b8b-a5f6-88d70788756a", "label": "摘要8", "info": "12.4.2　神经语言模型", "keywords": "神经语言模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4d0d993c-e6ef-428f-a792-a0c608c6b8bd", "label": "摘要9", "info": "12.4.3　高维输出", "keywords": "高维输出", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "bdbae9d4-dec8-4c9a-bbc8-6a1cb256a762", "label": "摘要10", "info": "12.4.4　结合n-gram和神；经语言模型", "keywords": "和神, 结合, 经语言模型", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a1f4402d-aaad-4fca-839b-5a3f7f3e03b6", "label": "摘要11", "info": "12.4.5　神经机器翻译", "keywords": "神经机器翻译", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "559d40b5-1722-428e-945a-ed9cb0d59219", "label": "摘要12", "info": "12.4.6　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3b8f05c8-e603-4084-997d-7ae63ae17688", "label": "12.5：其他应用", "level": 2, "group": "chapter-12", "type": "子章節"}, {"id": "2efa5da7-aa33-4b58-8b5a-53e2a74cc303", "label": "摘要1", "info": "12.5.1　推荐系统", "keywords": "推荐系统", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8804a62f-7be8-4919-9758-bb6feab00bca", "label": "摘要2", "info": "12.5.2　知识表示、推理和回答", "keywords": "知识表示, 推理和回答", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4cdfb5e6-5e29-42e8-aa7f-7ad50cf784a9", "label": "摘要3", "info": "第3部分　深度学习研究", "keywords": "部分, 深度学习研究", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "52db2db4-e79a-4fed-b990-925a76ded5d8", "label": "摘要4", "info": "在本节中，我们介绍深度学习一些其他类型的应用，它们与上面讨论的；标准对象识别、语音识别和自然语言处理任务不同。本书的第3部分将；扩大这个范围，甚至进一步扩展到仍是目前主要研究领域的任务。", "keywords": "在本节中, 本书的第, 扩大这个范围, 语音识别和自然语言处理任务不同, 部分将", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "1042c604-797b-4eb2-803c-b9fe894da2d8", "label": "摘要5", "info": "12.5.1　推荐系统", "keywords": "推荐系统", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "343ef0fc-58a1-4b2f-90be-52a181a1cfc9", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；信息技术部门中机器学习的主要应用之一是向潜在用户或客户推荐项；目。这可以分为两种主要的应用：在线广告和项目建议（通常这些建议", "keywords": "这可以分为两种主要的应用, 通常这些建议, 信息技术部门中机器学习的主要应用之一是向潜在用户或客户推荐项, 在线广告和项目建议", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f5c2ff78-0cde-4626-b69d-912e8e323b9b", "label": "摘要7", "info": "通常，这种关联问题可以作为监督学习问题来处理：给出一些关于项目；和关于用户的信息，预测感兴趣的行为（用户点击广告、输入评级、点；击“喜欢”按钮、购买产品，在产品上花钱、花时间访问产品页面等）。", "keywords": "在产品上花钱, 通常, 预测感兴趣的行为, 喜欢, 给出一些关于项目", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2c40367a-cdd3-4f53-a15a-9c314e787209", "label": "摘要8", "info": "早期推荐系统的工作依赖于这些预测输入的最小信息：用户ID和项目；ID。在这种情况下，唯一的泛化方式依赖于不同用户或不同项目的目标；变量值之间的模式相似性。假设用户1和用户2都喜欢项目A，B和C．由", "keywords": "用户, 在这种情况下, 都喜欢项目, 唯一的泛化方式依赖于不同用户或不同项目的目标, 和用户", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "3c9f1c69-befb-460f-bf3e-0b17c2252110", "label": "摘要9", "info": "通常，人们希望最小化预测评级  和实际评级  之间的平方误差。；当用户嵌入和项目嵌入首次缩小到低维度（两个或三个）时，它们就可；以方便地可视化，或者可以将用户或项目彼此进行比较（就像词嵌", "keywords": "当用户嵌入和项目嵌入首次缩小到低维度, 通常, 以方便地可视化, 它们就可, 两个或三个", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b54b9426-e481-4325-9793-48fef15fc1ad", "label": "摘要10", "info": "除了这些具有分布式表示的双线性模型之外，第一次用于协同过滤的神；al.  ，；经网络之一是基于RBM的无向概率模型（Salakhutdinov", "keywords": "第一次用于协同过滤的神, 经网络之一是基于, 的无向概率模型, 除了这些具有分布式表示的双线性模型之外", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6afbad31-1c29-495a-9461-a3ca2bfb14ac", "label": "摘要11", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ecd0e9f4-9408-4258-ba6d-722d3f7a5ffd", "label": "摘要12", "info": "然而，协同过滤系统有一个基本限制：当引入新项目或新用户时，缺乏；评级历史意味着无法评估其与其他项目或用户的相似性，或者说无法评；估新的用户和现有项目的联系。这被称为冷启动推荐问题。解决冷启动", "keywords": "解决冷启动, 缺乏, 估新的用户和现有项目的联系, 或者说无法评, 然而", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "018d6a23-b284-4e6b-8adb-f471331ed4a3", "label": "摘要13", "info": "专用的深度学习架构，如卷积网络已经应用于从丰富内容中提取特征，；如提取用于音乐推荐的音乐音轨（van den Oörd et al. ，2013）。在该工；作中，卷积网络将声学特征作为输入并计算相关歌曲的嵌入。该歌曲嵌", "keywords": "如提取用于音乐推荐的音乐音轨, 在该工, 作中, 该歌曲嵌, 专用的深度学习架构", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4745c971-3e54-474c-b8c7-8969ec160f44", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；12.5.1.1　探索与开发", "keywords": "探索与开发", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6a8986b2-7fd1-4979-9d94-d4982c2133c1", "label": "摘要15", "info": "当向用户推荐时，会产生超出普通监督学习范围的问题，并进入强化学；习的领域。理论上，许多推荐问题最准确的描述是contextual；bandit（Langford  and  Zhang，2008；Lu  et  al.  ，2010）。问题是，当我", "keywords": "当我, 习的领域, 理论上, 问题是, 许多推荐问题最准确的描述是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f582d6e5-57c7-4b23-a545-0bab434079df", "label": "摘要16", "info": "强化学习需要权衡探索 （exploration）与开发  （exploitation）。开发指；的是从目前学到的最好策略采取动作，也就是我们所知的将获得高奖励；的动作。探索  是指采取行动以获得更多的训练数据。如果我们知道给", "keywords": "强化学习需要权衡探索, 开发指, 是指采取行动以获得更多的训练数据, 如果我们知道给, 与开发", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8eb0f5b5-c5c4-4370-ac30-d32fc24b95b2", "label": "摘要17", "info": "无论如何，我们至少获得了一些知识。", "keywords": "我们至少获得了一些知识, 无论如何", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "2ed96f4a-4118-4373-8905-29afd4cec687", "label": "摘要18", "info": "探索  可以以许多方式实现，从覆盖可能动作的整个空间的随机动作到；基于模型的方法（基于预期回报和模型对该回报不确定性的量来计算动；作的选择）。", "keywords": "基于模型的方法, 从覆盖可能动作的整个空间的随机动作到, 探索, 基于预期回报和模型对该回报不确定性的量来计算动, 作的选择", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6a19baea-905e-4d1a-98b2-54e85cb90def", "label": "摘要19", "info": "许多因素决定了我们喜欢探索或开发的程度。最突出的因素之一是我们；感兴趣的时间尺度。如果代理只有短暂的时间积累奖励，那么我们喜欢；更多的开发。如果代理有很长时间积累奖励，那么我们开始更多的探", "keywords": "最突出的因素之一是我们, 许多因素决定了我们喜欢探索或开发的程度, 如果代理只有短暂的时间积累奖励, 更多的开发, 如果代理有很长时间积累奖励", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "14546998-8441-404e-816a-10b46b2058b0", "label": "摘要20", "info": "监督学习在探索或开发之间没有权衡，因为监督信号总是指定哪个输出；对于每个输入是正确的。我们总是知道标签是最好的输出，没有必要尝；试不同的输出来确定是否优于模型当前的输出。", "keywords": "我们总是知道标签是最好的输出, 因为监督信号总是指定哪个输出, 监督学习在探索或开发之间没有权衡, 试不同的输出来确定是否优于模型当前的输出, 没有必要尝", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "cb32538a-e98c-4b81-b704-de63e86756f7", "label": "摘要21", "info": "除了权衡探索和开发之外，强化学习背景下出现的另一个困难是难以评；估和比较不同的策略。强化学习包括学习者和环境之间的相互作用。这；个反馈回路意味着使用固定的测试集输入评估学习者的表现不是直接", "keywords": "估和比较不同的策略, 除了权衡探索和开发之外, 强化学习背景下出现的另一个困难是难以评, 个反馈回路意味着使用固定的测试集输入评估学习者的表现不是直接, 强化学习包括学习者和环境之间的相互作用", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "65934208-3ad6-4bd6-8936-24718ea9e80c", "label": "摘要22", "info": "12.5.2　知识表示、推理和回答", "keywords": "知识表示, 推理和回答", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "5e6b4188-04d7-4394-a792-3f7c53cf56ff", "label": "摘要23", "info": "因为使用符号（Rumelhart  et  al.  ，1986a）和词嵌入（Deerwester  et  al.；，1990；Bengio et al. ，2001b），深度学习方法在语言模型、机器翻译；和自然语言处理方面非常成功。这些嵌入表示关于单个词或概念的语义", "keywords": "深度学习方法在语言模型, 机器翻译, 和自然语言处理方面非常成功, 和词嵌入, 这些嵌入表示关于单个词或概念的语义", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f59c68f9-1b46-4439-8533-3169ea5fce7a", "label": "摘要24", "info": "12.5.2.1　知识、联系和回答", "keywords": "知识, 联系和回答", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "626548b3-8fcf-4952-8e67-f08b213d43d2", "label": "摘要25", "info": "一个有趣的研究方向是确定如何训练分布式表示才能捕获两个实体之间；的关系 （relation）。", "keywords": "一个有趣的研究方向是确定如何训练分布式表示才能捕获两个实体之间, 的关系", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "738be25a-d18f-4118-b5e0-82dd7bf498aa", "label": "摘要26", "info": "数学中，二元关系是一组有序的对象对。集合中的对具有这种关系，而", "keywords": "数学中, 二元关系是一组有序的对象对, 集合中的对具有这种关系", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "55f66f9a-d103-40a4-80db-da00a02c6c83", "label": "摘要27", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；那些不在集合中的对则没有。例如，我们可以在实体集{1，2，3}上定；。一旦", "keywords": "那些不在集合中的对则没有, 一旦, 例如, 我们可以在实体集, 上定", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c98c3c1c-2bca-4932-9d27-84c785e18869", "label": "摘要28", "info": "在AI的背景下，我们将关系看作句法上简单且高度结构化的语言。关系；起到动词的作用，而关系的两个参数发挥着主体和客体的作用。这些句；子是一个三元组标记的形式：", "keywords": "子是一个三元组标记的形式, 而关系的两个参数发挥着主体和客体的作用, 我们将关系看作句法上简单且高度结构化的语言, 起到动词的作用, 的背景下", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a690d02e-5cfe-46a9-ba53-150dab2cf19b", "label": "摘要29", "info": "其值是", "keywords": "其值是", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7efe1db2-8dc1-4d06-92fa-edfcedd46e3e", "label": "摘要30", "info": "我们还可以定义属性  （attribute），类似于关系的概念，但只需要一个；参数：", "keywords": "参数, 类似于关系的概念, 我们还可以定义属性, 但只需要一个", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "38cff021-6079-477f-85fe-b1a80e163ccf", "label": "摘要31", "info": "例如，我们可以定义has_fur 属性，并将其应用于像狗这样的实体。", "keywords": "并将其应用于像狗这样的实体, 属性, 我们可以定义, 例如", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "bdb679b8-88e6-4151-bace-131668411238", "label": "摘要32", "info": "许多应用中需要表示关系和推理。我们如何在神经网络中做到这一点？", "keywords": "许多应用中需要表示关系和推理, 我们如何在神经网络中做到这一点", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "a2b78f79-732d-4a27-94c5-aa87e6976e77", "label": "摘要33", "info": "机器学习模型当然需要训练数据。我们可以推断非结构化自然语言组成；的训练数据集中实体之间的关系，也可以使用明确定义关系的结构化数；据库。这些数据库的共同结构是关系型数据库，它存储这种相同类型的", "keywords": "也可以使用明确定义关系的结构化数, 据库, 我们可以推断非结构化自然语言组成, 的训练数据集中实体之间的关系, 它存储这种相同类型的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "99473665-3d6f-41a8-9847-b6765c52769f", "label": "摘要34", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "b3e36db4-5a8b-4fc7-ac7e-08e425774f82", "label": "摘要35", "info": "除了训练数据，我们还需定义训练的模型族。一种常见的方法是将神经；语言模型扩展到模型实体和关系。神经语言模型学习提供每个词分布式；表示的向量。他们还通过学习这些向量的函数来学习词之间的相互作", "keywords": "一种常见的方法是将神经, 语言模型扩展到模型实体和关系, 他们还通过学习这些向量的函数来学习词之间的相互作, 我们还需定义训练的模型族, 神经语言模型学习提供每个词分布式", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "639719cc-4862-4f9f-8d50-ea3a93de3112", "label": "摘要36", "info": "et", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7b6826b9-79f2-4038-8493-3cb977262416", "label": "摘要37", "info": "这种模型的实际短期应用是链接预测 （link prediction）：预测知识图谱；中缺失的弧。这是基于旧事实推广新事实的一种形式。目前存在的大多；数知识库都是通过人力劳动构建的，这往往使知识库缺失许多并且可能", "keywords": "目前存在的大多, 这是基于旧事实推广新事实的一种形式, 这往往使知识库缺失许多并且可能, 这种模型的实际短期应用是链接预测, 预测知识图谱", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d53120c3-5719-4385-9b31-2266b6d2c6bc", "label": "摘要38", "info": "我们很难评估链接预测任务上模型的性能，因为我们的数据集只有正样；本（已知是真实的事实）。如果模型提出了不在数据集中的事实，我们；不确定模型是犯了错误还是发现了一个新的以前未知的事实。度量基于", "keywords": "不确定模型是犯了错误还是发现了一个新的以前未知的事实, 因为我们的数据集只有正样, 如果模型提出了不在数据集中的事实, 我们, 我们很难评估链接预测任务上模型的性能", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "31c42e93-f25d-4af2-8c76-4faa6eb28048", "label": "摘要39", "info": "知识库和分布式表示的另一个应用是词义消歧；（word-sense；disambiguation）（Navigli  and  Velardi，2005；Bordes  et  al.  ，2012），", "keywords": "知识库和分布式表示的另一个应用是词义消歧", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "43546a1a-7f80-4749-8146-97c194f25755", "label": "摘要40", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最后，知识的关系结合一个推理过程和对自然语言的理解可以让我们建；立一个一般的问答系统。一般的问答系统必须能处理输入信息并记住重", "keywords": "知识的关系结合一个推理过程和对自然语言的理解可以让我们建, 一般的问答系统必须能处理输入信息并记住重, 立一个一般的问答系统, 最后", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "fbc89323-53cf-4d03-9b3b-e6071066e03a", "label": "摘要41", "info": "深度学习已经应用于其他许多应用（除了这里描述的应用以外），并且；肯定会在此之后应用于更多的场景。我们不可能全面描述与此主题相关；的所有应用。本项调查尽可能地提供了在本文写作之时的代表性样本。", "keywords": "深度学习已经应用于其他许多应用, 除了这里描述的应用以外, 的所有应用, 肯定会在此之后应用于更多的场景, 我们不可能全面描述与此主题相关", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "daaebf17-f5ff-472d-88d4-26c1bf60f511", "label": "摘要42", "info": "本书第2部分介绍了涉及深度学习的现代实践，囊括了所有非常成功的；方法。一般而言，这些方法使用代价函数的梯度寻找模型（近似于某些；所期望的函数）的参数。当具有足够的训练数据时，这种方法是非常强", "keywords": "的参数, 当具有足够的训练数据时, 所期望的函数, 本书第, 部分介绍了涉及深度学习的现代实践", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c5ec68c7-eee4-452a-a7ad-6a5b1eb52aec", "label": "摘要43", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "7989c7a0-1841-46a9-935b-44d2bd444271", "label": "摘要44", "info": "(1)  译者注：所有样本相似的距离。", "keywords": "所有样本相似的距离, 译者注", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "9fa9d38e-50ef-4093-80c2-b953e1ce28fb", "label": "摘要45", "info": "分别可以在如下网址获取：freebase.com，cyc.com/opencyc，wordnet.princeton.edu，", "keywords": "分别可以在如下网址获取", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "aef54462-1228-4484-85f4-337fc3c9c512", "label": "摘要46", "info": "(2)；wikiba.se", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "6dd082a0-51ed-41de-a7fe-396733699587", "label": "摘要47", "info": "(3)  geneontology.org", "keywords": "", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "8fbe5265-d424-46a8-a522-847e8993d8b9", "label": "摘要48", "info": "第3部分　深度学习研究", "keywords": "部分, 深度学习研究", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "359cdbad-41ac-4a98-9224-22805c763915", "label": "摘要49", "info": "本书这一部分描述目前研究社群所追求的、更有远见和更先进的深度学；习方法。", "keywords": "习方法, 更有远见和更先进的深度学, 本书这一部分描述目前研究社群所追求的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "ee016b75-03f6-4a22-b4ca-e7b01c56f70f", "label": "摘要50", "info": "在本书的前两部分，我们已经展示了如何解决监督学习问题，即在给定；足够的映射样本的情况下，学习将一个向量映射到另一个。", "keywords": "学习将一个向量映射到另一个, 我们已经展示了如何解决监督学习问题, 在本书的前两部分, 足够的映射样本的情况下, 即在给定", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "d8ad2987-aa20-4219-b993-f75f28bf4ae2", "label": "摘要51", "info": "我们想要解决的问题并不全都属于这个类别。我们可能希望生成新的样；本、或确定一个点的似然性、或处理缺失值以及利用一组大量的未标记；样本或相关任务的样本。当前应用于工业的最先进技术的缺点是我们的", "keywords": "我们可能希望生成新的样, 当前应用于工业的最先进技术的缺点是我们的, 或确定一个点的似然性, 我们想要解决的问题并不全都属于这个类别, 样本或相关任务的样本", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "f7c8b249-8116-4adb-bf2d-5bbdd7df79ae", "label": "摘要52", "info": "许多深度学习算法被设计为处理无监督学习问题，但不像深度学习已经；在很大程度上解决了各种任务的监督学习问题，没有一个算法能以同样；的方式真正解决无监督学习问题。在本书这一部分，我们描述无监督学", "keywords": "在很大程度上解决了各种任务的监督学习问题, 在本书这一部分, 但不像深度学习已经, 没有一个算法能以同样, 的方式真正解决无监督学习问题", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "06a4006b-d9ee-4389-8352-0e1d7566486d", "label": "摘要53", "info": "无监督学习困难的核心原因是被建模的随机变量的高维度。这带来了两；个不同的挑战：统计挑战和计算挑战。统计挑战与泛化相关：我们可能；想要区分的配置数会随着感兴趣的维度数指数增长，并且这快速变得比", "keywords": "统计挑战和计算挑战, 这带来了两, 统计挑战与泛化相关, 个不同的挑战, 并且这快速变得比", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "4b981c20-c159-4c0f-a379-ae6ecbd204f9", "label": "摘要54", "info": "使用概率模型，这种计算挑战来自执行难解的推断或归一化分布。", "keywords": "使用概率模型, 这种计算挑战来自执行难解的推断或归一化分布", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "dfebeb35-ab81-4dc3-a5ad-03bfb4698059", "label": "摘要55", "info": "难解的推断：推断主要在第19章讨论。推断关于捕获a、b和c上联；合分布的模型，给定其他变量b的情况下，猜测一些变量a的可能；值。为了计算这样的条件概率，我们需要对变量c的值求和，以及", "keywords": "难解的推断, 我们需要对变量, 上联, 章讨论, 推断主要在第", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "115576c1-4c88-4643-bfb8-40d6f6a811c5", "label": "摘要56", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；面对这些难以处理的计算的一种方法是近似它们，如在本书的第3部分；中讨论的，研究者已经提出了许多方法。这里还讨论另一种有趣的方式", "keywords": "中讨论的, 部分, 如在本书的第, 研究者已经提出了许多方法, 这里还讨论另一种有趣的方式", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "96748920-67fa-4381-bc97-c4146621af51", "label": "摘要57", "info": "第3部分对于研究者来说是最重要的，研究者想要了解深度学习领域的；广度，并将领域推向真正的人工智能。", "keywords": "并将领域推向真正的人工智能, 广度, 研究者想要了解深度学习领域的, 部分对于研究者来说是最重要的", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c2469ca1-7ffc-40c1-a5e7-187a937cd15c", "label": "摘要58", "info": "12.5.1　推荐系统", "keywords": "推荐系统", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "c40b65cd-25ce-4299-b584-aaa3395f46ee", "label": "摘要59", "info": "12.5.2　知识表示、推理；和回答", "keywords": "推理, 知识表示, 和回答", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "18772017-100d-477b-8910-c45f0d64ca36", "label": "摘要60", "info": "第3部分　深度学习研究", "keywords": "部分, 深度学习研究", "level": 3, "group": "chapter-12", "type": "段落"}, {"id": "59d043fe-ba87-441e-84c8-9d202ce3d334", "label": "第13章：线性因子模型", "level": 1, "group": "chapter-13", "type": "章節"}, {"id": "f4c1962e-7454-4516-b1a3-01508092cd07", "label": "12.5：其他应用", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "62fab4b6-8f4c-4b0a-92ca-142fed841d89", "label": "摘要1", "info": "许多深度学习的研究前沿均涉及构建输入的概率模型p  model  (  x  )。原则；上说，给定任何其他变量的情况下，这样的模型可以使用概率推断来预；h  ，其中", "keywords": "许多深度学习的研究前沿均涉及构建输入的概率模型, 其中, 给定任何其他变量的情况下, 原则, 上说", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "52836780-2d57-46f1-9dd8-65f140111aaa", "label": "摘要2", "info": "在本章中，我们描述了一些基于潜变量的最简单的概率模型：线性因子；模型 （linear  factor  model）。这些模型有时被用来作为混合模型的组成；模块（Hinton et  al.  ，1995a；Ghahramani  and  Hinton，1996；Roweis  et", "keywords": "模块, 我们描述了一些基于潜变量的最简单的概率模型, 模型, 线性因子, 这些模型有时被用来作为混合模型的组成", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "8f532643-8344-4bc0-b18e-3307c8b25c36", "label": "摘要3", "info": "线性因子模型通过随机线性解码器函数来定义，该函数通过对 h 的线性；变换以及添加噪声来生成 x 。", "keywords": "线性因子模型通过随机线性解码器函数来定义, 该函数通过对, 变换以及添加噪声来生成, 的线性", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a136bc59-2233-4511-a8a5-92f4e7828d9f", "label": "摘要4", "info": "有趣的是，通过这些模型我们能够发现一些符合简单联合分布的解释性；因子。线性解码器的简单性使得它们成为了最早被广泛研究的潜变量模；型。", "keywords": "线性解码器的简单性使得它们成为了最早被广泛研究的潜变量模, 有趣的是, 通过这些模型我们能够发现一些符合简单联合分布的解释性, 因子", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "36ca49e8-d56f-4e7d-872e-cb9b9ad14b81", "label": "摘要5", "info": "线性因子模型描述如下的数据生成过程。首先，我们从一个分布中抽取；解释性因子 h ，", "keywords": "首先, 我们从一个分布中抽取, 解释性因子, 线性因子模型描述如下的数据生成过程", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f54e4bd7-c41d-4110-aad9-0ab85402d026", "label": "摘要6", "info": "其中p( h )是一个因子分布，满足p( h )＝∏ i p(h i )，所以易于从中采样。；接下来，在给定因子的情况下，我们对实值的可观察变量进行采样", "keywords": "接下来, 是一个因子分布, 满足, 其中, 我们对实值的可观察变量进行采样", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "0f4bde4f-b6ab-4c73-9e3b-c3512ff4982a", "label": "摘要7", "info": "其中噪声通常是对角化的（在维度上是独立的）且服从高斯分布。这在；图13.1有具体说明。", "keywords": "这在, 且服从高斯分布, 有具体说明, 在维度上是独立的, 其中噪声通常是对角化的", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "ab4cd026-474c-4046-a4d2-c07410beda78", "label": "摘要8", "info": "图13.1　描述线性因子模型族的有向图模型，其中我们假设观察到的数据向量 x 是通过独立的潜；在因子 h 的线性组合再加上一定噪声获得的。不同的模型，比如概率PCA、因子分析或者是；ICA，都是选择了不同形式的噪声以及先验p( h )", "keywords": "在因子, 都是选择了不同形式的噪声以及先验, 其中我们假设观察到的数据向量, 描述线性因子模型族的有向图模型, 的线性组合再加上一定噪声获得的", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f9df9436-6520-4194-afd0-994590b1bacc", "label": "13.1：概率PCA和因子分析", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "e949c1b4-54af-4d85-b840-8d7fd23a72b8", "label": "摘要1", "info": "概率  PCA（probabilistic  PCA）、因子分析和其他线性因子模型是上述；等式（式（13.1）和式（13.2））的特殊情况，并且仅在对观测到  x  之；前的噪声分布和潜变量 h 先验的选择上有所不同。", "keywords": "等式, 因子分析和其他线性因子模型是上述, 的特殊情况, 先验的选择上有所不同, 概率", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a2cae305-678a-48c5-b1ec-3d12f7847a2e", "label": "摘要2", "info": "在因子分析  （factor；1994）中，潜变量的先验是一个方差为单位矩阵的高斯分布", "keywords": "潜变量的先验是一个方差为单位矩阵的高斯分布, 在因子分析", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b97f23c3-3c57-404f-b3b9-2be0a1916968", "label": "摘要3", "info": "analysis）（Bartholomew，1987；Basilevsky，", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "3904e6fd-2fe0-436a-84c3-4e93f6338be5", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；i  是条件独立  （conditionally；同时，假定在给定  h  的条件下观察值x", "keywords": "假定在给定, 同时, 是条件独立, 的条件下观察值", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "44890840-35bb-4745-bc6a-00c8d257a04d", "label": "摘要5", "info": "σ", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "9498bd60-b97a-4b9a-9ef2-deb9c4c80486", "label": "摘要6", "info": "2", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "496d56da-975a-4ed7-9ad8-0c6d5b262250", "label": "摘要7", "info": "差。", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a807bd0d-08ce-4555-9366-06b9e1489ef2", "label": "摘要8", "info": "因此，潜变量的作用是捕获不同观测变量x i 之间的依赖关系。实际上，；可以容易地看出 x 服从多维正态分布，并满足", "keywords": "潜变量的作用是捕获不同观测变量, 因此, 服从多维正态分布, 实际上, 可以容易地看出", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "85503dd2-af2c-42a3-abd5-bafb4bf54703", "label": "摘要9", "info": "为了将PCA引入到概率框架中，我们可以对因子分析模型作轻微修改，；使条件方差   等于同一个值。在这种情况下，  x  的协方差简化为；，这里的σ  2  是一个标量。由此可以得到条件分布，如", "keywords": "是一个标量, 的协方差简化为, 由此可以得到条件分布, 使条件方差, 在这种情况下", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "d60eff68-01c8-4f99-bf72-67bf31e88ad5", "label": "摘要10", "info": "下：", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "7b65ff29-72a9-4d7d-a204-5515e6fb439d", "label": "摘要11", "info": "或者等价地", "keywords": "或者等价地", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "8a730a3e-ca48-4550-b303-f5f88805ea70", "label": "摘要12", "info": "其中；出了一种迭代的EM算法来估计参数 W 和σ 2 。", "keywords": "其中, 算法来估计参数, 出了一种迭代的", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "08106e4d-9042-43cb-b2f8-44b7b4f8e0a9", "label": "摘要13", "info": "是高斯噪声。之后Tipping and Bishop（1999）提", "keywords": "是高斯噪声, 之后", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "acf4dcb2-19fd-4642-b050-124f4d0bf33e", "label": "摘要14", "info": "这个概率PCA  （probabilistic  PCA）模型利用了这样一种观察现象：除；了一些微小残余的重构误差  （reconstruction  error）（至多为σ  2  ），数；据中的大多数变化可以由潜变量", "keywords": "据中的大多数变化可以由潜变量, 至多为, 这个概率, 了一些微小残余的重构误差, 模型利用了这样一种观察现象", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f6b48f5e-8268-4828-b574-673677de5b7f", "label": "摘要15", "info": "描述。通过Tipping", "keywords": "通过, 描述", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b6095c0b-d255-460e-a3ec-79d4400b778d", "label": "摘要16", "info": "h", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "641f025a-27f2-4e59-8e42-866bca99fc92", "label": "摘要17", "info": "当σ→0时，概率PCA所定义的密度函数在d维的  W  的列生成空间周围非", "keywords": "概率, 的列生成空间周围非, 维的, 所定义的密度函数在", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "cf04282e-2eb0-49b9-9cff-6aaff70f18dd", "label": "摘要18", "info": "常尖锐。这导致模型会为没有在一个超平面附近聚集的数据分配非常低；的概率。", "keywords": "的概率, 常尖锐, 这导致模型会为没有在一个超平面附近聚集的数据分配非常低", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "label": "13.2：独立成分分析", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "1c721586-6bf8-4fcf-a49c-94c7ad86e4b3", "label": "摘要1", "info": "独立成分分析 （independent component analysis，ICA）是最古老的表示；学习算法之一（Herault  and  Ans，1984；Jutten  and  Herault，1991；；Comon，1994；Hyvärinen，1999；Hyvärinen  et  al.  ，2001a；Hinton  et", "keywords": "独立成分分析, 是最古老的表示, 学习算法之一", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "3a0cf010-11a6-4083-81fd-cb3ed1d408ae", "label": "摘要2", "info": "许多不同的具体方法被称为ICA。与我们本书中描述的其他生成模型最；相似的ICA变种（Pham  et  al.  ，1992）训练了完全参数化的生成模型。；潜在因子  h  的先验p(  h  )，必须由用户提前给出并固定。接着模型确定", "keywords": "必须由用户提前给出并固定, 训练了完全参数化的生成模型, 潜在因子, 许多不同的具体方法被称为, 相似的", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "2c3cc3a0-8b95-4438-b920-a2fbb939ba52", "label": "摘要3", "info": "这种方法的动机是，通过选择一个独立的p(  h  )，我们可以尽可能恢复；接近独立的潜在因子。这是一种常用的方法，它并不是用来捕捉高级别；的抽象因果因子，而是恢复已经混合在一起的低级别信号。在该设置", "keywords": "接近独立的潜在因子, 而是恢复已经混合在一起的低级别信号, 在该设置, 通过选择一个独立的, 的抽象因果因子", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b6c66144-64a8-4657-950f-2a7662696f69", "label": "摘要4", "info": "如前所述，ICA存在许多变种。一些版本在  x  的生成中添加一些噪声，；而不是使用确定性的解码器。大多数方法不使用最大似然准则，而是旨", "keywords": "如前所述, 而是旨, 存在许多变种, 一些版本在, 的生成中添加一些噪声", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "cf2b6863-46fc-422c-88ad-09ef9a3f6635", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在使  h  ＝  W  -1  x  的元素彼此独立。许多准则能够达成这个目标。式；（3.47）需要用到  W  的行列式，这可能是代价很高且数值不稳定的操", "keywords": "这可能是代价很高且数值不稳定的操, 的元素彼此独立, 在使, 的行列式, 需要用到", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "70b00a5b-7ee2-4ba1-af87-b6fff462882b", "label": "摘要6", "info": "ICA的所有变种均要求p( h )是非高斯的。这是因为如果p( h )是具有高斯；分量的独立先验，则  W  是不可识别的。对于许多  W  值，我们可以在p(；x )上获得相同的分布。这与其他线性因子模型有很大的区别，例如概率", "keywords": "例如概率, 上获得相同的分布, 是具有高斯, 是非高斯的, 对于许多", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "60f056d3-85ee-4733-8715-81100c254775", "label": "摘要7", "info": "用", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f944e135-6461-4491-a09e-68aa9db68583", "label": "摘要8", "info": "。这些非高斯分布的典型选择在", "keywords": "这些非高斯分布的典型选择在", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "2a514b74-4902-46a6-88c0-eb523649aa20", "label": "摘要9", "info": "0附近具有比高斯分布更高的峰值，因此我们也可以看到独立成分分析；经常用于学习稀疏特征。", "keywords": "附近具有比高斯分布更高的峰值, 因此我们也可以看到独立成分分析, 经常用于学习稀疏特征", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "bffb4279-7f99-4154-860d-af55426552c0", "label": "摘要10", "info": "按照我们对生成模型这个术语的定义，ICA的许多变种不是生成模型。；在本书中，生成模型可以直接表示p(  x  )，也可以认为是从p(  x  )中抽取；样本。ICA的许多变种仅知道如何在 x 和 h 之间变换，而没有任何表示", "keywords": "生成模型可以直接表示, 样本, 中抽取, 按照我们对生成模型这个术语的定义, 在本书中", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "272ed851-21d0-4cf1-b129-3ac5cb908116", "label": "摘要11", "info": "正如PCA可以推广到第14章中描述的非线性自编码器，ICA也可以推广；到非线性生成模型，其中我们使用非线性函数f来生成观测数据。关于；非线性ICA最初的工作可以参考Hyvärinen and Pajunen（1999），它和集", "keywords": "到非线性生成模型, 可以推广到第, 非线性, 它和集, 也可以推广", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "69c2d9b1-4818-49ca-b168-23c6b97f732d", "label": "摘要12", "info": "ICA的另一个推广是通过鼓励组内统计依赖关系、抑制组间依赖关系来", "keywords": "抑制组间依赖关系来, 的另一个推广是通过鼓励组内统计依赖关系", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "ce4a2150-4ead-4577-be84-f1d52c6af321", "label": "摘要13", "info": "学习特征组（Hyvärinen and Hoyer，1999；Hyvärinen et al. ，2001b）。；当相关单元的组被选为不重叠时，这被称为独立子空间分析；（independent  subspace  analysis）。我们还可以向每个隐藏单元分配空", "keywords": "我们还可以向每个隐藏单元分配空, 当相关单元的组被选为不重叠时, 这被称为独立子空间分析, 学习特征组", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "1cefff4f-7f7b-4be5-8f44-6458ff2004a7", "label": "摘要14", "info": "ICA）方法可以学习Gabor滤波器，从而使得相邻特征具", "keywords": "从而使得相邻特征具, 方法可以学习, 滤波器", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "label": "13.3：慢特征分析", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "f1104393-b44c-4fdf-94cb-2354eed805aa", "label": "摘要1", "info": "慢特征分析  （slow  feature  analysis，SFA）是使用来自时间信号的信息；学习不变特征的线性因子模型（Wiskott and Sejnowski，2002）。", "keywords": "慢特征分析, 是使用来自时间信号的信息, 学习不变特征的线性因子模型", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "c5bba5c9-b5e7-4eb1-8c8a-2911fecb0df9", "label": "摘要2", "info": "慢特征分析的想法源于所谓的慢性原则  （slowness  principle）。其基本；思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变；化得非常缓慢。例如，在计算机视觉中，单个像素值可以非常快速地改", "keywords": "单个像素值可以非常快速地改, 场景的重要特性通常变, 思想是, 例如, 其基本", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "e4813aff-fe6f-4c9a-a537-bfed42c58591", "label": "摘要3", "info": "慢性原则早于慢特征分析，并已被应用于各种模型（Hinton，1989；；Földiák，1989；Mobahi et al. ，2009；Bergstra and Bengio，2009）。一；般来说，我们可以将慢性原则应用于可以使用梯度下降训练的任何可微", "keywords": "我们可以将慢性原则应用于可以使用梯度下降训练的任何可微, 并已被应用于各种模型, 般来说, 慢性原则早于慢特征分析", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b071bc0d-b250-47af-90b2-7e743815e4ed", "label": "摘要4", "info": "其中λ是确定慢度正则化强度的超参数项，t是样本时间序列的索引，f是；需要正则化的特征提取器，L是测量f（ x  (t)  ）和f(  x  (t+1)  )之间的距离的；损失函数。L的一个常见选择是均方误差。", "keywords": "需要正则化的特征提取器, 之间的距离的, 的一个常见选择是均方误差, 其中, 是样本时间序列的索引", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "c8f8ebe7-dfe6-4ccd-9775-24b32855c4db", "label": "摘要5", "info": "慢特征分析是慢性原则中一个特别高效的应用。由于它被应用于线性特", "keywords": "慢特征分析是慢性原则中一个特别高效的应用, 由于它被应用于线性特", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "06b608dc-1583-4957-8c7d-91e63b6feeaa", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；征提取器，并且可以通过闭式解训练，所以它是高效的。像ICA的一些；变种一样，SFA本身并不是生成模型，只是在输入空间和特征空间之间", "keywords": "的一些, 本身并不是生成模型, 并且可以通过闭式解训练, 变种一样, 只是在输入空间和特征空间之间", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "dc5ff139-69a2-4648-8d0d-446e9425d92d", "label": "摘要7", "info": "SFA算法（Wiskott and Sejnowski，2002）先将f( x ;θ)定义为线性变换，；然后求解如下优化问题：", "keywords": "先将, 定义为线性变换, 算法, 然后求解如下优化问题", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "087252d1-707b-4281-ba32-20659b6e484a", "label": "摘要8", "info": "并且满足下面的约束：", "keywords": "并且满足下面的约束", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b0e4e1bf-f632-4219-ab3d-f8d6c1a5d315", "label": "摘要9", "info": "以及", "keywords": "以及", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "00460bc3-4ca8-41c8-b678-a358a06ca08d", "label": "摘要10", "info": "学习特征具有零均值的约束对于使问题具有唯一解是必要的，否则我们；可以向所有特征值添加一个常数，并获得具有相等慢度目标值的不同；解。特征具有单位方差的约束对于防止所有特征趋近于0的病态解是必", "keywords": "特征具有单位方差的约束对于防止所有特征趋近于, 否则我们, 学习特征具有零均值的约束对于使问题具有唯一解是必要的, 可以向所有特征值添加一个常数, 的病态解是必", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "4ca40986-6d2c-4c65-9655-ed0080b8d5d9", "label": "摘要11", "info": "这要求学习的特征必须彼此线性去相关。没有这个约束，所有学习到的；特征将简单地捕获一个最慢的信号。可以想象使用其他机制，如最小化；重构误差，也可以迫使特征多样化。但是由于SFA特征的线性，这种去", "keywords": "但是由于, 所有学习到的, 特征将简单地捕获一个最慢的信号, 重构误差, 这要求学习的特征必须彼此线性去相关", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "3a445fb4-ba12-4845-8c35-344bcfb7bb1b", "label": "摘要12", "info": "在运行SFA之前，SFA通常通过对  x  使用非线性的基扩充来学习非线性；特征。例如，通常用 x 的二次基扩充来代替原来的 x ，得到一个包含所；有x i x j 的向量。由此，我们可以通过反复地学习一个线性SFA特征提取", "keywords": "在运行, 的二次基扩充来代替原来的, 例如, 特征提取, 由此", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "95582872-e484-48ab-98cb-803b78bbf349", "label": "摘要13", "info": "SFA特征提取器的方式来组合线性SFA模块，从而学习深度非线性慢特；征提取器。", "keywords": "模块, 特征提取器的方式来组合线性, 从而学习深度非线性慢特, 征提取器", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "fdc4f251-321e-4168-b6d4-682a0353fcac", "label": "摘要14", "info": "当在自然场景视频的小块空间部分上训练时，使用二次基扩展的SFA所；学习到的特征与V1皮层中那些复杂细胞的特征有许多共同特性（Berkes；and  Wiskott，2005）。当在计算机渲染的3D环境内随机运动的视频上训", "keywords": "当在计算机渲染的, 皮层中那些复杂细胞的特征有许多共同特性, 当在自然场景视频的小块空间部分上训练时, 学习到的特征与, 环境内随机运动的视频上训", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "aecff16a-23ad-4920-b353-8acbc31c0ce9", "label": "摘要15", "info": "SFA的一个主要优点是，即使在深度非线性条件下，它依然能够在理论；上预测SFA能够学习哪些特征。为了做出这样的理论预测，必须知道关；于配置空间的环境动力（例如，在3D渲染环境中随机运动的例子中，", "keywords": "能够学习哪些特征, 必须知道关, 为了做出这样的理论预测, 例如, 于配置空间的环境动力", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f7824bb7-804d-4a1b-96d1-fc41a2014f97", "label": "摘要16", "info": "深度SFA也已经被用于学习用在对象识别和姿态估计的特征（Franzius；et  al.  ，2008）。到目前为止，慢性原则尚未成为任何最先进应用的基；础。究竟是什么因素限制了其性能仍有待研究。我们推测，或许慢度先", "keywords": "究竟是什么因素限制了其性能仍有待研究, 也已经被用于学习用在对象识别和姿态估计的特征, 到目前为止, 或许慢度先, 慢性原则尚未成为任何最先进应用的基", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "1646ebab-effc-469c-8529-78a0cb48f5b4", "label": "13.4：稀疏编码", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "a750373d-f1bc-4556-976f-6b1c02d133e8", "label": "摘要1", "info": "稀疏编码 （sparse coding）（Olshausen and Field，1996）是一个线性因；子模型，已作为一种无监督特征学习和特征提取机制得到了广泛研究。；严格来说，术语“稀疏编码”是指在该模型中推断  h  值的过程，而“稀疏", "keywords": "已作为一种无监督特征学习和特征提取机制得到了广泛研究, 是指在该模型中推断, 稀疏编码, 子模型, 术语", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "72a1291c-5853-41e4-8077-852e79d795fa", "label": "摘要2", "info": "像大多数其他线性因子模型一样，它使用了线性的解码器加上噪声的方", "keywords": "它使用了线性的解码器加上噪声的方, 像大多数其他线性因子模型一样", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "ae486e37-7225-4401-aa05-f09233428ab4", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；式获得一个  x  的重构，就像式（13.2）描述的一样。更具体地说，稀疏；编码模型通常假设线性因子有一个各向同性精度为β的高斯噪声：", "keywords": "编码模型通常假设线性因子有一个各向同性精度为, 式获得一个, 描述的一样, 就像式, 的重构", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "34b626e7-772c-4158-996f-c9ac899445a8", "label": "摘要4", "info": "分布p(  h  )通常选取为一个峰值很尖锐且接近0的分布（Olshausen  and；Field，1996）。常见的选择包括可分解的Laplace、Cauchy或者可分解；的Student-t分布。例如，以稀疏惩罚系数λ为参数的Laplace先验可以表", "keywords": "为参数的, 或者可分解, 例如, 先验可以表, 常见的选择包括可分解的", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f96a29d3-dccb-4d84-8ff8-ebfe1c782333", "label": "摘要5", "info": "相应地，Student-t先验分布可以表示为", "keywords": "相应地, 先验分布可以表示为", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "b0938d62-7202-4bfc-b467-960cef39af88", "label": "摘要6", "info": "使用最大似然的方法来训练稀疏编码模型是不可行的。相反，为了在给；定编码的情况下更好地重构数据，训练过程在编码数据和训练解码器之；间交替进行。稍后在第19.3节中，这种方法将被进一步证明为是解决最", "keywords": "定编码的情况下更好地重构数据, 稍后在第, 为了在给, 这种方法将被进一步证明为是解决最, 节中", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a79f34e9-aa57-4e60-9157-b21219c30222", "label": "摘要7", "info": "对于诸如PCA的模型，我们已经看到使用了预测  h 的参数化的编码器函；数，并且该函数仅包括乘以权重矩阵。稀疏编码中的编码器不是参数化；的编码器。相反，编码器是一个优化算法，在这个优化问题中，我们寻", "keywords": "编码器是一个优化算法, 稀疏编码中的编码器不是参数化, 在这个优化问题中, 的模型, 的参数化的编码器函", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "db5b1a8a-b4a3-421e-9716-b64542fb0c9c", "label": "摘要8", "info": "结合式（13.13）和式（13.12），我们得到如下的优化问题：", "keywords": "结合式, 我们得到如下的优化问题, 和式", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "2e9591d9-0de8-4679-b04c-c876d8f5487d", "label": "摘要9", "info": "其中，我们扔掉了与  h  无关的项，并除以一个正的缩放因子来简化表；达。", "keywords": "并除以一个正的缩放因子来简化表, 其中, 无关的项, 我们扔掉了与", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "18b6b7cc-450f-4249-998f-be870dc17ac2", "label": "摘要10", "info": "由于在  h  上施加L  1  范数，这个过程将产生稀疏的  h  ∗  （详见第7.1.2；节）。", "keywords": "这个过程将产生稀疏的, 上施加, 由于在, 范数, 详见第", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "c955df4e-53e8-40ac-accb-bf45866890e8", "label": "摘要11", "info": "为了训练模型而不仅仅是进行推断，我们交替迭代关于  h  和  W  的最小；化过程。在这里，我们将β视为超参数。我们通常将其设置为1，因为它；在此优化问题的作用与λ类似，没有必要使用两个超参数。原则上，我", "keywords": "我们交替迭代关于, 在这里, 我们将, 因为它, 没有必要使用两个超参数", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "3cde6418-4264-4fbc-a606-35241432305e", "label": "摘要12", "info": "不是所有的稀疏编码方法都显式地构建了一个p( h )和一个p( x  ｜  h  )。；通常我们只是对学习一个带有激活值的特征的字典感兴趣，当特征是由；这个推断过程提取时，这个激活值通常为0。", "keywords": "不是所有的稀疏编码方法都显式地构建了一个, 当特征是由, 通常我们只是对学习一个带有激活值的特征的字典感兴趣, 和一个, 这个激活值通常为", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "da29fd87-6d4f-42ae-afe9-a4f1d8a17307", "label": "摘要13", "info": "如果我们从Laplace先验中采样 h ， h 的元素实际上为0是一个零概率事；件。生成模型本身并不稀疏，只有特征提取器是稀疏的。Goodfellow  et；al.  （2013f）描述了不同模型族中的近似推断，如尖峰和平板稀疏编码", "keywords": "如尖峰和平板稀疏编码, 先验中采样, 是一个零概率事, 如果我们从, 描述了不同模型族中的近似推断", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "82e27ccf-de13-4d81-acf1-978277e11028", "label": "摘要14", "info": "与非参数编码器结合的稀疏编码方法原则上可以比任何特定的参数化编；码器更好地最小化重构误差和对数先验的组合。另一个优点是编码器没；有泛化误差。参数化的编码器必须泛化地学习如何将 x 映射到 h 。对于", "keywords": "与非参数编码器结合的稀疏编码方法原则上可以比任何特定的参数化编, 另一个优点是编码器没, 有泛化误差, 参数化的编码器必须泛化地学习如何将, 对于", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a2bf40ce-fcb7-44b1-aa08-2d880c675864", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；预测编码值时，基于优化的稀疏编码模型的编码过程中较小的泛化误差；可以得到更好的泛化能力。Coates  and  Ng（2011）证明了在对象识别任", "keywords": "可以得到更好的泛化能力, 基于优化的稀疏编码模型的编码过程中较小的泛化误差, 证明了在对象识别任, 预测编码值时", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "ef1d5ccc-fc75-498d-a2b5-2678b1797096", "label": "摘要16", "info": "al.", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "6756575c-f5ef-46b5-83cc-eaea15e0f9f5", "label": "摘要17", "info": "et", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "14b80778-3b28-48d8-9bff-222d47cd9f6f", "label": "摘要18", "info": "非参数编码器的主要缺点是在给定 x 的情况下需要大量的时间来计算  h；，因为非参数方法需要运行迭代算法。在第14章中讲到的参数化自编码；器方法仅使用固定数量的层，通常只有一层。另一个缺点是它不直接通", "keywords": "的情况下需要大量的时间来计算, 器方法仅使用固定数量的层, 另一个缺点是它不直接通, 章中讲到的参数化自编码, 在第", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "a2037e08-029a-4813-97e8-3e31228d4c30", "label": "摘要19", "info": "像其他线性因子模型一样，稀疏编码经常产生糟糕的样本，如图13.2所；示。即使当模型能够很好地重构数据并为分类器提供有用的特征时，也；会发生这种情况。这种现象发生的原因是每个单独的特征可以很好地被", "keywords": "像其他线性因子模型一样, 即使当模型能够很好地重构数据并为分类器提供有用的特征时, 会发生这种情况, 如图, 稀疏编码经常产生糟糕的样本", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "cc47b75f-784f-4dfe-af07-efb091f4b4f4", "label": "摘要20", "info": "图13.2　尖峰和平板稀疏编码模型上在MNIST数据集训练的样例和权重。（左）这个模型中的；样本和训练样本相差很大。第一眼看来，我们可能认为模型拟合得很差。（右）这个模型的权；重向量已经学习到了如何表示笔迹，有时候还能写完整的数字。因此这个模型也学习到了有用", "keywords": "这个模型的权, 第一眼看来, 样本和训练样本相差很大, 重向量已经学习到了如何表示笔迹, 有时候还能写完整的数字", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "0184762e-742e-4efd-97cf-45b0efd46285", "label": "摘要21", "info": "Goodfellow et al. （2013f）允许转载", "keywords": "允许转载", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "label": "13.5：PCA的流形解释", "level": 2, "group": "chapter-13", "type": "子章節"}, {"id": "3d2a5672-9e75-42d3-b945-6641fc94336d", "label": "摘要1", "info": "线性因子模型，包括PCA和因子分析，可以理解为学习一个流形；（Hinton  et  al.  ，1997）。我们可以将概率PCA定义为高概率的薄饼状；区域，即一个高斯分布，沿着某些轴非常窄，就像薄饼沿着其垂直轴非", "keywords": "区域, 和因子分析, 沿着某些轴非常窄, 我们可以将概率, 线性因子模型", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "6cc8ee79-c2de-4dd9-853e-118bb626de60", "label": "摘要2", "info": "图13.3　平坦的高斯能够描述一个低维流形附近的概率密度。此图表示了“流形平面”上“馅饼”的；上半部分，并且这个平面穿过了馅饼的中心。正交于流形方向（指向平面外的箭头方向）的方；差非常小，可以被视作“噪声”，其他方向（平面内的箭头）的方差则很大，对应了“信号”以及", "keywords": "流形平面, 平坦的高斯能够描述一个低维流形附近的概率密度, 馅饼, 的方, 的方差则很大", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "c6672ae5-6e9a-4fc3-852b-6683e504f996", "label": "摘要3", "info": "编码器表示为", "keywords": "编码器表示为", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "aa365c6a-fb13-41c2-8bc4-e6624acf19ec", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；编码器计算h的低维表示。从自编码器的角度来看，解码器负责计算重；构：", "keywords": "解码器负责计算重, 编码器计算, 的低维表示, 从自编码器的角度来看", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "0447b6d7-675f-4541-aedb-39733d71823b", "label": "摘要5", "info": "能够最小化重构误差", "keywords": "能够最小化重构误差", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "f0326a75-ddf0-441a-90b6-15bd6b8484fd", "label": "摘要6", "info": "的线性编码器和解码器的选择对应着 V ＝ W ，；的列形成一组标准正交基，这组基生成的子空间与协方差矩阵 C", "keywords": "这组基生成的子空间与协方差矩阵, 的列形成一组标准正交基, 的线性编码器和解码器的选择对应着", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "8a850ad0-6bda-4c9b-b667-197e8bd93c12", "label": "摘要7", "info": "， W", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "bee8388f-2348-4bcd-8963-404c5fdba430", "label": "摘要8", "info": "的主特征向量所生成的子空间相同。在PCA中，  W  的列是按照对应特；征值（其全部是实数和非负数）幅度大小排序所对应的特征向量。", "keywords": "其全部是实数和非负数, 的列是按照对应特, 的主特征向量所生成的子空间相同, 征值, 幅度大小排序所对应的特征向量", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "935c744e-929a-455c-9274-a9ab2d6d9547", "label": "摘要9", "info": "我们还可以发现 C 的特征值λ i 对应了 x 在特征向量 ν (i) 方向上的方差。；如果 x ∈；， h ∈  并且满足d＜D，则（给定上述的 µ ， b ， V", "keywords": "给定上述的, 如果, 我们还可以发现, 的特征值, 方向上的方差", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "e501cf46-cedb-4662-bd7b-fd6c32a465af", "label": "摘要10", "info": "因此，如果协方差矩阵的秩为d，则特征值λ  d+1  到λ  D  都为0，并且重构；误差为0。", "keywords": "则特征值, 都为, 因此, 并且重构, 如果协方差矩阵的秩为", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "c54389a8-66d9-4c19-88d9-29f396d1df63", "label": "摘要11", "info": "此外，我们还可以证明上述解可以通过在给定正交矩阵  W  的情况下最；大化 h 元素的方差，而不是最小化重构误差来获得。", "keywords": "此外, 大化, 的情况下最, 而不是最小化重构误差来获得, 我们还可以证明上述解可以通过在给定正交矩阵", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "31abbdcd-3cba-4672-b695-f0477b9dc4d4", "label": "摘要12", "info": "从某种程度上说，线性因子模型是最简单的生成模型和学习数据表示的；最简单模型。许多模型如线性分类器和线性回归模型可以扩展到深度前；馈网络，而这些线性因子模型可以扩展到自编码器网络和深度概率模", "keywords": "馈网络, 线性因子模型是最简单的生成模型和学习数据表示的, 最简单模型, 许多模型如线性分类器和线性回归模型可以扩展到深度前, 而这些线性因子模型可以扩展到自编码器网络和深度概率模", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "9c0a4be0-e3f3-47f8-9dab-9150a9cc7cd4", "label": "摘要13", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "bd35d951-d381-49be-8da3-4bdbc5c4184d", "label": "摘要14", "info": "(1)  第3.8节讨论了不相关变量和独立变量之间的差异。", "keywords": "节讨论了不相关变量和独立变量之间的差异", "level": 3, "group": "chapter-13", "type": "段落"}, {"id": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "label": "第14章：自编码器", "level": 1, "group": "chapter-14", "type": "章節"}, {"id": "0c2b8187-6061-486f-a82b-238e5b2b3686", "label": "13.5：PCA的流形解释", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "b6ce863a-fe7b-4677-8cd1-255e0279036b", "label": "摘要1", "info": "自编码器  （autoencoder）是神经网络的一种，经过训练后能尝试将输；h  ，可以产生编码；入复制到输出。自编码器  内部有一个隐藏层", "keywords": "经过训练后能尝试将输, 内部有一个隐藏层, 是神经网络的一种, 自编码器, 可以产生编码", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "af58a5bb-0b71-42ec-a8dc-2cb46a908d54", "label": "摘要2", "info": "现代自编码器将编码器和解码器的概念推而广之，将其中的确定函数推；广为随机映射p encoder ( h ｜ x )和p decoder ( x ｜ h )。", "keywords": "将其中的确定函数推, 广为随机映射, 现代自编码器将编码器和解码器的概念推而广之", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c6ca9e15-d14e-4aef-a909-802ab67b89fd", "label": "摘要3", "info": "数十年间，自编码器的想法一直是神经网络历史景象的一部分；（LeCun，1987；Bourlard  and  Kamp，1988；Hinton  and  Zemel，；1994）。传统自编码器被用于降维或特征学习。近年来，自编码器与潜", "keywords": "数十年间, 自编码器的想法一直是神经网络历史景象的一部分, 近年来, 自编码器与潜, 传统自编码器被用于降维或特征学习", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "d204da3b-6326-4145-85b4-517b1ac10911", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图14.1　自编码器的一般结构，通过内部表示或编码 h 将输入 x 映射到输出（称为重构） r 。自；编码器具有两个组件：编码器f(将 x 映射到 h )和解码器g(将 h 映射到 r )", "keywords": "编码器, 将输入, 映射到输出, 映射到, 自编码器的一般结构", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "label": "14.1：欠完备自编码器", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "05e55176-79cd-4fad-b443-ea6fdc07183f", "label": "摘要1", "info": "将输入复制到输出听起来没什么用，但我们通常不关心解码器的输出。；相反，我们希望通过训练自编码器对输入进行复制而使 h 获得有用的特；性。", "keywords": "获得有用的特, 将输入复制到输出听起来没什么用, 但我们通常不关心解码器的输出, 我们希望通过训练自编码器对输入进行复制而使, 相反", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "feb3a81f-dc92-4d37-9eac-fad8687bf86c", "label": "摘要2", "info": "从自编码器获得有用特征的一种方法是限制 h 的维度比 x 小，这种编码；维度小于输入维度的自编码器称为欠完备  （undercomplete）自编码；器。学习欠完备的表示将强制自编码器捕捉训练数据中最显著的特征。", "keywords": "自编码, 维度小于输入维度的自编码器称为欠完备, 这种编码, 从自编码器获得有用特征的一种方法是限制, 的维度比", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "056ef51a-310e-43f8-98ef-301d2bb1bbd3", "label": "摘要3", "info": "学习过程可以简单地描述为最小化一个损失函数", "keywords": "学习过程可以简单地描述为最小化一个损失函数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "078821a5-42b5-44b1-bb18-0e1a972715b1", "label": "摘要4", "info": "其中L是一个损失函数，惩罚g(f( x ))与 x 的差异，如均方误差。", "keywords": "其中, 惩罚, 是一个损失函数, 如均方误差, 的差异", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "390f1dea-056f-4288-bcdc-49c07da79aab", "label": "摘要5", "info": "当解码器是线性的且L是均方误差，欠完备的自编码器会学习出与PCA；相同的生成子空间。这种情况下，自编码器在训练来执行复制任务的同；时学到了训练数据的主元子空间。", "keywords": "是均方误差, 欠完备的自编码器会学习出与, 时学到了训练数据的主元子空间, 这种情况下, 相同的生成子空间", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "20352cdd-8f59-4e9a-8a87-c665441e5a10", "label": "摘要6", "info": "因此，拥有非线性编码器函数f和非线性解码器函数g的自编码器能够学；习出更强大的PCA非线性推广。不幸的是，如果编码器和解码器被赋予；过大的容量，自编码器会执行复制任务而捕捉不到任何有关数据分布的", "keywords": "和非线性解码器函数, 因此, 过大的容量, 习出更强大的, 如果编码器和解码器被赋予", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e3fbe242-0b8c-477c-ae38-064968266a52", "label": "14.2：正则自编码器", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "243a9832-c16d-4363-885f-702744591b5e", "label": "摘要1", "info": "14.2.1　稀疏自编码器", "keywords": "稀疏自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e3602308-e0c3-409c-8540-1945c678a6b9", "label": "摘要2", "info": "14.2.2　去噪自编码器", "keywords": "去噪自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5680fd15-29c8-41d4-b397-ee9b1adc5934", "label": "摘要3", "info": "14.2.3　惩罚导数作为正则", "keywords": "惩罚导数作为正则", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "dbddcb73-d489-442e-a8a5-1a4f834e6da5", "label": "摘要4", "info": "编码维数小于输入维数的欠完备自编码器可以学习数据分布最显著的特；征。我们已经知道，如果赋予这类自编码器过大的容量，它就不能学到；任何有用的信息。", "keywords": "如果赋予这类自编码器过大的容量, 编码维数小于输入维数的欠完备自编码器可以学习数据分布最显著的特, 我们已经知道, 它就不能学到, 任何有用的信息", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e69da00a-eb8a-4245-894d-e67f2c49f20d", "label": "摘要5", "info": "如果隐藏编码的维数允许与输入相等，或隐藏编码维数大于输入的过完；备  （overcomplete）情况下，会发生类似的问题。在这些情况下，即使；是线性编码器和线性解码器也可以学会将输入复制到输出，而学不到任", "keywords": "或隐藏编码维数大于输入的过完, 而学不到任, 即使, 是线性编码器和线性解码器也可以学会将输入复制到输出, 情况下", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "defc1a72-91ab-497d-8f96-bcfa2ee4e11a", "label": "摘要6", "info": "理想情况下，根据要建模的数据分布的复杂性，选择合适的编码维数和；编码器、解码器容量，就可以成功训练任意架构的自编码器。正则自编；码器提供这样的能力。正则自编码器使用的损失函数可以鼓励模型学习", "keywords": "根据要建模的数据分布的复杂性, 正则自编码器使用的损失函数可以鼓励模型学习, 码器提供这样的能力, 解码器容量, 就可以成功训练任意架构的自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "02b29c56-e274-4582-8a72-864103f1a313", "label": "摘要7", "info": "除了这里所描述的方法（正则化自编码器最自然的解释），几乎任何带；有潜变量并配有一个推断过程（计算给定输入的潜在表示）的生成模；型，都可以看作自编码器的一种特殊形式。强调与自编码器联系的两个", "keywords": "强调与自编码器联系的两个, 几乎任何带, 有潜变量并配有一个推断过程, 除了这里所描述的方法, 计算给定输入的潜在表示", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "cc330bac-58dd-4775-9d28-52a0759567c0", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；入数据中有用的结构信息，并且也无须对模型进行正则化。这些编码显；然是有用的，因为这些模型被训练为近似训练数据的概率分布而不是将", "keywords": "因为这些模型被训练为近似训练数据的概率分布而不是将, 入数据中有用的结构信息, 然是有用的, 并且也无须对模型进行正则化, 这些编码显", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "04ee0aa2-059f-460c-afaa-b68e79b35e05", "label": "摘要9", "info": "14.2.1　稀疏自编码器", "keywords": "稀疏自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "519b173e-0a15-47b6-a43d-dcc92a84597c", "label": "摘要10", "info": "稀疏自编码器简单地在训练时结合编码层的稀疏惩罚Ω(  h；差：", "keywords": "稀疏自编码器简单地在训练时结合编码层的稀疏惩罚", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "88aaa073-aed5-4874-94e8-3e24f3d808fd", "label": "摘要11", "info": ")和重构误", "keywords": "和重构误", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "43161072-949a-4f5c-9705-20ecc3d092f9", "label": "摘要12", "info": "其中g( h )是解码器的输出，通常 h 是编码器的输出，即 h ＝f( x )。", "keywords": "是编码器的输出, 通常, 其中, 是解码器的输出", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "557b1f25-6b95-46d9-9061-4f4ff3c7ef0e", "label": "摘要13", "info": "稀疏自编码器一般用来学习特征，以便用于像分类这样的任务。稀疏正；则化的自编码器必须反映训练数据集的独特统计特征，而不是简单地充；当恒等函数。以这种方式训练，执行附带稀疏惩罚的复制任务可以得到", "keywords": "而不是简单地充, 执行附带稀疏惩罚的复制任务可以得到, 以便用于像分类这样的任务, 稀疏自编码器一般用来学习特征, 以这种方式训练", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9953dd93-913d-4bcd-88b9-ec9a89bc5399", "label": "摘要14", "info": "我们可以简单地将惩罚项Ω(  h  )视为加到前馈网络的正则项，这个前馈；网络的主要任务是将输入复制到输出（无监督学习的目标），并尽可能；地根据这些稀疏特征执行一些监督学习任务（根据监督学习的目标）。", "keywords": "并尽可能, 根据监督学习的目标, 我们可以简单地将惩罚项, 视为加到前馈网络的正则项, 地根据这些稀疏特征执行一些监督学习任务", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "d8dbea16-727b-4ca3-9f39-3de9a84faf1b", "label": "摘要15", "info": "我们可以认为整个稀疏自编码器框架是对带有潜变量的生成模型的近似；最大似然训练，而不将稀疏惩罚视为复制任务的正则化。假如我们有一；个带有可见变量 x 和潜变量 h 的模型，且具有明确的联合分布p model ( x", "keywords": "和潜变量, 的模型, 我们可以认为整个稀疏自编码器框架是对带有潜变量的生成模型的近似, 且具有明确的联合分布, 假如我们有一", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "ea491dd6-79a7-41d1-a912-3097ad4f0d84", "label": "摘要16", "info": "方式不同，之前指分布p( θ )在我们看到数据前就对模型参数的先验进行；编码。对数似然函数可分解为", "keywords": "编码, 方式不同, 在我们看到数据前就对模型参数的先验进行, 之前指分布, 对数似然函数可分解为", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "2a83c808-c918-4169-98d2-1f262a5636c7", "label": "摘要17", "info": "我们可以认为自编码器使用一个高似然值 h 的点估计近似这个总和。这；类似于稀疏编码生成模型（第13.4节），但  h  是参数编码器的输出，而；不是从优化结果推断出的最可能的h。从这个角度来看，我们根据这个", "keywords": "不是从优化结果推断出的最可能的, 我们根据这个, 类似于稀疏编码生成模型, 是参数编码器的输出, 的点估计近似这个总和", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "62e75a77-028b-4518-aa08-27ef76dedf6b", "label": "摘要18", "info": "log p model ( h )项能被稀疏诱导。如Laplace先验，", "keywords": "先验, 项能被稀疏诱导", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "73ef763a-3f78-459d-9065-0df7d86a3d10", "label": "摘要19", "info": "对应于绝对值稀疏惩罚。将对数先验表示为绝对值惩罚，我们得到", "keywords": "将对数先验表示为绝对值惩罚, 对应于绝对值稀疏惩罚, 我们得到", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "39b81aae-3b78-4b7b-be5f-279a38e156ff", "label": "摘要20", "info": "这里的常数项只跟λ有关。通常我们将λ视为超参数，因此可以丢弃不影；响参数学习的常数项。其他如Student-t先验也能诱导稀疏性。从稀疏性；导致p  model  (  h  )学习成近似最大似然的结果看，稀疏惩罚完全不是一个", "keywords": "稀疏惩罚完全不是一个, 因此可以丢弃不影, 其他如, 从稀疏性, 有关", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "29d4b2c3-f558-41b8-ba22-482716644b5c", "label": "摘要21", "info": "稀疏自编码器的早期工作（Ranzato  et  al.  ，2007a，2008）探讨了各种；形式的稀疏性，并提出了稀疏惩罚和log Z项（将最大似然应用到无向概", "keywords": "稀疏自编码器的早期工作, 探讨了各种, 将最大似然应用到无向概, 形式的稀疏性, 并提出了稀疏惩罚和", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5d54fbd8-2628-446f-a205-5b056ee5f6e0", "label": "摘要22", "info": "率模型", "keywords": "率模型", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "b8b9fb77-3ccc-45ea-8663-9a3d1cc5f5dc", "label": "摘要23", "info": "时产生）之间的联系。这个想", "keywords": "之间的联系, 时产生, 这个想", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "d9cceeea-34f1-40a6-a03d-e057b199cd17", "label": "摘要24", "info": "法是最小化log Z防止概率模型处处具有高概率，同理强制稀疏可以防止", "keywords": "同理强制稀疏可以防止, 法是最小化, 防止概率模型处处具有高概率", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "a3a2ee58-47af-465c-9ab5-c2fde836e144", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；自编码器处处具有低的重构误差。这种情况下，这种联系是对通用机制；的直观理解而不是数学上的对应。在数学上更容易解释稀疏惩罚对应于", "keywords": "这种情况下, 这种联系是对通用机制, 自编码器处处具有低的重构误差, 在数学上更容易解释稀疏惩罚对应于, 的直观理解而不是数学上的对应", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5d2a6658-93be-46f7-abb1-1edcea9a4479", "label": "摘要26", "info": "Glorot et  al. （2011b）提出了一种在稀疏（和去噪）自编码器的 h 中实；现真正为零的方式。该想法是使用整流线性单元产生编码层。基于将表；示真正推向零（如绝对值惩罚）的先验，可以间接控制表示中零的平均", "keywords": "中实, 示真正推向零, 该想法是使用整流线性单元产生编码层, 提出了一种在稀疏, 基于将表", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9b1870c3-40ed-4054-8a1c-ef38712958a1", "label": "摘要27", "info": "14.2.2　去噪自编码器", "keywords": "去噪自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4a6712b8-f14b-4072-8828-2eb48324be4c", "label": "摘要28", "info": "除了向代价函数增加一个惩罚项，我们也可以通过改变重构误差项来获；得一个能学到有用信息的自编码器。", "keywords": "除了向代价函数增加一个惩罚项, 我们也可以通过改变重构误差项来获, 得一个能学到有用信息的自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "08933edc-9210-4c61-98f8-728e729dc652", "label": "摘要29", "info": "传统的自编码器最小化以下目标", "keywords": "传统的自编码器最小化以下目标", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "ab007bc3-823c-44c4-9760-6b8d1c6ba06c", "label": "摘要30", "info": "其中L是一个损失函数，惩罚g(f( x ))与 x 的差异，如它们彼此差异的L 2；范数。如果模型被赋予过大的容量，L仅仅使得g◦f学成一个恒等函数。", "keywords": "如果模型被赋予过大的容量, 其中, 惩罚, 仅仅使得, 是一个损失函数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "28517301-00cb-4b97-9a51-d090cecf243f", "label": "摘要31", "info": "相反，去噪自编码器 （denoising autoencoder，DAE）最小化", "keywords": "最小化, 去噪自编码器, 相反", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "37148dbd-1130-432d-8011-1cce94b9aaaa", "label": "摘要32", "info": "其中   是被某种噪声损坏的  x  的副本。因此去噪自编码器必须撤销这；些损坏，而不是简单地复制输入。", "keywords": "是被某种噪声损坏的, 的副本, 其中, 些损坏, 因此去噪自编码器必须撤销这", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5bea6493-9fdf-4f96-9f9d-17964598ec8b", "label": "摘要33", "info": "Alain and Bengio（2013）和Bengio et al. （2013c）指出去噪训练过程强；制f和g隐式地学习p  data  (  x  )的结构。因此，去噪自编码器也是一个通过；最小化重构误差获取有用特性的例子。这也是将过完备、高容量的模型", "keywords": "去噪自编码器也是一个通过, 因此, 这也是将过完备, 指出去噪训练过程强, 最小化重构误差获取有用特性的例子", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "09433c03-4316-4636-be79-6f5f0a7e257f", "label": "摘要34", "info": "14.2.3　惩罚导数作为正则", "keywords": "惩罚导数作为正则", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "50871430-b261-4b5d-bf44-77ed6a299c10", "label": "摘要35", "info": "另一正则化自编码器的策略是使用一个类似稀疏自编码器中的惩罚项；Ω，", "keywords": "另一正则化自编码器的策略是使用一个类似稀疏自编码器中的惩罚项", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "39fc72e2-c29e-4084-abc6-3eb20aa64e85", "label": "摘要36", "info": "但Ω的形式不同：", "keywords": "的形式不同", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "d611f63c-0b73-4216-89b8-bf3f59d72456", "label": "摘要37", "info": "这迫使模型学习一个在 x  变化小时目标也没有太大变化的函数。因为这；个惩罚只对训练数据适用，它迫使自编码器学习可以反映训练数据分布；信息的特征。", "keywords": "信息的特征, 它迫使自编码器学习可以反映训练数据分布, 因为这, 变化小时目标也没有太大变化的函数, 个惩罚只对训练数据适用", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "6775d8d9-5693-4aeb-97c8-0a49ce3f838a", "label": "摘要38", "info": "这样正则化的自编码器被称为收缩自编码器 （contractive  autoencoder，；CAE）。这种方法与去噪自编码器、流形学习和概率模型存在一定理论；联系。收缩自编码器将在第14.7节更详细地描述。", "keywords": "这种方法与去噪自编码器, 这样正则化的自编码器被称为收缩自编码器, 节更详细地描述, 流形学习和概率模型存在一定理论, 联系", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e154f0a0-0482-4d3d-9b33-e87e007b5dca", "label": "摘要39", "info": "14.2.1　稀疏自编码器", "keywords": "稀疏自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "ba070847-0374-469c-82f1-3264acc1bdc8", "label": "摘要40", "info": "14.2.2　去噪自编码器", "keywords": "去噪自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9401a8c5-ba5c-4cd3-9c37-e766459b8697", "label": "摘要41", "info": "14.2.3　惩罚导数作为正；则", "keywords": "惩罚导数作为正", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "label": "14.3：表示能力、层的大小和深度", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "fd720561-c463-4c03-aca4-fd20ce41b184", "label": "摘要1", "info": "自编码器通常只有单层的编码器和解码器，但这不是必然的。实际上深；度编码器和解码器能提供更多优势。", "keywords": "但这不是必然的, 实际上深, 自编码器通常只有单层的编码器和解码器, 度编码器和解码器能提供更多优势", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "cf843570-77eb-49f7-9129-a594e3e65c3f", "label": "摘要2", "info": "回忆第6.4.1节，其中提到加深前馈网络有很多优势。这些优势也同样适；用于自编码器，因为它也属于前馈网络。此外，编码器和解码器各自都；是一个前馈网络，因此这两个部分也能各自从深度结构中获得好处。", "keywords": "因为它也属于前馈网络, 回忆第, 此外, 编码器和解码器各自都, 用于自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "788be409-ce89-4df8-88d3-97c3d50a9522", "label": "摘要3", "info": "万能近似定理保证至少有一层隐藏层且隐藏单元足够多的前馈神经网络；能以任意精度近似任意函数（在很大范围里），这是非平凡深度（至少；有一层隐藏层）的一个主要优点。这意味着具有单隐藏层的自编码器在", "keywords": "在很大范围里, 这意味着具有单隐藏层的自编码器在, 有一层隐藏层, 的一个主要优点, 至少", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9124f913-f3f1-4e91-83c8-2245b63d6708", "label": "摘要4", "info": "深度可以指数地降低表示某些函数的计算成本。深度也能指数地减少学；习一些函数所需的训练数据量。读者可以参考第6.4.1节巩固深度在前馈", "keywords": "深度也能指数地减少学, 习一些函数所需的训练数据量, 节巩固深度在前馈, 读者可以参考第, 深度可以指数地降低表示某些函数的计算成本", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "f156b2f4-3cc0-48d0-8501-98401188ce46", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；网络中的优势。", "keywords": "网络中的优势", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c5b807fe-15ff-45dd-bcd5-a992ea7b7c97", "label": "摘要6", "info": "实验中，深度自编码器能比相应的浅层或线性自编码器产生更好的压缩；效率（Hinton and Salakhutdinov，2006）。", "keywords": "深度自编码器能比相应的浅层或线性自编码器产生更好的压缩, 实验中, 效率", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "fee54833-d4c1-4887-b43b-99fa541de048", "label": "摘要7", "info": "训练深度自编码器的普遍策略是训练一堆浅层的自编码器来贪心地预训；练相应的深度架构。所以即使最终目标是训练深度自编码器，我们也经；常会遇到浅层自编码器。", "keywords": "练相应的深度架构, 训练深度自编码器的普遍策略是训练一堆浅层的自编码器来贪心地预训, 常会遇到浅层自编码器, 我们也经, 所以即使最终目标是训练深度自编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "682f4267-f1cb-462f-928d-5b42d771ca10", "label": "14.4：随机编码器和解码器", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "fc0f7c7e-9027-4f36-b07d-945423887ca9", "label": "摘要1", "info": "自编码器本质上是一个前馈网络，可以使用与传统前馈网络相同的损失；函数和输出单元。", "keywords": "函数和输出单元, 可以使用与传统前馈网络相同的损失, 自编码器本质上是一个前馈网络", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "82962f90-b8b3-45f7-a961-a5a544b6ed47", "label": "摘要2", "info": "如第6.2.2.4节中描述，设计前馈网络的输出单元和损失函数普遍策略是；定义一个输出分布p( y ｜ x  )并最小化负对数似然−log p( y ｜ x )。在这；种情况下， y 是关于目标的向量（如类标）。", "keywords": "节中描述, 在这, 定义一个输出分布, 如类标, 是关于目标的向量", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "44855884-d2fa-451a-bf6c-587afb9f1a74", "label": "摘要3", "info": "在自编码器中， x 既是输入也是目标。然而，我们仍然可以使用与之前；相同的架构。给定一个隐藏编码 h ，我们可以认为解码器提供了一个条；件分布p model ( x ｜ h )。接着我们根据最小化−log p decoder ( x ｜ h )来训", "keywords": "既是输入也是目标, 接着我们根据最小化, 来训, 在自编码器中, 相同的架构", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e403350b-fadb-40db-a55a-1c64ec1358b2", "label": "摘要4", "info": "为了更彻底地与我们之前了解到的前馈网络相区别，我们也可以将编码；函数  （encoding  function）f(  x  )的概念推广为编码分布  （encoding；distribution）p encoder ( h ｜ x )，如图14.2所示。", "keywords": "为了更彻底地与我们之前了解到的前馈网络相区别, 函数, 所示, 的概念推广为编码分布, 如图", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "ad273dc6-5303-4b90-ab26-fa0c7ddb198e", "label": "摘要5", "info": "任何潜变量模型p model ( h , x )定义一个随机编码器", "keywords": "定义一个随机编码器, 任何潜变量模型", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "d9cf8690-28f2-45a2-bc8d-60ed88f9af86", "label": "摘要6", "info": "以及一个随机解码器", "keywords": "以及一个随机解码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "28200dbc-d923-40f5-beb5-4aaad5e92c52", "label": "摘要7", "info": "图14.2　随机自编码器的结构，其中编码器和解码器包括一些噪声注入，而不是简单的函数。；这意味着可以将它们的输出视为来自分布的采样（对于编码器是p encoder ( h ｜ x )，对于解码器；是p decoder ( x ｜ h )）", "keywords": "对于解码器, 随机自编码器的结构, 而不是简单的函数, 对于编码器是, 其中编码器和解码器包括一些噪声注入", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "309d5ed3-fd3d-47bc-b7ba-f7cf35ff0cb2", "label": "摘要8", "info": "通常情况下，编码器和解码器的分布没有必要是与唯一一个联合分布p；model ( x , h )相容的条件分布。Alain et al. （2015）指出，在保证足够的；容量和样本的情况下，将编码器和解码器作为去噪自编码器训练，能使", "keywords": "指出, 通常情况下, 容量和样本的情况下, 能使, 将编码器和解码器作为去噪自编码器训练", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e55414b2-46e7-4899-84fa-e8a9462cba10", "label": "14.5：去噪自编码器详解", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "1f734ebd-b275-4fb0-8e0e-d87dbee740ee", "label": "摘要1", "info": "14.5.1　得分估计", "keywords": "得分估计", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "40d8b1f3-79f0-4442-aa88-986cb92d4fe6", "label": "摘要2", "info": "14.5.2　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "26b1a9b8-c465-4a9b-9ba8-c4cfd3b765e1", "label": "摘要3", "info": "去噪自编码器  （denoising  autoencoder，DAE）是一类接受损坏数据作；为输入，并训练来预测原始未被损坏数据作为输出的自编码器。", "keywords": "并训练来预测原始未被损坏数据作为输出的自编码器, 为输入, 去噪自编码器, 是一类接受损坏数据作", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "10dbbc95-57ce-417a-9b7f-5d2c2dabe657", "label": "摘要4", "info": "DAE的训练过程如图14.3所示。我们引入一个损坏过程；，这；个条件分布代表给定数据样本x  产生损坏样本   的概率。自编码器则", "keywords": "产生损坏样本, 我们引入一个损坏过程, 的训练过程如图, 的概率, 所示", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c4234698-2d43-45b4-a23d-a57023a0cab5", "label": "摘要5", "info": "x", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "b9bc027e-5745-44dd-8aba-13067e001178", "label": "摘要6", "info": ",", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "b8e3d45b-564b-4865-8bcc-a5f008399a36", "label": "摘要7", "info": "（1）从训练数据中采一个训练样本 x 。", "keywords": "从训练数据中采一个训练样本", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c01f07d7-ed4f-4eaa-9d0c-71792e929e00", "label": "摘要8", "info": "（2）从 C (", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "fef17546-cc50-4d3f-96e8-b7f11f004657", "label": "摘要9", "info": "｜ x ＝ x )采一个损坏样本  。", "keywords": "采一个损坏样本", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4938255f-c89e-4774-8c6b-671abced3d0c", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（3）将（ x ,；x ｜  )＝p decoder ( x ｜ h )，其中 h 是编码器f(", "keywords": "是编码器, 其中", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "8cdff998-5ff5-464b-8e24-9418446e83d2", "label": "摘要11", "info": "）作为训练样本来估计自编码器的重构分布p  reconstruct (；)的输出，p  decoder 根", "keywords": "的输出, 作为训练样本来估计自编码器的重构分布", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c26f428f-d2e2-46a0-bf2a-5acee5a2d9b7", "label": "摘要12", "info": "通常我们可以简单地对负对数似然−log p decoder ( x ｜ h )进行基于梯度法；（如小批量梯度下降）的近似最小化。只要编码器是确定性的，去噪自；编码器就是一个前馈网络，并且可以使用与其他前馈网络完全相同的方", "keywords": "如小批量梯度下降, 只要编码器是确定性的, 编码器就是一个前馈网络, 通常我们可以简单地对负对数似然, 的近似最小化", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4c7f6f82-362f-476a-91ec-4016c3714758", "label": "摘要13", "info": "图14.3　去噪自编码器代价函数的计算图。去噪自编码器被训练为从损坏的版本；))实现，其中；据点 x 。这可以通过最小化损失L＝−log p decoder ( x ｜ h ＝f(", "keywords": "实现, 其中, 去噪自编码器被训练为从损坏的版本, 据点, 这可以通过最小化损失", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "3c24f3a4-e790-4a45-8e39-44346443fb95", "label": "摘要14", "info": "｜ x )后得到的损坏版本。通常，分布p decoder 是因子的分布（平均参数由前馈网", "keywords": "通常, 是因子的分布, 平均参数由前馈网, 分布, 后得到的损坏版本", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c9770066-6b62-4a33-8774-a42b7eb3d381", "label": "摘要15", "info": "重构干净数；是样本 x 经过损", "keywords": "是样本, 重构干净数, 经过损", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "f2d0c9e2-57aa-4df6-9086-cb402d9d4620", "label": "摘要16", "info": "因此我们可以认为DAE是在以下期望下进行随机梯度下降：", "keywords": "是在以下期望下进行随机梯度下降, 因此我们可以认为", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "848e6560-fd2d-4dc8-ad7c-59914627ef68", "label": "摘要17", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "70bf12c8-942f-44c3-b46c-72d5048364b9", "label": "摘要18", "info": "是训练数据的分布。", "keywords": "是训练数据的分布", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "a2f47b6c-c33a-4c85-9ca6-726cb4219bbd", "label": "摘要19", "info": "14.5.1　得分估计", "keywords": "得分估计", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "36f8a7f1-6a6a-45c9-861d-2ff5746bbe85", "label": "摘要20", "info": "得分匹配（Hyvärinen，2005a）是最大似然的代替。它提供了概率分布；的一致估计，促使模型在各个数据点  x  上获得与数据分布相同的得分；（score）。在这种情况下，得分是一个特定的梯度场：", "keywords": "它提供了概率分布, 的一致估计, 在这种情况下, 促使模型在各个数据点, 得分匹配", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "921125fa-b44d-4836-ae5d-b05d33ed1ac1", "label": "摘要21", "info": "我们将在第18.4节中更详细地讨论得分匹配。对于现在讨论的自编码；器，理解学习log p data 的梯度场是学习p data 结构的一种方式就足够了。", "keywords": "节中更详细地讨论得分匹配, 我们将在第, 理解学习, 的梯度场是学习, 对于现在讨论的自编码", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "fda294fa-1349-4a6d-af86-7079e7ba818a", "label": "摘要22", "info": "DAE的训练准则（条件高斯p(  x  ｜  h  )）能让自编码器学到能估计数据；分布得分的向量场（g(f( x ))− x ），这是DAE的一个重要特性，具体如；图14.4所示。", "keywords": "能让自编码器学到能估计数据, 具体如, 这是, 的训练准则, 分布得分的向量场", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4c6b7deb-a768-47cd-9f80-df63482101ba", "label": "摘要23", "info": "图14.4　去噪自编码器被训练为将损坏的数据点；为位于低维流形（粗黑线）附近的红叉。我们用灰色圆圈表示等概率的损坏过程 C (；灰色箭头演示了如何将一个训练样本转换为经过此损坏过程的样本。当训练去噪自编码器最小", "keywords": "粗黑线, 灰色箭头演示了如何将一个训练样本转换为经过此损坏过程的样本, 去噪自编码器被训练为将损坏的数据点, 为位于低维流形, 我们用灰色圆圈表示等概率的损坏过程", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1a40208c-3959-4f8e-9b8f-f351c11000e0", "label": "摘要24", "info": "映射回原始数据点 x 。我们将训练样本 x 表示", "keywords": "表示, 我们将训练样本, 映射回原始数据点", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "f8bec5b9-fa36-41ce-8337-9bdcaf9c1b00", "label": "摘要25", "info": "的平均值时，重构g(f(", "keywords": "的平均值时, 重构", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "39ff90c9-d776-4b31-b861-8c0a138de07b", "label": "摘要26", "info": "｜ x )。", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "ae29ef57-adce-425f-8e95-b02190989c45", "label": "摘要27", "info": "))估计；。对可能产生", "keywords": "估计, 对可能产生", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "2ea98194-4916-4ef6-bf31-0cebacd446a8", "label": "摘要28", "info": "的原始点 x 的质心进行估", "keywords": "的原始点, 的质心进行估", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "b3a2bb01-c480-4a08-9cec-4efa32b31e52", "label": "摘要29", "info": "计，所以向量g(f(", "keywords": "所以向量", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9cbf9daa-ff80-4de2-b1cd-4085b3aeee4a", "label": "摘要30", "info": "))−", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4bf5ea6f-40da-48cf-b3ee-7e57ed71963a", "label": "摘要31", "info": "近似指向流形上最近的点。因此自编码器可以学习由绿色箭头表示的", "keywords": "近似指向流形上最近的点, 因此自编码器可以学习由绿色箭头表示的", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "22637ee7-e262-49c2-a640-389513af996a", "label": "摘要32", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；向量场g(f( x ))− x 。该向量场将得分；方根的平均", "keywords": "方根的平均, 该向量场将得分, 向量场", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "675c348a-7e35-46e2-95fe-fcbe3a4721ec", "label": "摘要33", "info": "估计为一个乘性因子，即重构误差均", "keywords": "估计为一个乘性因子, 即重构误差均", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "0d45a59a-f895-4d4f-9232-7d88704dc601", "label": "摘要34", "info": "对一类采用高斯噪声和均方误差作为重构误差的特定去噪自编码器（具；有sigmoid隐藏单元和线性重构单元）的去噪训练过程，与训练一类特；定的被称为RBM的无向概率模型是等价的（Vincent，2011）。这类模", "keywords": "与训练一类特, 的无向概率模型是等价的, 这类模, 对一类采用高斯噪声和均方误差作为重构误差的特定去噪自编码器, 定的被称为", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1dabce8e-effa-4e4b-8d25-9e4f363b173a", "label": "摘要35", "info": "自编码器和RBM还存在其他联系。在RBM上应用得分匹配后，其代价；函数将等价于重构误差结合类似CAE惩罚的正则项（Swersky  et  al.  ，；2011）。Bengio  and  Delalleau（2009）指出自编码器的梯度是对RBM对", "keywords": "函数将等价于重构误差结合类似, 还存在其他联系, 其代价, 自编码器和, 上应用得分匹配后", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "60ca24be-d278-4ee5-a342-807ee1b11cb7", "label": "摘要36", "info": "对于连续的 x ，高斯损坏和重构分布的去噪准则得到的得分估计适用于；一般编码器和解码器的参数化（Alain and Bengio，2013）。这意味着一；个使用平方误差准则", "keywords": "一般编码器和解码器的参数化, 个使用平方误差准则, 对于连续的, 这意味着一, 高斯损坏和重构分布的去噪准则得到的得分估计适用于", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "8fd21a5e-6efb-4497-9643-7f575fb08d20", "label": "摘要37", "info": "和噪声方差为σ 2 的损坏", "keywords": "的损坏, 和噪声方差为", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "75cf1e5d-cf50-4109-9317-dc47f3e6fa04", "label": "摘要38", "info": "的通用编码器-解码器架构可以用来训练估计得分。图14.5展示了其中的；工作原理。", "keywords": "展示了其中的, 解码器架构可以用来训练估计得分, 的通用编码器, 工作原理", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "550c1836-53f8-4b8d-a67c-e5a50f6b0f7c", "label": "摘要39", "info": "图14.5　由去噪自编码器围绕一维弯曲流形学习的向量场，其中数据集中在二维空间中。每个；箭头与重构向量减去自编码器的输入向量后的向量成比例，并且根据隐式估计的概率分布指向；较高的概率。向量场在估计的密度函数的最大值处（在数据流形上）和密度函数的最小值处都", "keywords": "箭头与重构向量减去自编码器的输入向量后的向量成比例, 其中数据集中在二维空间中, 由去噪自编码器围绕一维弯曲流形学习的向量场, 在数据流形上, 并且根据隐式估计的概率分布指向", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "6056a966-3d1e-4896-8b69-3b533931659a", "label": "摘要40", "info": "一般情况下，不能保证重构函数g(f( x ))减去输入 x 后对应于某个函数的；梯度，更不用说得分。这是早期工作（Vincent，2011）专用于特定参数；x  能通过另一个函数的导数获得）。", "keywords": "减去输入, 梯度, 这是早期工作, 能通过另一个函数的导数获得, 专用于特定参数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "39252fa8-49ad-48a3-b0af-fc85b25b01b3", "label": "摘要41", "info": "))−", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "7118620e-3b0e-44c7-b28b-ba97e5307e15", "label": "摘要42", "info": "x", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "b1d5a205-fb6e-41b7-a27b-f9897e10d6c2", "label": "摘要43", "info": "目前为止我们所讨论的仅限于去噪自编码器如何学习表示一个概率分；布。更一般的，我们可能希望使用自编码器作为生成模型，并从其分布；中进行采样。这将在第20.11节中讨论。", "keywords": "更一般的, 目前为止我们所讨论的仅限于去噪自编码器如何学习表示一个概率分, 我们可能希望使用自编码器作为生成模型, 这将在第, 并从其分布", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "2fe67d1f-7349-4ed7-b5f6-70f6132978d7", "label": "摘要44", "info": "14.5.2　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "bc738eee-ed2a-4a1a-9c1c-0ab5aade3653", "label": "摘要45", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；et", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "bcb169be-1f06-46f0-b235-99661dae904d", "label": "摘要46", "info": "采用MLP去噪的想法可以追溯到LeCun（1987）和Gallinari；al.；（1987）的工作。Behnke（2001）也曾使用循环网络对图像去噪。在某", "keywords": "采用, 在某, 去噪的想法可以追溯到, 也曾使用循环网络对图像去噪, 的工作", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "8ca830e2-ff25-438c-891e-fa1af029e564", "label": "摘要47", "info": "在引入现代DAE之前，Inayoshi and Kurita（2005）探索了其中一些相同；的方法和目标。他们除了在监督目标的情况下最小化重构误差之外，还；在监督MLP的隐藏层注入噪声，通过引入重构误差和注入噪声提升泛化", "keywords": "探索了其中一些相同, 在引入现代, 在监督, 通过引入重构误差和注入噪声提升泛化, 他们除了在监督目标的情况下最小化重构误差之外", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4b7ed0f2-4cac-400e-9ce6-fc29cff09391", "label": "摘要48", "info": "14.5.1　得分估计", "keywords": "得分估计", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1c5ac0b9-de78-4075-b21b-fce6086b186a", "label": "摘要49", "info": "14.5.2　历史展望", "keywords": "历史展望", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1c86de8c-f3e2-43d3-8794-0422fada648f", "label": "14.6：使用自编码器学习流形", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "08368a43-afb3-410c-86f6-eefcbfcc55d2", "label": "摘要1", "info": "如第5.11.3节描述，自编码器跟其他很多机器学习算法一样，也利用了；数据集中在一个低维流形或者一小组这样的流形的思想。其中一些机器；学习算法仅能学习到在流形上表现良好但给定不在流形上的输入会导致", "keywords": "节描述, 数据集中在一个低维流形或者一小组这样的流形的思想, 自编码器跟其他很多机器学习算法一样, 也利用了, 学习算法仅能学习到在流形上表现良好但给定不在流形上的输入会导致", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9281c124-891d-4731-b704-0b7c7a8b8470", "label": "摘要2", "info": "要了解自编码器如何做到这一点，我们必须介绍流形的一些重要特性。", "keywords": "要了解自编码器如何做到这一点, 我们必须介绍流形的一些重要特性", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "930f1020-cabf-4c5b-b638-c6cd1f5483fe", "label": "摘要3", "info": "流形的一个重要特征是切平面 （tangent plane）的集合。d维流形上的一；点  x  ，切平面由能张成流形上允许变动的局部方向的d维基向量给出。；如图14.6所示，这些局部方向决定了我们能如何微小地变动  x  而保持于", "keywords": "维基向量给出, 而保持于, 所示, 这些局部方向决定了我们能如何微小地变动, 维流形上的一", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "36b7bfd0-1aa9-403c-9cda-3888c6e31b72", "label": "摘要4", "info": "所有自编码器的训练过程涉及两种推动力的折衷：", "keywords": "所有自编码器的训练过程涉及两种推动力的折衷", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5f03aede-269c-47e0-959b-60b8310863dc", "label": "摘要5", "info": "（1）学习训练样本  x  的表示  h  使得  x  能通过解码器近似地从  h  中恢；复。 x 是从训练数据挑出的这一事实很关键，因为这意味着在自编码器；不需要成功重构不属于数据生成分布下的输入。", "keywords": "的表示, 学习训练样本, 能通过解码器近似地从, 中恢, 是从训练数据挑出的这一事实很关键", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "bcaafdbb-0d05-43e7-962c-e1d2542ee19f", "label": "摘要6", "info": "（2）满足约束或正则惩罚。这既可以是限制自编码器容量的架构约；束，也可以是加入到重构代价的一个正则项。这些技术一般倾向那些对；输入较不敏感的解。", "keywords": "满足约束或正则惩罚, 输入较不敏感的解, 也可以是加入到重构代价的一个正则项, 这些技术一般倾向那些对, 这既可以是限制自编码器容量的架构约", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "440f1dec-1203-40e8-855e-7961e6f32be3", "label": "摘要7", "info": "显然，单一的推动力是无用的——从它本身将输入复制到输出是无用；的，同样忽略输入也是没用的。相反，两种推动力结合是有用的，因为；它们驱使隐藏的表示能捕获有关数据分布结构的信息。重要的原则是，", "keywords": "显然, 两种推动力结合是有用的, 因为, 重要的原则是, 单一的推动力是无用的", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c702ab20-188d-4437-a1c8-854fc394bbbb", "label": "摘要8", "info": "图14.7中一维的例子说明，我们可以通过构建对数据点周围的输入扰动；不敏感的重构函数，使得自编码器恢复流形结构。", "keywords": "我们可以通过构建对数据点周围的输入扰动, 使得自编码器恢复流形结构, 不敏感的重构函数, 中一维的例子说明", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "191f28fe-c438-446b-87c7-822fb392819b", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图14.6　正切超平面概念的图示。我们在784维空间中创建了一维流形。我们使用一张784像素；的MNIST图像，并通过垂直平移来转换它。垂直平移的量定义沿着一维流形的坐标，轨迹为通", "keywords": "维空间中创建了一维流形, 正切超平面概念的图示, 像素, 图像, 轨迹为通", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "301ec334-413e-45a3-90b7-3bcbfdf5f814", "label": "摘要10", "info": "图14.7　如果自编码器学习到对数据点附近的小扰动不变的重构函数，它就能捕获数据的流形；结构。这里，流形结构是0维流形的集合。虚线对角线表示重构的恒等函数目标。最佳重构函数；会在存在数据点的任意处穿过恒等函数。图底部的水平箭头表示在输入空间中基于箭头的 r ( x )", "keywords": "图底部的水平箭头表示在输入空间中基于箭头的, 流形结构是, 最佳重构函数, 如果自编码器学习到对数据点附近的小扰动不变的重构函数, 这里", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9730e9cc-a08e-4fc9-a27e-cc46eb4eac0a", "label": "摘要11", "info": "为了理解自编码器可用于流形学习的原因，我们可以将自编码器和其他；方法进行对比。学习表征流形最常见的是流形上（或附近）数据点的表；示  （representation）。对于特定的实例，这样的表示也被称为嵌入。它", "keywords": "学习表征流形最常见的是流形上, 我们可以将自编码器和其他, 或附近, 数据点的表, 方法进行对比", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "a2d4b5aa-216d-4d53-a560-b7b178e95c4c", "label": "摘要12", "info": "流形学习大多专注于试图捕捉到这些流形的无监督学习过程。最初始的；学习非线性流形的机器学习研究专注基于最近邻图  （nearest  neighbor；graph）的非参数  （non-parametric）方法。该图中每个训练样例对应一", "keywords": "该图中每个训练样例对应一, 的非参数, 流形学习大多专注于试图捕捉到这些流形的无监督学习过程, 学习非线性流形的机器学习研究专注基于最近邻图, 最初始的", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9ef206b9-bceb-4b49-8593-51875a4a8217", "label": "摘要13", "info": "al. ，1998b；Roweis and Saul，2000；Tenenbaum et al. ，2000；Brand，；2003b；Belkin；and  Grimes，2003；", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "3d5891e4-41ee-4ea0-a3f9-7908e642a813", "label": "摘要14", "info": "and  Niyogi，2003a；Donoho", "keywords": "", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9e09992e-dee0-44dc-9e44-c5133d1726e6", "label": "摘要15", "info": "图14.8　非参数流形学习过程构建的最近邻图，其中节点表示训练样本，有向边指示最近邻关；系。因此，各种过程可以获得与图的邻域相关联的切平面以及将每个训练样本与实值向量位置；或 嵌入 （embedding）相关联的坐标系。我们可以通过插值将这种表示概括为新的样本。只要", "keywords": "其中节点表示训练样本, 相关联的坐标系, 因此, 嵌入, 有向边指示最近邻关", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "97a4fc8e-7304-4398-9bf6-6cb37538e211", "label": "摘要16", "info": "全局坐标系则可以通过优化或求解线性系统获得。图14.9展示了如何通；过大量局部线性的类高斯样平铺（或“薄煎饼”，因为高斯块在切平面方；向是扁平的）得到一个流形。", "keywords": "过大量局部线性的类高斯样平铺, 展示了如何通, 向是扁平的, 薄煎饼, 因为高斯块在切平面方", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "79988209-5c9c-4245-85e3-aafd7c1f6145", "label": "摘要17", "info": "然而，Bengio  and  Monperrus（2005）指出了这些局部非参数方法应用；于流形学习的根本困难：如果流形不是很光滑（它们有许多波峰、波谷；和曲折），为覆盖其中的每一个变化，我们可能需要非常多的训练样", "keywords": "和曲折, 指出了这些局部非参数方法应用, 我们可能需要非常多的训练样, 然而, 它们有许多波峰", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c22296a5-75de-4cb0-8448-18d69237ab55", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；能具有非常复杂的结构，难以仅从局部插值捕获特征。考虑图14.6转换；所得的流形样例。如果我们只观察输入向量内的一个坐标x i ，当平移图", "keywords": "能具有非常复杂的结构, 难以仅从局部插值捕获特征, 所得的流形样例, 考虑图, 转换", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "2a580fbe-c45b-4fbf-a443-8fae1d4a8b15", "label": "摘要19", "info": "图14.9　如果每个位置处的切平面（见图14.6）是已知的，则它们可以平铺后形成全局坐标系或；密度函数。每个局部块可以被认为是局部欧几里德坐标系，或者是局部平面高斯或“薄饼”，在；与薄饼正交的方向上具有非常小的方差而在定义坐标系的方向上具有非常大的方差。这些高斯", "keywords": "是已知的, 这些高斯, 密度函数, 如果每个位置处的切平面, 薄饼", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "label": "14.7：收缩自编码器", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "e78a68c0-fddf-4a65-92a4-bfba53903ee0", "label": "摘要1", "info": "收缩自编码器（Rifai et  al. ，2011a，b）在编码 h ＝f( x )的基础上添加；了显式的正则项，鼓励f的导数尽可能小：", "keywords": "收缩自编码器, 了显式的正则项, 在编码, 的导数尽可能小, 的基础上添加", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9fb916c5-fff7-432a-9970-5133ed568204", "label": "摘要2", "info": "惩罚项Ω(  h  )为平方Frobenius范数（元素平方之和），作用于与编码器", "keywords": "作用于与编码器, 惩罚项, 范数, 为平方, 元素平方之和", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4bcbfd08-a38f-4663-8370-e4bc9080d3cc", "label": "摘要3", "info": "的函数相关偏导数的的Jacobian矩阵。", "keywords": "的函数相关偏导数的的, 矩阵", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "0683fbca-4e0d-4da3-94fc-26c6ebcfe1d1", "label": "摘要4", "info": "去噪自编码器和收缩自编码器之间存在一定联系：Alain；and；Bengio（2013）指出在小高斯噪声的限制下，当重构函数将  x  映射到  r", "keywords": "指出在小高斯噪声的限制下, 去噪自编码器和收缩自编码器之间存在一定联系, 当重构函数将, 映射到", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "86146dde-1c1b-44c8-94f7-5d44e052381d", "label": "摘要5", "info": "分类任务中，基于Jacobian的收缩惩罚预训练特征函数f(  x  )，将收缩惩；罚应用在f( x )而不是g(f(  x  ))可以产生最好的分类精度。如第14.5.1节所；讨论的，应用于f( x )的收缩惩罚与得分匹配也有紧密的联系。", "keywords": "应用于, 可以产生最好的分类精度, 讨论的, 的收缩惩罚与得分匹配也有紧密的联系, 而不是", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5e446d4f-7cd0-4f5a-a49b-e92d36f96d2a", "label": "摘要6", "info": "收缩  （contractive）源于CAE弯曲空间的方式。具体来说，由于CAE训；练为抵抗输入扰动，鼓励将输入点邻域映射到输出点处更小的邻域。我；们能认为这是将输入的邻域收缩到更小的输出邻域。", "keywords": "们能认为这是将输入的邻域收缩到更小的输出邻域, 弯曲空间的方式, 收缩, 鼓励将输入点邻域映射到输出点处更小的邻域, 由于", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1b829b6c-06a5-478d-bd93-db8c3185e6b5", "label": "摘要7", "info": "说得更清楚一点，CAE只在局部收缩——一个训练样本 x 的所有扰动都；映射到f( x )的附近。全局来看，两个不同的点 x 和 x ＇会分别被映射到；远离原点的两个点f(  x  )和f(  x  ＇)。f扩展到数据流形的中间或远处是合", "keywords": "一个训练样本, 远离原点的两个点, 两个不同的点, 的所有扰动都, 只在局部收缩", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e209d306-a4d4-4186-a5f7-e9bc2086c080", "label": "摘要8", "info": "我们可以认为点  x  处的Jacobian矩阵  J  能将非线性编码器近似为线性算；子。这允许我们更形式地使用“收缩”这个词。在线性理论中，当  Jx  的；范数对于所有单位  x  都小于等于1时，  J  被称为收缩的。换句话说，如", "keywords": "换句话说, 收缩, 这个词, 在线性理论中, 这允许我们更形式地使用", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "802f2a64-0698-49d6-99a3-a1b67c12e169", "label": "摘要9", "info": "如第14.6节中描述，正则自编码器基于两种相反的推动力学习流形。在；CAE的情况下，这两种推动力是重构误差和收缩惩罚Ω(  h  )。单独的重；构误差鼓励CAE学习一个恒等函数。单独的收缩惩罚将鼓励CAE学习关", "keywords": "单独的重, 学习一个恒等函数, 单独的收缩惩罚将鼓励, 正则自编码器基于两种相反的推动力学习流形, 这两种推动力是重构误差和收缩惩罚", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "74cd3f53-80de-47c1-80f2-3020b62b136c", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；于  x  是恒定的特征。这两种推动力的的折衷产生导数", "keywords": "是恒定的特征, 这两种推动力的的折衷产生导数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c9b84b0c-d055-4ec1-9a22-b407939197ab", "label": "摘要11", "info": "大多是", "keywords": "大多是", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "afc355fa-946e-4864-9227-0205c438bc3b", "label": "摘要12", "info": "微小的自编码器。只有少数隐藏单元，对应于一小部分输入数据的方；向，可能有显著的导数。", "keywords": "微小的自编码器, 对应于一小部分输入数据的方, 只有少数隐藏单元, 可能有显著的导数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5789db87-74a3-40a3-abd3-363cc5f4518c", "label": "摘要13", "info": "CAE的目标是学习数据的流形结构。使  Jx  很大的方向  x  ，会快速改变；h  ，因此很可能是近似流形切平面的方向。Rifai  et  al.  （2011a，b）的；实验显示训练CAE会导致  J  中大部分奇异值（幅值）比1小，因此是收", "keywords": "实验显示训练, 的目标是学习数据的流形结构, 会快速改变, 因此是收, 会导致", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "faa51386-8d5e-4f3c-a3d3-0e2f0cdef29a", "label": "摘要14", "info": "图14.10　通过局部PCA和收缩自编码器估计的流形切向量的图示。流形的位置由来自CIFAR-10", "keywords": "流形的位置由来自, 通过局部, 和收缩自编码器估计的流形切向量的图示", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "195dd2f6-a639-4ec4-871b-101dc76d43ae", "label": "摘要15", "info": "数据集中狗的输入图像定义。切向量通过输入到代码映射的Jacobian矩阵", "keywords": "数据集中狗的输入图像定义, 矩阵, 切向量通过输入到代码映射的", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "0705e5d2-cc06-42bd-9f0a-61a5c1587d6e", "label": "摘要16", "info": "的前导奇异向量", "keywords": "的前导奇异向量", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5ef1f9d0-a2bf-4daa-a6a1-dde7dd71c685", "label": "摘要17", "info": "估计。虽然局部PCA和CAE都可以捕获局部切方向，但CAE能够从有限训练数据形成更准确的；估计，因为它利用了不同位置的参数共享（共享激活的隐藏单元子集）。CAE切方向通常对应；于物体的移动或改变部分（例如头或腿）。经Rifai et al. （2011c）许可转载此图", "keywords": "估计, 许可转载此图, 于物体的移动或改变部分, 共享激活的隐藏单元子集, 例如头或腿", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4fe30ae5-4491-4771-ada4-06534e18eeb3", "label": "摘要18", "info": "收缩自编码器正则化准则的一个实际问题是，尽管它在单一隐藏层的自；编码器情况下是容易计算的，但在更深的自编码器情况下会变得难以计；算。根据Rifai  et  al.  （2011a）的策略，分别训练一系列单层的自编码", "keywords": "收缩自编码器正则化准则的一个实际问题是, 根据, 的策略, 编码器情况下是容易计算的, 但在更深的自编码器情况下会变得难以计", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "1f4fad65-77a4-41c0-a0c2-ed055cfe2802", "label": "摘要19", "info": "度自编码器自然也是收缩的。这个结果与联合训练深度模型完整架构；（带有关于Jacobian的惩罚项）获得的结果是不同的，但它抓住了许多；理想的定性特征。", "keywords": "的惩罚项, 带有关于, 这个结果与联合训练深度模型完整架构, 度自编码器自然也是收缩的, 但它抓住了许多", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "84bcfdfb-7055-47d3-9762-3a301e69f41e", "label": "摘要20", "info": "另一个实际问题是，如果我们不对解码器强加一些约束，收缩惩罚可能；导致无用的结果。例如，编码器将输入乘一个小常数   ，解码器将编；码除以一个小常数  。随着  趋向于0，编码器会使收缩惩罚项Ω( h )", "keywords": "导致无用的结果, 如果我们不对解码器强加一些约束, 趋向于, 码除以一个小常数, 编码器将输入乘一个小常数", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "c4313204-9c3e-4156-85f2-2c3eedda6168", "label": "14.8：预测稀疏分解", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "4e139601-d947-49ea-a283-bbb3f488dfb4", "label": "摘要1", "info": "预测稀疏分解 （predictive sparse decomposition，PSD）是稀疏编码和参；数化自编码器（Kavukcuoglu et al. ，2008）的混合模型。参数化编码器；被训练为能预测迭代推断的输出。PSD被应用于图片和视频中对象识别", "keywords": "的混合模型, 预测稀疏分解, 数化自编码器, 被训练为能预测迭代推断的输出, 被应用于图片和视频中对象识别", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "428f9cef-4200-463f-b01f-e077711f6b05", "label": "摘要2", "info": "就像稀疏编码，训练算法交替地相对 h 和模型的参数最小化上述目标。；相对 h 最小化较快，因为f( x )提供 h 的良好初始值以及损失函数将 h 约；束在f( x )附近。简单的梯度下降算法只需10步左右就能获得理想的 h 。", "keywords": "相对, 训练算法交替地相对, 最小化较快, 因为, 附近", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "9c90817c-d4b5-4cdd-a61b-ae274056f5fd", "label": "摘要3", "info": "PSD所使用的训练程序不是先训练稀疏编码模型，然后训练f(  x  )来预测；稀疏编码的特征。PSD训练过程正则化解码器，使用f(  x  )可以推断出良；好编码的参数。", "keywords": "稀疏编码的特征, 所使用的训练程序不是先训练稀疏编码模型, 训练过程正则化解码器, 然后训练, 可以推断出良", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "4fc4698a-5525-4c0f-9956-fcbd260e7408", "label": "摘要4", "info": "预测稀疏分解是学习近似推断 （learned appro x imate inference）的一个；例子。在第19.5节中，这个话题将会进一步展开。第19章中展示的工具；能让我们了解到，PSD能够被解释为通过最大化模型的对数似然下界训", "keywords": "章中展示的工具, 的一个, 能让我们了解到, 节中, 预测稀疏分解是学习近似推断", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "8848a701-9d84-49b0-a5e6-d05f3db99d38", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在PSD的实际应用中，迭代优化仅在训练过程中使用。模型被部署后，；参数编码器f用于计算已经习得的特征。相比通过梯度下降推断  h  ，计", "keywords": "相比通过梯度下降推断, 的实际应用中, 模型被部署后, 迭代优化仅在训练过程中使用, 参数编码器", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "label": "14.9：自编码器的应用", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "b1bcfa5c-86d1-49e6-b2a1-f1e7b838679e", "label": "摘要1", "info": "自编码器已成功应用于降维和信息检索任务。降维是表示学习和深度学；习的第一批应用之一。它是研究自编码器早期驱动力之一。例如，；Hinton  and  Salakhutdinov（2006）训练了一个栈式RBM，然后利用它们", "keywords": "习的第一批应用之一, 然后利用它们, 降维是表示学习和深度学, 例如, 它是研究自编码器早期驱动力之一", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "3f214f35-4784-4ffd-b46e-cfe0cba2bed5", "label": "摘要2", "info": "低维表示可以提高许多任务的性能，例如分类。小空间的模型消耗更少；的内存和运行时间。据Salakhutdinov  and  Hinton（2007b）和Torralba  et；al.  （2008）观察，许多降维的形式会将语义上相关的样本置于彼此邻", "keywords": "低维表示可以提高许多任务的性能, 许多降维的形式会将语义上相关的样本置于彼此邻, 例如分类, 的内存和运行时间, 小空间的模型消耗更少", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "714472eb-a006-4e4f-9eb5-ded52c7dcf7c", "label": "摘要3", "info": "相比普通任务，信息检索  （information  retrieval）从降维中获益更多，；此任务需要找到数据库中类似查询的条目。此任务不仅和其他任务一样；从降维中获得一般益处，还使某些低维空间中的搜索变得极为高效。特", "keywords": "从降维中获得一般益处, 相比普通任务, 还使某些低维空间中的搜索变得极为高效, 此任务需要找到数据库中类似查询的条目, 从降维中获益更多", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "2990a9bc-7527-43f5-8fa5-5a74e30c4aad", "label": "摘要4", "info": "通常在最终层上使用sigmoid编码函数产生语义哈希的二值编码。；sigmoid单元必须被训练为到达饱和，对所有输入值都接近0或接近1。；能做到这一点的窍门就是训练时在sigmoid非线性单元前简单地注入加", "keywords": "能做到这一点的窍门就是训练时在, 单元必须被训练为到达饱和, 编码函数产生语义哈希的二值编码, 非线性单元前简单地注入加, 或接近", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "84880f9b-05a2-4fec-a640-bcc8738e9003", "label": "摘要5", "info": "学习哈希函数的思想已在其他多个方向进一步探讨，包括改变损失训练；表示的想法，其中所需优化的损失与哈希表中查找附近样本的任务有更；直接的联系（Norouzi and Fleet，2011）。", "keywords": "表示的想法, 学习哈希函数的思想已在其他多个方向进一步探讨, 直接的联系, 包括改变损失训练, 其中所需优化的损失与哈希表中查找附近样本的任务有更", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "e9b09991-a6cd-427c-b123-0c800ba404c1", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；第15章　表示学习", "keywords": "表示学习", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "5aafed38-d568-4557-bb8d-6da1f1a265b5", "label": "15.1：贪心逐层无监督预训练", "level": 2, "group": "chapter-14", "type": "子章節"}, {"id": "de1ac076-0f57-4f49-9bb8-4045ce94d486", "label": "摘要1", "info": "15.1.1　何时以及为何无；监督预训练有效有效", "keywords": "何时以及为何无, 监督预训练有效有效", "level": 3, "group": "chapter-14", "type": "段落"}, {"id": "756da707-03b0-45a1-a6cc-d157ab898e19", "label": "第15章：表示学习", "level": 1, "group": "chapter-15", "type": "章節"}, {"id": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "label": "14.9：自编码器的应用", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "81aa421b-9b93-4517-aeb1-ccd5e737c7b2", "label": "摘要1", "info": "在本章中，首先我们会讨论表示学习是什么意思，以及表示的概念如何；有助于深度框架的设计。我们探讨学习算法如何在不同任务中共享统计；信息，包括使用无监督任务中的信息来完成监督任务。共享表示有助于", "keywords": "首先我们会讨论表示学习是什么意思, 有助于深度框架的设计, 信息, 包括使用无监督任务中的信息来完成监督任务, 共享表示有助于", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "05336a6c-68af-45b2-a0c0-c22206f3a980", "label": "摘要2", "info": "很多信息处理任务可能非常容易，也可能非常困难，这取决于信息是如；何表示的。这是一个广泛适用于日常生活、计算机科学及机器学习的基；本原则。例如，对于人而言，可以直接使用长除法计算210除以6。但如", "keywords": "可以直接使用长除法计算, 除以, 这取决于信息是如, 但如, 何表示的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "59ec13de-e7bb-41eb-87c8-09b6e06cd017", "label": "摘要3", "info": "在机器学习中，到底是什么因素决定了一种表示比另一种表示更好呢？；一般而言，一个好的表示可以使后续的学习任务更容易。选择什么表示；通常取决于后续的学习任务。", "keywords": "一个好的表示可以使后续的学习任务更容易, 到底是什么因素决定了一种表示比另一种表示更好呢, 在机器学习中, 通常取决于后续的学习任务, 选择什么表示", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9ce5507f-b792-4621-a277-f2c88a6e3f10", "label": "摘要4", "info": "我们可以将监督学习训练的前馈网络视为表示学习的一种形式。具体；地，网络的最后一层通常是线性分类器，如softmax回归分类器。网络；的其余部分学习出该分类器的表示。监督学习训练模型，一般会使得模", "keywords": "网络, 具体, 监督学习训练模型, 的其余部分学习出该分类器的表示, 我们可以将监督学习训练的前馈网络视为表示学习的一种形式", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f2de9bda-3de3-440a-9137-47df481d7642", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最后一层的类型学习不同的性质。", "keywords": "最后一层的类型学习不同的性质", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "27c3195e-d782-4745-802d-65c820528cb0", "label": "摘要6", "info": "前馈网络的监督训练并没有给学成的中间特征明确强加任何条件。其他；的表示学习算法往往会以某种特定的方式明确设计表示。例如，我们想；要学习一种使得密度估计更容易的表示。具有更多独立性的分布会更容", "keywords": "要学习一种使得密度估计更容易的表示, 我们想, 具有更多独立性的分布会更容, 前馈网络的监督训练并没有给学成的中间特征明确强加任何条件, 例如", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "10afcf46-c489-4313-8b56-44bce2b6a556", "label": "摘要7", "info": "大多数表示学习算法都会在尽可能多地保留与输入相关的信息和追求良；好的性质（如独立性）之间作出权衡。", "keywords": "好的性质, 如独立性, 大多数表示学习算法都会在尽可能多地保留与输入相关的信息和追求良, 之间作出权衡", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9cba6734-189a-41ad-b522-8b983dc6424a", "label": "摘要8", "info": "表示学习特别有趣，因为它提供了进行无监督学习和半监督学习的一种；方法。我们通常会有巨量的未标注训练数据和相对较少的标注训练数；据。在非常有限的标注数据集上监督学习通常会导致严重的过拟合。半", "keywords": "因为它提供了进行无监督学习和半监督学习的一种, 在非常有限的标注数据集上监督学习通常会导致严重的过拟合, 我们通常会有巨量的未标注训练数据和相对较少的标注训练数, 表示学习特别有趣, 方法", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5214a9eb-30f0-4cd6-a9e6-965af67d3c40", "label": "摘要9", "info": "人类和动物能够从非常少的标注样本中学习。我们至今仍不知道这是如；何做到的。有许多假说解释人类的卓越学习能力——例如，大脑可能使；用了大量的分类器或者贝叶斯推断技术的集成。一种流行的假说是，大", "keywords": "有许多假说解释人类的卓越学习能力, 人类和动物能够从非常少的标注样本中学习, 例如, 何做到的, 我们至今仍不知道这是如", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "label": "15.1：贪心逐层无监督预训练", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "f031c0f2-470a-4440-81f3-79d8aa23d95f", "label": "摘要1", "info": "15.1.1　何时以及为何无监督预训练有效有效", "keywords": "何时以及为何无监督预训练有效有效", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "1101b47b-e76d-47bc-b8f0-41ecff0155bf", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；15.2　迁移学习和领域自适应", "keywords": "迁移学习和领域自适应", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e268c901-721d-4788-89e8-2d5d6db3e35b", "label": "摘要3", "info": "无监督学习在深度神经网络的复兴上起到了关键的、历史性的作用，它；使研究者首次可以训练不含诸如卷积或者循环这类特殊结构的深度监督；（unsupervised", "keywords": "无监督学习在深度神经网络的复兴上起到了关键的, 历史性的作用, 使研究者首次可以训练不含诸如卷积或者循环这类特殊结构的深度监督", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2c20d956-c4d0-4ef0-a0bf-0327130eef70", "label": "摘要4", "info": "贪心逐层无监督预训练依赖于单层表示学习算法，例如RBM、单层自；编码器、稀疏编码模型或其他学习潜在表示的模型。每一层使用无监督；学习预训练，将前一层的输出作为输入，输出数据的新的表示。这个新", "keywords": "这个新, 贪心逐层无监督预训练依赖于单层表示学习算法, 例如, 学习预训练, 输出数据的新的表示", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "7cf9bde8-8142-4dcf-9e41-cc3c1efcb6d9", "label": "摘要5", "info": "算法15.1 贪心逐层无监督预训练的协定。", "keywords": "贪心逐层无监督预训练的协定, 算法", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "7de044f4-eab3-48c2-859d-48164772c20a", "label": "摘要6", "info": "给定如下：无监督特征学习算法；使用训练集样本并返回编码；器或特征函数f。原始输入数据是 X ，每行一个样本，并且f (1)  ( x )是第", "keywords": "原始输入数据是, 器或特征函数, 使用训练集样本并返回编码, 无监督特征学习算法, 给定如下", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e0b6969b-a08c-4640-a1a9-b90809b1323c", "label": "摘要7", "info": "目标 Y ），并返回细调好函数。阶段数为m。", "keywords": "目标, 阶段数为, 并返回细调好函数", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "08ebf2e4-d3d7-45f0-b5b2-cc28709229b2", "label": "摘要8", "info": "基于无监督标准的贪心逐层训练过程，早已被用来规避监督问题中深度；神经网络难以联合训练多层的问题。这种方法至少可以追溯神经认知机；（Fukushima，1975）。深度学习的复兴始于2006年，源于发现这种贪", "keywords": "源于发现这种贪, 这种方法至少可以追溯神经认知机, 早已被用来规避监督问题中深度, 基于无监督标准的贪心逐层训练过程, 神经网络难以联合训练多层的问题", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e30c88ba-905b-4abc-849b-2eb7c11cba36", "label": "摘要9", "info": "al.  ，2006b；Hinton", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "892a8d6d-7e21-4b3d-880d-5c613addbaa3", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；贪心逐层无监督预训练被称为贪心  （greedy）的，是因为它是一个贪心；算法  （greedy  algo-rithm），这意味着它独立地优化解决方案的每一个", "keywords": "这意味着它独立地优化解决方案的每一个, 贪心逐层无监督预训练被称为贪心, 算法, 是因为它是一个贪心", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "186157bf-390c-4936-bbac-9bcc5222096e", "label": "摘要11", "info": "通常而言，“预训练”不仅单指预训练阶段，也指结合预训练和监督学习；的两阶段学习过程。监督学习阶段可能会使用预训练阶段得到的顶层特；征训练一个简单分类器，或者可能会对预训练阶段得到的整个网络进行", "keywords": "或者可能会对预训练阶段得到的整个网络进行, 的两阶段学习过程, 征训练一个简单分类器, 不仅单指预训练阶段, 通常而言", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "23c3d888-b83a-4b2d-92bd-c2ee9c37b0ca", "label": "摘要12", "info": "贪心逐层无监督预训练也能用作其他无监督学习算法的初始化，比如深；度自编码器（Hin-ton  and  Salakhutdinov，2006）和具有很多潜变量层的；概率模型。这些模型包括深度信念网络（Hinton et  al.  ，2006b）和深度", "keywords": "度自编码器, 贪心逐层无监督预训练也能用作其他无监督学习算法的初始化, 这些模型包括深度信念网络, 和深度, 和具有很多潜变量层的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "3c2140e8-e66d-44d4-9c2c-c67ae9a072cf", "label": "摘要13", "info": "正如第8.7.4节所探讨的，我们也可以进行贪心逐层监督预训练。这是建；立在训练浅层模型比深度模型更容易的前提下，而该前提似乎在一些情；况下已被证实（Erhan et al. ，2010）。", "keywords": "节所探讨的, 正如第, 立在训练浅层模型比深度模型更容易的前提下, 况下已被证实, 我们也可以进行贪心逐层监督预训练", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2346421d-95a1-42cc-8b72-9d1a562caa3e", "label": "摘要14", "info": "15.1.1　何时以及为何无监督预训练有效有效", "keywords": "何时以及为何无监督预训练有效有效", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "571a5445-600b-4515-acd4-17a7a397bc9d", "label": "摘要15", "info": "在很多分类任务中，贪心逐层无监督预训练能够在测试误差上获得重大；提升。这一观察结果始于2006年对深度神经网络的重新关注（Hinton  et；al. ，2006b；Bengio et al. ，2007d；Ranzato et al. ，2007a）。然而，在", "keywords": "然而, 这一观察结果始于, 提升, 在很多分类任务中, 贪心逐层无监督预训练能够在测试误差上获得重大", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "3d83c9a4-b219-4c3d-99ce-14ec8215f427", "label": "摘要16", "info": "测上的影响。结果发现，平均而言预训练是有轻微负面影响的，但在有；些问题上会有显著帮助。由于无监督预训练有时有效，但经常也会带来；负面效果，因此很有必要了解它何时有效以及有效的原因，以确定它是", "keywords": "但在有, 测上的影响, 以确定它是, 结果发现, 些问题上会有显著帮助", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "a5970173-a499-4114-8a28-c305129f6246", "label": "摘要17", "info": "首先，要注意的是这个讨论大部分都是针对贪心无监督预训练而言。还；有很多其他完全不同的方法使用半监督学习来训练神经网络，比如第；7.13节介绍的虚拟对抗训练。我们还可以在训练监督模型的同时训练自", "keywords": "要注意的是这个讨论大部分都是针对贪心无监督预训练而言, 有很多其他完全不同的方法使用半监督学习来训练神经网络, 我们还可以在训练监督模型的同时训练自, 比如第, 首先", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b42326bc-4f41-4952-8731-d44b80e15602", "label": "摘要18", "info": "无监督预训练结合了两种不同的想法。第一，它利用了深度神经网络对；初始参数的选择，可以对模型有着显著的正则化效果（在较小程度上，；可以改进优化）的想法。第二，它利用了更一般的想法——学习输入分", "keywords": "可以对模型有着显著的正则化效果, 第一, 在较小程度上, 它利用了更一般的想法, 可以改进优化", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "268a69f8-7c4e-447f-b45e-33ba2eff45a8", "label": "摘要19", "info": "这两个想法都涉及机器学习算法中多个未能完全理解的部分之间复杂的；相互作用。", "keywords": "这两个想法都涉及机器学习算法中多个未能完全理解的部分之间复杂的, 相互作用", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "d7ea19da-4c5f-4be0-98bf-180681a53f7b", "label": "摘要20", "info": "第一个想法，即深度神经网络初始参数的选择对其性能具有很强的正则；化效果，很少有关于这个想法的理解。在预训练变得流行时，在一个位；置初始化模型被认为会使其接近某一个局部极小点，而不是另一个局部", "keywords": "在预训练变得流行时, 而不是另一个局部, 即深度神经网络初始参数的选择对其性能具有很强的正则, 很少有关于这个想法的理解, 第一个想法", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8c65ef4f-0d84-4297-a7ba-e017250c61cc", "label": "摘要21", "info": "另一个想法有更好的理解，即学习算法可以使用无监督阶段学习的信", "keywords": "另一个想法有更好的理解, 即学习算法可以使用无监督阶段学习的信", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f4bdf908-61d0-4f0a-8521-a40a138f2204", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；息，在监督学习的阶段表现得更好。其基本想法是，对于无监督任务有；用的一些特征对于监督学习任务也可能是有用的。例如，如果我们训练", "keywords": "用的一些特征对于监督学习任务也可能是有用的, 如果我们训练, 例如, 在监督学习的阶段表现得更好, 对于无监督任务有", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "7793d99a-b7e6-4f5c-8845-bdec9c5bc27f", "label": "摘要23", "info": "从无监督预训练作为学习一个表示的角度来看，我们可以期望无监督预；训练在初始表示较差的情况下更有效。一个重要的例子是词嵌入。使用；one-hot向量表示的词并不具有很多信息，因为任意两个不同的one-hot向", "keywords": "训练在初始表示较差的情况下更有效, 向量表示的词并不具有很多信息, 因为任意两个不同的, 从无监督预训练作为学习一个表示的角度来看, 一个重要的例子是词嵌入", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "6d6be1ff-77e2-4e89-9bf1-f2948d000c3b", "label": "摘要24", "info": "从无监督预训练作为正则化项的角度来看，我们可以期望无监督预训练；在标注样本数量非常小时很有帮助。因为无监督预训练添加的信息来源；于未标注数据，所以当未标注样本的数量非常大时，我们也可以期望无", "keywords": "从无监督预训练作为正则化项的角度来看, 因为无监督预训练添加的信息来源, 我们可以期望无监督预训练, 于未标注数据, 所以当未标注样本的数量非常大时", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "98bf940c-2a31-434a-ad02-0b0d908f6323", "label": "摘要25", "info": "还可能涉及一些其他的因素。例如，当我们要学习的函数非常复杂时，；无监督预训练可能会非常有用。无监督学习不同于权重衰减这样的正则；化项，它不偏向于学习一个简单的函数，而是学习对无监督学习任务有", "keywords": "无监督预训练可能会非常有用, 无监督学习不同于权重衰减这样的正则, 例如, 还可能涉及一些其他的因素, 当我们要学习的函数非常复杂时", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e851fd59-4e29-4059-8ff2-67e0370c30c8", "label": "摘要26", "info": "除了这些注意事项外，我们现在分析一些无监督预训练改善性能的成功；示例，并解释这种改进发生的已知原因。无监督预训练通常用来改进分；类器，并且从减少测试集误差的观点来看是很有意思的。然而，无监督", "keywords": "并且从减少测试集误差的观点来看是很有意思的, 无监督, 然而, 除了这些注意事项外, 无监督预训练通常用来改进分", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "408c8d82-aeb5-43cf-abd6-047fc4e2de53", "label": "摘要27", "info": "Erhan et  al. （2010）进行了许多实验来解释无监督预训练的几个成功原；因。对训练误差和测试误差的改进都可以解释为，无监督预训练将参数；引入到了其他方法可能探索不到的区域。神经网络训练是非确定性的，", "keywords": "进行了许多实验来解释无监督预训练的几个成功原, 无监督预训练将参数, 对训练误差和测试误差的改进都可以解释为, 神经网络训练是非确定性的, 引入到了其他方法可能探索不到的区域", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "c3884d74-2587-4bef-aad4-107f63839287", "label": "摘要28", "info": "图15.1　在函数空间（并非参数空间，避免从参数向量到函数的多对一映射）不同神经网络学；习轨迹的非线性映射的可视化。不同网络采用不同的随机初始化，并且有的使用了无监督预训；练，有的没有。每个点对应着训练过程中一个特定时间的神经网络。经Erhan et al. （2010）许", "keywords": "避免从参数向量到函数的多对一映射, 不同网络采用不同的随机初始化, 习轨迹的非线性映射的可视化, 并且有的使用了无监督预训, 不同神经网络学", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5b466cd9-270b-4f20-9960-a783a13b267a", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Isomap（Tenenbaum et al. ，2000）进行进一步的非线性投影并投到二维空间。颜色表示时间。；所有的网络初始化在图15.1的中心点附近（对应的函数区域在不多数输入上具有近似均匀分布", "keywords": "进行进一步的非线性投影并投到二维空间, 所有的网络初始化在图, 的中心点附近, 颜色表示时间, 对应的函数区域在不多数输入上具有近似均匀分布", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "ca13ebf6-61b7-47b8-b237-495ad8a42d92", "label": "摘要30", "info": "Erhan et  al. （2010）也回答了何时预训练效果最好——预训练的网络越；深，测试误差的均值和方差下降得越多。值得注意的是，这些实验是在；训练非常深层网络的现代方法发明和流行（整流线性单元、Dropout和", "keywords": "训练非常深层网络的现代方法发明和流行, 预训练的网络越, 测试误差的均值和方差下降得越多, 这些实验是在, 值得注意的是", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b8bdcca2-e7e8-4d9e-99ae-fd85bcd38303", "label": "摘要31", "info": "一个重要的问题是无监督预训练是如何起到正则化项作用的。一个假设；是，预训练鼓励学习算法发现那些与生成观察数据的潜在原因相关的特；征。这也是启发除无监督预训练之外许多其他算法的重要思想，将会在", "keywords": "将会在, 预训练鼓励学习算法发现那些与生成观察数据的潜在原因相关的特, 一个假设, 这也是启发除无监督预训练之外许多其他算法的重要思想, 一个重要的问题是无监督预训练是如何起到正则化项作用的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2b7ff346-5a0b-4a71-80f5-51894c202d8b", "label": "摘要32", "info": "与无监督学习的其他形式相比，无监督预训练的缺点是其使用了两个单；独的训练阶段。很多正则化技术都具有一个优点，允许用户通过调整单；一超参数的值来控制正则化的强度。无监督预训练没有一种明确的方法", "keywords": "无监督预训练的缺点是其使用了两个单, 一超参数的值来控制正则化的强度, 无监督预训练没有一种明确的方法, 允许用户通过调整单, 很多正则化技术都具有一个优点", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "02303756-1efa-4438-9cc3-ee61409a2ecd", "label": "摘要33", "info": "具有两个单独的训练阶段的另一个缺点是每个阶段都具有各自的超参；数。第二阶段的性能通常不能在第一阶段期间预测，因此在第一阶段提；出超参数和第二阶段根据反馈来更新之间存在较长的延迟。最通用的方", "keywords": "最通用的方, 具有两个单独的训练阶段的另一个缺点是每个阶段都具有各自的超参, 因此在第一阶段提, 出超参数和第二阶段根据反馈来更新之间存在较长的延迟, 第二阶段的性能通常不能在第一阶段期间预测", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f704c7ca-4415-4685-b577-ba151b3db1ff", "label": "摘要34", "info": "如今，大部分算法已经不使用无监督预训练了，除了在自然语言处理领；域中单词作为one-hot向量的自然表示不能传达相似性信息，并且有非常；多的未标注数据集可用。在这种情况下，预训练的优点是可以对一个巨", "keywords": "向量的自然表示不能传达相似性信息, 大部分算法已经不使用无监督预训练了, 除了在自然语言处理领, 多的未标注数据集可用, 在这种情况下", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "a4aff58c-6542-4601-8210-5b4ec9558dc2", "label": "摘要35", "info": "基于监督学习的深度学习技术，通过Dropout或批标准化来正则化，能；够在很多任务上达到人类级别的性能，但仅仅是在极大的标注数据集；上。在中等大小的数据集（例如CIFAR-10和MNIST，每个类大约有", "keywords": "够在很多任务上达到人类级别的性能, 例如, 在中等大小的数据集, 但仅仅是在极大的标注数据集, 每个类大约有", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "label": "15.2：迁移学习和领域自适应", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "bf86814d-f759-4714-85cd-3d1c503a89ca", "label": "摘要1", "info": "迁移学习和领域自适应指的是利用一个情景（例如，分布P  1  ）中已经；学到的内容去改善另一个情景（比如分布P  2  ）中的泛化情况。这点概；括了上一节提出的想法，即在无监督学习任务和监督学习任务之间转移", "keywords": "括了上一节提出的想法, 学到的内容去改善另一个情景, 比如分布, 中的泛化情况, 这点概", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "04111f8f-c378-4906-b071-87221d27a57d", "label": "摘要2", "info": "在迁移学习 （transfer  learning）中，学习器必须执行两个或更多个不同；的任务，但是我们假设能够解释P  1  变化的许多因素和学习P  2  需要抓住；的变化相关。这通常能够在监督学习中解释，输入是相同的，但是输出", "keywords": "但是输出, 学习器必须执行两个或更多个不同, 的任务, 输入是相同的, 但是我们假设能够解释", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "083b9508-b241-41fb-aabb-78d9d6695e6f", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；如猫和狗，然后在第二种情景中学习一组不同的视觉类别，比如蚂蚁和；黄蜂。如果第一种情景（从P  1  采样）中具有非常多的数据，那么这有", "keywords": "如果第一种情景, 如猫和狗, 那么这有, 采样, 黄蜂", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "1d63e159-5c6c-4259-8aab-4855d06e0b69", "label": "摘要4", "info": "然而，有时不同任务之间共享的不是输入的语义，而是输出的语义。例；如，语音识别系统需要在输出层产生有效的句子，但是输入附近的较低；层可能需要识别相同音素或子音素发音的非常不同的版本（这取决于说", "keywords": "语音识别系统需要在输出层产生有效的句子, 但是输入附近的较低, 有时不同任务之间共享的不是输入的语义, 然而, 而是输出的语义", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9086675f-f28c-4ecf-9bde-d8ea1184c1de", "label": "摘要5", "info": "图15.2　多任务学习或者迁移学习的架构示例。输出变量 y 在所有的任务上具有相同的语义，输；入变量 x 在每个任务（或者，比如每个用户）上具有不同的意义（甚至可能具有不同的维；度）。图上3个任务为 x (1) 、 x (2) 、 x （3） 。底层结构（决定了选择方向）是面向任务的，上", "keywords": "决定了选择方向, 多任务学习或者迁移学习的架构示例, 上具有不同的意义, 比如每个用户, 在每个任务", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "1774acfc-38b0-42eb-b002-45f9934235b7", "label": "摘要6", "info": "层结构是共享的。底层结构学习将面向特定任务的输入转化为通用特征", "keywords": "层结构是共享的, 底层结构学习将面向特定任务的输入转化为通用特征", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "325d1bfe-07dd-4f9d-ba80-116d31ec31cb", "label": "摘要7", "info": "在领域自适应 （domain adaption）的相关情况下，在每个情景之间任务；（和最优的输入到输出的映射）都是相同的，但是输入分布稍有不同。；例如，考虑情感分析的任务，如判断一条评论是表达积极的还是消极的", "keywords": "如判断一条评论是表达积极的还是消极的, 和最优的输入到输出的映射, 例如, 在领域自适应, 但是输入分布稍有不同", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "c0287cfb-8df1-4cce-8322-6af7d2dbb361", "label": "摘要8", "info": "一个相关的问题是概念漂移  （concept  drift），我们可以将其视为一种；迁移学习，因为数据分布随时间而逐渐变化。概念漂移和迁移学习都可；以被视为多任务学习的特定形式。“多任务学习”这个术语通常指监督学", "keywords": "概念漂移和迁移学习都可, 我们可以将其视为一种, 因为数据分布随时间而逐渐变化, 迁移学习, 以被视为多任务学习的特定形式", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "82681adf-4c3b-4a7a-beb3-a7764d82a280", "label": "摘要9", "info": "在所有这些情况下，我们的目标是利用第一个情景下的数据，提取那些；在第二种情景中学习时或直接进行预测时可能有用的信息。表示学习的；核心思想是相同的表示可能在两种情景中都是有用的。两个情景使用相", "keywords": "在第二种情景中学习时或直接进行预测时可能有用的信息, 核心思想是相同的表示可能在两种情景中都是有用的, 表示学习的, 在所有这些情况下, 两个情景使用相", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "34607e8e-1eb5-44aa-93b2-1cb2a487e9fa", "label": "摘要10", "info": "如前所述，迁移学习中无监督深度学习已经在一些机器学习比赛中取得；了成功（Mesnil et al. ，2011；Goodfellow et al.  ，2011）。这些比赛中；的某一个实验配置如下。首先每个参与者获得一个第一种情景（来自分", "keywords": "如前所述, 这些比赛中, 来自分, 了成功, 的某一个实验配置如下", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "4e845515-5003-4a3a-9754-97af39df76a0", "label": "摘要11", "info": "迁移学习的两种极端形式是一次学习  （one-shot  learning）和零次学习", "keywords": "和零次学习, 迁移学习的两种极端形式是一次学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b248f3cb-ed02-45d5-ab46-4cb9d99753a9", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（zero-shot；learning）。只有一个标注样本的迁移任务被称为一次学习；没有标注", "keywords": "没有标注, 只有一个标注样本的迁移任务被称为一次学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "1762cbea-1733-435a-b5d1-a64cc938719c", "label": "摘要13", "info": "learning），有时也被称为零数据学习", "keywords": "有时也被称为零数据学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "dc18c8b3-d69e-47c0-a444-f525e6edb19d", "label": "摘要14", "info": "（zero-data", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "410ff9af-5cb9-42d2-abee-9a412bc654db", "label": "摘要15", "info": "因为第一阶段学习出的表示就可以清楚地分离出潜在的类别，所以一次；学习（Fei-Fei  et  al.  ，2006）是可能的。在迁移学习阶段，仅需要一个；标注样本来推断表示空间中聚集在相同点周围许多可能测试样本的标", "keywords": "标注样本来推断表示空间中聚集在相同点周围许多可能测试样本的标, 在迁移学习阶段, 是可能的, 所以一次, 学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "93590696-c0c3-4e7e-93b8-71b1ca5512c8", "label": "摘要16", "info": "考虑一个零次学习情景的例子，学习器已经读取了大量文本，然后要解；决对象识别的问题。如果文本足够好地描述了对象，那么即使没有看到；某对象的图像，也能识别出该对象的类别。例如，已知猫有4条腿和尖", "keywords": "已知猫有, 那么即使没有看到, 学习器已经读取了大量文本, 某对象的图像, 也能识别出该对象的类别", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "35324c24-b41e-42f6-8bcc-e9e682c1634c", "label": "摘要17", "info": "只有在训练时使用了额外信息，零数据学习（Larochelle et  al.  ，2008）；和零次学习（Palatucci et al. ，2009；Socher et al. ，2013b）才是有可能；的。我们可以认为零数据学习场景包含3个随机变量：传统输入  x  ，传", "keywords": "只有在训练时使用了额外信息, 才是有可能, 零数据学习, 和零次学习, 我们可以认为零数据学习场景包含", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b57d9ce9-007f-4b5e-a5e2-6db0195d094a", "label": "摘要18", "info": "零次学习要求T被表示为某种形式的泛化。例如，T不能仅是指示对象；类别的one-hot编码。通过使用每个类别词的词嵌入表示，Socher  et  al.；（2013b）提出了对象类别的分布式表示。", "keywords": "类别的, 提出了对象类别的分布式表示, 被表示为某种形式的泛化, 编码, 通过使用每个类别词的词嵌入表示", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "ae33e708-33d8-4426-b623-9a4f23e9d71e", "label": "摘要19", "info": "我们还可以在机器翻译中发现一种类似的现象（Klementiev  et  al.  ，；2012；Mikolov et al. ，2013b；Gouws et al. ，2014）：我们已经知道一；种语言中的单词，还可以学到单一语言语料库中词与词之间的关系；另", "keywords": "我们还可以在机器翻译中发现一种类似的现象, 还可以学到单一语言语料库中词与词之间的关系, 我们已经知道一, 种语言中的单词", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "df09ae1d-2128-415f-a1d8-1386acf5f86b", "label": "摘要20", "info": "的句子。即使我们可能没有将语言X中的单词A翻译成语言Y中的单词B；的标注样本，我们也可以泛化并猜出单词A的翻译，这是由于我们已经；学习了语言X和Y单词的分布式表示，并且通过两种语言句子的匹配对", "keywords": "翻译成语言, 的翻译, 我们也可以泛化并猜出单词, 学习了语言, 这是由于我们已经", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "d8e38808-c520-4203-a5c9-814589390e60", "label": "摘要21", "info": "零次学习是迁移学习的一种特殊形式。同样的原理可以解释如何能执行；多模态学习  （multimodal  learning），学习两种模态的表示，和一种模；态中的观察结果 x 与另一种模态中的观察结果y组成的对（ x  ，  y  ）之", "keywords": "学习两种模态的表示, 组成的对, 与另一种模态中的观察结果, 和一种模, 多模态学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8ab42e7a-3934-4db4-b3f6-0bb73c830497", "label": "摘要22", "info": "and", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8d696d44-eba1-4704-be26-2e94cfdb2a96", "label": "摘要23", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图15.3　两个域 x 和 y 之间的迁移学习能够进行零次学习。标注或未标注样本 x 可以学习表示函；数 f x 。同样地，样本 y 也可以学习表示函数 f y 。图中 f x 和 f y 旁都有一个向上的箭头，不同的", "keywords": "可以学习表示函, 也可以学习表示函数, 样本, 同样地, 之间的迁移学习能够进行零次学习", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "label": "15.3：半监督解释因果关系", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "a828fcf5-e7ef-46b4-bfc9-5b7bd7157cf4", "label": "摘要1", "info": "表示学习的一个重要问题是“什么原因能够使一个表示比另一个表示更；好？”一种假设是，理想表示中的特征对应到观测数据的潜在成因，特；征空间中不同的特征或方向对应着不同的原因，从而表示能够区分这些", "keywords": "从而表示能够区分这些, 什么原因能够使一个表示比另一个表示更, 理想表示中的特征对应到观测数据的潜在成因, 征空间中不同的特征或方向对应着不同的原因, 一种假设是", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2e341363-22a9-4a37-9e5c-b2d43c36f192", "label": "摘要2", "info": "et", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "997367dd-e775-420b-a48f-b0838c489fac", "label": "摘要3", "info": "在表示学习的其他方法中，我们大多关注易于建模的表示——例如，数；据稀疏或是各项之间相互独立的情况。能够清楚地分离出潜在因素的表；示可能并不一定易于建模。然而，该假设促使半监督学习使用无监督表", "keywords": "在表示学习的其他方法中, 我们大多关注易于建模的表示, 据稀疏或是各项之间相互独立的情况, 例如, 然而", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2864268a-f15d-4eef-90b4-7a8569c85c48", "label": "摘要4", "info": "首先，让我们看看p(x  )的无监督学习无助于学习p(y  ｜x  )时，半监督学；习为何失败。例如，考虑一种情况，p(x  )是均匀分布的，我们希望学习", "keywords": "的无监督学习无助于学习, 我们希望学习, 考虑一种情况, 例如, 半监督学", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "48121686-093f-491f-b7ee-86e959295e3b", "label": "摘要5", "info": "p(y ｜x )的任何信息。", "keywords": "的任何信息", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "d998189e-ded6-40dd-824d-e0e2f306b034", "label": "摘要6", "info": "。显然，仅仅观察训练集的值  x  不能给我们关于", "keywords": "显然, 不能给我们关于, 仅仅观察训练集的值", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "833c446a-1c16-4c24-9f00-bcdf4d79ec5c", "label": "摘要7", "info": "接下来，让我们看看半监督学习成功的一个简单例子。考虑这样的情；况，x  来自一个混合分布，每个y  值具有一个混合分量，如图15.4所；示。如果混合分量很好地分出来了，那么建模p(x  )可以精确地指出每个", "keywords": "接下来, 可以精确地指出每个, 考虑这样的情, 值具有一个混合分量, 让我们看看半监督学习成功的一个简单例子", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5598e4fe-5265-44b6-85b5-cd16bcaab779", "label": "摘要8", "info": "图15.4　混合模型。具有3个混合分量的 x 上混合密度示例。混合分量的内在本质是潜在解释因；子 y 。因为混合分量（例如，图像数据中的自然对象类别）在统计学上是显著的，所以仅仅使；用未标注样本无监督建模p( x )也能揭示解释因子 y", "keywords": "图像数据中的自然对象类别, 所以仅仅使, 个混合分量的, 混合模型, 混合分量的内在本质是潜在解释因", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "0005250a-4311-4ab0-a3d6-0b38f822e2dc", "label": "摘要9", "info": "如果y 与x 的成因之一非常相关，那么p(x )和p(y ｜x )也会紧密关联，试；图找到变化潜在因素的无监督表示学习可能像半监督学习一样有用。", "keywords": "如果, 图找到变化潜在因素的无监督表示学习可能像半监督学习一样有用, 也会紧密关联, 那么, 的成因之一非常相关", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "bad39dd0-1ea5-4d15-a200-f06d592626f6", "label": "摘要10", "info": "假设y  是x  的成因之一，让h  代表所有这些成因。真实的生成过程可以；被认为是根据这个有向图模型结构化出来的，其中h 是x 的父节点：", "keywords": "真实的生成过程可以, 代表所有这些成因, 其中, 的父节点, 被认为是根据这个有向图模型结构化出来的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "6cae8caa-161f-4ca4-8788-b7a4bf1b2e01", "label": "摘要11", "info": "因此，数据的边缘概率是", "keywords": "数据的边缘概率是, 因此", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "50266f9a-1b50-4c23-a1c5-ffe8d8347b13", "label": "摘要12", "info": "从这个直观的观察中，我们得出结论，x  最好可能的模型（从广义的观", "keywords": "最好可能的模型, 我们得出结论, 从这个直观的观察中, 从广义的观", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "27ce2723-83d4-4683-b603-abb22b22479b", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；点）是会表示上述“真实”结构的，其中 h 作为潜变量解释 x 中可观察的；变化。上文讨论的“理想”的表示学习应该能够反映出这些潜在因子。如", "keywords": "结构的, 的表示学习应该能够反映出这些潜在因子, 真实, 其中, 理想", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "4ecf86e2-26ee-4e73-8fdc-e845bb561c65", "label": "摘要14", "info": "因此边缘概率p(x  )和条件概率p(y  ｜x  )密切相关，前者的结构信息应该；有助于学习后者。因此，在这些假设情况下，半监督学习应该能提高性；能。", "keywords": "密切相关, 前者的结构信息应该, 因此边缘概率, 因此, 半监督学习应该能提高性", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "99061817-0ad7-4bf1-9612-53ee5d8a770e", "label": "摘要15", "info": "关于这个事实的一个重要的研究问题是，大多数观察是由极其大量的潜；在成因形成的。假设y ＝h i ，但是无监督学习器并不知道是哪一个h i 。；对于一个无监督学习器暴力求解就是学习一种表示，这种表示能够捕获", "keywords": "大多数观察是由极其大量的潜, 但是无监督学习器并不知道是哪一个, 对于一个无监督学习器暴力求解就是学习一种表示, 这种表示能够捕获, 假设", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b3e701ce-4cdb-4bf5-a083-f38748198ee3", "label": "摘要16", "info": "在实践中，暴力求解是不可行的，因为不可能捕获影响观察的所有或大；多数变化因素。例如，在视觉场景中，表示是否应该对背景中的所有最；小对象进行编码？根据一个有据可查的心理学现象，人们不会察觉到环", "keywords": "因为不可能捕获影响观察的所有或大, 人们不会察觉到环, 在视觉场景中, 多数变化因素, 暴力求解是不可行的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "6facb8e7-5609-4239-87aa-cffad64fadbe", "label": "摘要17", "info": "无监督学习的另一个思路是选择一个更好的确定哪些潜在因素最为关键；的定义。之前，自编码器和生成模型被训练来优化一个类似于均方误差；的固定标准。这些固定标准确定了哪些因素是重要的。例如，图像像素", "keywords": "这些固定标准确定了哪些因素是重要的, 自编码器和生成模型被训练来优化一个类似于均方误差, 图像像素, 例如, 无监督学习的另一个思路是选择一个更好的确定哪些潜在因素最为关键", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "7e4c4a04-f90b-499b-a640-908097dca060", "label": "摘要18", "info": "著）。", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "33d23223-82bf-491d-99d4-0e6136c69ab5", "label": "摘要19", "info": "图15.5　机器人任务上，基于均方误差训练的自编码器不能重构乒乓球。乒乓球的存在及其所；有空间坐标，是生成图像且与机器人任务相关的重要潜在因素。不幸的是，自编码器具有有限；的容量，基于均方误差的训练没能将乒乓球作为显著物体识别出来编码。以上图像由Chelsea", "keywords": "机器人任务上, 自编码器具有有限, 以上图像由, 的容量, 乒乓球的存在及其所", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5ffbfa53-62bc-4cbc-b556-06b8cb611874", "label": "摘要20", "info": "还有一些其他的显著性的定义。例如，如果一组像素具有高度可识别的；模式，那么即使该模式不涉及极端的亮度或暗度，该模式还是会被认为；非常显著。实现这样一种定义显著的方法是使用最近提出的生成式对抗", "keywords": "实现这样一种定义显著的方法是使用最近提出的生成式对抗, 如果一组像素具有高度可识别的, 例如, 非常显著, 那么即使该模式不涉及极端的亮度或暗度", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8022ccd1-ed74-47e3-90ab-fb6d263a21f9", "label": "摘要21", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图15.6　预测生成网络是一个学习哪些特征显著的例子。在这个例子中，预测生成网络已被训；练成在特定视角预测人头的3D模型。（左）真实情况。这是一张网络应该生成的正确图片。", "keywords": "预测生成网络是一个学习哪些特征显著的例子, 在这个例子中, 模型, 预测生成网络已被训, 练成在特定视角预测人头的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "90742030-ad49-42f7-9f4a-dfbbf7a5b143", "label": "摘要22", "info": "正如Schölkopf  et  al.  （2012）指出，学习潜在因素的好处是，如果真实；的生成过程中x 是结果，y 是原因，那么建模p(x ｜y )对于p(y )的变化是；鲁棒的。如果因果关系被逆转，这是不对的，因为根据贝叶斯规则，", "keywords": "指出, 学习潜在因素的好处是, 是原因, 是结果, 的变化是", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "label": "15.4：分布式表示", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "3ea228f6-40a2-4725-b530-8daec048cfda", "label": "摘要1", "info": "分布式表示的概念（由很多元素组合的表示，这些元素之间可以设置成；可分离的）是表示学习最重要的工具之一。分布式表示非常强大，因为；他们能用具有k个值的n个特征去描述k  n  个不同的概念。正如我们在本", "keywords": "因为, 他们能用具有, 可分离的, 个特征去描述, 个不同的概念", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9b997a12-6328-43ec-a2df-47211c30d3e5", "label": "摘要2", "info": "n维二元向量是一个分布式表示的示例，有2  n  种配置，每一种都对应输；入空间中的一个不同区域，如图15.7所示。这可以与符号表示相比较，；其中输入关联到单一符号或类别。如果字典中有n个符号，那么可以想", "keywords": "入空间中的一个不同区域, 那么可以想, 所示, 其中输入关联到单一符号或类别, 个符号", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "37d52922-ead6-4bc1-b807-0a5c649900f1", "label": "摘要3", "info": "图15.7　基于分布式表示的学习算法如何将输入空间分割成多个区域的图示。这个例子具有二；元变量h 1 、h 2 、h 3 。每个特征通过为学成的线性变换设定输出阈值而定义。每个特征将；分成两个半平面。令", "keywords": "分成两个半平面, 基于分布式表示的学习算法如何将输入空间分割成多个区域的图示, 这个例子具有二, 元变量, 每个特征将", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "56ccb4dc-c185-43cc-8cbd-ee5ad415a2fd", "label": "摘要4", "info": "表示输入点h i ＝0的集合。在这个图示；区域。整个表示在这些半平；对应着区域", "keywords": "区域, 表示输入点, 在这个图示, 整个表示在这些半平, 的集合", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b2ac10d2-57d3-45ad-815f-0ecbec1bfe52", "label": "摘要5", "info": "表示输入点h i ＝1的集合；", "keywords": "表示输入点, 的集合", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "c6e082d1-176f-4727-affe-6dbf347adb10", "label": "摘要6", "info": "。可以将以上表示和图15.8中的非分布式表示进行比较。在输入维度是d的一；。具有n个特征的分布式表", "keywords": "个特征的分布式表, 在输入维度是, 的一, 具有, 中的非分布式表示进行比较", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8049a18b-58dc-4203-a6ad-2a10b3d3bc78", "label": "摘要7", "info": "般情况下，分布式表示通过半空间（而不是半平面）的交叉分割；示给O(n d )个不同区域分配唯一的编码，而具有n个样本的最近邻算法只能给n个不同区域分配", "keywords": "个不同区域分配唯一的编码, 示给, 个不同区域分配, 个样本的最近邻算法只能给, 的交叉分割", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "6977d0c1-0781-4d73-a83c-856cc417c974", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；唯一的编码。因此，分布式表示能够比非分布式表示多分配指数级的区域。注意并非所有的 h；值都是可取的（这个例子中没有 h ＝ 0 ），在分布式表示上的线性分类器不能向每个相邻区域分", "keywords": "唯一的编码, 分布式表示能够比非分布式表示多分配指数级的区域, 注意并非所有的, 因此, 在分布式表示上的线性分类器不能向每个相邻区域分", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e876e7a7-2dda-4c7d-aa48-b969b177ffc1", "label": "摘要9", "info": "以下是基于非分布式表示的学习算法的示例：", "keywords": "以下是基于非分布式表示的学习算法的示例", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "c6cf316f-c267-4f0e-93ab-7d9a7335cd04", "label": "摘要10", "info": "聚类算法，包含k-means算法：每个输入点恰好分配到一个类别。；k-最近邻算法：给定一个输入，一个或几个模板或原型样本与之关；联。在k＞1的情况下，每个输入都使用多个值来描述，但是它们不", "keywords": "每个输入点恰好分配到一个类别, 包含, 算法, 聚类算法, 一个或几个模板或原型样本与之关", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e3831b2b-dd9e-47b7-a9ca-a4cc7a4abeb4", "label": "摘要11", "info": "图15.8　最近邻算法如何将输入空间分成不同区域的图示。最近邻算法是一个基于非分布式表；示的学习算法的示例。不同的非分布式算法可以具有不同的几何形状，但是它们通常将输入空；间分成区域，每个区域具有不同的参数。非分布式方法的优点是，给定足够的参数，它能够拟", "keywords": "但是它们通常将输入空, 最近邻算法是一个基于非分布式表, 不同的非分布式算法可以具有不同的几何形状, 每个区域具有不同的参数, 间分成区域", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "82b5c4d6-8bce-4927-871b-e7550125aa47", "label": "摘要12", "info": "对于部分非分布式算法而言，有些输出并非是恒定的，而是在相邻区域；之间内插。参数（或样本）的数量和它们能够定义区域的数量之间仍保；持线性关系。", "keywords": "的数量和它们能够定义区域的数量之间仍保, 对于部分非分布式算法而言, 参数, 而是在相邻区域, 或样本", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f3b22d84-2d6d-4f7a-99b8-b16bfa1f81df", "label": "摘要13", "info": "将分布式表示和符号表示区分开来的一个重要概念是，由不同概念之间；的共享属性而产生的泛化。作为纯符号，“猫”和“狗”之间的距离和任意；其他两种符号的距离一样。然而，如果将它们与有意义的分布式表示相", "keywords": "由不同概念之间, 将分布式表示和符号表示区分开来的一个重要概念是, 然而, 如果将它们与有意义的分布式表示相, 之间的距离和任意", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "3ef216ad-0864-4f3f-a1a2-be1948971045", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；操作的模型泛化得更好。分布式表示具有丰富的相似性空间，语义上相；近的概念（或输入）在距离上接近，这是纯粹的符号表示所缺少的特", "keywords": "或输入, 在距离上接近, 近的概念, 分布式表示具有丰富的相似性空间, 这是纯粹的符号表示所缺少的特", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "42ba9669-67f0-488a-a9f9-d3cfaaabb8cd", "label": "摘要15", "info": "在学习算法中使用分布式表示何时以及为什么具有统计优势？当一个明；显复杂的结构可以用较少参数紧致地表示时，分布式表示具有统计上的；优点。一些传统的非分布式学习算法仅仅在平滑假设的情况下能够泛", "keywords": "当一个明, 在学习算法中使用分布式表示何时以及为什么具有统计优势, 优点, 一些传统的非分布式学习算法仅仅在平滑假设的情况下能够泛, 显复杂的结构可以用较少参数紧致地表示时", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "024ccc17-0066-40f4-aa57-50dc9b601c26", "label": "摘要16", "info": "如果我们幸运的话，除了平滑之外，目标函数可能还有一些其他规律。；例如，具有最大池化的卷积网络可以在不考虑对象在图像中位置（即使；对象的空间变换不对应输入空间的平滑变换）的情况下识别出对象。", "keywords": "除了平滑之外, 即使, 对象的空间变换不对应输入空间的平滑变换, 目标函数可能还有一些其他规律, 具有最大池化的卷积网络可以在不考虑对象在图像中位置", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "eb775a8d-9386-4981-9304-2846d087f005", "label": "摘要17", "info": "让我们检查分布式表示学习算法的一个特殊情况，它通过对输入的线性；函数进行阈值处理来提取二元特征。该表示中的每个二元特征将  分；成一对半空间，如图15.7所示。n个相应半空间的指数级数量的交集确", "keywords": "函数进行阈值处理来提取二元特征, 该表示中的每个二元特征将, 个相应半空间的指数级数量的交集确, 所示, 它通过对输入的线性", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b334e28b-fe83-4330-8ef5-08add13ac0eb", "label": "摘要18", "info": "因此，我们会发现关于输入大小呈指数级增长，关于隐藏单元的数量呈；多项式级增长。", "keywords": "因此, 我们会发现关于输入大小呈指数级增长, 多项式级增长, 关于隐藏单元的数量呈", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "8c5d119d-25b0-49d2-af46-c479e683ac81", "label": "摘要19", "info": "这提供了分布式表示泛化能力的一种几何解释：O(nd)个参数（空间", "keywords": "这提供了分布式表示泛化能力的一种几何解释, 空间, 个参数", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "1440f06f-0c66-4dfa-813e-b749405cb85f", "label": "摘要20", "info": "中的n个线性阈值特征）能够明确表示输入空间中O(n  d  )个不同区；域。如果我们没有对数据做任何假设，并且每个区域使用唯一的符号来；表示，每个符号使用单独的参数去识别   中的对应区域，那么指定", "keywords": "表示, 能够明确表示输入空间中, 个不同区, 如果我们没有对数据做任何假设, 那么指定", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "f07437ed-df5b-4c74-bd57-b93546b74955", "label": "摘要21", "info": "另一个解释基于分布式表示的模型泛化能力更好的说法是，尽管能够明；确地编码这么多不同的区域，但它们的容量仍然是很有限的。例如，线；性阈值单元神经网络的VC维仅为O(w", "keywords": "维仅为, 尽管能够明, 另一个解释基于分布式表示的模型泛化能力更好的说法是, 例如, 性阈值单元神经网络的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "4767b609-3282-49da-a07a-0d193e7a2be1", "label": "摘要22", "info": "到目前为止讨论的想法都是抽象的，但是它们可以通过实验验证。Zhou；et  al.  （2015）发现，在ImageNet和Places基准数据集上训练的深度卷积；网络中的隐藏单元学成的特征通常是可以解释的，对应人类自然分配的", "keywords": "网络中的隐藏单元学成的特征通常是可以解释的, 对应人类自然分配的, 到目前为止讨论的想法都是抽象的, 发现, 基准数据集上训练的深度卷积", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e43e994b-2a60-4c6a-ab18-c500ee0e472f", "label": "摘要23", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；是女性，而另一个方向对应着该人是否戴着眼镜。这些特征都是自动发；现的，而非先验固定的。我们没有必要为隐藏单元分类器提供标签：只", "keywords": "我们没有必要为隐藏单元分类器提供标签, 现的, 而非先验固定的, 这些特征都是自动发, 是女性", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "45ec86f2-e290-4207-9c46-e720ee948811", "label": "摘要24", "info": "图15.9　生成模型学到了分布式表示，能够从戴眼镜的概念中区分性别的概念。如果我们从一；个戴眼镜的男人的概念表示向量开始，然后减去一个没戴眼镜的男人的概念表示向量，最后加；上一个没戴眼镜的女人的概念表示向量，那么我们会得到一个戴眼镜的女人的概念表示向量。", "keywords": "个戴眼镜的男人的概念表示向量开始, 上一个没戴眼镜的女人的概念表示向量, 生成模型学到了分布式表示, 那么我们会得到一个戴眼镜的女人的概念表示向量, 然后减去一个没戴眼镜的男人的概念表示向量", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5607b770-4812-463b-a08c-bf25a12d2b02", "label": "15.5：得益于深度的指数增益", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "79bc278c-76db-48f3-a0f0-301ae01f9cd9", "label": "摘要1", "info": "我们已经在第6.4.1节中看到，多层感知机是万能近似器，相比于浅层网；络，一些函数能够用指数级小的深度网络表示。缩小模型规模能够提高；统计效率。在本节中，我们描述如何将类似结果更一般地应用于其他具", "keywords": "一些函数能够用指数级小的深度网络表示, 在本节中, 我们描述如何将类似结果更一般地应用于其他具, 统计效率, 缩小模型规模能够提高", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "da9f4769-91e7-4953-b5b2-8878c8fc325f", "label": "摘要2", "info": "在第15.4节中，我们看到了一个生成模型的示例，能够学习人脸图像的；潜在解释因子，包括性别以及是否佩戴眼镜。完成这个任务的生成模型；是基于一个深度神经网络的。浅层网络例如线性网络不能学习出这些抽", "keywords": "是基于一个深度神经网络的, 我们看到了一个生成模型的示例, 浅层网络例如线性网络不能学习出这些抽, 节中, 在第", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "b1670e92-3465-47be-87a3-98de3e51d1b3", "label": "摘要3", "info": "输入的函数）或因子（被视为生成原因）。", "keywords": "或因子, 输入的函数, 被视为生成原因", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "7b63fbc1-bd72-4e6e-b638-2ba5085f8502", "label": "摘要4", "info": "在许多不同情景中已经证明，非线性和重用特征层次结构的组合来组织；计算，可以使分布式表示获得指数级加速之外，还可以获得统计效率的；指数级提升。许多种类的只有一个隐藏层的网络（例如，具有饱和非线", "keywords": "在许多不同情景中已经证明, 可以使分布式表示获得指数级加速之外, 还可以获得统计效率的, 许多种类的只有一个隐藏层的网络, 例如", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "4cab08aa-88e6-423c-9e71-7e62b72e54b9", "label": "摘要5", "info": "在第6.4.1节中，我们看到确定性前馈网络是函数的万能近似器。许多具；有单个隐藏层（潜变量）的结构化概率模型（包括受限玻尔兹曼机、深；度信念网络）是概率分布的万能近似器（Le  Roux  and  Bengio，2008，", "keywords": "是概率分布的万能近似器, 潜变量, 节中, 的结构化概率模型, 度信念网络", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9fb4f0db-89d4-4e5a-8546-a4b3ca024c0d", "label": "摘要6", "info": "在第6.4.1节中，我们看到足够深的前馈网络会比深度不够的网络具有指；数级优势。这样的结果也能从诸如概率模型的其他模型中获得。和—积；网络 （sum-product network，SPN）（Poon and Domingos，2011）是这", "keywords": "网络, 这样的结果也能从诸如概率模型的其他模型中获得, 数级优势, 节中, 我们看到足够深的前馈网络会比深度不够的网络具有指", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "615d71dd-9e3f-4689-9b7c-b36deb74b16b", "label": "摘要7", "info": "另一个有趣的进展是，一系列和卷积网络相关的深度回路族表达能力的；理论结果，即使让浅度回路只去近似深度回路计算的函数，也能突出反；映深度回路的指数级优势（Cohen et al. ，2015）。相比之下，以前的理", "keywords": "也能突出反, 以前的理, 映深度回路的指数级优势, 一系列和卷积网络相关的深度回路族表达能力的, 理论结果", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "label": "15.6：提供发现潜在原因的线索", "level": 2, "group": "chapter-15", "type": "子章節"}, {"id": "d08efac5-c1f2-40af-ac2c-4fbc08928f22", "label": "摘要1", "info": "我们回到最初的问题之一来结束本章：什么原因能够使一个表示比另一", "keywords": "我们回到最初的问题之一来结束本章, 什么原因能够使一个表示比另一", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "5d7973ee-2d0c-4662-8f2f-dffabdce44aa", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；个表示更好？首先在第15.3节中介绍的一个答案是，一个理想的表示能；够区分生成数据变化的潜在因果因子，特别是那些与我们的应用相关的", "keywords": "够区分生成数据变化的潜在因果因子, 节中介绍的一个答案是, 个表示更好, 一个理想的表示能, 特别是那些与我们的应用相关的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "9e359aea-bcf3-4f12-acbd-3c07612a0619", "label": "摘要3", "info": "在此，我们提供了一些通用正则化策略的列表。该列表显然是不详尽；的，但是给出了一些学习算法是如何发现对应潜在因素的特征的具体示；例。该列表在Bengio et al. （2013d）的第3.1节中提出，这里进行了部分", "keywords": "的第, 但是给出了一些学习算法是如何发现对应潜在因素的特征的具体示, 该列表在, 在此, 我们提供了一些通用正则化策略的列表", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "45013813-5d8c-419d-8fb7-ea3414113107", "label": "摘要4", "info": "平滑：假设对于单位  d  和小量   有；。这；个假设允许学习器从训练样本泛化到输入空间中附近的点。许多机", "keywords": "个假设允许学习器从训练样本泛化到输入空间中附近的点, 许多机, 假设对于单位, 平滑, 和小量", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "83055007-f57a-4b44-be60-eb6f3f3feb06", "label": "摘要5", "info": "是有利的，当潜在成因上的分布发生改变，或者我们应用模型到一；个新的任务上时，学成的模型都会更加鲁棒。；深度，或者解释因子的层次组织：高级抽象概念能够通过将简单概", "keywords": "高级抽象概念能够通过将简单概, 学成的模型都会更加鲁棒, 当潜在成因上的分布发生改变, 或者我们应用模型到一, 是有利的", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "34bf3a46-8980-4a78-bd1a-8b711db6d0c7", "label": "摘要6", "info": "表示学习的概念将许多深度学习形式联系在了一起。前馈网络和循环网", "keywords": "前馈网络和循环网, 表示学习的概念将许多深度学习形式联系在了一起", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "779bdc5c-682d-4b83-9a9d-5359702170a1", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；络，自编码器和深度概率模型都在学习和使用表示。学习最佳表示仍然；是一个令人兴奋的研究方向。", "keywords": "自编码器和深度概率模型都在学习和使用表示, 是一个令人兴奋的研究方向, 学习最佳表示仍然", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "eaa2dc73-6139-450d-a272-3f4b79cb12e1", "label": "摘要8", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "a60b6b34-3dd5-46ae-98de-34aca3b9132a", "label": "摘要9", "info": "(1)；一般来说，我们可能会想要学习一个函数，这个函数在指数级数量区域的表现都是不同；的：在d-维空间中，为了区分每一维，至少有两个不同的值。我们想要函数f区分这2  d  个不同", "keywords": "我们想要函数, 这个函数在指数级数量区域的表现都是不同, 至少有两个不同的值, 区分这, 我们可能会想要学习一个函数", "level": 3, "group": "chapter-15", "type": "段落"}, {"id": "e078d34b-b800-4e25-a283-0abcb1bde121", "label": "第16章：深度学习中的结构化概率模型", "level": 1, "group": "chapter-16", "type": "章節"}, {"id": "dc63e22d-deff-4467-bfaf-f198f3226c18", "label": "15.6：提供发现潜在原因的线索", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "f1467f78-216b-4030-b08a-d19e3f5d92b1", "label": "摘要1", "info": "深度学习为研究者们提供了许多建模方式，用以设计以及描述算法。其；中一种形式是结构化概率模型  （structured  probabilistic  model）的思；想。我们曾经在第3.14节中简要讨论过结构化概率模型。此前简要的介", "keywords": "深度学习为研究者们提供了许多建模方式, 中一种形式是结构化概率模型, 我们曾经在第, 此前简要的介, 的思", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "cb007f63-4305-44e3-9b97-b9b8ccaa6e3f", "label": "摘要2", "info": "结构化概率模型使用图来描述概率分布中随机变量之间的直接相互作；用，从而描述一个概率分布。在这里我们使用了图论（一系列结点通过；一系列边来连接）中“图”的概念，由于模型结构是由图定义的，所以这", "keywords": "由于模型结构是由图定义的, 一系列边来连接, 在这里我们使用了图论, 一系列结点通过, 所以这", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e1397c8b-295b-4950-8e16-be9dbf596bf3", "label": "摘要3", "info": "图模型的研究社群是巨大的，并提出过大量的模型、训练算法和推断算；法。在本章中，我们将介绍图模型中几个核心方法的基本背景，并且重；点描述已被证明对深度学习社群最有用的观点。如果你已经熟知图模", "keywords": "我们将介绍图模型中几个核心方法的基本背景, 点描述已被证明对深度学习社群最有用的观点, 训练算法和推断算, 图模型的研究社群是巨大的, 如果你已经熟知图模", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c0efd449-264c-4474-aead-63a74c676e98", "label": "摘要4", "info": "我们首先介绍了构建大规模概率模型时面临的挑战。之后，我们介绍如", "keywords": "之后, 我们首先介绍了构建大规模概率模型时面临的挑战, 我们介绍如", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8e40c0cf-1cca-4d11-9efe-15c917c4eca3", "label": "摘要5", "info": "何使用一个图来描述概率分布的结构。尽管这个方法能够帮助我们解决；许多挑战和问题，它本身仍有很多缺陷。图模型中的一个主要难点就是；判断哪些变量之间存在直接的相互作用关系，也就是对于给定的问题哪", "keywords": "判断哪些变量之间存在直接的相互作用关系, 许多挑战和问题, 也就是对于给定的问题哪, 它本身仍有很多缺陷, 图模型中的一个主要难点就是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "10a8cadb-7a97-45c2-8a6b-6b2903d42ed7", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；16.1　非结构化建模的挑战", "keywords": "非结构化建模的挑战", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3e7ed91c-c557-49c1-b743-b155a615beba", "label": "摘要7", "info": "深度学习的目标是使得机器学习能够解决许多人工智能中亟需解决的挑；战。这也意味着它们能够理解具有丰富结构的高维数据。举个例子，我；们希望AI的算法能够理解自然图片 (1) ，表示语音的声音信号和包含许多", "keywords": "表示语音的声音信号和包含许多, 举个例子, 这也意味着它们能够理解具有丰富结构的高维数据, 深度学习的目标是使得机器学习能够解决许多人工智能中亟需解决的挑, 们希望", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "aaf79bae-232c-49a9-b1e9-f8eb4921cda7", "label": "摘要8", "info": "分类问题可以把这样一个来自高维分布的数据作为输入，然后使用一个；类别的标签来概括它——这个标签既可以是照片中有什么物品，一段语；音中说的是哪个单词，也可以是一段文档描述的是哪个话题。这个分类", "keywords": "一段语, 这个分类, 然后使用一个, 类别的标签来概括它, 分类问题可以把这样一个来自高维分布的数据作为输入", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "611013dd-a0a8-499c-b3c6-a82d0e586a82", "label": "摘要9", "info": "我们也可以使用概率模型完成许多其他的任务。这些任务通常相比于分；类成本更高。其中的一些任务需要产生多个输出。大部分任务需要对输；入数据整个结构的完整理解，所以并不能舍弃数据的一部分。这些任务", "keywords": "这些任务, 入数据整个结构的完整理解, 这些任务通常相比于分, 所以并不能舍弃数据的一部分, 类成本更高", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "05dee522-e3fd-440c-bf6a-7ce29b7f4cd4", "label": "摘要10", "info": "估计密度函数：  给定一个输入  x  ，机器学习系统返回一个对数据；生成分布的真实密度函数p( x )的估计。这只需要一个输出，但它需；要完全理解整个输入。即使向量中只有一个元素不太正常，系统也", "keywords": "的估计, 估计密度函数, 系统也, 要完全理解整个输入, 机器学习系统返回一个对数据", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "daa99f74-52ab-4f15-a657-28f9bcd32114", "label": "摘要11", "info": "采样：  模型从分布p(  x  )中抽取新的样本。其应用包括语音合成，；即产生一个听起来很像人说话的声音。这个模型也需要多个输出以；及对输入整体的良好建模。即使样本只有一个从错误分布中产生的", "keywords": "这个模型也需要多个输出以, 模型从分布, 采样, 及对输入整体的良好建模, 其应用包括语音合成", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5eef27af-a9cc-4c1d-ba37-3fae54ae9b1f", "label": "摘要12", "info": "图16.1中描述了一个使用较小的自然图片的采样任务。", "keywords": "中描述了一个使用较小的自然图片的采样任务", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8159614c-1831-420d-8e8b-6619ef83ecd8", "label": "摘要13", "info": "对上千甚至是上百万随机变量的分布建模，无论从计算上还是从统计意；义上说，都是一个极具挑战性的任务。假设我们只想对二值的随机变量；建模。这是一个最简单的例子，但是我们仍然无能为力。对一个只有", "keywords": "对上千甚至是上百万随机变量的分布建模, 无论从计算上还是从统计意, 建模, 但是我们仍然无能为力, 对一个只有", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5d781a29-ac1b-4555-936d-6322c5f6a429", "label": "摘要14", "info": "通常意义上讲，如果我们希望对一个包含n个离散变量并且每个变量都；能取k个值的 x  的分布建模，那么最简单的表示P( x  )的方法需要存储一；个可以查询的表格。这个表格记录了每一种可能值的概率，则需要k", "keywords": "这个表格记录了每一种可能值的概率, 则需要, 的分布建模, 那么最简单的表示, 能取", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3df905eb-82ab-4d26-b8e6-b9ffed845931", "label": "摘要15", "info": "基于下述几个原因，这种方式是不可行的。", "keywords": "基于下述几个原因, 这种方式是不可行的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7ce04953-3109-4141-8c52-651f3e31da56", "label": "摘要16", "info": "内存：存储参数的开销。除了极小的n和k的值，用表格的形式来表；示这样一个分布需要太多的存储空间。；统计的高效性：当模型中的参数个数增加时，使用统计估计器估计", "keywords": "内存, 用表格的形式来表, 统计的高效性, 除了极小的, 存储参数的开销", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "df5681fa-a0d7-4b03-9d91-9e9fe31c81dc", "label": "摘要17", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；素。最差情况下，这个操作需要读取整个表格，所以和其他操作一；样，它也需要指数级别的时间。", "keywords": "这个操作需要读取整个表格, 所以和其他操作一, 它也需要指数级别的时间, 最差情况下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ba78de9f-0526-468b-9578-05df41938eb7", "label": "摘要18", "info": "图16.1　自然图片的概率建模。（上）CIFAR-10数据集（Krizhevsky and Hinton，2009）中的；32×32像素的样例图片。（下）从这个数据集上训练的结构化概率模型中抽出的样本。每一个样；本都出现在与其欧式距离最近的训练样本的格点中。这种比较使得我们发现这个模型确实能够", "keywords": "像素的样例图片, 每一个样, 本都出现在与其欧式距离最近的训练样本的格点中, 这种比较使得我们发现这个模型确实能够, 从这个数据集上训练的结构化概率模型中抽出的样本", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8f62d872-e93c-4e3c-996b-0854746159f4", "label": "摘要19", "info": "基于表格操作的方法的主要问题是我们显式地对每一种可能的变量子集；所产生的每一种可能类型的相互作用建模。在实际问题中我们遇到的概；率分布远比这个简单。通常，许多变量只是间接地相互作用。", "keywords": "许多变量只是间接地相互作用, 通常, 在实际问题中我们遇到的概, 率分布远比这个简单, 基于表格操作的方法的主要问题是我们显式地对每一种可能的变量子集", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "024b4f96-7956-4d65-b89b-d44e459577c4", "label": "摘要20", "info": "例如，我们想要对接力跑步比赛中一个队伍完成比赛的时间进行建模。；假设这个队伍有3名成员：Alice、Bob和Carol。在比赛开始时，Alice拿；着接力棒，开始跑第一段距离。在跑完她的路程以后，她把棒递给了", "keywords": "名成员, 我们想要对接力跑步比赛中一个队伍完成比赛的时间进行建模, 她把棒递给了, 开始跑第一段距离, 例如", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "18290a37-497a-4f36-9cc8-d62f066b2c2c", "label": "摘要21", "info": "Bob。然后Bob开始跑，再把棒给Carol，Carol跑最后一棒。我们可以用；连续变量来建模他们每个人完成的时间。因为Alice第一个跑，所以她的；完成时间并不依赖于其他的人。Bob的完成时间依赖于Alice的完成时", "keywords": "因为, 完成时间并不依赖于其他的人, 的完成时间依赖于, 第一个跑, 再把棒给", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "78364ccb-05b1-4ed5-9b4f-89f49a61baac", "label": "摘要22", "info": "结构化概率模型为随机变量之间的直接作用提供了一个正式的建模框；架。这种方式大大减少了模型的参数个数，以至于模型只需要更少的数；据来进行有效的估计。这些更小的模型大大减小了在模型存储、模型推", "keywords": "结构化概率模型为随机变量之间的直接作用提供了一个正式的建模框, 模型推, 这些更小的模型大大减小了在模型存储, 以至于模型只需要更少的数, 这种方式大大减少了模型的参数个数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "label": "16.2：使用图描述模型结构", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "655a6626-7074-4675-8197-94ff11abda22", "label": "摘要1", "info": "16.2.1　有向模型", "keywords": "有向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "477dc2f1-e1db-4a5b-9457-60ff03055094", "label": "摘要2", "info": "16.2.2　无向模型", "keywords": "无向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4b0f940e-8418-4319-87b4-54030eaa9ed2", "label": "摘要3", "info": "16.2.3　配分函数", "keywords": "配分函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "05a427f7-0915-49de-bc9a-73af80a50d92", "label": "摘要4", "info": "16.2.4　基于能量的模型", "keywords": "基于能量的模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f5158f3c-7d36-4c26-8881-aabf08ceff7c", "label": "摘要5", "info": "16.2.5　分离和d-分离", "keywords": "分离, 分离和", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "437940ea-1e4a-45f3-943e-d827b286fc7a", "label": "摘要6", "info": "16.2.6　在有向模型和无向模型中转换", "keywords": "在有向模型和无向模型中转换", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5fcac5a1-e6bd-4b98-9a14-0b1f34fa44a0", "label": "摘要7", "info": "16.2.7　因子图", "keywords": "因子图", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6e40002b-5628-46dc-af39-50e102ffb7e5", "label": "摘要8", "info": "结构化概率模型使用图（在图论中“结点”是通过“边”来连接的）来表示；随机变量之间的相互作用。每一个结点代表一个随机变量。每一条边代；表一个直接相互作用。这些直接相互作用隐含着其他的间接相互作用，", "keywords": "结点, 在图论中, 每一条边代, 结构化概率模型使用图, 表一个直接相互作用", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "94e423fd-8989-456d-a11e-06d54e326404", "label": "摘要9", "info": "使用图来描述概率分布中相互作用的方法不止一种。在下文中我们会介；绍几种最为流行和有用的方法。图模型可以被大致分为两类：基于有向；无环图的模型和基于无向图的模型。", "keywords": "绍几种最为流行和有用的方法, 图模型可以被大致分为两类, 使用图来描述概率分布中相互作用的方法不止一种, 在下文中我们会介, 无环图的模型和基于无向图的模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "11938ed4-694c-4b2d-8964-117fa2948345", "label": "摘要10", "info": "16.2.1　有向模型", "keywords": "有向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "574f6e27-6a3c-438b-a2ce-dcdbb6836d8e", "label": "摘要11", "info": "有向图模型  （directed  graphical  model）是一种结构化概率模型，也被；称为信念网络 （belief network）或者贝叶斯网络  （Bayesian  network）；(2) （Pearl，1985）。", "keywords": "有向图模型, 是一种结构化概率模型, 也被, 或者贝叶斯网络, 称为信念网络", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "786cbec7-d64a-45f9-9832-458ca4f78a28", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；之所以命名为有向图模型，是因为所有的边都是有方向的，即从一个结；点指向另一个结点。这个方向可以通过画一个箭头来表示。箭头所指的", "keywords": "点指向另一个结点, 箭头所指的, 这个方向可以通过画一个箭头来表示, 之所以命名为有向图模型, 是因为所有的边都是有方向的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b7b0cbc7-c87c-426d-88b9-2ea2372ee57b", "label": "摘要13", "info": "我们继续第16.1节所讲的接力赛的例子，我们假设Alice的完成时间为t  0；，Bob的完成时间为t 1 ，Carol的完成时间为t 2 。就像我们之前看到的一；样，t 1 的估计是依赖于t 0 的，t 2 的估计是直接依赖于t 1 的，但是仅仅间", "keywords": "的估计是直接依赖于, 但是仅仅间, 的完成时间为, 我们继续第, 我们假设", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "bbf6c556-07c0-4150-a0b9-1632382a8bc5", "label": "摘要14", "info": "图16.2　描述接力赛例子的有向图模型。Alice的完成时间t 0 影响了Bob的完成时间t 1 ，因为；Bob只能在Alice完成比赛后才开始。类似地，Carol也只会在Bob完成之后才开始，所以Bob的完；成时间t 1 直接影响了Carol的完成时间t 2", "keywords": "因为, 影响了, 成时间, 完成比赛后才开始, 完成之后才开始", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7af59dcf-4f7f-4663-a3e9-51f7fb5b47da", "label": "摘要15", "info": "正式地说，变量x 的有向概率模型是通过有向无环图  （每个结点都是；模型中的随机变量）和一系列局部条件概率分布  （local；conditional", "keywords": "和一系列局部条件概率分布, 每个结点都是, 模型中的随机变量, 正式地说, 的有向概率模型是通过有向无环图", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b5fe9fbb-d056-4128-a560-5de145eab328", "label": "摘要16", "info": "distribution）", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f2556acb-a5a0-40d5-b608-af507a24d870", "label": "摘要17", "info": "表示结点x i 的所有父结点。x 的概率分布可以表示为", "keywords": "的所有父结点, 表示结点, 的概率分布可以表示为", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "83b0af9b-8000-41c3-a89a-ac7b4325eef0", "label": "摘要18", "info": "在之前所述的接力赛的例子中，参考图16.2，这意味着概率分布可以被；表示为", "keywords": "在之前所述的接力赛的例子中, 参考图, 表示为, 这意味着概率分布可以被", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3935fa6e-1bc9-4be3-9fc9-0da25000ca08", "label": "摘要19", "info": "这是我们看到的第一个结构化概率模型的实际例子。我们能够检查这样；建模的计算开销，为了验证相比于非结构化建模，结构化建模为什么有；那么多的优势。", "keywords": "建模的计算开销, 我们能够检查这样, 结构化建模为什么有, 那么多的优势, 为了验证相比于非结构化建模", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f10925ba-4bda-438d-a122-2dc03777a2ad", "label": "摘要20", "info": "假设我们采用从第0分钟到第10分钟每6秒一块的方式离散化地表示时；间。这使得t  0  、t  1  和t  2  都是一个有100个取值可能的离散变量。如果我；们尝试着用一个表来表示p(t  0  ,t  1  ,t  2  )，那么我们需要存储999  999个值", "keywords": "这使得, 秒一块的方式离散化地表示时, 如果我, 那么我们需要存储, 分钟到第", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7988c834-1190-4f6d-b107-e5053444b9e6", "label": "摘要21", "info": "通常意义上说，对每个变量都能取k个值的n个变量建模，基于建表的方；法需要的复杂度是O(k  n  )，就像我们之前观察到的一样。现在假设我们；用一个有向图模型来对这些变量建模。如果m代表图模型的单个条件概", "keywords": "如果, 通常意义上说, 对每个变量都能取, 代表图模型的单个条件概, 用一个有向图模型来对这些变量建模", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "aa12c344-9114-47a5-b6fd-23bec40134a4", "label": "摘要22", "info": "，那么复杂度就会被大大地减小。", "keywords": "那么复杂度就会被大大地减小", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "94bf9210-6fc3-4b5c-b31f-d27969b07d50", "label": "摘要23", "info": "换一句话说，只要图中的每个变量都只有少量的父结点，那么这个分布；就可以用较少的参数来表示。图结构上的一些限制条件，比如说要求这；个图为一棵树，也可以保证一些操作（例如求一小部分变量的边缘或者", "keywords": "那么这个分布, 换一句话说, 个图为一棵树, 也可以保证一些操作, 图结构上的一些限制条件", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6ea5cf8f-f32a-440e-9dca-d14f1cecd7f4", "label": "摘要24", "info": "决定哪些信息需要被包含在图中而哪些不需要是很重要的。如果变量之；间可以被假设为是条件独立的，那么这个图可以包含这种简化假设。当；然也存在其他类型的简化图模型的假设。例如，我们可以假设无论Alice", "keywords": "然也存在其他类型的简化图模型的假设, 间可以被假设为是条件独立的, 我们可以假设无论, 例如, 决定哪些信息需要被包含在图中而哪些不需要是很重要的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8cf5e181-029e-4a51-b041-314cd6a627d0", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；计算Bob的完成时间时需要加上Alice的时间。这个假设使得我们所需要；的参数量从O(k  2  )  降到了O(k)。然而，值得注意的是，在这个假设下t  0", "keywords": "的完成时间时需要加上, 然而, 的参数量从, 值得注意的是, 在这个假设下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ffe42a05-1044-4f5e-b419-742241646f28", "label": "摘要26", "info": "16.2.2　无向模型", "keywords": "无向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "53fe4ba4-f13c-48ad-8f4c-38020d87adb7", "label": "摘要27", "info": "有向图模型为我们提供了一种描述结构化概率模型的语言。而另一种常；见的语言则是无向模型  （undirected  model），也被称为马尔可夫随机；field，MRF）或者是马尔可夫网络  （Markov", "keywords": "见的语言则是无向模型, 也被称为马尔可夫随机, 有向图模型为我们提供了一种描述结构化概率模型的语言, 而另一种常, 或者是马尔可夫网络", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f6961812-1e9e-4c1e-bc83-0220bb9e6718", "label": "摘要28", "info": "random", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8e8a721e-6b72-43a5-87e0-17ea3be38553", "label": "摘要29", "info": "当存在很明显的理由画出每一个指向特定方向的箭头时，有向模型显然；最适用。有向模型中，经常存在我们理解的具有因果关系以及因果关系；有明确方向的情况。接力赛的例子就是一个这样的情况。之前运动员的", "keywords": "有向模型中, 有向模型显然, 当存在很明显的理由画出每一个指向特定方向的箭头时, 接力赛的例子就是一个这样的情况, 有明确方向的情况", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "565da2a3-d922-4d12-8118-8eaa7a3bf203", "label": "摘要30", "info": "然而并不是所有情况的相互作用都有一个明确的方向关系。当相互的作；用并没有本质性的指向，或者是明确的双向相互作用时，使用无向模型；更加合适。", "keywords": "当相互的作, 或者是明确的双向相互作用时, 然而并不是所有情况的相互作用都有一个明确的方向关系, 用并没有本质性的指向, 更加合适", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f6cf0648-f2de-45e8-be93-2e648b6ccff7", "label": "摘要31", "info": "作为一个这种情况的例子，假设我们希望对3个二值随机变量建模：你；是否生病，你的同事是否生病以及你的室友是否生病。就像在接力赛的；例子中所作的简化假设一样，我们可以在这里做一些关于相互作用的简", "keywords": "作为一个这种情况的例子, 我们可以在这里做一些关于相互作用的简, 例子中所作的简化假设一样, 是否生病, 就像在接力赛的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9ee92aac-2840-4449-9b8b-8405f35b41a5", "label": "摘要32", "info": "另一个人。我们通过对你的同事传染给你以及你传染给你的室友建模来；对这种间接的从你的同事到你的室友的感冒传染建模。", "keywords": "对这种间接的从你的同事到你的室友的感冒传染建模, 另一个人, 我们通过对你的同事传染给你以及你传染给你的室友建模来", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3d466711-4515-4941-8468-5eb3ccc5d3e3", "label": "摘要33", "info": "在这种情况下，你传染给你的室友和你的室友传染给你都是非常容易；的，所以模型不存在一个明确的单向箭头。这启发我们使用无向模型。；其中随机变量对应着图中的相互作用的结点。与有向模型相同的是，如", "keywords": "所以模型不存在一个明确的单向箭头, 这启发我们使用无向模型, 你传染给你的室友和你的室友传染给你都是非常容易, 其中随机变量对应着图中的相互作用的结点, 在这种情况下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7fa20a49-3874-44c6-938f-45138a376812", "label": "摘要34", "info": "我们把对应你健康状况的随机变量记作h  y  ，对应你的室友健康状况的；随机变量记作h r ，你的同事健康的变量记作h c 。图16.3表示这种关系。", "keywords": "对应你的室友健康状况的, 表示这种关系, 你的同事健康的变量记作, 随机变量记作, 我们把对应你健康状况的随机变量记作", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c6d0ee39-d733-4533-a819-a478575c6bfe", "label": "摘要35", "info": "图16.3　表示你室友健康状况的h r 、你健康状况的h y 和你同事健康状况的h c 之间如何相互影；响的一个无向图。你和你的室友可能会相互传染感冒，你和你的同事之间也是如此，但是假设；你室友和同事之间相互不认识，他们只能通过你来间接传染", "keywords": "你健康状况的, 之间如何相互影, 你室友和同事之间相互不认识, 你和你的室友可能会相互传染感冒, 你和你的同事之间也是如此", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d74e3754-f8d2-4fbe-82ea-da1c001d115b", "label": "摘要36", "info": "正式地说，一个无向模型是一个定义在无向模型   上的结构化概率模；型。对于图中的每一个团 (3)；，一个因子 （factor）φ（  ）（也称为", "keywords": "一个无向模型是一个定义在无向模型, 也称为, 一个因子, 正式地说, 上的结构化概率模", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "032034b4-20a2-49a0-8da1-05cfa5bce07b", "label": "摘要37", "info": "只要所有团中的结点数都不大，那么我们就能够高效地处理这些未归一；化概率函数。它包含了这样的思想，密切度越高的状态有越大的概率。；然而，不像贝叶斯网络，几乎不存在团定义的结构，所以不能保证把它", "keywords": "几乎不存在团定义的结构, 它包含了这样的思想, 化概率函数, 所以不能保证把它, 然而", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5bc0f328-cbb5-41c8-8eaa-97599017f702", "label": "摘要38", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；型中读取分解信息的例子。", "keywords": "型中读取分解信息的例子", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3b388e33-5d45-4f0d-8a1b-bd80e222f94b", "label": "摘要39", "info": "图16.4　这个图说明通过选择适当的φ，函数p(a,b,c,d,e,f)可以写作", "keywords": "函数, 这个图说明通过选择适当的, 可以写作", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6b47df1c-488d-4ae1-811d-a063a1539270", "label": "摘要40", "info": "在你、你的室友和同事之间感冒传染的例子中包含了两个团。一个团包；含了h  y  和h  c  。这个团的因子可以通过一个表来定义，可能取到下面的；值。", "keywords": "一个团包, 含了, 在你, 可能取到下面的, 你的室友和同事之间感冒传染的例子中包含了两个团", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0c831708-ecce-4e8a-870c-7b71a5789a67", "label": "摘要41", "info": "状态为1代表了健康的状态，相对的状态为0则表示不好的健康状态（即；感染了感冒）。你们两个通常都是健康的，所以对应的状态拥有最高的", "keywords": "相对的状态为, 感染了感冒, 则表示不好的健康状态, 代表了健康的状态, 你们两个通常都是健康的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "a7f0305b-a7a8-4593-b63e-70fbd7e2340f", "label": "摘要42", "info": "密切程度。两个人中只有一个人是生病的密切程度是最低的，因为这是；一个很罕见的状态。两个人都生病的状态（通过一个人来传染给了另一；个人）有一个稍高的密切程度，尽管仍然不及两个人都健康的密切程", "keywords": "两个人都生病的状态, 个人, 有一个稍高的密切程度, 尽管仍然不及两个人都健康的密切程, 因为这是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "aeb7d2e7-c83b-4213-9202-b5a6c7a967a1", "label": "摘要43", "info": "为了完整地定义这个模型，我们需要对包含h  y  和h  r  的团定义类似的因；子。", "keywords": "我们需要对包含, 的团定义类似的因, 为了完整地定义这个模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "414729cb-71f7-4e3b-a5fb-a5ce9e54a49d", "label": "摘要44", "info": "16.2.3　配分函数", "keywords": "配分函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "2677b034-c663-4cef-9b68-3b434eba1d14", "label": "摘要45", "info": "尽管这个未归一化概率函数处处不为零，我们仍然无法保证它的概率之；和或者积分为1。为了得到一个有效的概率分布，我们需要使用对应的；归一化的概率分布 (4) ：", "keywords": "为了得到一个有效的概率分布, 尽管这个未归一化概率函数处处不为零, 我们仍然无法保证它的概率之, 我们需要使用对应的, 归一化的概率分布", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c91b7ad7-264d-4cc8-afe7-300510abcf75", "label": "摘要46", "info": "其中，Z是使得所有的概率之和或者积分为1的常数，并且满足：", "keywords": "并且满足, 是使得所有的概率之和或者积分为, 的常数, 其中", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9afb98ec-0b3f-49e3-bcf1-a1498eac51c1", "label": "摘要47", "info": "当函数φ固定时，我们可以把Z当成是一个常数。值得注意的是，如果函；数φ带有参数时，那么Z是这些参数的一个函数。在相关文献中为了节省；空间忽略控制Z的变量而直接写Z是一个常用的方式。归一化常数Z被称", "keywords": "在相关文献中为了节省, 的变量而直接写, 我们可以把, 带有参数时, 是一个常用的方式", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "17b43a4b-fd60-4120-89fd-4e5ca932534a", "label": "摘要48", "info": "由于Z通常是由对所有可能的x  状态的联合分布空间求和或者求积分得；到的，它通常是很难计算的。为了获得一个无向模型的归一化概率分；布，模型的结构和函数φ的定义通常需要设计为有助于高效地计算Z。在", "keywords": "状态的联合分布空间求和或者求积分得, 到的, 它通常是很难计算的, 由于, 模型的结构和函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "fec89566-8016-4836-97de-4e917f4b3ec4", "label": "摘要49", "info": "在设计无向模型时，我们必须牢记于心的一个要点是设定一些使得Z不；存在的因子也是有可能的。当模型中的一些变量是连续的，且  在其定；义域上的积分发散时这种情况就会发生。例如，当我们需要对一个单独", "keywords": "我们必须牢记于心的一个要点是设定一些使得, 义域上的积分发散时这种情况就会发生, 存在的因子也是有可能的, 例如, 在其定", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0e83c7c1-600e-4ec2-83af-dd6b3804cbae", "label": "摘要50", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的标量变量；这种情况下，", "keywords": "的标量变量, 这种情况下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "bc3ddbe6-43c2-49e7-b84f-a9aaaae154fd", "label": "摘要51", "info": "建模，并且单个团势能定义为φ(x)＝x  2  时。在", "keywords": "并且单个团势能定义为, 建模", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "1f6ef305-20df-4649-aea2-a642ebe0768e", "label": "摘要52", "info": "由于这个积分是发散的，所以不存在一个对应着这个势能函数φ(x)的概；率分布。有时候φ函数某些参数的选择可以决定相应的概率分布是否能；够被定义。例如，对φ函数φ(x;β)＝exp(−βx 2 )来说，参数β决定了归一化", "keywords": "够被定义, 参数, 决定了归一化, 率分布, 函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ea042fcb-7737-423b-929d-8ea72b3d17f4", "label": "摘要53", "info": "有向建模和无向建模之间一个重要的区别就是有向模型是通过从起始点；的概率分布直接定义的，反之无向模型的定义显得更加宽松，通过φ函；数转化为概率分布而定义。这改变了我们处理这些建模问题的直觉。当", "keywords": "数转化为概率分布而定义, 这改变了我们处理这些建模问题的直觉, 有向建模和无向建模之间一个重要的区别就是有向模型是通过从起始点, 的概率分布直接定义的, 反之无向模型的定义显得更加宽松", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b82014de-c4fd-4ebc-93be-2f4b79423a2b", "label": "摘要54", "info": "i", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6ecf3789-f90d-4740-999d-a13b5809aa37", "label": "摘要55", "info": "i", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "fe747cad-a19d-495a-b048-37aaf78953b2", "label": "摘要56", "info": ")。如果x", "keywords": "如果", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "13d81eac-f7a2-4057-8af6-2150e852a72f", "label": "摘要57", "info": "＝1)＝sigmoid(b", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "1b0789f6-b5d5-4805-a10f-78d1236aac02", "label": "摘要58", "info": "，那么p(x )可以被分解成n个独立的分布，并且满足p(x；的定义域是基本单位向量；的集合，", "keywords": "可以被分解成, 个独立的分布, 那么, 的集合, 并且满足", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0feff2bf-3fe9-47ab-a450-4332f69c4c18", "label": "摘要59", "info": "16.2.4　基于能量的模型", "keywords": "基于能量的模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0f8d1c5d-a941-4c74-aebf-481c551d3133", "label": "摘要60", "info": "这个假；无向模型中许多有趣的理论结果都依赖于∀  x  ，；设。使这个条件满足的一种简单方式是使用基于能量的模型  （Energy-", "keywords": "这个假, 无向模型中许多有趣的理论结果都依赖于, 使这个条件满足的一种简单方式是使用基于能量的模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "49fd0ddf-7eac-40ca-9dba-5022bfd83541", "label": "摘要61", "info": "based model，EBM），其中", "keywords": "其中", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9f0342f1-3043-40c5-b994-8001ceec036f", "label": "摘要62", "info": "E(x  )被称作是能量函数  （energy  function）。对所有的z，exp(z)都是正；的，这保证了没有一个能量函数会使得某一个状态x  的概率为0。我们；可以完全自由地选择那些能够简化学习过程的能量函数。如果我们直接", "keywords": "可以完全自由地选择那些能够简化学习过程的能量函数, 被称作是能量函数, 我们, 如果我们直接, 的概率为", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "18624676-d797-4715-b873-5098488ec405", "label": "摘要63", "info": "（Boltzmann", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4020ed14-c0ea-41e7-b04a-7a69aaddd1c5", "label": "摘要64", "info": "服从式（16.7）形式的任意分布都是玻尔兹曼分布；distribution）的一个实例。正是基于这个原因，我们把许多基于能量的；模型称为玻尔兹曼机 （Boltzmann  Machine）（Fahlman  et  al.  ，1983；", "keywords": "模型称为玻尔兹曼机, 形式的任意分布都是玻尔兹曼分布, 服从式, 我们把许多基于能量的, 的一个实例", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "473b8dc2-04c6-4689-98c3-43287870baf3", "label": "摘要65", "info": "无向模型中的团对应于未归一化概率函数中的因子。通过exp(a＋b)＝；exp(a)exp(b)，我们发现无向模型中的不同团对应于能量函数的不同项。；换句话说，基于能量的模型只是一种特殊的马尔可夫网络：求幂使能量", "keywords": "无向模型中的团对应于未归一化概率函数中的因子, 我们发现无向模型中的不同团对应于能量函数的不同项, 求幂使能量, 基于能量的模型只是一种特殊的马尔可夫网络, 通过", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "49a8b58d-caa7-4458-96d9-4aa26607eeb6", "label": "摘要66", "info": "of", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ae7f530b-c910-4d14-b172-484b102e63a2", "label": "摘要67", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图16.5　这个图说明通过为每个团选择适当的能量函数E(a,b,c,d,e,f)可以写作E a，b （a,b）＋E；b,c (b,c)＋E a,d (a,d)＋E b,e (b,e)＋E e,f (e,f)。值得注意的是，我们令φ等于对应负能量的指数，", "keywords": "我们令, 可以写作, 值得注意的是, 等于对应负能量的指数, 这个图说明通过为每个团选择适当的能量函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "885d73be-5722-4599-ba37-57fc315eb7eb", "label": "摘要68", "info": "基于能量的模型定义的一部分无法用机器学习观点来解释：即式；（16.7）中的“-”符号。这个“-”符号可以被包含在E的定义之中。对于很；多E函数的选择来说，学习算法可以自由地决定能量的符号。这个负号", "keywords": "这个负号, 符号, 的定义之中, 对于很, 函数的选择来说", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d92e47a7-f36f-4a08-98ef-9436a57a5302", "label": "摘要69", "info": "许多对概率模型进行操作的算法不需要计算p  model  (  x  )，而只需要计算；。对于具有潜变量 h 的基于能量的模型，这些算法有", "keywords": "的基于能量的模型, 而只需要计算, 许多对概率模型进行操作的算法不需要计算, 对于具有潜变量, 这些算法有", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "69c93d6a-6fd4-42d8-90cd-554daca543eb", "label": "摘要70", "info": "时会将该量的负数称为自由能 （free energy）：", "keywords": "时会将该量的负数称为自由能", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e05c63e8-cc73-4009-ba87-faa9fec3abf8", "label": "摘要71", "info": "在本书中，我们更倾向于更为通用的基于", "keywords": "在本书中, 我们更倾向于更为通用的基于", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "211a3a32-3bcc-4ea1-91d7-bca8915e1e29", "label": "摘要72", "info": "的定义。", "keywords": "的定义", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "83d59d9b-d93d-4e18-9514-affac13c064c", "label": "摘要73", "info": "16.2.5　分离和d-分离", "keywords": "分离, 分离和", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "34c3b461-d9ea-4ccd-9d86-2efff8cdc783", "label": "摘要74", "info": "图模型中的边告诉我们哪些变量直接相互作用。我们经常需要知道哪些；变量间接相互作用。某些间接相互作用可以通过观察其他变量来启用或；禁用。更正式地，我们想知道在给定其他变量子集的值时，哪些变量子", "keywords": "变量间接相互作用, 哪些变量子, 某些间接相互作用可以通过观察其他变量来启用或, 我们经常需要知道哪些, 禁用", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6ac0ccb8-7499-442e-86ee-dc1ceb65a089", "label": "摘要75", "info": "在无向模型中，识别图中的条件独立性是非常简单的。在这种情况下，；图中隐含的条件独立性称为分离  （separation）。如果图结构显示给定；变量集   的情况下变量集   与变量集   无关，那么我们声称给定变", "keywords": "识别图中的条件独立性是非常简单的, 在无向模型中, 变量集, 与变量集, 在这种情况下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "06c088fe-843e-4c35-aa54-55060ccd1035", "label": "摘要76", "info": "当我们画图时，我们可以通过加阴影来表示观察到的变量。图16.6用于；描述当以这种方式绘图时无向模型中的活跃和非活跃路径的样子。图；16.7描述了一个从无向模型中读取分离信息的例子。", "keywords": "当我们画图时, 描述当以这种方式绘图时无向模型中的活跃和非活跃路径的样子, 用于, 我们可以通过加阴影来表示观察到的变量, 描述了一个从无向模型中读取分离信息的例子", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c65af275-d8e8-4368-8d0d-c4d8364e6d85", "label": "摘要77", "info": "图16.6　（a）随机变量a和随机变量b之间穿过s的路径是活跃的，因为s是观察不到的。这意味；着a和b之间不是分离的。（b）图中s用阴影填充，表示它是可观察的。因为a和b之间的唯一路；径通过s，并且这条路径是不活跃的，我们可以得出结论，在给定s的条件下a和b是分离的", "keywords": "因为, 径通过, 的条件下, 这意味, 是分离的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3813a713-7bea-4f3d-9009-334eae1feab0", "label": "摘要78", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图16.7　从一个无向图中读取分离性质的一个例子。这里b用阴影填充，表示它是可观察的。由；于b挡住了从a到c的唯一路径，我们说在给定b的情况下a和c是相互分离的。观察值b同样挡住了", "keywords": "观察值, 的唯一路径, 同样挡住了, 从一个无向图中读取分离性质的一个例子, 表示它是可观察的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "1a945375-92e2-4acd-98b4-e165d312f19d", "label": "摘要79", "info": "类似的概念适用于有向模型，只是在有向模型中，这些概念被称为d-分；离  （d-separation）。“d”代表“依赖”的意思。有向图中d-分离的定义与；无向模型中分离的定义相同：如果图结构显示给定变量集   时，变量", "keywords": "这些概念被称为, 有向图中, 类似的概念适用于有向模型, 的意思, 只是在有向模型中", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "19daa41f-f621-4aec-b402-d6a621d32732", "label": "摘要80", "info": "与无向模型一样，我们可以通过查看图中存在的活跃路径来检查图中隐；含的独立性。如前所述，如果两个变量之间存在活跃路径，则两个变量；是依赖的。如果没有活跃路径，则为d-分离。在有向网络中，确定路径", "keywords": "如前所述, 是依赖的, 如果两个变量之间存在活跃路径, 我们可以通过查看图中存在的活跃路径来检查图中隐, 则两个变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "389b88af-da31-4086-b917-51a0115a2a62", "label": "摘要81", "info": "尤其重要的是，要记住分离和d-分离只能告诉我们图中隐含的条件独立；性。图并不需要表示所有存在的独立性。进一步的，使用完全图（具有；所有可能的边的图）来表示任何分布总是合法的。事实上，一些分布包", "keywords": "一些分布包, 事实上, 来表示任何分布总是合法的, 尤其重要的是, 分离只能告诉我们图中隐含的条件独立", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5d75361f-6b30-49c6-b41f-b5509036ae01", "label": "摘要82", "info": "的，但是当a是1时，b确定地等于c。当a＝1时，图模型需要连接b和c的；边。但是图不能说明当a＝0时，b和c不是独立的。", "keywords": "不是独立的, 确定地等于, 但是图不能说明当, 图模型需要连接, 但是当", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b5cbda86-b981-4e91-99ac-5ed0aa8c7e6c", "label": "摘要83", "info": "一般来说，当独立性不存在时，图不会显示独立性。然而，图可能无法；编码独立性。", "keywords": "编码独立性, 然而, 图不会显示独立性, 一般来说, 当独立性不存在时", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "39c7ee0f-b16a-4afb-86de-d4e87d110605", "label": "摘要84", "info": "图16.8　两个随机变量a和b之间存在长度为2的所有种类的活跃路径。（a）箭头方向从a指向b的；任何路径，反过来也一样。如果s可以被观察到，这种路径就是阻塞的。在接力赛的例子中，我；们已经看到过这种类型的路径。（b）变量a和b通过共因s相连。举个例子，假设s是一个表示是", "keywords": "如果, 在接力赛的例子中, 们已经看到过这种类型的路径, 指向, 是一个表示是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "5af36eea-356c-40ef-9cf3-fd5ffa531181", "label": "摘要85", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图16.9　从这张图中，我们可以发现一些d-分离的性质。它包括了以下几点", "keywords": "它包括了以下几点, 我们可以发现一些, 分离的性质, 从这张图中", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ad8c053a-d600-4c02-af85-dc571e74a16e", "label": "摘要86", "info": "给定空集的情况下，a和b是d-分离的。；给定c的情况下，a和e是d-分离的。；给定c的情况下，d和e是d-分离的。", "keywords": "分离的, 给定空集的情况下, 给定, 的情况下", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "1de8318d-16f3-4aa6-837c-6e852660936c", "label": "摘要87", "info": "我们还可以发现当我们观察到一些变量时，一些变量不再是d-分离的。", "keywords": "分离的, 一些变量不再是, 我们还可以发现当我们观察到一些变量时", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "487079ac-683e-4b64-a377-f50bb369416a", "label": "摘要88", "info": "给定c的情况下，a和b不是d-分离的。；给定d的情况下，a和b不是d-分离的", "keywords": "的情况下, 给定, 不是, 分离的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "44f4e612-ea33-4187-8684-714ae881bc7a", "label": "摘要89", "info": "16.2.6　在有向模型和无向模型中转换", "keywords": "在有向模型和无向模型中转换", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "ff0a2f60-bf76-42d3-b66e-4b388466d2e6", "label": "摘要90", "info": "我们经常将特定的机器学习模型称为无向模型或有向模型。例如，我们；通常将受限玻尔兹曼机称为无向模型，而稀疏编码则被称为有向模型。", "keywords": "通常将受限玻尔兹曼机称为无向模型, 我们, 例如, 而稀疏编码则被称为有向模型, 我们经常将特定的机器学习模型称为无向模型或有向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b9d91f95-40df-425c-8d43-955e5928d83c", "label": "摘要91", "info": "这种措辞的选择可能有点误导，因为没有概率模型本质上是有向或无向；的。但是，一些模型很适合使用有向图描述，而另一些模型很适合使用；无向模型描述。", "keywords": "一些模型很适合使用有向图描述, 但是, 无向模型描述, 因为没有概率模型本质上是有向或无向, 而另一些模型很适合使用", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "dfda9b77-5bd9-4847-902d-98a4f25ad646", "label": "摘要92", "info": "有向模型和无向模型都有其优点和缺点。这两种方法都不是明显优越和；普遍优选的。相反，我们根据具体的每个任务来决定使用哪一种模型。；这个选择部分取决于我们希望描述的概率分布。根据哪种方法可以最大", "keywords": "普遍优选的, 这两种方法都不是明显优越和, 根据哪种方法可以最大, 这个选择部分取决于我们希望描述的概率分布, 有向模型和无向模型都有其优点和缺点", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f623bdba-b7c6-4827-98ef-4151fe7288a5", "label": "摘要93", "info": "每个概率分布可以由有向模型或由无向模型表示。在最坏的情况下，我；们可以使用“完全图”来表示任何分布。在有向模型的情况下，完全图是；任意有向无环图，其中我们对随机变量排序，并且每个变量在排序中位", "keywords": "任意有向无环图, 在最坏的情况下, 完全图, 来表示任何分布, 完全图是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "18a328ae-57c8-4b7c-8f1c-f0dccb3c3689", "label": "摘要94", "info": "图16.10　完全图的例子，完全图能够描述任何的概率分布。这里我们展示了一个带有4个随机；变量的例子。（左）完全无向图。在无向图中，完全图是唯一的。（右）一个完全有向图。在；有向图中，并不存在唯一的完全图。我们选择一种变量的排序，然后对每一个变量，从它本身", "keywords": "有向图中, 完全图的例子, 个随机, 这里我们展示了一个带有, 完全图是唯一的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e4f318fb-527a-48b4-bd74-39f024596468", "label": "摘要95", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；种完全图。在这个例子中，我们从左到右、从上到下地排序变量", "keywords": "在这个例子中, 种完全图, 从上到下地排序变量, 我们从左到右", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4acc97e3-6f39-479e-8ae7-353e82983d82", "label": "摘要96", "info": "当然，图模型的优势在于图能够包含一些变量不直接相互作用的信息。；完全图并不是很有用，因为它并不隐含任何独立性。", "keywords": "当然, 因为它并不隐含任何独立性, 完全图并不是很有用, 图模型的优势在于图能够包含一些变量不直接相互作用的信息", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9005e310-8a5c-4632-8c42-cb238d063d99", "label": "摘要97", "info": "当我们用图表示概率分布时，我们想要选择一个包含尽可能多独立性的；图，但是并不会假设任何实际上不存在的独立性。", "keywords": "但是并不会假设任何实际上不存在的独立性, 当我们用图表示概率分布时, 我们想要选择一个包含尽可能多独立性的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "996256aa-d54c-4d25-8ea6-b3fab9db02d6", "label": "摘要98", "info": "从这个角度来看，一些分布可以使用有向模型更高效地表示，而其他分；布可以使用无向模型更高效地表示。换句话说，有向模型可以编码一些；无向模型所不能编码的独立性，反之亦然。", "keywords": "反之亦然, 而其他分, 无向模型所不能编码的独立性, 布可以使用无向模型更高效地表示, 有向模型可以编码一些", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "70e2f50c-cc35-4ff7-a09c-1f9dfdac97d7", "label": "摘要99", "info": "有向模型能够使用一种无向模型无法完美表示的特定类型的子结构。这；个子结构被称为不道德  （immorality）。这种结构出现在当两个随机变；量a和b都是第三个随机变量c的父结点，并且不存在任一方向上直接连", "keywords": "的父结点, 个子结构被称为不道德, 有向模型能够使用一种无向模型无法完美表示的特定类型的子结构, 并且不存在任一方向上直接连, 这种结构出现在当两个随机变", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7262ba27-4b88-4a96-8124-3e445b7ce25f", "label": "摘要100", "info": "图16.11　通过构造道德图将有向模型（上一行）转化为无向模型（下一行）的例子。（左）只；需要把有向边替换成无向边就可以把这个简单的链转化为一个道德图。得到的无向模型包含了；完全相同的独立关系和条件独立关系。（中）是在不丢失独立性的情况下无法转化为无向模型", "keywords": "转化为无向模型, 通过构造道德图将有向模型, 完全相同的独立关系和条件独立关系, 上一行, 是在不丢失独立性的情况下无法转化为无向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "a771a458-3690-4276-a877-c4e849151c39", "label": "摘要101", "info": "同样地，无向模型可以包括有向模型不能完美表示的子结构。具体来；说，如果  包含长度大于3的环 （loop），则有向图  不能捕获无向；模型  所包含的所有条件独立性，除非该环还包含弦 （chord）。环指", "keywords": "如果, 具体来, 不能捕获无向, 环指, 所包含的所有条件独立性", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "20f193f1-5f9a-4961-b550-3cb6fbbe9280", "label": "摘要102", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；graph）或者三角形化图 （triangulated  graph），因为我们现在可以用更；小的、三角的环来描述所有的环。要从弦图构建有向图   ，我们还需", "keywords": "要从弦图构建有向图, 因为我们现在可以用更, 或者三角形化图, 我们还需, 小的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b0cade23-c4ba-496a-ac56-e5326bd3164f", "label": "摘要103", "info": "图16.12　将一个无向模型转化为一个有向模型。（左）这个无向模型无法转化为有向模型，因；为它有一个长度为4且不带有弦的环。具体说来，这个无向模型包含了两种不同的独立性，并且；不存在一个有向模型可以同时描述这两种性质：a⊥c｜{b,d}和b⊥d｜{a,c}。（中）为了将无向", "keywords": "不存在一个有向模型可以同时描述这两种性质, 为了将无向, 具体说来, 为它有一个长度为, 将一个无向模型转化为一个有向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "cc5f66d0-5a88-4425-b6fe-ac0ab5f9d330", "label": "摘要104", "info": "16.2.7　因子图", "keywords": "因子图", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "7a760c82-6934-4f01-8221-6a2ef0d69577", "label": "摘要105", "info": "因子图 （factor graph）是从无向模型中抽样的另一种方法，它可以解决；标准无向模型语法中图表达的模糊性。在无向模型中，每个φ函数的范；围必须是图中某个团的子集。我们无法确定每一个团是否含有一个作用", "keywords": "在无向模型中, 我们无法确定每一个团是否含有一个作用, 因子图, 每个, 它可以解决", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e0fb23c5-d2d6-4d39-999b-ccde02f29a79", "label": "摘要106", "info": "变量。图16.13给出了一个例子来说明因子图如何解决无向网络中的模；糊性。", "keywords": "给出了一个例子来说明因子图如何解决无向网络中的模, 糊性, 变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "01557297-4d2f-4603-a77f-d3e5b4949cd9", "label": "摘要107", "info": "图16.13　因子图如何解决无向网络中模糊性的一个例子。（左）一个包含3个变量（a、b和c）；的团组成的无向网络。（中）对应这个无向模型的因子图。这个因子图有一个包含3个变量的因；子。（右）对应这个无向模型的另一种有效的因子图。这个因子图包含了3个因子，每个因子只", "keywords": "因子图如何解决无向网络中模糊性的一个例子, 的团组成的无向网络, 对应这个无向模型的因子图, 每个因子只, 个变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9d4e996f-dd0d-4083-92fe-9541d8456950", "label": "摘要108", "info": "16.2.1　有向模型", "keywords": "有向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "120e6eec-1f68-4d0a-8f4e-c3587d7cc9c0", "label": "摘要109", "info": "16.2.2　无向模型", "keywords": "无向模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "fae6c5cd-2474-408b-86c3-11e0d7d59f4e", "label": "摘要110", "info": "16.2.3　配分函数", "keywords": "配分函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "bdbf2adb-226f-4a69-a3d0-70d311e40a07", "label": "摘要111", "info": "16.2.4　基于能量的模型", "keywords": "基于能量的模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d165d65a-80d7-4b20-a73e-cfbcba3574c4", "label": "摘要112", "info": "16.2.5　分离和d-分离", "keywords": "分离, 分离和", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "72460300-c229-4e5d-aa2b-365691043f8e", "label": "摘要113", "info": "16.2.6　在有向模型和无；向模型中转换", "keywords": "向模型中转换, 在有向模型和无", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "641c86a8-9e71-41ef-bb14-a7bb654ae856", "label": "摘要114", "info": "16.2.7　因子图", "keywords": "因子图", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "label": "16.3：从图模型中采样", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "7e250707-0616-471f-a42f-0ae96ba349cb", "label": "摘要1", "info": "图模型同样简化了从模型中采样的过程。", "keywords": "图模型同样简化了从模型中采样的过程", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d2c61390-496c-4eaa-aa00-046bb0e3f188", "label": "摘要2", "info": "有向图模型的一个优点是，可以通过一个简单高效的过程从模型所表示；的联合分布中产生样本，这个过程被称为原始采样；（ancestral", "keywords": "有向图模型的一个优点是, 可以通过一个简单高效的过程从模型所表示, 的联合分布中产生样本, 这个过程被称为原始采样", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "83e44fdc-af37-45a0-a68e-c1832d19aebd", "label": "摘要3", "info": "原始采样的基本思想是将图中的变量x  i  使用拓扑排序，使得对于所有i；和j，如果x i 是x j 的一个父亲结点，则j大于i。然后可以按此顺序对变量；)，然后采", "keywords": "如果, 然后可以按此顺序对变量, 的一个父亲结点, 使用拓扑排序, 原始采样的基本思想是将图中的变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3f6e2422-0c51-451d-acbd-e5f00904ffe1", "label": "摘要4", "info": "∼P(x", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "100df787-a1e7-4f95-adc4-15c9d0886461", "label": "摘要5", "info": "1", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "605b697b-e926-4c44-8f21-2a9461635e6d", "label": "摘要6", "info": "有些图可能存在多个拓扑排序。原始采样可以使用这些拓扑排序中的任；何一个。", "keywords": "何一个, 有些图可能存在多个拓扑排序, 原始采样可以使用这些拓扑排序中的任", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f4d1c9c8-2f54-48d8-929b-349ebbf4c111", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；原始采样通常非常快（假设从每个条件分布中采样都是很容易的），并；且非常简便。", "keywords": "假设从每个条件分布中采样都是很容易的, 原始采样通常非常快, 且非常简便", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "f07b453e-b36c-414f-b8f0-c52140849344", "label": "摘要8", "info": "原始采样的一个缺点是其仅适用于有向图模型。另一个缺点是它并不是；每次采样都是条件采样操作。当我们希望从有向图模型中变量的子集中；采样时，给定一些其他变量，我们经常要求所有给定的条件变量在顺序", "keywords": "当我们希望从有向图模型中变量的子集中, 原始采样的一个缺点是其仅适用于有向图模型, 采样时, 给定一些其他变量, 另一个缺点是它并不是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "de80cf90-5972-4cc5-a206-9836b4e5f6c0", "label": "摘要9", "info": "不幸的是，原始采样仅适用于有向模型。我们可以通过将无向模型转换；为有向模型来实现从无向模型中采样，但是这通常需要解决棘手的推断；问题（要确定新有向图的根节点上的边缘分布），或者需要引入许多", "keywords": "原始采样仅适用于有向模型, 要确定新有向图的根节点上的边缘分布, 或者需要引入许多, 问题, 不幸的是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9d4c3a06-68f6-43f7-aa86-f896d3275341", "label": "16.4：结构化建模的优势", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "70515647-44c3-4ba9-803d-8116b1be0ca0", "label": "摘要1", "info": "使用结构化概率模型的主要优点是，它们能够显著降低表示概率分布、；学习和推断的成本。有向模型中采样还可以被加速，但是对于无向模型；情况则较为复杂。选择不对某些变量的相互作用进行建模是允许所有这", "keywords": "它们能够显著降低表示概率分布, 但是对于无向模型, 使用结构化概率模型的主要优点是, 学习和推断的成本, 情况则较为复杂", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c7e8c442-881e-4d03-9ca5-57264be4cce1", "label": "摘要2", "info": "些操作使用较少的运行时间和内存的主要机制。图模型通过省略某些边；来传达信息。在没有边的情况下，模型假设不对变量之间直接的相互作；用建模。", "keywords": "用建模, 在没有边的情况下, 来传达信息, 模型假设不对变量之间直接的相互作, 图模型通过省略某些边", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "32776b69-c91e-44bd-a2ca-7f7e7d4b9108", "label": "摘要3", "info": "结构化概率模型允许我们明确地将给定的现有知识与知识的学习或者推；断分开，这是一个不容易量化的益处。这使我们的模型更容易开发和调；试。我们可以设计、分析和评估适用于更广范围的图的学习算法和推断", "keywords": "这使我们的模型更容易开发和调, 结构化概率模型允许我们明确地将给定的现有知识与知识的学习或者推, 这是一个不容易量化的益处, 我们可以设计, 断分开", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "89f50736-9e3a-4095-9863-486c0bc35c01", "label": "16.5：学习依赖关系", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "f9c2a37c-ecea-4f8c-9b76-b791e3919851", "label": "摘要1", "info": "良好的生成模型需要准确地捕获所观察到的或“可见”变量v  上的分布。；通常v  的不同元素彼此高度依赖。在深度学习中，最常用于建模这些依；赖关系的方法是引入几个潜在或“隐藏”变量h  。然后，该模型可以捕获", "keywords": "可见, 的不同元素彼此高度依赖, 通常, 隐藏, 然后", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4ecaefb1-3844-4031-8ffa-49586589b993", "label": "摘要2", "info": "如果一个良好的关于v  的模型不包含任何潜变量，那么它在贝叶斯网络；中的每个节点需要具有大量父节点或在马尔可夫网络中具有非常大的；团。仅仅表示这些高阶相互作用的成本就很高了，首先从计算角度考", "keywords": "那么它在贝叶斯网络, 中的每个节点需要具有大量父节点或在马尔可夫网络中具有非常大的, 仅仅表示这些高阶相互作用的成本就很高了, 如果一个良好的关于, 首先从计算角度考", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "cf277a4a-e2b1-489a-8343-3ff4c19ee9f9", "label": "摘要3", "info": "当模型旨在描述直接连接的可见变量之间的依赖关系时，通常不可能连；接所有变量，因此设计图模型时需要连接那些紧密相关的变量，并忽略；其他变量之间的作用。机器学习中有一个称为结构学习", "keywords": "通常不可能连, 因此设计图模型时需要连接那些紧密相关的变量, 并忽略, 当模型旨在描述直接连接的可见变量之间的依赖关系时, 接所有变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b98db071-4d35-497d-9efc-cbe7e45c3601", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；使用潜变量而不是自适应结构避免了离散搜索和多轮训练的需要。可见；变量和潜变量之间的固定结构可以使用可见单元和隐藏单元之间的直接", "keywords": "可见, 变量和潜变量之间的固定结构可以使用可见单元和隐藏单元之间的直接, 使用潜变量而不是自适应结构避免了离散搜索和多轮训练的需要", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0e524ed3-3129-4896-8aac-0e0f1974a798", "label": "摘要5", "info": "潜变量除了发挥本来的作用，即能够高效地描述p( v )以外，还具有另外；的优势。新变量h  还提供了v  的替代表示。例如，如第3.9.6节所示，高；斯混合模型学习了一个潜变量，这个潜变量对应于输入样本是从哪一个", "keywords": "还提供了, 即能够高效地描述, 的替代表示, 潜变量除了发挥本来的作用, 的优势", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d4461547-da57-4e48-8fe4-8b658c3f8158", "label": "16.6：推断和近似推断", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "94ba4a86-698f-4050-88c9-f2b48606634f", "label": "摘要1", "info": "解决变量之间如何相互关联的问题是我们使用概率模型的一个主要方；式。给定一组医学测试，我们可以询问患者可能患有什么疾病。在一个；的特征", "keywords": "的特征, 在一个, 我们可以询问患者可能患有什么疾病, 给定一组医学测试, 解决变量之间如何相互关联的问题是我们使用概率模型的一个主要方", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "bf749216-50d8-4286-a9aa-c689651910bc", "label": "摘要2", "info": "用最大似然的准则来训练我们的模型。由于", "keywords": "用最大似然的准则来训练我们的模型, 由于", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e3e59b5a-70a6-416f-8f36-3294d2c7e120", "label": "摘要3", "info": ")。所有这些都是推断；学习过程中，我们经常需要计算p(h  ｜；（inference）问题的例子，其中我们必须预测给定其他变量的情况下一", "keywords": "学习过程中, 问题的例子, 我们经常需要计算, 其中我们必须预测给定其他变量的情况下一, 所有这些都是推断", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b2426894-6d30-4483-be99-d3d823cccda0", "label": "摘要4", "info": "ν", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "eefeb6fc-34f8-4b34-8920-7532a7370c26", "label": "摘要5", "info": "不幸的是，对于大多数有趣的深度模型来说，即使我们使用结构化图模；型来简化这些推断问题，它们仍然是难以处理的。图结构允许我们用合；理数量的参数来表示复杂的高维分布，但是用于深度学习的图并不满足", "keywords": "对于大多数有趣的深度模型来说, 理数量的参数来表示复杂的高维分布, 型来简化这些推断问题, 不幸的是, 图结构允许我们用合", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "368ce8bf-782a-4d38-accf-2051834017ee", "label": "摘要6", "info": "我们可以直接看出，计算一般图模型的边缘概率是#P-hard的。复杂性类；别#P是复杂性类别NP的泛化。NP中的问题只需确定其中一个问题是否；有解决方案，并找到一个解决方案（如果存在）就可以解决。#P中的问", "keywords": "就可以解决, 复杂性类, 是复杂性类别, 中的问题只需确定其中一个问题是否, 计算一般图模型的边缘概率是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "6ccdb336-39b6-4220-ae28-feb84b816a86", "label": "摘要7", "info": "这促使我们使用近似推断。在深度学习中，这通常涉及变分推断，其中；通过寻求尽可能接近真实分布的近似分布q(h  ｜v  )来逼近真实分布p(h；｜ ν )。这个技术将在第19章中深入讨论。", "keywords": "这通常涉及变分推断, 其中, 在深度学习中, 通过寻求尽可能接近真实分布的近似分布, 来逼近真实分布", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "fafda261-518d-408f-947c-56ce939e7f48", "label": "16.7：结构化概率模型的深度学习方法", "level": 2, "group": "chapter-16", "type": "子章節"}, {"id": "e2b174ed-aeaa-49af-aef3-f7f70cd2b492", "label": "摘要1", "info": "16.7.1　实例：受限玻尔兹曼机", "keywords": "受限玻尔兹曼机, 实例", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9ca4df29-65f2-4138-a1d6-68ffcdd639d6", "label": "摘要2", "info": "深度学习从业者通常与其他从事结构化概率模型研究的机器学习研究者；使用相同的基本计算工具。然而，在深度学习中，我们通常对如何组合；这些工具作出不同的设计决定，导致总体算法、模型与更传统的图模型", "keywords": "模型与更传统的图模型, 深度学习从业者通常与其他从事结构化概率模型研究的机器学习研究者, 使用相同的基本计算工具, 导致总体算法, 然而", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "513c5628-c398-4b51-b84b-75023922300c", "label": "摘要3", "info": "深度学习并不总是涉及特别深的图模型。在图模型中，我们可以根据图；模型的图而不是计算图来定义模型的深度。如果从潜变量h i 到可观察变；量的最短路径是j步，我们可以认为潜变量h  j  处于深度j。我们通常将模", "keywords": "在图模型中, 深度学习并不总是涉及特别深的图模型, 我们可以根据图, 如果从潜变量, 到可观察变", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "15905da5-1850-4d01-9775-437ab6437f23", "label": "摘要4", "info": "深度学习基本上总是利用分布式表示的思想。即使是用于深度学习目的；的浅层模型（例如预训练浅层模型，稍后将形成深层模型），也几乎总；是具有单个大的潜变量层。深度学习模型通常具有比可观察变量更多的", "keywords": "也几乎总, 深度学习基本上总是利用分布式表示的思想, 即使是用于深度学习目的, 的浅层模型, 例如预训练浅层模型", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "58a51edf-67e5-43fb-8bf3-b74e96fd419f", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；潜变量。变量之间复杂的非线性相互作用通过多个潜变量的间接连接来；实现。", "keywords": "变量之间复杂的非线性相互作用通过多个潜变量的间接连接来, 实现, 潜变量", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d4d038c2-f160-41cf-816c-453f6ef8d1aa", "label": "摘要6", "info": "相比之下，传统的图模型通常包含至少是偶尔观察到的变量，即使一些；训练样本中的许多变量随机地丢失。传统模型大多使用高阶项和结构学；习来捕获变量之间复杂的非线性相互作用。如果有潜变量，则它们的数", "keywords": "则它们的数, 即使一些, 习来捕获变量之间复杂的非线性相互作用, 如果有潜变量, 传统模型大多使用高阶项和结构学", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "79a8646d-d018-4f67-ac01-caf900cbcaed", "label": "摘要7", "info": "潜变量的设计方式在深度学习中也有所不同。深度学习从业者通常不希；望潜变量提前包含了任何特定的含义——训练算法可以自由地开发对特；定数据集建模所需要的概念。在事后解释潜变量通常是很困难的，但是", "keywords": "潜变量的设计方式在深度学习中也有所不同, 但是, 深度学习从业者通常不希, 望潜变量提前包含了任何特定的含义, 在事后解释潜变量通常是很困难的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "9872ed1f-6807-4010-8ccf-d30e20afd735", "label": "摘要8", "info": "另一个明显的区别是深度学习方法中经常使用的连接类型。深度图模型；通常具有大的与其他单元组全连接的单元组，使得两个组之间的相互作；用可以由单个矩阵描述。传统的图模型具有非常少的连接，并且每个变", "keywords": "另一个明显的区别是深度学习方法中经常使用的连接类型, 深度图模型, 并且每个变, 用可以由单个矩阵描述, 传统的图模型具有非常少的连接", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d1234e57-189d-40fb-b647-83352f630138", "label": "摘要9", "info": "最后，图模型的深度学习方法的一个主要特征在于对未知量的较高容忍；度。与简化模型直到它的每一个量都可以被精确计算不同的是，我们仅；仅直接使用数据运行或者是训练，以增强模型的能力。一般我们使用边", "keywords": "我们仅, 图模型的深度学习方法的一个主要特征在于对未知量的较高容忍, 一般我们使用边, 以增强模型的能力, 与简化模型直到它的每一个量都可以被精确计算不同的是", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "79597bef-17aa-4bd5-b3aa-254800d8840e", "label": "摘要10", "info": "16.7.1　实例：受限玻尔兹曼机", "keywords": "受限玻尔兹曼机, 实例", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "2e5e2553-775e-49ce-950a-91fb0fa08baa", "label": "摘要11", "info": "Boltzmann", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "146918de-8b99-474f-af3f-a33ee3105b73", "label": "摘要12", "info": "（Restricted", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "47cf754f-5b92-4979-ab39-33508cd3a255", "label": "摘要13", "info": "Machine，RBM）；受限玻尔兹曼机；（Smolensky，1986）或者簧风琴  （harmonium）是图模型如何用于深", "keywords": "受限玻尔兹曼机, 或者簧风琴, 是图模型如何用于深", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "baf20e7b-313c-4b3b-b0a7-bc4d8c6b02c2", "label": "摘要14", "info": "标准的RBM是具有二值的可见和隐藏单元的基于能量的模型。其能量；函数为", "keywords": "函数为, 其能量, 是具有二值的可见和隐藏单元的基于能量的模型, 标准的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "189d34e1-af14-41e3-b4a6-85f19a41d462", "label": "摘要15", "info": "其中 b、c 和 W 都是无约束、实值的可学习参数。我们可以看到，模型；被分成两组单元： ν  和  h  ，它们之间的相互作用由矩阵  W  来描述。该；模型在图16.14中以图的形式描绘。该图能够使我们更清楚地发现，该", "keywords": "模型在图, 来描述, 其中, 我们可以看到, 被分成两组单元", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "838e9932-e578-4a5f-93d8-80c5f88169fc", "label": "摘要16", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图16.14　一个画成马尔可夫网络形式的RBM", "keywords": "一个画成马尔可夫网络形式的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c7b693a7-54bd-478b-bf21-1899b5217eb6", "label": "摘要17", "info": "对RBM结构的限制产生了良好的属性", "keywords": "结构的限制产生了良好的属性", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "0ec81ec8-68c9-4b10-b9df-c911c9773add", "label": "摘要18", "info": "以及", "keywords": "以及", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "e3f8d505-c566-4514-b2ae-94c02066554f", "label": "摘要19", "info": "独立的条件分布很容易计算。对于二元的受限玻尔兹曼机，我们可以得；到", "keywords": "独立的条件分布很容易计算, 对于二元的受限玻尔兹曼机, 我们可以得", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "238b388c-29b7-4675-878e-f9b6d4475126", "label": "摘要20", "info": "结合这些属性可以得到高效的块吉布斯采样；Gibbs；Sampling），它在同时采样所有 h 和同时采样所有 ν 之间交替。RBM模", "keywords": "和同时采样所有, 之间交替, 结合这些属性可以得到高效的块吉布斯采样, 它在同时采样所有", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "d129b107-a319-4863-a482-67f3b6444de7", "label": "摘要21", "info": "（block", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4e7e6727-cb10-4377-9469-2846ff2c26b1", "label": "摘要22", "info": "图16.15　训练好的RBM的样本及其权重。（左）用MNIST训练模型，然后用Gibbs采样进行采；样。每一列是一个单独的Gibbs采样过程。每一行表示另一个1000步后Gibbs采样的输出。连续；的样本之间彼此高度相关。（右）对应的权重向量。将本图结果与图13.2中描述的线性因子模", "keywords": "采样进行采, 每一行表示另一个, 连续, 中描述的线性因子模, 的样本之间彼此高度相关", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c19d7e04-5727-47d1-9942-0f29ba772ce5", "label": "摘要23", "info": "由于能量函数本身只是参数的线性函数，很容易获取能量函数的导数。；例如，", "keywords": "很容易获取能量函数的导数, 例如, 由于能量函数本身只是参数的线性函数", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "2755e516-6336-4762-9c76-d5ab8e83a812", "label": "摘要24", "info": "这两个属性，高效的Gibbs采样和导数计算，使训练过程变得非常方；便。在第18章中，我们将看到，可以通过计算应用于这种来自模型样本；的导数来训练无向模型。", "keywords": "的导数来训练无向模型, 章中, 我们将看到, 高效的, 使训练过程变得非常方", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "a0449ff2-e5c6-45d2-b11d-8e6a89a0e7f3", "label": "摘要25", "info": "训练模型可以得到数据 v 的表示 h 。我们经常使用；一组描述 v 的特征。", "keywords": "的表示, 的特征, 一组描述, 训练模型可以得到数据, 我们经常使用", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b118c509-502b-4e37-8f94-cc81a8713839", "label": "摘要26", "info": "作为", "keywords": "作为", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "4ed97f18-2f79-4c73-873b-f00f45f4a5ff", "label": "摘要27", "info": "总的来说，RBM展示了典型的图模型深度学习方法：使用多层潜变；量，并由矩阵参数化层之间的高效相互作用来完成表示学习。", "keywords": "并由矩阵参数化层之间的高效相互作用来完成表示学习, 展示了典型的图模型深度学习方法, 总的来说, 使用多层潜变", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "b28c8e11-ecdd-4f3d-8f60-c9c91fe32fba", "label": "摘要28", "info": "图模型为描述概率模型提供了一种优雅、灵活、清晰的语言。在后续的；章节中，我们将使用这种语言，以其他视角来描述各种各样的深度概率；模型。", "keywords": "章节中, 在后续的, 灵活, 我们将使用这种语言, 图模型为描述概率模型提供了一种优雅", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "cdaa40d6-beab-4406-8cc2-52ab369ae91f", "label": "摘要29", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "aa4d41e6-ed32-476e-8c80-12155463eef7", "label": "摘要30", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；(1)    自然图片指的是能够在正常的环境下被照相机拍摄的图片，不同于合成的图片，或者一个；网页的截图等。", "keywords": "网页的截图等, 不同于合成的图片, 或者一个, 自然图片指的是能够在正常的环境下被照相机拍摄的图片", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "afe70485-00a6-437f-a8f8-c8e28e7cbd82", "label": "摘要31", "info": "(2)  当我们希望“强调”从网络中计算出的值的“推断”本质，即强调这些值代表的是置信程度大小；而不是事件的频率时，Judea Pearl建议使用“贝叶斯网络”这个术语", "keywords": "强调, 推断, 建议使用, 这个术语, 即强调这些值代表的是置信程度大小", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "3bb4b4d9-29a1-4da0-a382-62b58e69bd7a", "label": "摘要32", "info": "(3)  图的一个团是图中结点的一个子集，并且其中的点是全连接的。", "keywords": "图的一个团是图中结点的一个子集, 并且其中的点是全连接的", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "81623471-86ce-4679-a992-cf681cc75f43", "label": "摘要33", "info": "(4)  一个通过归一化团势能乘积定义的分布也被称作 吉布斯分布 （Gibbs distribution）。", "keywords": "吉布斯分布, 一个通过归一化团势能乘积定义的分布也被称作", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "c72351ec-d232-47a0-9bb9-01b91249d5a3", "label": "摘要34", "info": "(5)  对于某些模型，我们可以仍然使用约束优化方法来确保Z存在。", "keywords": "对于某些模型, 我们可以仍然使用约束优化方法来确保, 存在", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "515ab736-0427-4537-80a0-3b3a17141efb", "label": "摘要35", "info": "16.7.1　实例：受限玻尔；兹曼机", "keywords": "实例, 受限玻尔, 兹曼机", "level": 3, "group": "chapter-16", "type": "段落"}, {"id": "8da00874-11db-488b-8351-c53dc0d78471", "label": "第17章：蒙特卡罗方法", "level": 1, "group": "chapter-17", "type": "章節"}, {"id": "d4ea06ed-4c91-4e0b-b144-da9a021b7fa0", "label": "16.7：结构化概率模型的深度学习方法", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "fc47e110-fd2a-47ee-b3aa-ec4a3f61ff27", "label": "摘要1", "info": "Vegas算法和蒙特卡罗算法。Las", "keywords": "算法和蒙特卡罗算法", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "bdaa74bf-4059-4b06-a7d6-f3fcc99f1122", "label": "摘要2", "info": "随机算法可以粗略地分为两类：Las；Vegas算法总是精确地返回一个正确答案（或者返回算法失败了）。这；类方法通常需要占用随机量的计算资源（一般指内存或运行时间）。与", "keywords": "一般指内存或运行时间, 随机算法可以粗略地分为两类, 或者返回算法失败了, 算法总是精确地返回一个正确答案, 类方法通常需要占用随机量的计算资源", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "c6c4e65a-ea46-48dc-98b5-efb7efb2369d", "label": "摘要3", "info": "对于机器学习中的许多问题来说，我们很难得到精确的答案。这类问题；很难用精确的确定性算法如Las Vegas算法解决。取而代之的是确定性的；近似算法或蒙特卡罗近似方法。这两种方法在机器学习中都非常普遍。", "keywords": "取而代之的是确定性的, 这两种方法在机器学习中都非常普遍, 对于机器学习中的许多问题来说, 近似算法或蒙特卡罗近似方法, 这类问题", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "label": "17.1：采样和蒙特卡罗方法", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "bfcf6330-a328-4f34-98d9-50c07faeb19b", "label": "摘要1", "info": "17.1.1　为什么需要采样", "keywords": "为什么需要采样", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "fc507e9d-3134-4c90-a9a9-52e738aeab33", "label": "摘要2", "info": "17.1.2　蒙特卡罗采样的基础", "keywords": "蒙特卡罗采样的基础", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f84849e0-4a73-4e2d-91b5-5047e113a8cf", "label": "摘要3", "info": "机器学习中的许多重要工具都基于从某种分布中采样，以及用这些样本；对目标量做一个蒙特卡罗估计。", "keywords": "机器学习中的许多重要工具都基于从某种分布中采样, 对目标量做一个蒙特卡罗估计, 以及用这些样本", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "6c57c57d-56e6-49ba-a9e5-0b97cf811ac4", "label": "摘要4", "info": "17.1.1　为什么需要采样", "keywords": "为什么需要采样", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "48b2aa8a-7fa5-44d5-abbf-70d9e757c1e3", "label": "摘要5", "info": "有许多原因使我们希望从某个分布中采样。当我们需要以较小的代价近；似许多项的和或某个积分时，采样是一种很灵活的选择。有时候，我们；使用它加速一些很费时却易于处理的求和估计，就像我们使用小批量对", "keywords": "就像我们使用小批量对, 采样是一种很灵活的选择, 当我们需要以较小的代价近, 我们, 有时候", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5ea6c804-1411-4750-8756-f06edd620ac9", "label": "摘要6", "info": "整个训练代价进行子采样一样。在其他情况下，我们需要近似一个难以；处理的求和或积分，例如估计一个无向模型中配分函数对数的梯度时。；在许多其他情况下，抽样实际上是我们的目标，例如我们想训练一个可", "keywords": "例如估计一个无向模型中配分函数对数的梯度时, 我们需要近似一个难以, 整个训练代价进行子采样一样, 处理的求和或积分, 抽样实际上是我们的目标", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "153a80a9-ae42-40de-ba58-8f80ee05e480", "label": "摘要7", "info": "17.1.2　蒙特卡罗采样的基础", "keywords": "蒙特卡罗采样的基础", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "dac41db6-17fd-42e1-9b8b-f567b1776e6d", "label": "摘要8", "info": "当无法精确计算和或积分（例如，和具有指数数量个项，且无法被精确；简化）时，通常可以使用蒙特卡罗采样来近似它。这种想法把和或者积；分视作某分布下的期望，然后通过估计对应的平均值来近似这个期望。", "keywords": "当无法精确计算和或积分, 这种想法把和或者积, 分视作某分布下的期望, 然后通过估计对应的平均值来近似这个期望, 简化", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "276ba9a1-dd4c-44e4-aed6-bbbe6c43cc6c", "label": "摘要9", "info": "或者", "keywords": "或者", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "8d314bd2-7aca-48fc-a286-4429026fa0d1", "label": "摘要10", "info": "为我们所需要估计的和或者积分，写成期望的形式，p是一个关于随机；变量x 的概率分布（求和时）或者概率密度函数（求积分时）。", "keywords": "的概率分布, 或者概率密度函数, 为我们所需要估计的和或者积分, 写成期望的形式, 是一个关于随机", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "a0076bdb-d29a-476d-8b16-34a9447273bc", "label": "摘要11", "info": "我们可以通过从p中抽取n个样本 x  (1)  ，…，  x  (n)  来近似s并得到一个经；验平均值", "keywords": "我们可以通过从, 并得到一个经, 个样本, 中抽取, 验平均值", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "bde148b2-3b83-4051-95eb-dfe8530c5360", "label": "摘要12", "info": "下面几个性质表明了这种近似的合理性。首先很容易观察到   这个估计；是无偏的，由于", "keywords": "这个估计, 下面几个性质表明了这种近似的合理性, 由于, 首先很容易观察到, 是无偏的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "7c5367b0-5e04-45c7-9b51-519a9e49e1d2", "label": "摘要13", "info": "此外，根据大数定理 （Law of large number），如果样本 x  (i)  是独立同；分布的，那么其平均值几乎必然收敛到期望值，即", "keywords": "那么其平均值几乎必然收敛到期望值, 是独立同, 此外, 根据大数定理, 如果样本", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "0884cf0e-f46e-43bc-be3a-49b2c5e885e7", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；只需要满足各个单项的方差Var［f(  x  (i)  )］有界。详细地说，我们考虑；当n增大时  的方差。只要满足Var［f( x  (i) )］＜∞，方差", "keywords": "有界, 详细地说, 我们考虑, 只需要满足各个单项的方差, 方差", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f4e9ba9e-a010-4736-a693-637ed88b77a8", "label": "摘要15", "info": "这个简单有用的结果启迪我们如何估计蒙特卡罗均值中的不确定性，或；者等价地说是蒙特卡罗估计的期望误差。我们计算了f( x  (i)  )的经验均值；和方差 (1) ，然后将估计的方差除以样本数n来得到", "keywords": "这个简单有用的结果启迪我们如何估计蒙特卡罗均值中的不确定性, 和方差, 者等价地说是蒙特卡罗估计的期望误差, 来得到, 然后将估计的方差除以样本数", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "8fbbdded-f82f-4b7b-ad3e-6b3f9e4b028c", "label": "摘要16", "info": "值以", "keywords": "值以", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "7ca3cacb-68ad-43cc-ad8d-321d68e0a594", "label": "摘要17", "info": "为方差的正态分布。这使得我们可以利用正态分布", "keywords": "为方差的正态分布, 这使得我们可以利用正态分布", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "1cccbd4a-7ab7-4d8a-8974-cf749d0171e9", "label": "摘要18", "info": "的累积函数来估计  的置信区间。", "keywords": "的置信区间, 的累积函数来估计", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "bd316430-6147-4c34-b1c7-24e5c9c536f6", "label": "摘要19", "info": "以上的所有结论都依赖于我们可以从基准分布p(x  )中轻易地采样，但是；这个假设并不是一直成立的。当我们无法从p中采样时，一个备选方案；是用第17.2节讲到的重要采样。一种更加通用的方式是构建一个收敛到", "keywords": "一个备选方案, 是用第, 但是, 当我们无法从, 节讲到的重要采样", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "9df38132-c39e-4720-9d55-d6e8006569a1", "label": "摘要20", "info": "17.1.1　为什么需要采样", "keywords": "为什么需要采样", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "d78a1cc4-f600-468e-8eb7-b983cd130c90", "label": "摘要21", "info": "17.1.2　蒙特卡罗采样的；基础", "keywords": "基础, 蒙特卡罗采样的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "label": "17.2：重要采样", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "33db6608-612f-49e2-90cb-9f1fc1e2f600", "label": "摘要1", "info": "如方程（17.2）所示，在蒙特卡罗方法中，对积分（或者和）分解，确；定积分中哪一部分作为概率分布p( x )以及哪一部分作为被积的函数f( x )；（我们感兴趣的是估计f(  x  )在概率分布p(  x  )下的期望）是很关键的一", "keywords": "分解, 我们感兴趣的是估计, 定积分中哪一部分作为概率分布, 下的期望, 是很关键的一", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "1eccd0b7-67f9-4c53-bbd0-7a55b1183b4c", "label": "摘要2", "info": "在这里，我们从q分布中采样，然后估计   在此分布下的均值。许多", "keywords": "在这里, 在此分布下的均值, 许多, 我们从, 然后估计", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "51d12e7a-f03d-4603-a206-440778323f27", "label": "摘要3", "info": "情况中，我们希望在给定p和f的情况下计算某个期望，这个问题既然是；求期望，那么很自然地p和f是一种分解选择。然而，如果考虑达到某给；定精度所需要的样本数量，这个问题最初的分解选择不是最优的选择。", "keywords": "这个问题既然是, 求期望, 如果考虑达到某给, 然而, 的情况下计算某个期望", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "97b85b8e-a152-4301-bd39-28b585328cfc", "label": "摘要4", "info": "从式（17.8）所示的关系中可以发现，任意蒙特卡罗估计", "keywords": "所示的关系中可以发现, 任意蒙特卡罗估计, 从式", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "b0ad26c2-a1d0-4781-937c-9dc4bce94a8b", "label": "摘要5", "info": "可以被转化为一个重要采样的估计", "keywords": "可以被转化为一个重要采样的估计", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "740e89e5-06c0-44e0-805f-cbf0769682cc", "label": "摘要6", "info": "我们可以容易地发现估计的期望与q分布无关：", "keywords": "分布无关, 我们可以容易地发现估计的期望与", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "c44183c6-e26f-443f-b4e4-fd1a366786e5", "label": "摘要7", "info": "然而，重要采样的方差可能对q的选择非常敏感。这个方差可以表示为", "keywords": "这个方差可以表示为, 然而, 的选择非常敏感, 重要采样的方差可能对", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5bb3d49a-9596-48d7-8be8-2a4064410db3", "label": "摘要8", "info": "方差想要取到最小值，q需要满足", "keywords": "方差想要取到最小值, 需要满足", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "61ec4fb4-405f-49a7-bc5b-8110ed143720", "label": "摘要9", "info": "在这里Z表示归一化常数，选择适当的Z使得q  ∗  (  x  )之和或者积分为1。；一个更好的重要采样分布会把更多的权重放在被积函数较大的地方。事；实上，当f(  x  )的正负符号不变时，", "keywords": "在这里, 之和或者积分为, 的正负符号不变时, 选择适当的, 实上", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "079d0587-1979-418c-884e-63975f26e37d", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；∗  时已经解决了原问题。所以在实践中这种只需要采样一个样本的方法；往往是无法实现的。", "keywords": "时已经解决了原问题, 往往是无法实现的, 所以在实践中这种只需要采样一个样本的方法", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "93007ec3-a920-4abc-b52a-eb6046fa8d84", "label": "摘要11", "info": "对于重要采样来说，任意q分布都是可行的（从得到一个期望上正确的；值的角度来说），q  ∗  指的是最优的q分布（从得到最小方差的角度上考；虑）。从q  ∗  中采样往往是不可行的，但是其他仍然能降低方差的q的选", "keywords": "对于重要采样来说, 从得到一个期望上正确的, 但是其他仍然能降低方差的, 分布都是可行的, 中采样往往是不可行的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "dc6142f1-c521-4e47-a314-fc76ac775779", "label": "摘要12", "info": "另一种方法是采用有偏重要采样  （biased  importance  sampling），这种；方法有一个优势，即不需要归一化的p或q分布。在处理离散变量时，有；偏重要采样估计可以表示为", "keywords": "这种, 另一种方法是采用有偏重要采样, 偏重要采样估计可以表示为, 分布, 方法有一个优势", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "b32a7018-406f-4501-8b03-dc9e2f95c564", "label": "摘要13", "info": "其中   和   分别是分布p和q的未经归一化的形式，  x  (i)  是从分布q中抽；取的样本。这种估计是有偏的，因为；，只有当n→∞且方", "keywords": "因为, 只有当, 中抽, 取的样本, 这种估计是有偏的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "69c0e2ff-cd89-4787-9e7a-825db6b1a89d", "label": "摘要14", "info": "一个好的q分布的选择可以显著地提高蒙特卡罗估计的效率，而一个糟；糕的q分布选择则会使效率更糟糕。我们回过头来看看方程式（17.12）", "keywords": "一个好的, 糕的, 我们回过头来看看方程式, 分布选择则会使效率更糟糕, 而一个糟", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "7ae03b6c-ad93-4923-a3a4-2f91251ad352", "label": "摘要15", "info": "会发现，如果存在一个q使得", "keywords": "如果存在一个, 使得, 会发现", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "87fbe8bf-809f-49b5-b81c-cbd3d2f00964", "label": "摘要16", "info": "很大，那么这个估计的方差", "keywords": "那么这个估计的方差, 很大", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f328b1e6-22e2-46c3-809d-ad4444b6782d", "label": "摘要17", "info": "也会很大。当q( x )很小，而f( x )和p( x )都较大并且无法抵消q时，这种；情况会非常明显。q分布经常会取一些简单常用的分布使得我们能够从q；分布中容易地采样。当 x  是高维数据时，q分布的简单性使得它很难与p", "keywords": "分布中容易地采样, 这种, 也会很大, 情况会非常明显, 都较大并且无法抵消", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "50f484ab-4d38-49b2-81a9-88282c12a4f6", "label": "摘要18", "info": "到了很多无用的样本（很小的数或零相加）。另一种相对少见的情况是；，相应的比值会非常大。正因为后一个", "keywords": "另一种相对少见的情况是, 正因为后一个, 到了很多无用的样本, 很小的数或零相加, 相应的比值会非常大", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "e0c03e10-d1c0-475a-99c5-06ac140bdd7f", "label": "摘要19", "info": "事件是很少发生的，这种样本很难被采到，通常使得对s的估计出现了；典型的欠估计，很难被整体的过估计抵消。这样的不均匀情况在高维数；据屡见不鲜，因为在高维度分布中联合分布的动态域可能非常大。", "keywords": "这样的不均匀情况在高维数, 事件是很少发生的, 因为在高维度分布中联合分布的动态域可能非常大, 典型的欠估计, 这种样本很难被采到", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "a7acb01f-8cd6-4b92-95ce-c3b14a44eff9", "label": "摘要20", "info": "尽管存在上述的风险，但是重要采样及其变种在机器学习的应用中仍然；扮演着重要的角色，包括深度学习算法。例如，重要采样被应用于加速；训练具有大规模词表的神经网络语言模型的过程中（见第12.4.3.3节）", "keywords": "尽管存在上述的风险, 但是重要采样及其变种在机器学习的应用中仍然, 例如, 包括深度学习算法, 扮演着重要的角色", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "label": "17.3：马尔可夫链蒙特卡罗方法", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "2e5188c5-f208-43e3-ab16-dc88b06c1e1a", "label": "摘要1", "info": "在许多实例中，我们希望采用蒙特卡罗方法，然而往往又不存在一种简；单的方法可以直接从目标分布p model (x )中精确采样或者一个好的（方差；较小的）重要采样分布q(  x  )。在深度学习中，当分布p  model  (x  )表示成", "keywords": "然而往往又不存在一种简, 单的方法可以直接从目标分布, 较小的, 在许多实例中, 在深度学习中", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "bb72f593-4647-4951-aeed-ce7b71466ef0", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；立。", "keywords": "", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "6f80b18a-011d-48a1-9028-e2a3e36c883b", "label": "摘要3", "info": "为了解释从基于能量的模型中采样困难的原因，我们考虑一个包含两个；变量的EBM的例子，记p(a,b)为其分布。为了采a，我们必须先从p(a｜b)；中采样；为了采b，我们又必须从p(b｜a)中采样。这似乎成了棘手的先", "keywords": "为了解释从基于能量的模型中采样困难的原因, 为了采, 为其分布, 我们必须先从, 的例子", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "ff33e33d-9de4-40bb-bd82-5a84bfd5f076", "label": "摘要4", "info": "在EBM中，我们通过使用马尔可夫链来采样，从而避免了先有鸡还是先；有蛋的问题。马尔可夫链的核心思想是从某个可取任意值的状态  x  出；发。随着时间的推移，我们随机地反复更新状态 x 。最终 x 成为了一个", "keywords": "有蛋的问题, 马尔可夫链的核心思想是从某个可取任意值的状态, 我们通过使用马尔可夫链来采样, 成为了一个, 从而避免了先有鸡还是先", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "acaaed8b-5013-4399-ac88-7ba921f3e6fc", "label": "摘要5", "info": "为了给出MCMC方法为何有效的一些理论解释，重参数化这个问题是很；有用的。首先我们关注一些简单的情况，其中随机变量x  有可数个状；态。我们将这种状态简单地记作正整数x。不同的整数x的大小对应着原", "keywords": "首先我们关注一些简单的情况, 为了给出, 有用的, 我们将这种状态简单地记作正整数, 有可数个状", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5cce76c5-a462-4a20-a743-d8079979828f", "label": "摘要6", "info": "接下来我们考虑如果并行地运行无穷多个马尔可夫链的情况。不同马尔；可夫链的所有状态都采样自某一个分布q (t) (x)，在这里t表示消耗的时间；数。开始时，对每个马尔可夫链，我们采用一个分布q  0  来任意地初始", "keywords": "接下来我们考虑如果并行地运行无穷多个马尔可夫链的情况, 在这里, 可夫链的所有状态都采样自某一个分布, 来任意地初始, 不同马尔", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "a00b8b90-5c7e-464a-8d6b-d19b90035e59", "label": "摘要7", "info": "因为我们已经用正整数x重参数化了这个问题，我们可以用一个向量；来描述这个概率分布q，", "keywords": "我们可以用一个向量, 来描述这个概率分布, 因为我们已经用正整数, 重参数化了这个问题", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "cdbb8e5a-7131-4726-84a1-c0158c5c2f12", "label": "摘要8", "info": "ν", "keywords": "", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "2fe9fa4c-5477-4a34-a16f-859ba0420d5c", "label": "摘要9", "info": "然后我们考虑更新单一的马尔可夫链，从状态x到新状态x＇。单一状态；转移到x＇的概率可以表示为", "keywords": "然后我们考虑更新单一的马尔可夫链, 转移到, 的概率可以表示为, 从状态, 单一状态", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f7726b53-8974-48f4-9b82-0c28ce70f29d", "label": "摘要10", "info": "根据状态为整数的参数化设定，我们可以将转移算子T表示成一个矩阵；A 。矩阵 A 的定义如下：", "keywords": "根据状态为整数的参数化设定, 矩阵, 的定义如下, 表示成一个矩阵, 我们可以将转移算子", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "2fd0edb2-f8ac-440e-83a4-070e274a06c4", "label": "摘要11", "info": "使用这一定义，我们可以改写式（17.18）。不同于之前使用q和T来理；解单个状态的更新，我们现在可以使用 ν 和 A 来描述当我们更新时（并；行运行的）不同马尔可夫链上整个分布是如何变化的：", "keywords": "使用这一定义, 不同马尔可夫链上整个分布是如何变化的, 来描述当我们更新时, 不同于之前使用, 我们可以改写式", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "6550b33e-95a7-4680-8610-9000f146edfa", "label": "摘要12", "info": "重复地使用马尔可夫链更新相当于重复地与矩阵 A 相乘。换言之，我们；可以认为这一过程就是关于 A 的幂乘：", "keywords": "相乘, 可以认为这一过程就是关于, 换言之, 重复地使用马尔可夫链更新相当于重复地与矩阵, 我们", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "95649467-4ca5-4364-8c70-a84845dbf292", "label": "摘要13", "info": "矩阵 A 有一种特殊的结构，因为它的每一列都代表一个概率分布。这样；的矩阵被称为随机矩阵  （Stochastic  Matrix）。如果对于任意状态x到任；意其他状态x＇存在一个t使得转移概率不为0，那么Perron-Frobenius定", "keywords": "的矩阵被称为随机矩阵, 使得转移概率不为, 到任, 如果对于任意状态, 矩阵", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5b581003-da37-4029-a67b-c026297ed148", "label": "摘要14", "info": "这个过程导致了所有不等于1的特征值都衰减到0。在一些额外的较为宽；松的假设下，我们可以保证矩阵  A  只有一个对应特征值为1的特征向；量。所以这个过程收敛到平稳分布  （Stationary  Distribution），有时也", "keywords": "我们可以保证矩阵, 只有一个对应特征值为, 的特征向, 所以这个过程收敛到平稳分布, 有时也", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "707cf3b6-d17a-456a-81b1-3107f1245c75", "label": "摘要15", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；这个条件也适用于收敛之后的每一步。这就是特征向量方程。作为收敛；的稳定点，  ν  一定是特征值为1所对应的特征向量。这个条件保证收敛", "keywords": "这个条件保证收敛, 作为收敛, 这个条件也适用于收敛之后的每一步, 所对应的特征向量, 的稳定点", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "ac13eb06-fd66-4b4f-a005-8527348e118e", "label": "摘要16", "info": "如果我们正确地选择了转移算子T，那么最终的平稳分布q将会等于我们；所希望采样的分布p。我们会将第17.4节介绍如何选择T。", "keywords": "所希望采样的分布, 那么最终的平稳分布, 我们会将第, 节介绍如何选择, 将会等于我们", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "2a6e4655-bc83-4440-a803-fef683aec7f4", "label": "摘要17", "info": "可数状态马尔可夫链的大多数性质可以被推广到连续状态的马尔可夫链；中。在这种情况下，一些研究者把这种马尔可夫链称为哈里斯链；（Harris Chain），但是我们将这两种情况都称为马尔可夫链。通常在一", "keywords": "但是我们将这两种情况都称为马尔可夫链, 在这种情况下, 通常在一, 一些研究者把这种马尔可夫链称为哈里斯链, 可数状态马尔可夫链的大多数性质可以被推广到连续状态的马尔可夫链", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "1fad9970-a38f-42cd-b5b6-2dd5f166a036", "label": "摘要18", "info": "这个方程的离散版本就相当于重新改写方程式（17.23）。当x  是离散值；时，这个期望对应着求和，而当x  是连续值时，这个期望对应的是积；分。", "keywords": "而当, 这个方程的离散版本就相当于重新改写方程式, 这个期望对应的是积, 是连续值时, 是离散值", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5a3a262c-e0c4-46d4-b264-7f1e080939ed", "label": "摘要19", "info": "无论状态是连续的还是离散的，所有的马尔可夫链方法都包括重复、随；机地更新直到最后状态开始从均衡分布中采样。运行马尔可夫链直到它；达到均衡分布的过程通常被称为马尔可夫链的磨合  （Burning-in）过", "keywords": "所有的马尔可夫链方法都包括重复, 运行马尔可夫链直到它, 达到均衡分布的过程通常被称为马尔可夫链的磨合, 机地更新直到最后状态开始从均衡分布中采样, 无论状态是连续的还是离散的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "98c9cc8d-fbb5-4aec-8a3f-b2d78805c085", "label": "摘要20", "info": "为100。", "keywords": "", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5f27436f-35c1-4a82-8bb7-ae0d40736d27", "label": "摘要21", "info": "另一个难点是我们无法预先知道马尔可夫链需要运行多少步才能到达均；衡分布。这段时间通常被称为混合时间  （Mixing  Time）。检测一个马；尔可夫链是否达到平衡是很困难的。我们并没有足够完善的理论来解决", "keywords": "检测一个马, 我们并没有足够完善的理论来解决, 衡分布, 另一个难点是我们无法预先知道马尔可夫链需要运行多少步才能到达均, 这段时间通常被称为混合时间", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5652c766-5e93-4995-a750-06af49522bde", "label": "17.4：Gibbs采样", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "3ec9bc3a-d6c4-41d4-80e9-e3ec42f67c24", "label": "摘要1", "info": "目前为止我们已经了解了如何通过反复更新 x ←− x ＇∼T( x ＇｜ x  )从；一个分布q(  x  )中采样，然而我们还没有介绍过如何确定q(  x  )是否是一；个有效的分布。本书中将会描述两种基本的方法。第一种方法是从已经", "keywords": "是否是一, 个有效的分布, 本书中将会描述两种基本的方法, 第一种方法是从已经, 目前为止我们已经了解了如何通过反复更新", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5d39521c-a223-482c-99a7-a5f6e828e6b0", "label": "摘要2", "info": "在深度学习中，我们通常使用马尔可夫链从定义为基于能量的模型的分；布p  model ( x  )中采样。在这种情况下，我们希望马尔可夫链的q(  x )分布；就是p  model ( x )。为了得到所期望的q( x  )分布，我们必须选取合适的T(", "keywords": "我们通常使用马尔可夫链从定义为基于能量的模型的分, 就是, 我们必须选取合适的, 在这种情况下, 在深度学习中", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "e72a4694-43df-4467-87c3-d8d9df6da142", "label": "摘要3", "info": "Gibbs采样  （Gibbs  Sampling）是一种概念简单而又有效的方法。它构；造一个从p  model  (  x  )中采样的马尔可夫链，其中在基于能量的模型中从；T(x ＇|x )采样是通过选择一个变量x i ，然后从p model 中该点关于在无向", "keywords": "是一种概念简单而又有效的方法, 其中在基于能量的模型中从, 然后从, 采样, 它构", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "de0cc862-6b00-4625-86cf-fd834d08ee3a", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图   （定义了基于能量的模型结构）中邻接点的条件分布中采样。只；要一些变量在给定相邻变量时是条件独立的，那么这些变量就可以被同", "keywords": "定义了基于能量的模型结构, 中邻接点的条件分布中采样, 要一些变量在给定相邻变量时是条件独立的, 那么这些变量就可以被同", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "710176f3-953e-4ba6-8ec1-9d0cada2374d", "label": "摘要5", "info": "model  中采样的马尔可夫链还存在其他备选方法。比如说，", "keywords": "比如说, 中采样的马尔可夫链还存在其他备选方法", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "46749a07-99c7-4c4b-b939-585c7a37ac23", "label": "摘要6", "info": "设计从p；Metropolis-Hastings算法在其他领域中广泛使用。不过在深度学习的无；向模型中，我们主要使用Gibbs采样，很少使用其他方法。改进采样技", "keywords": "设计从, 向模型中, 我们主要使用, 采样, 算法在其他领域中广泛使用", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "7b72ae23-713d-4ff4-af87-ccf478de426b", "label": "17.5：不同的峰值之间的混合挑战", "level": 2, "group": "chapter-17", "type": "子章節"}, {"id": "82211c41-e8bd-433e-a106-b47393f2c691", "label": "摘要1", "info": "17.5.1　不同峰值之间通过回火来混合", "keywords": "不同峰值之间通过回火来混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "8a85fda6-13aa-424d-9f11-a80db69f7746", "label": "摘要2", "info": "17.5.2　深度也许会有助于混合", "keywords": "深度也许会有助于混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "3ff895bf-1fcf-4f40-93dd-4cde59a92627", "label": "摘要3", "info": "使用MCMC方法的主要难点在于马尔可夫链的混合  （Mixing）通常不；理想。在理想情况下，从设计好的马尔可夫链中采出的连续样本之间是；完全独立的，而且在  x 空间中，马尔可夫链会按概率大小访问许多不同", "keywords": "完全独立的, 在理想情况下, 方法的主要难点在于马尔可夫链的混合, 通常不, 马尔可夫链会按概率大小访问许多不同", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "2e46664e-4879-42d8-b4b9-a3ab3ea0040f", "label": "摘要4", "info": "然而，MCMC方法采出的样本可能会具有很强的相关性，尤其是在高维；的情况下，我们把这种现象称为慢混合甚至混合失败。具有缓慢混合的；MCMC方法可以被视为对能量函数无意地执行类似于带噪声的梯度下降", "keywords": "方法采出的样本可能会具有很强的相关性, 然而, 的情况下, 尤其是在高维, 具有缓慢混合的", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "574148f0-55f4-46ba-8cc0-b138f64a9937", "label": "摘要5", "info": "当我们考虑Gibbs采样算法（见第17.4节）时，这种现象格外明显。在这；种情况下，我们考虑在一定步数内从一个峰值移动到一个临近峰值的概；率。决定这个概率的是两个峰值之间的“能量障碍”的形状。隔着一个巨", "keywords": "这种现象格外明显, 在这, 的形状, 我们考虑在一定步数内从一个峰值移动到一个临近峰值的概, 当我们考虑", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "ac6a7841-49e5-4503-a4d3-3aea189a6326", "label": "摘要6", "info": "图17.1　对于三种分布使用Gibbs采样所产生的路径，所有的分布马尔可夫链初始值都设为峰；值。（左）一个带有两个独立变量的多维正态分布。由于变量之间是相互独立的，Gibbs采样混；合得很好。（中）变量之间存在高度相关性的一个多维正态分布。变量之间的相关性使得马尔", "keywords": "由于变量之间是相互独立的, 采样所产生的路径, 一个带有两个独立变量的多维正态分布, 变量之间存在高度相关性的一个多维正态分布, 采样混", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "2d844019-9666-485a-82c5-874412b042c3", "label": "摘要7", "info": "举一个简单的例子，考虑两个变量a、b基于能量的模型，这两个变量都；是二值的，取值＋1或者−1。如果对某个较大的正数w，E(a,b)＝−wab，；那么这个模型传达了一个强烈的信息，a和b有相同的符号。当a＝1时用", "keywords": "是二值的, 取值, 如果对某个较大的正数, 这两个变量都, 那么这个模型传达了一个强烈的信息", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "8283ebbc-2ce2-450e-9716-6d545f48a392", "label": "摘要8", "info": "在更实际的问题中，这种挑战更加艰巨。因为在实际问题中我们不能仅；仅关注在两个峰值之间的转移，更要关注在多个峰值之间的转移。如果；由于峰值之间混合困难，而导致某几个这样的转移难以完成，那么得到", "keywords": "仅关注在两个峰值之间的转移, 如果, 那么得到, 这种挑战更加艰巨, 由于峰值之间混合困难", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "d434259b-8a2a-4159-8935-39bdb1402616", "label": "摘要9", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；通过寻找一些高度依赖变量的组以及分块同时更新块（组）中的变量，；这个问题有时候是可以被解决的。然而不幸的是，当依赖关系很复杂", "keywords": "这个问题有时候是可以被解决的, 当依赖关系很复杂, 通过寻找一些高度依赖变量的组以及分块同时更新块, 中的变量, 然而不幸的是", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "4825d19f-d8a2-4757-a2db-8774b6d6a74a", "label": "摘要10", "info": "在定义了一个联合分布p  model ( x ，  h  )的潜变量模型中，我们经常通过；交替地从p model ( x | h )和p model ( h | x )中采样来达到抽 x 的目的。从快；速混合的角度上说，我们更希望p model ( h | x )有很大的熵。然而，从学", "keywords": "在定义了一个联合分布, 的目的, 中采样来达到抽, 速混合的角度上说, 然而", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f3777fa0-9b10-4301-9a10-43042c67b441", "label": "摘要11", "info": "图17.2　深度概率模型中一个混合缓慢问题的例证。每张图都是按照从左到右从上到下的顺序；的。（左）Gibbs采样从MNIST数据集训练成的深度玻尔兹曼机中采出的连续样本。这些连续的；样本之间非常相似。由于Gibbs采样作用于一个深度图模型，相似度更多地是基于语义而非原始", "keywords": "这些连续的, 采样从, 采样作用于一个深度图模型, 样本之间非常相似, 深度概率模型中一个混合缓慢问题的例证", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f8586f85-3886-462a-b378-4641935b1c67", "label": "摘要12", "info": "当感兴趣的分布对于每个类具有单独的流形结构时，所有这些问题都使；MCMC方法变得不那么有用：分布集中在许多峰值周围，并且这些峰值；由大量高能量区域分割。我们在许多分类问题中遇到的是这种类型的分", "keywords": "并且这些峰值, 当感兴趣的分布对于每个类具有单独的流形结构时, 分布集中在许多峰值周围, 方法变得不那么有用, 我们在许多分类问题中遇到的是这种类型的分", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "3938cd04-3ea5-4e60-842e-e52aaa3f5398", "label": "摘要13", "info": "布，由于峰值之间混合缓慢，它将使得MCMC方法非常缓慢地收敛。", "keywords": "由于峰值之间混合缓慢, 方法非常缓慢地收敛, 它将使得", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "878b3b2a-1fc5-4489-9a19-17a057906d2d", "label": "摘要14", "info": "17.5.1　不同峰值之间通过回火来混合", "keywords": "不同峰值之间通过回火来混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "6815d8ed-a63a-4b0e-b3d4-3e5a750e2b9e", "label": "摘要15", "info": "当一个分布有一些陡峭的峰并且被低概率区域包围时，很难在分布的不；同峰值之间混合。一些加速混合的方法是基于构造一个概率分布替代目；标分布，这个概率分布的峰值没有那么高，峰值周围的低谷也没有那么", "keywords": "标分布, 这个概率分布的峰值没有那么高, 很难在分布的不, 当一个分布有一些陡峭的峰并且被低概率区域包围时, 同峰值之间混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "7c7455e9-918c-4d7c-93de-88835073bc65", "label": "摘要16", "info": "基于能量的模型可以通过添加一个额外的控制峰值尖锐程度的参数β来；加强：", "keywords": "加强, 基于能量的模型可以通过添加一个额外的控制峰值尖锐程度的参数", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "c2a12df8-7d24-4943-89d7-88f62cad82bd", "label": "摘要17", "info": "β参数可以被理解为温度  （temperature）的倒数，反映了基于能量的模；型的统计物理学起源。当温度趋近于0时，β趋近于无穷大，此时的基于；能量的模型是确定性的。当温度趋近于无穷大时，β趋近于0，基于能量", "keywords": "趋近于, 当温度趋近于, 反映了基于能量的模, 参数可以被理解为温度, 基于能量", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "fbd5ed9c-01e8-4085-8602-dc146095fb8c", "label": "摘要18", "info": "通常情况下，在β＝1时训练一个模型。但我们也可以利用其他温度，尤；其是β＜1的情况。回火  （tempering）作为一种通用的策略，它通过从β；＜1模型中采样来实现在p 1 的不同峰值之间快速混合。", "keywords": "通常情况下, 作为一种通用的策略, 的不同峰值之间快速混合, 回火, 的情况", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "f4fac133-2d51-4dfd-890b-4d50feca35de", "label": "摘要19", "info": "基于回火转移  （tempered  transition）（Neal，1994）的马尔可夫链临时；从高温度的分布中采样使其在不同峰值之间混合，然后继续从单位温度；的分布中采样。这些技巧被应用在一些模型比如RBM中", "keywords": "这些技巧被应用在一些模型比如, 基于回火转移, 的马尔可夫链临时, 然后继续从单位温度, 的分布中采样", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "bd63206b-7366-4ebb-bd5f-55e6fbf8b1b8", "label": "摘要20", "info": "（parallel", "keywords": "", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "4540cadd-1583-4eb7-a31a-88132a98ebb2", "label": "摘要21", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；界温度  （critical  temperatures）时温度转移算子必须设置得非常慢（因；为温度需要逐渐下降）来确保回火的有效性。", "keywords": "为温度需要逐渐下降, 时温度转移算子必须设置得非常慢, 来确保回火的有效性, 界温度", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "966ecc59-c877-4055-ab76-a6ccb62f9f69", "label": "摘要22", "info": "17.5.2　深度也许会有助于混合", "keywords": "深度也许会有助于混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "60e0c8c4-61d1-4138-b5e3-d578c063c659", "label": "摘要23", "info": "当我们从潜变量模型p( h , x )中采样时，我们可以发现如果p( h | x )将 x；编码得非常好，那么从p(  x  | h  )中采样时，并不会太大地改变  x  ，那么；混合结果会很糟糕。解决这个问题的一种方法是使得 h 成为一种将 x 编", "keywords": "解决这个问题的一种方法是使得, 编码得非常好, 成为一种将, 那么从, 并不会太大地改变", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "63253a03-8c94-481e-96d5-3d3f0faa280c", "label": "摘要24", "info": "尽管存在混合的难点，蒙特卡罗技术仍然是一个有用的工具，通常也是；最好的可用工具。事实上，在遇到难以处理的无向模型中的配分函数；时，蒙特卡罗方法仍然是最主要的工具，这将在下一章详细阐述。", "keywords": "事实上, 最好的可用工具, 通常也是, 蒙特卡罗技术仍然是一个有用的工具, 这将在下一章详细阐述", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "c39e6418-d7b9-462b-9ca8-1aac229c2a28", "label": "摘要25", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "b03b84ec-d2df-45bb-89d5-1504f14885fc", "label": "摘要26", "info": "(1)  通常我们会倾向于计算方差的无偏估计，它由偏差的平方和除以n−1而非n得到。", "keywords": "它由偏差的平方和除以, 通常我们会倾向于计算方差的无偏估计, 得到, 而非", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "6676059b-5556-4554-872c-1b22d064f791", "label": "摘要27", "info": "17.5.1　不同峰值之间通；过回火来混合", "keywords": "不同峰值之间通, 过回火来混合", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "5155c8ff-0cc6-4e31-8416-5f941014334b", "label": "摘要28", "info": "17.5.2　深度也许会有助；于混合", "keywords": "于混合, 深度也许会有助", "level": 3, "group": "chapter-17", "type": "段落"}, {"id": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "label": "第18章：直面配分函数", "level": 1, "group": "chapter-18", "type": "章節"}, {"id": "258db62d-1929-40c8-afe0-385f0e182428", "label": "17.5：不同的峰值之间的混合挑战", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "db9dee4c-31de-48c7-9012-ed50a67f70db", "label": "摘要1", "info": "在第16.2.2节中，我们看到许多概率模型（通常是无向图模型）由一个；未归一化的概率分布；来归一化  ，以获得一个有效的概率分布：", "keywords": "我们看到许多概率模型, 来归一化, 由一个, 节中, 未归一化的概率分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "88fde8ac-af22-4fd6-888d-3e12a4172e8c", "label": "摘要2", "info": "定义。我们必须通过除以配分函数Z(  θ  )", "keywords": "定义, 我们必须通过除以配分函数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "552918f0-72a5-4438-aa27-fd08f1a72894", "label": "摘要3", "info": "配分函数是未归一化概率所有状态的积分（对于连续变量）或求和（对；于离散变量）：", "keywords": "配分函数是未归一化概率所有状态的积分, 或求和, 对于连续变量, 于离散变量", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "45e478c1-d85f-4171-9f64-eff35f9645ac", "label": "摘要4", "info": "或者", "keywords": "或者", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "871ed99e-ec91-4108-a9ac-56062f790630", "label": "摘要5", "info": "对于很多有趣的模型而言，以上积分或求和难以计算。", "keywords": "以上积分或求和难以计算, 对于很多有趣的模型而言", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1673f5a9-dcfc-41c8-9393-f3581d25740b", "label": "摘要6", "info": "正如我们将在第20章看到的，有些深度学习模型被设计成具有一个易于；处理的归一化常数，或被设计成能够在不涉及计算p（x  ）的情况下使；用。然而，其他一些模型会直接面对难以计算的配分函数的挑战。在本", "keywords": "或被设计成能够在不涉及计算, 的情况下使, 然而, 其他一些模型会直接面对难以计算的配分函数的挑战, 处理的归一化常数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "label": "18.1：对数似然梯度", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "f76a80bb-f251-4fe9-9ee6-c09ca9d8799c", "label": "摘要1", "info": "通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数。；对数似然相对于参数的梯度具有一项对应于配分函数的梯度：", "keywords": "通过最大似然学习无向模型特别困难的原因在于配分函数依赖于参数, 对数似然相对于参数的梯度具有一项对应于配分函数的梯度", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d8b8324a-6e82-467e-822f-83cdd58ead02", "label": "摘要2", "info": "这是机器学习中非常著名的正相  （positive  phase）和负相  （negative；phase）的分解。", "keywords": "和负相, 这是机器学习中非常著名的正相, 的分解", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "11249ce3-4b3c-41ea-813f-e5c91576a30a", "label": "摘要3", "info": "对于大多数感兴趣的无向模型而言，负相是困难的。没有潜变量或潜变；量之间很少相互作用的模型通常会有一个易于计算的正相。RBM的隐；藏单元在给定可见单元的情况下彼此条件独立，是一个典型的具有简单", "keywords": "量之间很少相互作用的模型通常会有一个易于计算的正相, 对于大多数感兴趣的无向模型而言, 的隐, 负相是困难的, 藏单元在给定可见单元的情况下彼此条件独立", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "bee251d7-aba7-4c16-a46d-148b54e70acc", "label": "摘要4", "info": "让我们进一步分析log Z的梯度：", "keywords": "让我们进一步分析, 的梯度", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "bf87d395-4424-4ea9-9a25-1386bd06b3e5", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；对于保证所有的x", "keywords": "对于保证所有的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3e2539b8-fb8f-4d26-9d47-c3e8ef4a1433", "label": "摘要6", "info": "代替", "keywords": "代替", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "511b6eae-a5ce-40f1-91c6-11bac5697acf", "label": "摘要7", "info": "都有p（x；：", "keywords": "都有", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ed93277c-2908-4687-a569-2b40f3f992b6", "label": "摘要8", "info": "）＞0的模型，我们可以用", "keywords": "我们可以用, 的模型", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "76d6aa0e-0d17-4ddf-84cf-dcce843139ee", "label": "摘要9", "info": "上述推导对离散的 x 进行求和，对连续的 x 进行积分也可以得到类似结；果。在连续版本的推导中，使用在积分符号内取微分的莱布尼兹法则可；以得到等式", "keywords": "进行积分也可以得到类似结, 在连续版本的推导中, 使用在积分符号内取微分的莱布尼兹法则可, 进行求和, 以得到等式", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f8ad2cd6-59ec-4c0f-a367-91a55afbdb80", "label": "摘要10", "info": "该等式只适用于   和；上的一些特定规范条件。在测度论术语；中，这些条件是：（1）对每一个 θ  而言，未归一化分布  必须是 x  的", "keywords": "该等式只适用于, 对每一个, 而言, 在测度论术语, 未归一化分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a5d44008-9b3c-482d-990c-6f86b24f34dd", "label": "摘要11", "info": "R( x )使得", "keywords": "使得", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6eff4254-044b-485f-a05c-38d69de870da", "label": "摘要12", "info": "。幸运的是，", "keywords": "幸运的是", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "172a576e-ecf8-4801-bbfd-141e2e3f149c", "label": "摘要13", "info": "大多数感兴趣的机器学习模型都具有这些性质。", "keywords": "大多数感兴趣的机器学习模型都具有这些性质", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a434416a-c869-4cc7-9a32-62d1caa37b1f", "label": "摘要14", "info": "等式", "keywords": "等式", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1c333806-de7f-4d52-841c-a35baec59695", "label": "摘要15", "info": "是使用各种蒙特卡罗方法近似最大化（具有难计算配分函数模型的）似；然的基础。", "keywords": "是使用各种蒙特卡罗方法近似最大化, 具有难计算配分函数模型的, 然的基础", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "28e67728-ab29-4827-915e-60cecfaea09a", "label": "摘要16", "info": "蒙特卡罗方法为学习无向模型提供了直观的框架，我们能够在其中考虑；正相和负相。在正相中，我们增大从数据中采样得到的；。在", "keywords": "正相和负相, 蒙特卡罗方法为学习无向模型提供了直观的框架, 在正相中, 我们增大从数据中采样得到的, 我们能够在其中考虑", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f4b86217-f25a-4251-992d-379564a85fe4", "label": "摘要17", "info": "在深度学习文献中，经常会看到用能量函数（式（16.7））来参数化", "keywords": "来参数化, 经常会看到用能量函数, 在深度学习文献中", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "06020d99-680f-4240-9e4f-39215e7fc222", "label": "摘要18", "info": "。在这种情况下，正相可以解释为压低训练样本的能量，负相", "keywords": "正相可以解释为压低训练样本的能量, 负相, 在这种情况下", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3131e974-f567-42de-b8c3-0b95318f7e38", "label": "摘要19", "info": "可以解释为提高模型抽出的样本的能量，如图18.1所示。", "keywords": "如图, 所示, 可以解释为提高模型抽出的样本的能量", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1c3e4ffe-7943-44ab-afd5-c4f097064126", "label": "摘要20", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；18.2　随机最大似然和对比散度", "keywords": "随机最大似然和对比散度", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "fae974ba-261d-4e05-a53b-428d050242dd", "label": "18.2：随机最大似然和对比散度", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "c365f2b9-5385-4f97-8a26-f014be97cfe7", "label": "摘要1", "info": "实现式（18.15）的一个朴素方法是，每次需要计算梯度时，磨合随机；初始化的一组马尔可夫链。当使用随机梯度下降进行学习时，这意味着；马尔可夫链必须在每次梯度步骤中磨合。这种方法引导下的训练过程如", "keywords": "马尔可夫链必须在每次梯度步骤中磨合, 每次需要计算梯度时, 实现式, 这种方法引导下的训练过程如, 的一个朴素方法是", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0cabba36-302f-4e5c-8bef-a133cf9ad0a4", "label": "摘要2", "info": "我们可以将最大化似然的MCMC方法视为在两种力之间平衡，一种力拉；高数据出现时的模型分布，一种拉低模型采样出现时的模型分布。图；18.1展示了这个过程。这两种力分别对应最大化", "keywords": "我们可以将最大化似然的, 一种力拉, 展示了这个过程, 方法视为在两种力之间平衡, 高数据出现时的模型分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "617553dc-db99-4b4f-a5c6-53d7232d7453", "label": "摘要3", "info": "和最小化log", "keywords": "和最小化", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8dbabbe3-ab25-4c73-a4c2-69174b56c495", "label": "摘要4", "info": "算法18.1 一种朴素的MCMC算法，使用梯度上升最大化具有难以计算配", "keywords": "一种朴素的, 使用梯度上升最大化具有难以计算配, 算法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ea41c6a1-53a3-42c8-baf4-ea2a50781dd1", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；分函数的对数似然。", "keywords": "分函数的对数似然", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "373e62ee-ca71-4e03-810a-256bfc95233e", "label": "摘要6", "info": "设步长  为一个小正数。", "keywords": "设步长, 为一个小正数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4b31c0e1-76c6-4336-a012-4b612bb0cc1a", "label": "摘要7", "info": "设吉布斯步数k大到足以允许磨合。在小图像集上训练一个RBM大致；设为100。", "keywords": "设吉布斯步数, 大到足以允许磨合, 设为, 大致, 在小图像集上训练一个", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b0b37bd8-2245-4d96-8659-c4716722fd81", "label": "摘要8", "info": "while 不收敛do", "keywords": "不收敛", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "dc9ea710-c830-4d7b-a8be-4f4ae2f224f1", "label": "摘要9", "info": "从训练集中采包含m个样本{x (1) ，…，x (m) }的小批量。", "keywords": "个样本, 的小批量, 从训练集中采包含", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7fb98f90-8a43-4f3b-a3e6-ddd35467678a", "label": "摘要10", "info": "初始化m个样本；态分布中采，或大致与模型边缘分布匹配的分布）。", "keywords": "初始化, 个样本, 或大致与模型边缘分布匹配的分布, 态分布中采", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "eab4b4c7-cb36-4efa-97aa-1189dc9e1a12", "label": "摘要11", "info": "为随机值（例如，从均匀或正", "keywords": "从均匀或正, 为随机值, 例如", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b7e61cf1-2b0f-4056-a89e-6b4f89c18e17", "label": "摘要12", "info": "for i＝1 to k do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "41c8248e-de7b-4b3d-9a3f-5146a8c25b4f", "label": "摘要13", "info": "for j＝1 to m do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ba941b2c-d47c-4f49-a1af-93bbe6b69621", "label": "摘要14", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8435f514-9ba0-440d-9efd-4cdb20a45a53", "label": "摘要15", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d482d47b-7df5-4bc8-acb6-62f33203b19b", "label": "摘要16", "info": "end while", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "dc0b0e89-8a7f-4237-b497-dd0cef6bbc09", "label": "摘要17", "info": "图18.1　算法18.1角度的“正相”和“负相”。（左）在正相中，我们从数据分布中采样，然后推高；它们未归一化的概率。这意味着概率越高的数据点，未归一化的概率被推高得越多。（右）在；负相中，我们从模型分布中采样，然后压低它们未归一化的概率。这与正相的倾向相反，给未", "keywords": "负相, 我们从数据分布中采样, 算法, 它们未归一化的概率, 给未", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1f67a386-8a0c-4f17-8cf7-72c0cf796358", "label": "摘要18", "info": "因为负相涉及从模型分布中抽样，所以我们可以认为它在找模型信任度；很高的点。因为负相减少了这些点的概率，它们一般被认为代表了模型；不正确的信念。在文献中，它们经常被称为“幻觉”或“幻想粒子”。事实", "keywords": "所以我们可以认为它在找模型信任度, 它们经常被称为, 因为负相涉及从模型分布中抽样, 在文献中, 因为负相减少了这些点的概率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1361f705-941c-447d-8b41-d196c966dda8", "label": "摘要19", "info": "的梯度，在睡觉时会遵循", "keywords": "的梯度, 在睡觉时会遵循", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "af7db23a-c6e3-4b64-86ab-af7ec1ffc257", "label": "摘要20", "info": "这样理解学习正相和负相的作用之后，我们设计了一个比算法18.1计算；代价更低的替代算法。简单的MCMC算法的计算成本主要来自每一步的；随机初始化磨合马尔可夫链。一个自然的解决方法是初始化马尔可夫链", "keywords": "简单的, 一个自然的解决方法是初始化马尔可夫链, 这样理解学习正相和负相的作用之后, 算法的计算成本主要来自每一步的, 我们设计了一个比算法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "09164c53-d9d0-492d-92cc-5bdcc0790566", "label": "摘要21", "info": "算法18.2 对比散度算法，使用梯度上升作为优化过程。", "keywords": "对比散度算法, 使用梯度上升作为优化过程, 算法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d3586df3-decf-4155-963f-8bc19e456ce1", "label": "摘要22", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；设步长  为一个小正数。", "keywords": "设步长, 为一个小正数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "173ee379-e4bc-46ab-9c8a-0c0b365cfcd1", "label": "摘要23", "info": "设吉布斯步数k大到足以让从p data 初始化并从p（x ； θ ）采样的马尔；可夫链混合。在小图像集上训练一个RBM大致设为1∼20。", "keywords": "初始化并从, 设吉布斯步数, 在小图像集上训练一个, 采样的马尔, 大到足以让从", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d7018ff5-54ab-4ffe-90ea-e52071855ef5", "label": "摘要24", "info": "while 不收敛do", "keywords": "不收敛", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "5c8cd405-ca4a-4dd8-8892-7e2ef488dd93", "label": "摘要25", "info": "从训练集中采包含m个样本{x (1) ，…，x (m) }的小批量。", "keywords": "个样本, 的小批量, 从训练集中采包含", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e62f7e25-52d5-4536-8c59-5e9b6cfe4a47", "label": "摘要26", "info": "for i＝1 to m do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4630246f-b1e5-4a17-baff-088517e98e25", "label": "摘要27", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6f947af9-ee7b-46d2-8d99-5f9514e13e6f", "label": "摘要28", "info": "for i＝1 to k do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e1fff94c-a6c6-4903-99e7-3103dc464ed8", "label": "摘要29", "info": "for j＝1 to m do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e13cd0c9-343d-40fa-9329-2d6edd97f472", "label": "摘要30", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ea72f74a-a9e1-47f4-8474-562e456443bc", "label": "摘要31", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ccc9e104-e4c0-4fd3-8b3f-761eb1ef5bd8", "label": "摘要32", "info": "end while", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c218184b-72d0-409c-96ce-a99d7e8807ec", "label": "摘要33", "info": "对比散度  （CD，或者是具有k个Gibbs步骤的CD-k）算法在每个步骤中", "keywords": "或者是具有, 步骤的, 算法在每个步骤中, 对比散度", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3e775a4f-f4b0-4c7e-a613-d333a9b9bc7f", "label": "摘要34", "info": "初始化马尔可夫链为采样自数据分布中的样本（Hinton，2000，；2010），如算法18.2所示。从数据分布中获取样本是计算代价最小的，；因为它们已经在数据集中了。初始时，数据分布并不接近模型分布，因", "keywords": "数据分布并不接近模型分布, 初始时, 从数据分布中获取样本是计算代价最小的, 因为它们已经在数据集中了, 如算法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1867254e-7c57-4a8a-a312-c0a9db79b3ad", "label": "摘要35", "info": "当然，CD仍然是真实负相的一个近似。CD未能定性地实现真实负相的；主要原因是，它不能抑制远离真实训练样本的高概率区域。这些区域在；模型上具有高概率，但是在数据生成区域上具有低概率，被称为虚假模", "keywords": "仍然是真实负相的一个近似, 但是在数据生成区域上具有低概率, 主要原因是, 未能定性地实现真实负相的, 这些区域在", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "24ed5c94-2c64-4895-a7fc-a7a6a5af93b6", "label": "摘要36", "info": "Carreira-Perpiñan  and  Hinton（2005）实验上证明CD估计偏向于RBM和；完全可见的玻尔兹曼机，因为它会收敛到与最大似然估计不同的点。他；们认为，由于偏差较小，CD可以作为一种计算代价低的方式来初始化", "keywords": "们认为, 实验上证明, 因为它会收敛到与最大似然估计不同的点, 估计偏向于, 可以作为一种计算代价低的方式来初始化", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "74d1c785-ee3b-4075-bab7-f09506c32a73", "label": "摘要37", "info": "and", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "eaeef958-7219-460b-8ac4-0929b0f7e039", "label": "摘要38", "info": "在训练诸如RBM的浅层网络时CD是很有用的。反过来，这些可以堆叠；起来初始化更深的模型，如DBN或DBM。但是CD并不直接有助于训练；更深的模型。这是因为在给定可见单元样本的情况下，很难获得隐藏单", "keywords": "并不直接有助于训练, 的浅层网络时, 在训练诸如, 但是, 是很有用的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "67d56e3f-51d2-4e97-b39a-47659dcdd1ec", "label": "摘要39", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图18.2　一个虚假模态。说明对比散度（算法18.2）的负相为何无法抑制虚假模态的例子。一个；虚假模态指的是一个在模型分布中出现数据分布中却不存在的模式。由于对比散度从数据点中", "keywords": "一个虚假模态, 由于对比散度从数据点中, 算法, 的负相为何无法抑制虚假模态的例子, 虚假模态指的是一个在模型分布中出现数据分布中却不存在的模式", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "608a3fbe-08f7-45d9-9936-a8dbd3d70a35", "label": "摘要40", "info": "CD算法可以被理解为惩罚某类模型，这类模型的马尔可夫链会快速改；变来自数据的输入。这意味着使用CD训练从某种程度上说类似于训练；自编码器。即使CD估计比一些其他训练方法具有更大偏差，但是它有", "keywords": "估计比一些其他训练方法具有更大偏差, 训练从某种程度上说类似于训练, 即使, 自编码器, 这意味着使用", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d7c87005-b75c-4bfb-91ff-a3f67c4234ba", "label": "摘要41", "info": "Sutskever and Tieleman（2010）表明，CD的更新方向不是任何函数的梯；度。这使得CD可能存在永久循环的情况，但在实践中这并不是一个严；重的问题。", "keywords": "这使得, 重的问题, 但在实践中这并不是一个严, 表明, 的更新方向不是任何函数的梯", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1dc586de-596f-4f07-b213-89e9029f937e", "label": "摘要42", "info": "另一个解决CD中许多问题的不同策略是，在每个梯度步骤中初始化马；尔可夫链为先前梯度步骤的状态值。这个方法首先被应用数学和统计学；社群发现，命名为随机最大似然  （SML）（Younes，1998），后来又", "keywords": "后来又, 社群发现, 在每个梯度步骤中初始化马, 命名为随机最大似然, 这个方法首先被应用数学和统计学", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c4d44553-b236-4cdb-a002-1954dd5a2586", "label": "摘要43", "info": "体可以参考算法18.3。这种方法的基本思想是，只要随机梯度算法得到；的步长很小，那么前一步骤的模型将类似于当前步骤的模型。因此，来；自先前模型分布的样本将非常接近来自当前模型分布的客观样本，用这", "keywords": "体可以参考算法, 这种方法的基本思想是, 那么前一步骤的模型将类似于当前步骤的模型, 因此, 只要随机梯度算法得到", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "11252096-edd6-43a5-af27-a425f807d9cb", "label": "摘要44", "info": "因为每个马尔可夫链在整个学习过程中不断更新，而不是在每个梯度步；骤中重新开始，马尔可夫链可以自由探索很远，以找到模型的所有峰；值。因此，SML比CD更不容易形成具有虚假模态的模型。此外，因为", "keywords": "因为, 马尔可夫链可以自由探索很远, 骤中重新开始, 因此, 此外", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c13d8383-4aa2-4130-8200-8896fb209898", "label": "摘要45", "info": "算法18.3  随机最大似然/持续性对比散度算法，使用梯度上升作为优化；过程。", "keywords": "随机最大似然, 算法, 使用梯度上升作为优化, 持续性对比散度算法, 过程", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ddce4a1c-de2d-4bb8-be4a-4e71f179f323", "label": "摘要46", "info": "设步长  为一个小正数。", "keywords": "设步长, 为一个小正数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2532b86b-3a8c-41bb-92e0-95d97d3e9816", "label": "摘要47", "info": "设吉布斯步数k大到足以让从；采样的马尔可夫链磨；合（从采自p(x  ;  θ  )的样本开始）。在小图像集上训练一个RBM大致设", "keywords": "设吉布斯步数, 从采自, 大致设, 采样的马尔可夫链磨, 大到足以让从", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6b80db8d-a2b4-43cb-bc0e-b1a030dba797", "label": "摘要48", "info": "初始化m个样本；分布中采，或大致与模型边缘分布匹配的分布）。", "keywords": "初始化, 分布中采, 个样本, 或大致与模型边缘分布匹配的分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0e5cac48-7d55-47d3-9c1d-2ea483f9568e", "label": "摘要49", "info": "为随机值（例如，从均匀或正态", "keywords": "从均匀或正态, 为随机值, 例如", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4018c2d0-2557-406a-abe7-a9cfc8a58464", "label": "摘要50", "info": "while 不收敛do", "keywords": "不收敛", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "60f4fd0c-404b-481c-a52b-640e0313d050", "label": "摘要51", "info": "从训练集中采包含m个样本{x (1) ，…，x (m) }的小批量。", "keywords": "个样本, 的小批量, 从训练集中采包含", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "42a3c5c8-ce99-433e-9ce4-694214704488", "label": "摘要52", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；for i＝1 to k do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "63fd4773-9d3e-44e7-a208-086a3e789cda", "label": "摘要53", "info": "for j＝1 to m do", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d7064796-9b28-415a-acd1-83fb0c856e68", "label": "摘要54", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f9db6dfb-6ded-474a-a9b6-3ceebee00fb3", "label": "摘要55", "info": "end for", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f453849f-514c-4d48-908e-278fcc2b311c", "label": "摘要56", "info": "end while", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7c02f60c-7cd7-4667-823a-47cc6373df77", "label": "摘要57", "info": "在k太小或太大时，随机梯度算法移动模型的速率比马尔可夫链在迭代；步中混合更快，此时SML容易变得不准确。不幸的是，这些值的容许范；围高度依赖于具体问题。现在还没有方法能够正式地测试马尔可夫链是", "keywords": "容易变得不准确, 步中混合更快, 随机梯度算法移动模型的速率比马尔可夫链在迭代, 围高度依赖于具体问题, 这些值的容许范", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f4f402af-11b4-4406-8728-9111568e8ba7", "label": "摘要58", "info": "从使用SML训练的模型中评估采样必须非常小心。在模型训练完之后，；有必要从一个随机起点初始化的新马尔可夫链抽取样本。用于训练的连；续负相链中的样本受到了模型最近几个版本的影响，会使模型看起来具", "keywords": "在模型训练完之后, 有必要从一个随机起点初始化的新马尔可夫链抽取样本, 用于训练的连, 会使模型看起来具, 从使用", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b0981b51-3059-422e-a2d6-b27461860cc3", "label": "摘要59", "info": "Berglund  and  Raiko（2013）进行了实验来检验由CD和SML进行梯度估；计带来的偏差和方差。结果证明CD比基于精确采样的估计具有更低的；方差。而SML有更高的方差。CD方差低的原因是，其在正相和负相中", "keywords": "比基于精确采样的估计具有更低的, 有更高的方差, 进行梯度估, 计带来的偏差和方差, 进行了实验来检验由", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "bb75f242-f716-4994-96d5-22a132bab5ff", "label": "摘要60", "info": "所有基于MCMC从模型中抽取样本的方法在原则上几乎可以与MCMC；的任何变体一起使用。这意味着诸如SML这样的技术可以使用第17章中；描述的任何增强MCMC的技术（例如并行回火）来加以改进", "keywords": "章中, 所有基于, 从模型中抽取样本的方法在原则上几乎可以与, 例如并行回火, 来加以改进", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0405c72a-ab63-4b5e-b6ca-2daa3122bfa9", "label": "摘要61", "info": "一种在学习期间加速混合的方法是，不改变蒙特卡罗采样技术，而是改；变模型的参数化和代价函数。快速持续性对比散度  （fast；persistent", "keywords": "而是改, 一种在学习期间加速混合的方法是, 不改变蒙特卡罗采样技术, 变模型的参数化和代价函数, 快速持续性对比散度", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "df2f4565-44bb-4b64-be66-0fe7f10e372c", "label": "摘要62", "info": "现在的参数是以前的两倍多，将其逐个相加以定义原始模型的参数。快；速复制参数可以使用更大的学习率来训练，从而使其快速响应学习的负；相，并促使马尔可夫链探索新的区域。这能够使马尔可夫链快速混合，", "keywords": "将其逐个相加以定义原始模型的参数, 这能够使马尔可夫链快速混合, 从而使其快速响应学习的负, 速复制参数可以使用更大的学习率来训练, 并促使马尔可夫链探索新的区域", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2db05a78-6c90-41eb-a439-e7bedef7fc8e", "label": "摘要63", "info": "本节介绍的基于MCMC的方法，一个关键优点是它们提供了log  Z梯度；和log  Z两块。然；的估计，因此我们可以从本质上将问题分解为", "keywords": "梯度, 的估计, 因此我们可以从本质上将问题分解为, 本节介绍的基于, 两块", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "dd28958b-3404-4f83-bb50-13152b8af3fd", "label": "摘要64", "info": "下限的方法。然而，本章介绍处理log  Z的大多数其他方法都和基于", "keywords": "本章介绍处理, 下限的方法, 然而, 的大多数其他方法都和基于", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3ed9acce-a23f-4d28-b2e8-fd27fecf98c2", "label": "摘要65", "info": "边界的正相方法是不兼容的。", "keywords": "边界的正相方法是不兼容的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "label": "18.3：伪似然", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "6d7bc1aa-05c0-4c70-8ab6-f8981bbabd6d", "label": "摘要1", "info": "蒙特卡罗近似配分函数及其梯度需要直接处理配分函数。有些其他方法；通过训练不需要计算配分函数的模型来绕开这个问题。这些方法大多数；都基于以下观察：无向概率模型中很容易计算概率的比率。这是因为配", "keywords": "这些方法大多数, 这是因为配, 有些其他方法, 通过训练不需要计算配分函数的模型来绕开这个问题, 无向概率模型中很容易计算概率的比率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "10dba3bb-e40e-4acc-8c56-8d4f5bb0cb58", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；伪似然正是基于条件概率可以采用这种基于比率的形式，因此可以在没；有配分函数的情况下进行计算。假设我们将x  分为a、b  和c  ，其中a  包", "keywords": "假设我们将, 其中, 有配分函数的情况下进行计算, 伪似然正是基于条件概率可以采用这种基于比率的形式, 因此可以在没", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c098cdb8-15d0-4856-8c85-3ff907c0a5ce", "label": "摘要3", "info": "以上计算需要边缘化a ，假设a 和c 包含的变量并不多，那么这将是非常；高效的操作。在极端情况下，a  可以是单个变量，c  可以为空，那么该；计算仅需要估计与单个随机变量值一样多的  。", "keywords": "可以是单个变量, 以上计算需要边缘化, 包含的变量并不多, 高效的操作, 可以为空", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "5efb9541-75a5-4b3c-9d51-2e21da22340e", "label": "摘要4", "info": "不幸的是，为了计算对数似然，我们需要边缘化很多变量。如果总共有；n个变量，那么我们必须边缘化n−1个变量。根据概率的链式法则，我们；有", "keywords": "根据概率的链式法则, 个变量, 如果总共有, 那么我们必须边缘化, 我们", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "fc262b28-e9f1-4ce1-aed1-8b252018efdd", "label": "摘要5", "info": "在这种情况下，我们已经使a  尽可能小，但是c  可以大到x  2:n  。如果我；们简单地将c  移到b  中以减少计算代价，那么会发生什么呢？这便产生；了伪似然  （pseudolikelihood）（Besag，1975）目标函数，给定所有其", "keywords": "移到, 但是, 如果我, 了伪似然, 在这种情况下", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "20f7cc88-8ff1-4c69-8293-60a197f495c4", "label": "摘要6", "info": "如果每个随机变量有k个不同的值，那么计算   需要k×n次估计，而计；算配分函数需要k n 次估计。", "keywords": "那么计算, 如果每个随机变量有, 个不同的值, 而计, 次估计", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0571f88e-26f6-4821-86f0-0107f3153403", "label": "摘要7", "info": "这看起来似乎是一个没有道理的策略，但可以证明最大化伪似然的估计；是渐近一致的（Mase，1995）。当然，在数据集不趋近于大采样极限的；情况下，伪似然可能表现出与最大似然估计不同的结果。", "keywords": "但可以证明最大化伪似然的估计, 情况下, 这看起来似乎是一个没有道理的策略, 伪似然可能表现出与最大似然估计不同的结果, 是渐近一致的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "48ed2c82-398c-4ca7-83b3-874ea397b624", "label": "摘要8", "info": "我们可以使用广义伪似然估计 （generalized pseudolikelihood estimator）；来权衡计算复杂度和最大似然表现的偏差（Huang and Ogata，2002）。；，i＝1，…，m作为变量的指", "keywords": "作为变量的指, 我们可以使用广义伪似然估计, 来权衡计算复杂度和最大似然表现的偏差", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7b341a76-0c7d-42f0-be8d-efa9db09d04b", "label": "摘要9", "info": "基于伪似然的方法的性能在很大程度上取决于模型是如何使用的。对于；完全联合分布p(x  )模型的任务（例如密度估计和采样），伪似然通常效；果不好。对于在训练期间只需要使用条件分布的任务而言，它的效果比", "keywords": "例如密度估计和采样, 完全联合分布, 它的效果比, 基于伪似然的方法的性能在很大程度上取决于模型是如何使用的, 伪似然通常效", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c15c206a-e097-4ca9-a8d0-d6145e615cdc", "label": "摘要10", "info": "伪似然估计的一个弱点是它不能与仅在；上提供下界的其他近似；一起使用，例如第19章中介绍的变分推断。这是因为   出现在了分母", "keywords": "上提供下界的其他近似, 这是因为, 一起使用, 伪似然估计的一个弱点是它不能与仅在, 章中介绍的变分推断", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "65429266-a7b0-445c-98c7-c9005446560f", "label": "摘要11", "info": "伪似然比SML在每个梯度步骤中的计算代价要大得多，这是由于其对所；有条件进行显式计算。但是，如果每个样本只计算一个随机选择的条；件，那么广义伪似然和类似标准仍然可以很好地运行，从而使计算代价", "keywords": "在每个梯度步骤中的计算代价要大得多, 但是, 如果每个样本只计算一个随机选择的条, 那么广义伪似然和类似标准仍然可以很好地运行, 伪似然比", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "5db93692-57aa-4403-bf5b-0aa3b4d82248", "label": "摘要12", "info": "虽然伪似然估计没有显式地最小化log Z，但是我们仍然认为它具有类似；负相的效果。每个条件分布的分母会使得学习算法降低所有仅具有一个", "keywords": "虽然伪似然估计没有显式地最小化, 每个条件分布的分母会使得学习算法降低所有仅具有一个, 但是我们仍然认为它具有类似, 负相的效果", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "208d12fe-1eed-4d9e-afd7-17c32a719702", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；变量不同于训练样本的状态的概率。", "keywords": "变量不同于训练样本的状态的概率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "945882e7-51e0-47a0-957b-7fcf0e30ae42", "label": "摘要14", "info": "读者可以参考Marlin  and  de  Freitas（2011）了解伪似然渐近效率的理论；分析。", "keywords": "了解伪似然渐近效率的理论, 分析, 读者可以参考", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "label": "18.4：得分匹配和比率匹配", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "3da79470-4fb6-4005-9cf7-1e756919a017", "label": "摘要1", "info": "得分匹配（Hyvärinen，2005b）提供了另一种训练模型而不需要估计Z；，被；或其导数的一致性方法。对数密度关于参数的导数", "keywords": "得分匹配, 或其导数的一致性方法, 提供了另一种训练模型而不需要估计, 对数密度关于参数的导数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7f07b8a5-51f6-4b35-bb99-e0cf39329c70", "label": "摘要2", "info": "该目标函数避免了微分配分函数Z带来的难题，因为Z不是  x  的函数，；。最初，得分匹配似乎有一个新的困难：计算数据；所以", "keywords": "因为, 计算数据, 该目标函数避免了微分配分函数, 的函数, 所以", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c4a27d02-4640-40d7-a97d-75c4499f9a27", "label": "摘要3", "info": "其中n是 x 的维度。", "keywords": "的维度, 其中", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "47f32352-aa78-4386-869a-8bc45c06f1d8", "label": "摘要4", "info": "因为得分匹配需要关于x  的导数，所以它不适用于具有离散数据的模；型，但是模型中的潜变量可以是离散的。", "keywords": "但是模型中的潜变量可以是离散的, 因为得分匹配需要关于, 所以它不适用于具有离散数据的模, 的导数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b3618fc7-1b54-4ea9-a51a-4264ca588a7d", "label": "摘要5", "info": "类似于伪似然，得分匹配只有在我们能够直接估计；及其导数；的时候才有效。它与对", "keywords": "得分匹配只有在我们能够直接估计, 及其导数, 它与对, 的时候才有效, 类似于伪似然", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "36da6b1d-a80b-44cc-af8d-4dd7700c361f", "label": "摘要6", "info": "的模型估计，例如稀疏编码模型或深度玻尔兹曼机。虽然得分匹配可以；用于预训练较大模型的第一个隐藏层，但是它没有被用于预训练较大模；型的较深层网络。这可能是因为这些模型的隐藏层通常包含一些离散变", "keywords": "虽然得分匹配可以, 型的较深层网络, 但是它没有被用于预训练较大模, 的模型估计, 例如稀疏编码模型或深度玻尔兹曼机", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d7677747-bc2d-425c-b67b-8d3cae881abb", "label": "摘要7", "info": "虽然得分匹配没有明确显示具有负相信息，但是它可以被视为使用特定；类型马尔可夫链的对比散度的变种（Hyvärinen，2007a）。在这种情况；下，马尔可夫链并没有采用Gibbs采样，而是采用一种由梯度引导局部", "keywords": "在这种情况, 虽然得分匹配没有明确显示具有负相信息, 但是它可以被视为使用特定, 马尔可夫链并没有采用, 采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "fed96d98-6361-4390-87ff-18a6c2b773b8", "label": "摘要8", "info": "Lyu（2009）将得分匹配推广到离散的情况（但是推导有误，后由；Marlin et  al. （2010）修正）。Marlin et al.  （2010）发现，广义得分匹；配  （generalized score matching，GSM）在许多样本观测概率为0的高维", "keywords": "修正, 将得分匹配推广到离散的情况, 后由, 的高维, 但是推导有误", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7cb09a80-a684-4a5d-ac00-83138fd9974d", "label": "摘要9", "info": "一种更成功地将得分匹配的基本想法扩展到离散数据的方法是比率匹配；（ratio  matching）（Hyvärinen，2007b）。比率匹配特别适用于二值数；据。比率匹配最小化以下目标函数在样本上的均值：", "keywords": "比率匹配最小化以下目标函数在样本上的均值, 一种更成功地将得分匹配的基本想法扩展到离散数据的方法是比率匹配, 比率匹配特别适用于二值数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c7a8ba36-1555-4d57-840a-c10eeb756b0d", "label": "摘要10", "info": "其中f(  x  ,j)返回j处位值取反的x  。比率匹配使用了与伪似然估计相同的；策略来绕开配分函数：配分函数会在两个概率的比率中抵消掉。Marlin；et  al.  （2010）发现，训练模型给测试集图像去噪时，比率匹配的效果", "keywords": "处位值取反的, 比率匹配的效果, 其中, 训练模型给测试集图像去噪时, 配分函数会在两个概率的比率中抵消掉", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0e099cc6-bf71-49e2-ac2c-b4800707ed4c", "label": "摘要11", "info": "类似于伪似然估计，比率匹配对每个数据点都需要n个   的估计，因此；每次更新的计算代价大约比SML的计算代价高出n倍。", "keywords": "的估计, 比率匹配对每个数据点都需要, 类似于伪似然估计, 因此, 每次更新的计算代价大约比", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ef87e3a3-7172-4656-8f44-e25176ff83ef", "label": "摘要12", "info": "与伪似然估计一样，我们可以认为比率匹配减小了所有只有一个变量不；同于训练样本的状态的概率。由于比率匹配特别适用于二值数据，这意；味着在与数据的汉明距离为1内的所有状态上，比率匹配都是有效的。", "keywords": "与伪似然估计一样, 这意, 同于训练样本的状态的概率, 我们可以认为比率匹配减小了所有只有一个变量不, 由于比率匹配特别适用于二值数据", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "bf941c98-47a9-40b7-940c-e1b7ec2ca805", "label": "摘要13", "info": "比率匹配还可以作为处理高维稀疏数据（例如词计数向量）的基础。这", "keywords": "比率匹配还可以作为处理高维稀疏数据, 例如词计数向量, 的基础", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6aeb9075-f100-4061-bc81-01513fcb300c", "label": "摘要14", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；类稀疏数据对基于MCMC的方法提出了挑战，因为以密集格式表示数据；是非常消耗计算资源的，而只有在模型学会表示数据分布的稀疏性之", "keywords": "类稀疏数据对基于, 因为以密集格式表示数据, 是非常消耗计算资源的, 而只有在模型学会表示数据分布的稀疏性之, 的方法提出了挑战", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c12b07a1-050a-4bc2-a842-cbb0e0818c1a", "label": "摘要15", "info": "读者可以参考Marlin  and  de  Freitas（2011）了解比率匹配渐近效率的理；论分析。", "keywords": "了解比率匹配渐近效率的理, 论分析, 读者可以参考", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0d2078be-c9bf-465d-8ef7-9f0521b582f6", "label": "18.5：去噪得分匹配", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "fa8a269a-a72f-4098-96aa-84a739a1b683", "label": "摘要1", "info": "某些情况下，我们希望拟合以下分布来正则化得分匹配", "keywords": "我们希望拟合以下分布来正则化得分匹配, 某些情况下", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "244234fc-70bd-49ea-8216-b01fa5df3739", "label": "摘要2", "info": "而不是拟合真实分布p  data  。分布q(  x  ｜  y  )是一个损坏过程，通常在形；成 x 的过程中会向 y 中添加少量噪声。", "keywords": "的过程中会向, 而不是拟合真实分布, 通常在形, 分布, 中添加少量噪声", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ed4d4536-0b5e-41b0-984d-b82d95187d16", "label": "摘要3", "info": "去噪得分匹配非常有用，因为在实践中，通常我们不能获取真实的p  data；，而只能得到其样本确定的经验分布。给定足够容量，任何一致估计都；会使p  model 成为一组以训练点为中心的Dirac分布。考虑在第5.4.5节介绍", "keywords": "给定足够容量, 考虑在第, 节介绍, 成为一组以训练点为中心的, 任何一致估计都", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3ce2c6f7-d5ff-43f0-9378-33f8a4c3bb62", "label": "摘要4", "info": "回顾第14.5.1节，有一些自编码器训练算法等价于得分匹配或去噪得分；匹配。因此，这些自编码器训练算法也是解决配分函数问题的一种方；式。", "keywords": "有一些自编码器训练算法等价于得分匹配或去噪得分, 因此, 这些自编码器训练算法也是解决配分函数问题的一种方, 回顾第, 匹配", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "label": "18.6：噪声对比估计", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "55fd600e-1a04-4f8b-ab43-bb3b225668ad", "label": "摘要1", "info": "具有难求解的配分函数的大多数模型估计都没有估计配分函数。SML和；CD只估计对数配分函数的梯度，而不是估计配分函数本身。得分匹配；和伪似然避免了和配分函数相关的计算。", "keywords": "而不是估计配分函数本身, 只估计对数配分函数的梯度, 得分匹配, 和伪似然避免了和配分函数相关的计算, 具有难求解的配分函数的大多数模型估计都没有估计配分函数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "28c9b6c0-127b-472f-bdbf-f8978c6f5d97", "label": "摘要2", "info": "噪声对比估计  （noise-contrastive  estimation，NCE）（Gutmann  and；Hyvarinen，2010）采取了一种不同的策略。在这种方法中，模型估计；的概率分布被明确表示为", "keywords": "的概率分布被明确表示为, 噪声对比估计, 采取了一种不同的策略, 模型估计, 在这种方法中", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e0acbb5c-c211-4d9c-b59c-0c920739bca9", "label": "摘要3", "info": "其中c是−log  Z(  θ  )的近似。噪声对比估计过程将c视为另一参数，使用；相同的算法同时估计  θ 和c，而不是仅仅估计  θ  。因此，所得到的log  p；model (x  )可能并不完全对应有效的概率分布，但随着c估计的改进，它将", "keywords": "相同的算法同时估计, 它将, 因此, 的近似, 其中", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ce6d293b-76c5-49f7-9917-f41c08b29f4c", "label": "摘要4", "info": "这种方法不可能使用最大似然作为估计的标准。最大似然标准可以设置；c为任意大的值，而不是设置c以创建一个有效的概率分布。", "keywords": "最大似然标准可以设置, 这种方法不可能使用最大似然作为估计的标准, 为任意大的值, 而不是设置, 以创建一个有效的概率分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "80bf785e-5be2-460d-9591-2364ca92a606", "label": "摘要5", "info": "NCE将估计p(x  )的无监督学习问题转化为学习一个概率二元分类器，其；中一个类别对应模型生成的数据。该监督学习问题中的最大似然估计定；义了原始问题的渐近一致估计。", "keywords": "将估计, 义了原始问题的渐近一致估计, 中一个类别对应模型生成的数据, 该监督学习问题中的最大似然估计定, 的无监督学习问题转化为学习一个概率二元分类器", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1e9cdd05-c351-44ff-86d8-f0d916015003", "label": "摘要6", "info": "具体地说，我们引入第二个分布，噪声分布  （noise  distribution）p  noise；(x  )。噪声分布应该易于估计和从中采样。我们现在可以构造一个联合x；和新二值变量y的模型。在新的联合模型中，我们指定", "keywords": "我们引入第二个分布, 我们指定, 噪声分布, 的模型, 和新二值变量", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b160a12b-b6ce-4efa-bf19-b990471485a8", "label": "摘要7", "info": "和", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6b71557f-7846-4edf-93d5-ba0d13b95641", "label": "摘要8", "info": "换言之，y是一个决定我们从模型还是从噪声分布中生成x  的开关变；量。", "keywords": "的开关变, 换言之, 是一个决定我们从模型还是从噪声分布中生成", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "fabf067e-22ec-49cd-a200-77dec1af9920", "label": "摘要9", "info": "我们可以在训练数据上构造一个类似的联合模型。在这种情况下，开关；。正式地，；变量决定是从数据", "keywords": "开关, 正式地, 在这种情况下, 我们可以在训练数据上构造一个类似的联合模型, 变量决定是从数据", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "94ae887b-0dc0-4004-ba44-b770d23ebf9d", "label": "摘要10", "info": "还是从噪声分布中抽取x", "keywords": "还是从噪声分布中抽取", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a8299613-becb-46f9-b400-dd69473818dd", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；，p  train  (x  ｜y＝1)＝p  data  (x", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b214740d-c5f7-420f-a3ce-ee913bbcd2bb", "label": "摘要12", "info": ")，和p train (x ｜y＝0)＝p noise (x )。", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "bb3e1274-d41d-4c4c-9732-888edfc2932c", "label": "摘要13", "info": "现在我们可以应用标准的最大似然学习拟合p joint 到p  train 的监督 学习问；题：", "keywords": "现在我们可以应用标准的最大似然学习拟合, 学习问, 的监督", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "99ac7e7c-8b2c-46ab-ad7b-e5536e31e627", "label": "摘要14", "info": "joint  本质上是将逻辑回归模型应用于模型和噪声分布之间的对数", "keywords": "本质上是将逻辑回归模型应用于模型和噪声分布之间的对数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "161f12e4-3866-4a0d-b22b-be2b52800836", "label": "摘要15", "info": "分布p；概率之差：", "keywords": "概率之差, 分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ff09956a-62b2-4030-abb2-954195509c1c", "label": "摘要16", "info": "因此，只要；估计（以便评估p；使用。", "keywords": "估计, 因此, 以便评估, 只要, 使用", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2972ca42-95fc-4b19-87be-74a6276b60c1", "label": "摘要17", "info": "易于反向传播，并且如上所述，p noise 应易于；joint  ）和采样（以生成训练数据），那么NCE就易于", "keywords": "和采样, 并且如上所述, 就易于, 易于反向传播, 应易于", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2cff36b1-9336-4f73-9052-fb2d5f251fbf", "label": "摘要18", "info": "NCE能够非常成功地应用于随机变量较少的问题，但即使随机变量有很；多可以取的值时，它也很有效。例如，它已经成功地应用于给定单词上；下文建模单词的条件分布（Mnih  and  Kavukcuoglu，2013）。虽然单词", "keywords": "下文建模单词的条件分布, 虽然单词, 它已经成功地应用于给定单词上, 但即使随机变量有很, 多可以取的值时", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "eaae25d9-c12e-43f8-bb48-7cb9a689f32c", "label": "摘要19", "info": "当NCE应用于具有许多随机变量的问题时，其效率会变得较低。当逻辑；回归分类器发现某个变量的取值不大可能时，它会拒绝这个噪声样本。；这意味着在p  model  学习了基本的边缘统计之后，学习进程会大大减慢。", "keywords": "回归分类器发现某个变量的取值不大可能时, 其效率会变得较低, 它会拒绝这个噪声样本, 应用于具有许多随机变量的问题时, 当逻辑", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "308fa6e3-6fcf-469e-b52d-b2d831689a66", "label": "摘要20", "info": "想象一个使用非结构化高斯噪声作为p  noise  来学习面部图像的模型。如；果p  model  学会了眼睛，就算没有学习任何其他面部特征，比如嘴，它也；会拒绝几乎所有的非结构化噪声样本。", "keywords": "来学习面部图像的模型, 想象一个使用非结构化高斯噪声作为, 比如嘴, 学会了眼睛, 它也", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "952c38cd-047d-48a6-a65b-0628ebe70916", "label": "摘要21", "info": "噪声分布p  noise  必须是易于估计和采样的约束可能是过于严格的限制。；当p  noise  比较简单时，大多数采样可能与数据有着明显不同，而不会迫；使p model 进行显著改进。", "keywords": "比较简单时, 必须是易于估计和采样的约束可能是过于严格的限制, 大多数采样可能与数据有着明显不同, 进行显著改进, 而不会迫", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ce11c7c6-32ed-4203-a8d3-58fea07bfc2d", "label": "摘要22", "info": "类似于得分匹配和伪似然，如果   只有下界，那么NCE不会有效。这；样的下界能够用于构建p  joint  (y＝1｜x  )的下界，但是它只能用于构建p；joint  (y＝0｜x  )（出现在一半的NCE对象中）的上界。同样地，p  noise  的", "keywords": "只有下界, 如果, 对象中, 类似于得分匹配和伪似然, 不会有效", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "44cff836-5d9a-40bd-955a-330d6cbbb960", "label": "摘要23", "info": "在每个梯度步骤之前，模型分布被复制来定义新的噪声分布时，NCE定；义了一个被称为自对比估计 （self-contrastive  estimation）的过程，其梯；度期望等价于最大似然的梯度期望（Goodfellow，2014）。特殊情况的", "keywords": "的过程, 特殊情况的, 度期望等价于最大似然的梯度期望, 在每个梯度步骤之前, 模型分布被复制来定义新的噪声分布时", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0f407efa-04b6-4699-bbed-c5d5bdeaac4c", "label": "摘要24", "info": "在训练样本和生成样本（使用模型能量函数定义分类器）之间进行分类；以得到模型的梯度的方法，已经在更早的时候以各种形式提出来；（Welling et al. ，2003b；Bengio，2009）。", "keywords": "之间进行分类, 以得到模型的梯度的方法, 使用模型能量函数定义分类器, 在训练样本和生成样本, 已经在更早的时候以各种形式提出来", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8a433dd5-0628-48a6-8fd0-4b2d89f228c6", "label": "摘要25", "info": "噪声对比估计是基于良好生成模型应该能够区分数据和噪声的想法。一；个密切相关的想法是，良好的生成模型能够生成分类器无法将其与数据；区分的样本。这个想法诞生了生成式对抗网络（第20.10.4节）。", "keywords": "区分的样本, 个密切相关的想法是, 这个想法诞生了生成式对抗网络, 噪声对比估计是基于良好生成模型应该能够区分数据和噪声的想法, 良好的生成模型能够生成分类器无法将其与数据", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "label": "18.7：估计配分函数", "level": 2, "group": "chapter-18", "type": "子章節"}, {"id": "25e574af-386b-44ea-9176-3792f7839da4", "label": "摘要1", "info": "18.7.1　退火重要采样", "keywords": "退火重要采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4885871a-4ae4-4bf1-9b45-32781b07249c", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；18.7.2　桥式采样", "keywords": "桥式采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4b6a00fe-8499-4f5b-91e1-288dc59a93a0", "label": "摘要3", "info": "尽管本章中的大部分内容都在避免计算与无向图模型相关的难以计算的；配分函数Z（  θ  ），但在本节中我们将会讨论几种直接估计配分函数的；方法。", "keywords": "但在本节中我们将会讨论几种直接估计配分函数的, 配分函数, 尽管本章中的大部分内容都在避免计算与无向图模型相关的难以计算的, 方法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "afc7cb35-d295-4e9c-8270-c7ada78defa3", "label": "摘要4", "info": "估计配分函数可能会很重要，当希望计算数据的归一化似然时，我们会", "keywords": "我们会, 估计配分函数可能会很重要, 当希望计算数据的归一化似然时", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a9457134-a261-4aa4-a42b-7e520b8eddcc", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；需要它。在评估模型、监控训练性能和比较模型时，这通常是很重要；的。", "keywords": "需要它, 这通常是很重要, 在评估模型, 监控训练性能和比较模型时", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "70fc08ed-bb9d-4509-ab01-e9b116b42958", "label": "摘要6", "info": "例如，假设我们有两个模型：概率分布为", "keywords": "假设我们有两个模型, 概率分布为, 例如", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f3dbec27-2b5c-4a52-8d84-950f27a3453e", "label": "摘要7", "info": "的模型", "keywords": "的模型", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "14cc114d-3893-4bae-9926-8be2de2a87b5", "label": "摘要8", "info": "和概率分布为", "keywords": "和概率分布为", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6abf01c0-70b8-4451-b2eb-f2536e8f1b9f", "label": "摘要9", "info": "。比较模型的常用方法是评估和比较两个模型分配给独；的模型；立同分布测试数据集的似然。假设测试集含m个样本{  x  (1)  ，…，  x  (m)", "keywords": "个样本, 的模型, 立同分布测试数据集的似然, 假设测试集含, 比较模型的常用方法是评估和比较两个模型分配给独", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f8cdd3a4-7da3-4e56-a7a1-2fd1559e3dbc", "label": "摘要10", "info": "，或等价地，如果", "keywords": "如果, 或等价地", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "622439b8-70e3-49c8-a59b-48b4e53f7137", "label": "摘要11", "info": "是一个比", "keywords": "是一个比", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f1bbd085-638f-4a81-a2f7-73a8c2eb8792", "label": "摘要12", "info": "那么我们说；更好的模型（或者，至少可以说，；它在测试集上是一个更好的模型），这是指它有一个更好的测试对数似", "keywords": "更好的模型, 这是指它有一个更好的测试对数似, 那么我们说, 它在测试集上是一个更好的模型, 或者", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "58bff0ac-6f1a-4f1a-af00-a8a184fb97eb", "label": "摘要13", "info": "因此，我们可以在不知道任一模型的配分函数，而只知道它们比率的情；况下，判断模型；更优。正如我们将很快看到", "keywords": "况下, 因此, 我们可以在不知道任一模型的配分函数, 而只知道它们比率的情, 正如我们将很快看到", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "9fc8a0d8-27e4-4389-b587-700eacf7e7ba", "label": "摘要14", "info": "是否比模型", "keywords": "是否比模型", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4213e274-4db3-4041-b010-5ec1fa9f9cfe", "label": "摘要15", "info": "然而，如果我们想要计算测试数据在；上的真实概率，；我们需要计算配分函数的真实值。如果我们知道两个配分函数的比率，", "keywords": "我们需要计算配分函数的真实值, 如果我们知道两个配分函数的比率, 然而, 上的真实概率, 如果我们想要计算测试数据在", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0a78dc1a-552d-423a-8137-445ce028ca02", "label": "摘要16", "info": "或", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "64b72e19-f281-4eba-a95d-7f2a2ee072fd", "label": "摘要17", "info": "，并且知道两者中一个的实际值，比如说Z( θ  A )，那", "keywords": "并且知道两者中一个的实际值, 比如说", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ff921a61-2f90-423a-a100-136999ce9fc8", "label": "摘要18", "info": "么我们可以计算另一个的值：", "keywords": "么我们可以计算另一个的值", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2ee87191-74f9-4b78-98bd-bea7f8663c1a", "label": "摘要19", "info": "一种估计配分函数的简单方法是使用蒙特卡罗方法，例如简单重要采；样。以下用连续变量积分来表示该方法，也可以替换积分为求和，很容；易将其应用到离散变量的情况。我们使用提议分布", "keywords": "也可以替换积分为求和, 很容, 我们使用提议分布, 一种估计配分函数的简单方法是使用蒙特卡罗方法, 例如简单重要采", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "83c78fe3-d46b-46ba-b11d-2abe110a2476", "label": "摘要20", "info": "，其在配分函数Z 0 和未归一化分布", "keywords": "和未归一化分布, 其在配分函数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d72b0abd-f2ed-486b-a216-e748bd91582e", "label": "摘要21", "info": "上易于采样和估计。", "keywords": "上易于采样和估计", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b73afef1-2878-4b75-98b4-b5cb5c1e692f", "label": "摘要22", "info": "在最后一行，我们使用蒙特卡罗估计，使用从p  0  (x  )中抽取的采样计算；积分   ，然后用未归一化的   和提议分布p  0  的比率对每个采样加；权。", "keywords": "和提议分布, 我们使用蒙特卡罗估计, 使用从, 积分, 然后用未归一化的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "70e15733-e266-463b-a0b6-14d5818e5132", "label": "摘要23", "info": "这种方法使得我们可以估计配分函数之间的比率：", "keywords": "这种方法使得我们可以估计配分函数之间的比率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7cedd658-f372-4832-981f-27f6b5a74805", "label": "摘要24", "info": "然后该值可以直接比较式（18.39）中的两个模型。", "keywords": "然后该值可以直接比较式, 中的两个模型", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4d10b3b2-2a71-4b14-9d9d-ad2148d43b6b", "label": "摘要25", "info": "0  接近p", "keywords": "接近", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c0fc2cb1-5a45-474d-a1e8-bbba29c319e0", "label": "摘要26", "info": "如果分布p；1  ，那么式（18.44）能够有效地估计配分函数；（Minka，2005）。不幸的是，大多数时候p  1  都很复杂（通常是多峰值", "keywords": "那么式, 通常是多峰值, 能够有效地估计配分函数, 大多数时候, 不幸的是", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c0057c7c-a8a4-4986-a829-dd676c50ba9a", "label": "摘要27", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；和中产生（相对的）可忽略的贡献。", "keywords": "和中产生, 相对的, 可忽略的贡献", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1409e1e4-8feb-4721-86f7-83a6e5385c68", "label": "摘要28", "info": "如果求和中只有少数几个具有显著权重的样本，那么将会由于高方差而；导致估计的效果很差。这可以通过估计  的方差来定量地理解：", "keywords": "那么将会由于高方差而, 如果求和中只有少数几个具有显著权重的样本, 导致估计的效果很差, 这可以通过估计, 的方差来定量地理解", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "fbea2a33-d84a-4ad1-9037-370e7b4290e5", "label": "摘要29", "info": "当重要性权重", "keywords": "当重要性权重", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "ae309c5d-335b-4812-a802-462408b768d7", "label": "摘要30", "info": "存在显著偏差时，上式的值是最大的。", "keywords": "存在显著偏差时, 上式的值是最大的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "97030319-e6ac-4676-aa70-9bcf3016ef40", "label": "摘要31", "info": "我们现在关注两个解决高维空间复杂分布上估计配分函数的方法：退火；重要采样和桥式采样。两者都始于上面介绍的简单重要采样方法，并且；都试图通过引入缩小p 0 和p 1 之间差距的中间分布，来解决p 0 远离p 1 的", "keywords": "远离, 之间差距的中间分布, 重要采样和桥式采样, 来解决, 退火", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d0fc6765-5a98-4ae1-a828-58bf5c65a234", "label": "摘要32", "info": "18.7.1　退火重要采样", "keywords": "退火重要采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3681811b-4706-4a24-8fd3-7e2190f3d9df", "label": "摘要33", "info": "在D KL (p 0 ǁp 1 )很大的情况下（即p 0 和p 1 之间几乎没有重叠），一种称；为退火重要采样 （annealed importance sampling，AIS）的方法试图通过；引入中间分布来缩小这种差距（Jarzynski，1997；Neal，2001）。考虑", "keywords": "引入中间分布来缩小这种差距, 很大的情况下, 为退火重要采样, 之间几乎没有重叠, 一种称", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "07f07ed5-9b04-45f9-95f3-b88ebf28fd9f", "label": "摘要34", "info": "的第一个和最后一个分别是p 0 和p 1 。", "keywords": "的第一个和最后一个分别是", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6da87815-75d3-4ead-8cfe-47252eaff103", "label": "摘要35", "info": "这种方法使我们能够估计定义在高维空间多峰分布（例如训练RBM时；定义的分布）上的配分函数。我们从一个已知配分函数的简单模型（例；如，权重为零的RBM）开始，估计两个模型配分函数之间的比率。该", "keywords": "估计两个模型配分函数之间的比率, 例如训练, 定义的分布, 开始, 上的配分函数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a78c39e1-34ba-4978-9401-dc2c6842888f", "label": "摘要36", "info": "现在我们可以将比率", "keywords": "现在我们可以将比率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c708e930-ab96-4be5-b912-04596a032371", "label": "摘要37", "info": "写作", "keywords": "写作", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1d1c1334-95f0-4325-8067-d7339b02d4d4", "label": "摘要38", "info": "如果对于所有的", "keywords": "如果对于所有的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c42b32f5-e288-4175-b003-d22db149c380", "label": "摘要39", "info": "，分布", "keywords": "分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e5e4f747-ee5b-4df0-806a-1bd758fb5f3e", "label": "摘要40", "info": "和", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "1a00da82-634d-46c4-89ee-334c451a1226", "label": "摘要41", "info": "足够接", "keywords": "足够接", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c0f0aba9-df57-40a3-a9d2-858fb62fc0c7", "label": "摘要42", "info": "近，那么我们能够使用简单的重要采样来估计每个因子", "keywords": "那么我们能够使用简单的重要采样来估计每个因子", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "54890076-7a6f-40db-a709-dd788f272b9d", "label": "摘要43", "info": "，然后", "keywords": "然后", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "2ce54cc1-74a3-46b2-8bfb-fa37a83a3c3d", "label": "摘要44", "info": "使用这些得到  的估计。", "keywords": "的估计, 使用这些得到", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "5ce82d2d-49be-4f10-b11c-5a428653ff12", "label": "摘要45", "info": "这些中间分布是从哪里来的呢？正如最先的提议分布p  0  是一种设计选；择，分布序列；也是如此。也就是说，它们可以被", "keywords": "这些中间分布是从哪里来的呢, 正如最先的提议分布, 是一种设计选, 也是如此, 分布序列", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "112ba019-bc64-41fa-8500-256661bbe22f", "label": "摘要46", "info": "为了从这些中间分布中采样，我们定义了一组马尔可夫链转移函数T  ηj  (；x ＇｜ x )，定义了给定 x 转移到 x ＇的条件概率分布。转移算子T ηj ( x；＇｜ x )定义如下，保持p ηj ( x )不变：", "keywords": "定义如下, 不变, 转移到, 为了从这些中间分布中采样, 转移算子", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8978b73a-19bb-4e0b-8f4a-111622e2d90a", "label": "摘要47", "info": "这些转移可以被构造为任何马尔可夫链蒙特卡罗方法（例如，；Metropolis-Hastings，Gibbs），包括涉及多次遍历所有随机变量或其他；迭代的方法。", "keywords": "这些转移可以被构造为任何马尔可夫链蒙特卡罗方法, 迭代的方法, 例如, 包括涉及多次遍历所有随机变量或其他", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "3f3fbf5f-6ec1-476f-be78-14a3cde380d2", "label": "摘要48", "info": "然后，AIS采样方法从p  0  开始生成样本，并使用转移算子从中间分布顺；序地生成采样，直到我们得到目标分布p 1 的采样。", "keywords": "直到我们得到目标分布, 并使用转移算子从中间分布顺, 序地生成采样, 采样方法从, 的采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e73219b5-800d-4862-8751-47efbc2eadae", "label": "摘要49", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；对于采样k，通过连接式（18.49）给出的中间分布之间的重要性权重，；我们可以导出目标重要性权重：", "keywords": "通过连接式, 给出的中间分布之间的重要性权重, 对于采样, 我们可以导出目标重要性权重", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "493676d9-3f81-4619-817a-f65d222c7e55", "label": "摘要50", "info": "为了避免诸如上溢的数值问题，最佳方法可能是通过加法或减法计算；log w (k) ，而不是通过概率乘法和除法计算w (k) 。", "keywords": "最佳方法可能是通过加法或减法计算, 为了避免诸如上溢的数值问题, 而不是通过概率乘法和除法计算", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8d14474b-814d-4231-be2a-3de0253dcec8", "label": "摘要51", "info": "利用由此定义的采样过程和式（18.52）中给出的重要性权重，配分函；数的比率估计如下所示：", "keywords": "数的比率估计如下所示, 利用由此定义的采样过程和式, 配分函, 中给出的重要性权重", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e0d5a696-05ec-46de-9d20-d8a5f76c7528", "label": "摘要52", "info": "为了验证该过程定义的重要采样方案是否有效，我们可以展示（Neal，；2001）AIS过程对应着扩展状态空间上的简单重要采样，其中数据点采；样自乘积空间", "keywords": "为了验证该过程定义的重要采样方案是否有效, 过程对应着扩展状态空间上的简单重要采样, 样自乘积空间, 我们可以展示, 其中数据点采", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4063f482-e8ed-450f-8ee8-c66d19a75545", "label": "摘要53", "info": "。为此，我们将扩展空间上的", "keywords": "为此, 我们将扩展空间上的", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a602d998-f4c3-4466-801f-a8c242642b5a", "label": "摘要54", "info": "其中  是由T a 定义的转移算子的逆（应用贝叶斯规则）：", "keywords": "定义的转移算子的逆, 是由, 其中, 应用贝叶斯规则", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b403e2a6-e8f7-4556-8361-44317bbf3b9d", "label": "摘要55", "info": "将以上代入到式（18.55）给出的扩展状态空间上的联合分布中，我们；得到", "keywords": "给出的扩展状态空间上的联合分布中, 得到, 我们, 将以上代入到式", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "55a89b0b-7747-49e0-bd69-5b5c8ec02a39", "label": "摘要56", "info": "通过上面给定的采样方案，现在我们可以从扩展样本上的联合提议分布；q上生成采样，联合分布如下：", "keywords": "通过上面给定的采样方案, 上生成采样, 联合分布如下, 现在我们可以从扩展样本上的联合提议分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "0247c6a6-df63-4bfa-b447-7a8787a96903", "label": "摘要57", "info": "式（18.59）给出了扩展空间上的联合分布。将", "keywords": "给出了扩展空间上的联合分布", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "20cebf61-c5e3-4cfe-967f-6aa6636fdcd2", "label": "摘要58", "info": "作为扩展状态空间上的提议分布（我们", "keywords": "作为扩展状态空间上的提议分布, 我们", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "4d31e014-74c8-405e-80ff-7082b8162403", "label": "摘要59", "info": "会从中抽样），重要性权重如下：", "keywords": "会从中抽样, 重要性权重如下", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "c63f6bb0-c298-4820-b11d-9e22c5ac6ca7", "label": "摘要60", "info": "这些权重和AIS上的权重相同。因此，我们可以将AIS解释为应用于扩；展状态上的简单重要采样，其有效性直接来源于重要采样的有效性。", "keywords": "上的权重相同, 我们可以将, 因此, 解释为应用于扩, 展状态上的简单重要采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "115fde3c-f0f9-4b55-b790-1c347e310d82", "label": "摘要61", "info": "退火重要采样首先由Jarzynski（1997）发现，然后由Neal（2001）再次；独立发现。目前它是估计无向概率模型的配分函数的最常用方法。其原；因可能与一篇有影响力的论文（Salakhutdinov  and  Murray，2008）有", "keywords": "其原, 独立发现, 因可能与一篇有影响力的论文, 再次, 然后由", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e10d7ffa-94f0-4fc9-8ef2-c42480673dd5", "label": "摘要62", "info": "关于AIS估计性质（例如，方差和效率）的讨论，请参看；Neal（2001）。", "keywords": "请参看, 估计性质, 例如, 的讨论, 方差和效率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "17b5e47e-6587-45d9-891d-98df002c55ef", "label": "摘要63", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；18.7.2　桥式采样", "keywords": "桥式采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "38b40071-a579-4059-b80f-90ba01417e2b", "label": "摘要64", "info": "类似于AIS，桥式采样（Bennett，1976）是另一种处理重要采样缺点的；方法。并非将一系列中间分布连接在一起，桥式采样依赖于单个分布p  ∗；（被称为桥），在已知配分函数的分布p  0  和分布p  1  （我们试图估计其", "keywords": "在已知配分函数的分布, 桥式采样, 和分布, 被称为桥, 我们试图估计其", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "120118ab-5a64-4082-9ba3-772cbbf7e9d5", "label": "摘要65", "info": "桥式采样估计比率Z  1  /Z  0  ：；之间重要性权重的比率，", "keywords": "之间重要性权重的比率, 桥式采样估计比率", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "f0929d30-1595-464f-922a-288386db3d91", "label": "摘要66", "info": "和   之间重要性权重期望与   和", "keywords": "之间重要性权重期望与", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "7911435b-d559-4c88-9bff-d2c705dbe017", "label": "摘要67", "info": "如果仔细选择桥式采样p ∗ ，使其与p 0 和p  1  都有很大重合的话，那么桥；式采样能够允许两个分布（或更正式地，D  KL (p  0  ǁp  1  )）之间有较大差；距（相对标准重要采样而言）。", "keywords": "或更正式地, 那么桥, 都有很大重合的话, 式采样能够允许两个分布, 使其与", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "670d463b-1ca4-4ae6-9726-c448b4112c1b", "label": "摘要68", "info": "可以表明，最优的桥式采样是", "keywords": "可以表明, 最优的桥式采样是", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "6cc3660f-3f34-44ee-98a8-a78de8af99b6", "label": "摘要69", "info": "，其中r＝Z  1  /Z  0  。这似乎是一个不可行的解决方案，因为它似乎需要；我们估计数值Z  1  /Z  0  。然而，可以从粗糙的r开始估计，然后使用得到；的桥式采样逐步迭代以改进估计（Neal，2005）。也就是说，我们会迭", "keywords": "我们估计数值, 然后使用得到, 我们会迭, 其中, 然而", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "aacced62-941c-4b4c-b8af-637ede53d1b4", "label": "摘要70", "info": "链接重要采样  　AIS和桥式采样各有优点。如果D  KL  (p  0  ǁp  1  )不太大；（由于p 0 和p 1 足够接近）的话，那么桥式采样能比AIS更高效地估计配；分函数比率。然而，如果对于单个分布p  ∗  而言，两个分布相距太远难", "keywords": "如果, 链接重要采样, 和桥式采样各有优点, 而言, 然而", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "b62939a5-ad41-46ef-a09f-ac321ee3d918", "label": "摘要71", "info": "在训练期间估计配分函数 　虽然AIS已经被认为是用于估计许多无向模；型配分函数的标准方法，但是它在计算上代价很高，以致其在训练期间", "keywords": "在训练期间估计配分函数, 以致其在训练期间, 虽然, 型配分函数的标准方法, 但是它在计算上代价很高", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "d96cf0d9-add6-4476-831c-1aa32c89f3ee", "label": "摘要72", "info": "仍然不很实用。研究者探索了一些在训练过程中估计配分函数的替代方；法。", "keywords": "研究者探索了一些在训练过程中估计配分函数的替代方, 仍然不很实用", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "e4174ad2-ca67-4bcd-96ec-fcde3adbb7a9", "label": "摘要73", "info": "使用桥式采样、短链AIS和并行回火的组合，Desjardins  et  al.  （2011）；设计了一种在训练过程中追踪RBM配分函数的方法。该策略的基础；是，在并行回火方法操作的每个温度下，RBM配分函数的独立估计会", "keywords": "设计了一种在训练过程中追踪, 短链, 配分函数的独立估计会, 使用桥式采样, 配分函数的方法", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a26926e6-5f5a-48a8-a1fa-fbcec83e15b2", "label": "摘要74", "info": "本章中描述的工具提供了许多不同的方法，以解决难处理的配分函数问；题，但是在训练和使用生成模型时，可能会存在一些其他问题，其中最；重要的是我们接下来会遇到的难以推断的问题。", "keywords": "以解决难处理的配分函数问, 本章中描述的工具提供了许多不同的方法, 可能会存在一些其他问题, 重要的是我们接下来会遇到的难以推断的问题, 但是在训练和使用生成模型时", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "29c97baf-6378-40db-a102-7d41e0534934", "label": "摘要75", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "8b0f4fa1-9de4-4792-89fa-8641c7a0714a", "label": "摘要76", "info": "(1)    NCE也适用于具有易于处理的、不需要引入额外参数c的配分函数问题。它已经是最令人感；兴趣的、估计具有复杂配分函数模型的方法。", "keywords": "它已经是最令人感, 估计具有复杂配分函数模型的方法, 也适用于具有易于处理的, 兴趣的, 不需要引入额外参数", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "312eeb96-af3d-4da1-8501-eaba55b024bd", "label": "摘要77", "info": "18.7.1　退火重要采样", "keywords": "退火重要采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "474ba388-fcc7-4ecd-867c-2650fddec9af", "label": "摘要78", "info": "18.7.2　桥式采样", "keywords": "桥式采样", "level": 3, "group": "chapter-18", "type": "段落"}, {"id": "a2ad232d-ce37-4701-ba85-fcc32868545e", "label": "第19章：近似推断", "level": 1, "group": "chapter-19", "type": "章節"}, {"id": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "label": "18.7：估计配分函数", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "53c0e8a3-2c7a-4677-9c41-76489270a44b", "label": "摘要1", "info": "许多概率模型很难训练的原因是很难进行推断。在深度学习中，通常我；们有一系列可见变量 ν 和一系列潜变量 h 。推断困难通常是指难以计算；p( h ｜ ν )或其期望。而这样的操作在一些诸如最大似然学习的任务中往", "keywords": "而这样的操作在一些诸如最大似然学习的任务中往, 们有一系列可见变量, 通常我, 在深度学习中, 和一系列潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "44e56576-6bba-4011-a2c5-4849f19debe6", "label": "摘要2", "info": "许多仅含一个隐藏层的简单图模型会定义成易于计算p( h ｜ ν )或其期望；的形式，例如受限玻尔兹曼机和概率PCA。不幸的是，大多数具有多层；隐藏变量的图模型的后验分布都很难处理。对于这些模型而言，精确推", "keywords": "例如受限玻尔兹曼机和概率, 对于这些模型而言, 隐藏变量的图模型的后验分布都很难处理, 精确推, 不幸的是", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b24b1d66-c47a-4ed0-b0d9-38c00ef33532", "label": "摘要3", "info": "在本章中，我们将会介绍几个用来解决这些难以处理的推断问题的技；巧。稍后，在第20章中，我们还将描述如何将这些技巧应用到训练其他；方法难以奏效的概率模型中，如深度信念网络、深度玻尔兹曼机。", "keywords": "我们还将描述如何将这些技巧应用到训练其他, 章中, 我们将会介绍几个用来解决这些难以处理的推断问题的技, 深度玻尔兹曼机, 如深度信念网络", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b6d45939-90f8-4193-b52c-4c4f533244c7", "label": "摘要4", "info": "在深度学习中难以处理的推断问题通常源于结构化图模型中潜变量之间", "keywords": "在深度学习中难以处理的推断问题通常源于结构化图模型中潜变量之间", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "06863c2f-71ea-4a73-889f-ae2d80fbbe3b", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的相互作用。读者可以参考图19.1的几个例子。这些相互作用既可能是；无向模型的直接相互作用，也可能是有向模型中同一个可见变量的共同", "keywords": "的相互作用, 无向模型的直接相互作用, 读者可以参考图, 也可能是有向模型中同一个可见变量的共同, 这些相互作用既可能是", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "66954204-d341-40aa-bc31-32d238d96925", "label": "摘要6", "info": "图19.1　深度学习中难以处理的推断问题通常是由于结构化图模型中潜变量的相互作用。这些；相互作用产生于一个潜变量与另一个潜变量或者当V-结构的子节点可观察时与更长的激活路径；相连。（左）一个隐藏单元存在连接的 半受限波尔兹曼机 （semi-restricted Boltzmann", "keywords": "深度学习中难以处理的推断问题通常是由于结构化图模型中潜变量的相互作用, 这些, 相互作用产生于一个潜变量与另一个潜变量或者当, 相连, 半受限波尔兹曼机", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "label": "19.1：把推断视作优化问题", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "53179e4d-922c-494f-af07-1dbd6bf44942", "label": "摘要1", "info": "精确推断问题可以描述为一个优化问题，有许多方法正是由此解决了推；断的困难。通过近似这样一个潜在的优化问题，我们往往可以推导出近；似推断算法。", "keywords": "有许多方法正是由此解决了推, 通过近似这样一个潜在的优化问题, 似推断算法, 我们往往可以推导出近, 断的困难", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5ac8a4a5-4a12-4e7e-b18c-f8b9fb9d78dc", "label": "摘要2", "info": "为了构造这样一个优化问题，假设有一个包含可见变量 ν 和潜变量 h 的；概率模型。我们希望计算观察数据的对数概率log p( ν ； θ )。有时候如；果边缘化消去 h 的操作很费时，会难以计算log p( ν ； θ )。作为替代，", "keywords": "果边缘化消去, 的操作很费时, 和潜变量, 会难以计算, 作为替代", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1029598b-37b6-448d-906f-a1059cdc3fa6", "label": "摘要3", "info": "其中q是关于 h 的一个任意概率分布。", "keywords": "其中, 是关于, 的一个任意概率分布", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "6ebce659-cbed-431a-a5c8-3f7af83a7f0c", "label": "摘要4", "info": "因为log  p(  ν  )和；之间的距离是由KL散度来衡量的，且KL；散度总是非负的，我们可以发现   总是小于等于所求的对数概率。当", "keywords": "因为, 散度来衡量的, 总是小于等于所求的对数概率, 散度总是非负的, 之间的距离是由", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d0aa601c-0192-44d1-a64a-1eeae67ecf04", "label": "摘要5", "info": "令人吃惊的是，对于某些分布q，计算  可以变得相当简单。通过简单；的代数运算我们可以把  重写成一个更加简单的形式：", "keywords": "令人吃惊的是, 通过简单, 可以变得相当简单, 对于某些分布, 的代数运算我们可以把", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1a5c2f37-ddad-449e-9cf8-cccdd2b63bac", "label": "摘要6", "info": "这也给出了证据下界的标准定义：", "keywords": "这也给出了证据下界的标准定义", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "8193bf84-783e-4b98-887e-3ae6ae24fbb5", "label": "摘要7", "info": "对于一个选择的合适分布q来说，   是容易计算的。对任意分布q的选；择来说，  提供了似然函数的一个下界。越好地近似p( h ｜ ν )的分布；q( h ｜ ν )，得到的下界就越紧，换言之，就是与log p( ν )更加接近。当", "keywords": "就是与, 更加接近, 是容易计算的, 提供了似然函数的一个下界, 得到的下界就越紧", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a5c2082e-96ab-48f5-9a32-42820cbf3e79", "label": "摘要8", "info": ")＝p(  h  ｜  ν；。", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "0ac57517-bf71-4419-a62b-d854d474ef9c", "label": "摘要9", "info": "因此我们可以将推断问题看作找一个分布q使得  最大的过程。精确推；断能够在包含分布p(  h  ｜  ν  )的函数族中搜索一个函数，完美地最大化；。在本章中，我们将会讲到如何通过近似优化寻找分布q的方法来推", "keywords": "的方法来推, 我们将会讲到如何通过近似优化寻找分布, 因此我们可以将推断问题看作找一个分布, 最大的过程, 完美地最大化", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a2199c46-ba4d-4b9f-b84b-8b43042f2a21", "label": "摘要10", "info": "导出不同形式的近似推断。我们可以通过限定分布q的形式或者使用并；不彻底的优化方法来使得优化的过程更加高效（却更粗略），但是优化；的结果是不完美的，不求彻底地最大化  ，而只要显著地提升  。", "keywords": "却更粗略, 但是优化, 不彻底的优化方法来使得优化的过程更加高效, 的结果是不完美的, 我们可以通过限定分布", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "cd4cacf5-a2b7-4085-9370-17162f838175", "label": "摘要11", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；无论我们选择什么样的分布q，  始终是一个下界。我们可以通过选择；一个更简单或更复杂的计算过程来得到对应的更松或更紧的下界。通过", "keywords": "我们可以通过选择, 无论我们选择什么样的分布, 始终是一个下界, 一个更简单或更复杂的计算过程来得到对应的更松或更紧的下界, 通过", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "label": "19.2：期望最大化", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "f1f78dcc-0ff1-4fe0-9fc9-01d97500823c", "label": "摘要1", "info": "我们介绍的第一个最大化下界   的算法是期望最大化  （expectation；maximization，EM）算法。在潜变量模型中，这是一个非常常见的训练；算法。在这里我们描述Neal and Hinton（1999）所提出的EM算法。与大", "keywords": "这是一个非常常见的训练, 在这里我们描述, 算法, 我们介绍的第一个最大化下界, 的算法是期望最大化", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "4335f7c1-747b-4301-8d49-17f6d4f74b55", "label": "摘要2", "info": "EM算法由交替迭代，直到收敛的两步运算组成。", "keywords": "直到收敛的两步运算组成, 算法由交替迭代", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "61b0f024-ea77-4f94-a179-b49cec865168", "label": "摘要3", "info": "E步  （expectation  step）：令  θ  (0)  表示在这一步开始时的参数值。；对任何我们想要训练的（对所有的或者小批量数据均成立）索引为；i的训练样本 ν (i) ，令q( h (i) ｜ ν )＝p( h (i) ｜ ν (i) ； θ (0) )。通过这个", "keywords": "通过这个, 的训练样本, 索引为, 对所有的或者小批量数据均成立, 对任何我们想要训练的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5829f823-fab5-4b24-baaa-5439b77dde07", "label": "摘要4", "info": "这可以被看作通过坐标上升算法来最大化   。在第一步中，我们更新；分布q来最大化  ，而在另一步中，我们更新 θ 来最大化  。", "keywords": "而在另一步中, 来最大化, 我们更新, 分布, 在第一步中", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1e0ac4ec-332e-461d-a557-3eb078542fda", "label": "摘要5", "info": "基于潜变量模型的随机梯度上升可以被看作一个EM算法的特例，其中；M步包括了单次梯度操作。EM算法的其他变种可以实现多次梯度操；作。对一些模型族来说，M步甚至可以直接推出解析解，不同于其他方", "keywords": "算法的特例, 其中, 步包括了单次梯度操作, 不同于其他方, 对一些模型族来说", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "02582b86-0b07-4d78-8dc4-0ab685051a3b", "label": "摘要6", "info": "法，在给定当前q的情况下直接求出最优解。", "keywords": "在给定当前, 的情况下直接求出最优解", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "30ff53d2-7a78-4649-b1a5-65fb2e4f80a8", "label": "摘要7", "info": "尽管E步采用的是精确推断，我们仍然可以将EM算法视作是某种程度上；的近似推断。具体地说，M步假设一个分布q可以被所有的  θ  值分享。；当M步越来越远离E步中的 θ (0) 时，这将会导致  和真实的log p( ν  )之", "keywords": "步中的, 步采用的是精确推断, 值分享, 我们仍然可以将, 算法视作是某种程度上", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "99055e15-a3c9-4e37-a50c-345c4dc6aed4", "label": "摘要8", "info": "EM算法还包含一些不同的见解。首先，它包含了学习过程的一个基本；框架，就是我们通过更新模型参数来提高整个数据集的似然，其中缺失；变量的值是通过后验分布来估计的。这种特定的性质并非EM算法独有", "keywords": "其中缺失, 它包含了学习过程的一个基本, 算法还包含一些不同的见解, 框架, 变量的值是通过后验分布来估计的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "02b6cf98-6a41-4b83-9340-6e358e37690c", "label": "19.3：最大后验推断和稀疏编码", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "ad235b72-8099-40df-9d23-9e5f014f219f", "label": "摘要1", "info": "我们通常使用推断  （inference）这个术语来指代给定一些其他变量的情；况下计算某些变量概率分布的过程。当训练带有潜变量的概率模型时，；我们通常关注于计算p( h ｜ ν )。另一种可选的推断形式是计算一个缺失", "keywords": "另一种可选的推断形式是计算一个缺失, 这个术语来指代给定一些其他变量的情, 我们通常使用推断, 当训练带有潜变量的概率模型时, 我们通常关注于计算", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e10ffca0-7bec-420f-9ef2-dfa0af1d8956", "label": "摘要2", "info": "这被称作最大后验 （Maximum A Posteriori）推断，简称MAP推断。", "keywords": "简称, 这被称作最大后验, 推断", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "78a23a46-0755-491c-a768-b355bf9ac883", "label": "摘要3", "info": "MAP推断并不被视作一种近似推断，它只是精确地计算了最有可能的一；个 h ∗ 。然而，如果我们希望设计一个最大化  ( ν , h ,q)的学习过程，；那么把MAP推断视作是输出一个q值的学习过程是很有帮助的。在这种", "keywords": "推断并不被视作一种近似推断, 然而, 那么把, 推断视作是输出一个, 它只是精确地计算了最有可能的一", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "75ba7211-5d66-402c-b352-870c5c5fc7df", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最优的q。", "keywords": "最优的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c2e74431-530b-4a9d-9ee8-4e729130edc2", "label": "摘要5", "info": "我们回过头来看看第19.1节中所描述的精确推断，它指的是关于一个在；无限制的概率分布族中的分布q使用精确的优化算法来最大化", "keywords": "使用精确的优化算法来最大化, 它指的是关于一个在, 无限制的概率分布族中的分布, 节中所描述的精确推断, 我们回过头来看看第", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "8c1f0265-66f0-4b10-b202-76a2f1242c9a", "label": "摘要6", "info": "我们通过限定分布q属于某个分布族，能够使得MAP推断成为一种形式；的近似推断。具体地说，我们令分布q满足一个Dirac分布：", "keywords": "能够使得, 我们令分布, 推断成为一种形式, 分布, 满足一个", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5410b4e9-8754-49f3-92d7-940dedfcfd78", "label": "摘要7", "info": "这也意味着现在我们可以通过  µ  来完全控制分布q。将   中不随  µ  变；化的项丢弃，我们只需解决一个优化问题：", "keywords": "这也意味着现在我们可以通过, 中不随, 化的项丢弃, 来完全控制分布, 我们只需解决一个优化问题", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "90d5922d-e61f-46a9-8e04-a5812d90421c", "label": "摘要8", "info": "这等价于MAP推断问题", "keywords": "推断问题, 这等价于", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ee999324-921c-4e7e-9a2e-8674c6bd5b26", "label": "摘要9", "info": "因此我们能够证明一种类似于EM算法的学习算法，其中我们轮流迭代；两步，一步是用MAP推断估计出 h ∗  ，另一步是更新 θ 来增大log p(  h  ∗；，  ν  )。从EM算法角度来看，这也是对   的一种形式的坐标上升，交", "keywords": "来增大, 算法的学习算法, 一步是用, 两步, 推断估计出", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "4ee8137f-1f61-4518-bca1-731110789368", "label": "摘要10", "info": "MAP推断作为特征提取器以及一种学习机制被广泛地应用在了深度学习；中。它主要用于稀疏编码模型中。", "keywords": "推断作为特征提取器以及一种学习机制被广泛地应用在了深度学习, 它主要用于稀疏编码模型中", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "84793bf9-7fd3-4552-8bf9-d7d5f37b944d", "label": "摘要11", "info": "我们回过头来看第13.4节中的稀疏编码。稀疏编码是一种在隐藏单元上；加上了诱导稀疏性的先验知识的线性因子的模型。一个常用的选择是可；分解的Laplace先验，表示为", "keywords": "一个常用的选择是可, 加上了诱导稀疏性的先验知识的线性因子的模型, 分解的, 表示为, 稀疏编码是一种在隐藏单元上", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "95f66dd4-14ee-44fe-95fb-539c21e972d6", "label": "摘要12", "info": "可见的节点是由一个线性变化加上噪声生成的：", "keywords": "可见的节点是由一个线性变化加上噪声生成的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "43ca2678-654b-4127-99f6-2b042a9709cf", "label": "摘要13", "info": "分布p( h ｜ ν )难以计算，甚至难以表达。每一对h  i  ，h  j  变量都是 ν 的；母节点。这也意味着当 ν 可被观察时，图模型包含了一条连接h i 和h j 的；活跃路径。因此p(  h  ｜  ν  )中所有的隐藏单元都包含在了一个巨大的团", "keywords": "变量都是, 这也意味着当, 可被观察时, 每一对, 母节点", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b96fddd5-0821-4f12-adf9-22c4cfdb5bc5", "label": "摘要14", "info": "分布p(  x  ｜  h  )的难处理性导致了对数似然及其梯度也很难得到。因此；我们不能使用精确的最大似然估计来进行学习。取而代之的是，我们通；过MAP推断以及最大化由以 h 为中心的Dirac分布所定义而成的ELBO来", "keywords": "我们通, 取而代之的是, 为中心的, 因此, 分布所定义而成的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a946c6dc-3d6a-4957-ab5a-21b391cd3631", "label": "摘要15", "info": "如果我们将训练集中所有的向量  h  拼成矩阵  H  ，并将所有的向量  ν  拼；起来组成矩阵 V ，那么稀疏编码问题意味着最小化", "keywords": "起来组成矩阵, 并将所有的向量, 如果我们将训练集中所有的向量, 那么稀疏编码问题意味着最小化, 拼成矩阵", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d8a6cf0f-e44e-4b06-aa4d-d956048eb493", "label": "摘要16", "info": "为了避免如极端小的  H  和极端大的  W  这样的病态的解，大多数稀疏编；码的应用包含了权重衰减或者对 H 列范数的限制。", "keywords": "为了避免如极端小的, 和极端大的, 码的应用包含了权重衰减或者对, 这样的病态的解, 大多数稀疏编", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "f2eda3b7-2d30-404f-81ee-774f0d81efcb", "label": "摘要17", "info": "我们可以通过交替迭代，分别关于  H  和  W  最小化J的方式来最小化J。；且两个子问题都是凸的。事实上，关于  W  的最小化问题就是一个线性；回归问题。然而关于这两个变量同时最小化J的问题通常并不是凸的。", "keywords": "回归问题, 然而关于这两个变量同时最小化, 事实上, 我们可以通过交替迭代, 的方式来最小化", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "61d84297-720e-4822-81f4-924697a68574", "label": "摘要18", "info": "关于  H  的最小化问题需要某些特别设计的算法，例如特征符号搜索方；法（Lee et al. ，2007）。", "keywords": "例如特征符号搜索方, 关于, 的最小化问题需要某些特别设计的算法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "label": "19.4：变分推断和变分学习", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "5ff4d33e-ba01-4974-8f95-7f6d71687021", "label": "摘要1", "info": "19.4.1　离散型潜变量", "keywords": "离散型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "64a019bd-166c-410c-8b41-2f65bf2767de", "label": "摘要2", "info": "19.4.2　变分法", "keywords": "变分法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d6e47542-eaed-4285-88a2-e8022631a777", "label": "摘要3", "info": "19.4.3　连续型潜变量", "keywords": "连续型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1018273e-e8c3-4a40-843b-57825f2f7848", "label": "摘要4", "info": "19.4.4　学习和推断之间的相互作用", "keywords": "学习和推断之间的相互作用", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "551136b1-0d08-4743-92aa-3cf9c94f527c", "label": "摘要5", "info": "我们已经说明过了为什么证据下界  ( ν , θ ,q)是log p( ν ； θ )的一个下", "keywords": "的一个下, 我们已经说明过了为什么证据下界", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "adf37d2b-064b-49fc-ae58-ca50a90cf438", "label": "摘要6", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；界，如何将推断看作关于分布q最大化  的过程，以及如何将学习看作；关于参数  θ  最大化   的过程。我们也讲到了EM算法在给定了分布q的", "keywords": "的过程, 如何将推断看作关于分布, 以及如何将学习看作, 关于参数, 我们也讲到了", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a2c86e8b-e3a5-4198-b6ae-b34e8229ea80", "label": "摘要7", "info": "变分学习的核心思想就是在一个关于q的有约束的分布族上最大化  。；的难易度。一个典；选择这个分布族时应该考虑到计算", "keywords": "选择这个分布族时应该考虑到计算, 一个典, 变分学习的核心思想就是在一个关于, 的有约束的分布族上最大化, 的难易度", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a006e90f-5cc6-472b-9d24-389daf69147a", "label": "摘要8", "info": "一种常用的变分学习的方法是加入一些限制使得q是一个因子分布：", "keywords": "是一个因子分布, 一种常用的变分学习的方法是加入一些限制使得", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c6cf97e8-230d-4785-81b7-66eb22a53928", "label": "摘要9", "info": "这被称为均值场  （mean-field）方法。更一般地说，我们可以通过选择；分布q的形式来选择任何图模型的结构，通过选择变量之间相互作用的；多少来灵活地决定近似程度的大小。这种完全通用的图模型方法被称为", "keywords": "我们可以通过选择, 通过选择变量之间相互作用的, 这种完全通用的图模型方法被称为, 的形式来选择任何图模型的结构, 这被称为均值场", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "241756b2-394d-4391-a938-f6d5b3000829", "label": "摘要10", "info": "变分方法的优点是，我们不需要为分布q设定一个特定的参数化形式。；我们设定它如何分解，之后通过解决优化问题来找出在这些分解限制下；最优的概率分布。对离散型潜变量来说，这意味着我们使用传统的优化", "keywords": "变分方法的优点是, 我们设定它如何分解, 设定一个特定的参数化形式, 对离散型潜变量来说, 我们不需要为分布", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ed0fe35c-4ac3-47c3-9783-2c7e0c1eaec2", "label": "摘要11", "info": "因为  ( ν , θ ,q)被定义成log p( ν ; θ )−D KL (q( h ｜ ν )ǁp( h ｜ ν ; θ ))，；我们可以认为关于q最大化  的问题等价于（关于q）最小化D  KL  (q(  h；｜ ν )ǁp( h ｜ ν ))。在这种情况下，我们要用q来拟合p。然而，与以前的", "keywords": "因为, 与以前的, 我们可以认为关于, 然而, 在这种情况下", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c63cdc88-b46c-4653-9863-9eb9d940c545", "label": "摘要12", "info": "方法不同，我们使用KL散度的相反方向来拟合一个近似。当我们使用；最大似然估计来用模型拟合数据时，我们最小化D KL (p data ǁp model )。如；图3.6所示，这意味着最大似然鼓励模型在每一个数据达到高概率的地", "keywords": "这意味着最大似然鼓励模型在每一个数据达到高概率的地, 方法不同, 我们最小化, 我们使用, 散度的相反方向来拟合一个近似", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c8ae4372-85eb-435d-8ad5-a8baf8975d38", "label": "摘要13", "info": "19.4.1　离散型潜变量", "keywords": "离散型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "6dab5bd2-ea2a-420d-aa74-3a65d5a34232", "label": "摘要14", "info": "关于离散型潜变量的变分推断相对来说比较直接。我们定义一个分布；q，通常分布q的每个因子都由一些离散状态的可查询表格定义。在最简；单的情况中，  h  是二值的并且我们做了均值场假定，分布q可以根据每", "keywords": "单的情况中, 我们定义一个分布, 通常分布, 关于离散型潜变量的变分推断相对来说比较直接, 分布", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "62b6a91c-1547-4bb3-a95a-e915235f34ec", "label": "摘要15", "info": "的每一个元素都代表一个概率，即", "keywords": "的每一个元素都代表一个概率", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ac70c371-4503-44dd-9eaa-4eb528dde5d0", "label": "摘要16", "info": "。", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1c428715-c7e6-48f6-b68d-ba4c0bfcd8aa", "label": "摘要17", "info": "在确定了如何表示分布q以后，我们只需要优化它的参数。在离散型潜；变量模型中，这是一个标准的优化问题。基本上分布q的选择可以通过；任何优化算法解决，比如梯度下降算法。", "keywords": "以后, 这是一个标准的优化问题, 我们只需要优化它的参数, 比如梯度下降算法, 变量模型中", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "cad68049-9259-4de0-8890-6e7cb3c44c99", "label": "摘要18", "info": "因为它在许多学习算法的内循环中出现，所以这个优化问题必须可以很；快求解。为了追求速度，我们通常使用特殊设计的优化算法。这些算法；通常能够在极少的循环内解决一些小而简单的问题。一个常见的选择是", "keywords": "为了追求速度, 一个常见的选择是, 因为它在许多学习算法的内循环中出现, 通常能够在极少的循环内解决一些小而简单的问题, 所以这个优化问题必须可以很", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d2e90be1-6ead-4fde-85af-f1def78f216a", "label": "摘要19", "info": "我们反复地更新  不同的元素直到满足收敛准则。", "keywords": "我们反复地更新, 不同的元素直到满足收敛准则", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "80ace8e7-54f6-4f95-9694-df6348b6bb59", "label": "摘要20", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；为了具体化这些描述，我们接下来会讲如何将变分推断应用到二值稀疏；编码  （binary  sparse  coding）模型（这里我们所描述的模型是Henniges", "keywords": "这里我们所描述的模型是, 编码, 我们接下来会讲如何将变分推断应用到二值稀疏, 为了具体化这些描述, 模型", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b4a7c50b-2151-42ae-9f4b-20f3ae205e61", "label": "摘要21", "info": "，是由模型通过添加高斯噪；在二值稀疏编码模型中，输入；声到m个或有或无的不同成分的和而生成的。每一个成分可以是开或者", "keywords": "每一个成分可以是开或者, 声到, 在二值稀疏编码模型中, 是由模型通过添加高斯噪, 个或有或无的不同成分的和而生成的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "0d1d5fb4-1646-46bb-9521-720c042b9034", "label": "摘要22", "info": "其中 b 是一个可以学习的偏置集合， W 是一个可以学习的权值矩阵，β；是一个可以学习的对角精度矩阵。", "keywords": "是一个可以学习的偏置集合, 是一个可以学习的权值矩阵, 其中, 是一个可以学习的对角精度矩阵", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a688162d-b557-4ab8-b466-ca9ede84e97c", "label": "摘要23", "info": "使用最大似然来训练这样一个模型需要对参数进行求导。我们考虑对其；中一个偏置进行求导的过程：", "keywords": "我们考虑对其, 中一个偏置进行求导的过程, 使用最大似然来训练这样一个模型需要对参数进行求导", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "22c2bf2b-efc3-44e0-bfa1-9217d6454e5c", "label": "摘要24", "info": "这需要计算p(  h ｜ ν )下的期望。不幸的是，p( h ｜ ν  )是一个很复杂的；分布。关于p( h ， ν )和p( h ｜ ν )的图结构可以参考图19.2。隐藏单元的；后验分布对应的是关于隐藏单元的完全图，所以相对于暴力算法，变量", "keywords": "下的期望, 所以相对于暴力算法, 后验分布对应的是关于隐藏单元的完全图, 的图结构可以参考图, 变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c6f6c99a-5961-4e68-9bff-26a5d91b8e03", "label": "摘要25", "info": "图19.2　包含4个隐藏单元的二值稀疏编码的图结构。（左）p( h , ν )的图结构。要注意边是有向；的，每两个隐藏单元都是每个可见单元的共父。（右）p( h , ν )的图结构。为了解释共父之间的；活跃路径，后验分布所有隐藏单元之间都有边", "keywords": "每两个隐藏单元都是每个可见单元的共父, 包含, 个隐藏单元的二值稀疏编码的图结构, 要注意边是有向, 后验分布所有隐藏单元之间都有边", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a6325a21-086c-444e-b532-cf5136789ffd", "label": "摘要26", "info": "取而代之的是，我们可以应用变分推断和变分学习来解决这个难点。", "keywords": "取而代之的是, 我们可以应用变分推断和变分学习来解决这个难点", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "80d8127a-6460-4f5c-b034-502ea81deaf4", "label": "摘要27", "info": "我们可以做一个均值场近似：", "keywords": "我们可以做一个均值场近似", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d864c113-363f-4a69-aa56-1273249c8ea2", "label": "摘要28", "info": "二值稀疏编码中的潜变量是二值的，所以为了表示可分解的q我们假设；对m个Bernoulli分布q(h  i  ｜  ν  )建模。表示Bernoulli分布的一种很自然的；。为了避免计算中", "keywords": "表示, 为了避免计算中, 建模, 分布的一种很自然的, 我们假设", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c8c59822-8fc5-4491-9148-ed7525bba2c3", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；或者1。", "keywords": "或者", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "4261b786-2ebf-4139-adfc-61fd531868dd", "label": "摘要30", "info": "我们将会看到变分推断方程理论上永远不会赋予   为0或者1。然而在；软件实现过程中，机器的舍入误差会导致0或者1的值。在二值稀疏编码；的软件实现中，我们希望使用一个没有限制的变分参数向量z以及通过", "keywords": "的软件实现中, 在二值稀疏编码, 机器的舍入误差会导致, 以及通过, 软件实现过程中", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ddb721ee-e9a8-455b-8f30-059d9e2c6fc4", "label": "摘要31", "info": "。", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e200c332-5782-40b1-9ed3-8cb0927dbe53", "label": "摘要32", "info": "在开始二值稀疏编码模型中变分学习的推导时，我们首先说明了均值场；近似的使用可以使得学习过程更加简单。", "keywords": "在开始二值稀疏编码模型中变分学习的推导时, 近似的使用可以使得学习过程更加简单, 我们首先说明了均值场", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "511d84a1-2caf-460d-aaf4-76018970175d", "label": "摘要33", "info": "证据下界可以表示为", "keywords": "证据下界可以表示为", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "09a63235-081a-4ed9-8e06-8f7574277a99", "label": "摘要34", "info": "尽管这些方程从美学观点来看有些不尽如人意。它们展示了   可以被；表示为少量简单的代数运算。因此，证据下界   是易于处理的。我们；可以把  看作难以处理的对数似然函数的一个替代。", "keywords": "表示为少量简单的代数运算, 它们展示了, 是易于处理的, 因此, 尽管这些方程从美学观点来看有些不尽如人意", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "67082d3d-9a1f-477c-859f-384136f58bff", "label": "摘要35", "info": "原则上说，我们可以使用关于 ν 和 h 的梯度上升。这会成为一个推断和；学习算法的完美组合。但是，由于两个原因，我们往往不这么做。第一；点，对每一个 ν 我们需要存储  。我们通常更加偏向于那些不需要为每", "keywords": "我们可以使用关于, 我们通常更加偏向于那些不需要为每, 第一, 学习算法的完美组合, 但是", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a2d7732f-6dd7-4e06-a954-28160f50016d", "label": "摘要36", "info": "态更新的向量，使得算法很难处理几十亿的样本。第二个原因就是为了；能够识别 ν 的内容，我们希望能够有能力快速提取特征  。在实际应用；场景中，我们需要在有限时间内计算出  。", "keywords": "的内容, 在实际应用, 能够识别, 场景中, 使得算法很难处理几十亿的样本", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "56e49134-eb55-4470-97e1-f288a240ccc5", "label": "摘要37", "info": "由于以上两个原因，我们通常不会采用梯度下降来计算均值场参数  。；取而代之的是，我们使用不动点方程来快速估计。", "keywords": "我们使用不动点方程来快速估计, 我们通常不会采用梯度下降来计算均值场参数, 取而代之的是, 由于以上两个原因", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "54d8937a-7069-4963-b72f-eda366e12513", "label": "摘要38", "info": "不动点方程的核心思想是，我们寻找一个关于  h  的局部极大点，满足；。我们无法同时高效地计算所有  的元素。然而，", "keywords": "不动点方程的核心思想是, 的元素, 满足, 然而, 我们无法同时高效地计算所有", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "77a8b0e9-9649-4828-90a0-744537f6c67b", "label": "摘要39", "info": "我们可以解决单个变量的问题：", "keywords": "我们可以解决单个变量的问题", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b5acea46-265f-485d-9699-83c910a82da1", "label": "摘要40", "info": "我们可以迭代地将这个解应用到i＝1，…，m，然后重复这个循环直到；我们满足了收敛准则。常见的收敛准则包含了当整个循环所改进的L不；超过预设的容差量时停止，或者是循环中改变的   不超过某个值时停", "keywords": "我们满足了收敛准则, 然后重复这个循环直到, 超过预设的容差量时停止, 或者是循环中改变的, 我们可以迭代地将这个解应用到", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "f19b309e-0520-4e28-9c2c-073fac1e2d93", "label": "摘要41", "info": "在很多不同的模型中，迭代的均值场不动点方程是一种能够提供快速变；分推断的通用算法。为了使它更加具体，我们详细地讲一下如何推导出；二值稀疏编码模型的更新过程。", "keywords": "为了使它更加具体, 迭代的均值场不动点方程是一种能够提供快速变, 我们详细地讲一下如何推导出, 在很多不同的模型中, 分推断的通用算法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "030d2fc5-8905-40d7-a175-24f88c033ce4", "label": "摘要42", "info": "首先，我们给出了对   的导数表达式。为了得到这个表达式，我们将；式（19.36）代入到式（19.37）的左边：", "keywords": "我们给出了对, 的导数表达式, 我们将, 为了得到这个表达式, 的左边", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ef0f63ae-aa28-4f95-acab-0fade158759b", "label": "摘要43", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；为了应用固定点更新的推断规则，我们通过令式（19.43）等于0来解；：", "keywords": "我们通过令式, 等于, 来解, 为了应用固定点更新的推断规则", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "f93afa9e-5e92-4f14-8441-f151adf3ae39", "label": "摘要44", "info": "此时，我们可以发现图模型中的推断和循环神经网络之间存在着紧密的；联系。具体地说，均值场不动点方程定义了一个循环神经网络。这个神；经网络的任务就是完成推断。我们已经从模型描述的角度介绍了如何推", "keywords": "这个神, 经网络的任务就是完成推断, 我们可以发现图模型中的推断和循环神经网络之间存在着紧密的, 均值场不动点方程定义了一个循环神经网络, 我们已经从模型描述的角度介绍了如何推", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ea82d8f3-c73a-4530-a540-5b76e6ba451f", "label": "摘要45", "info": "在二值稀疏编码模型中，我们可以发现式（19.44）中描述的循环网络；连接包含了根据相邻隐藏单元变化值来反复更新当前隐藏单元的操作。；，然而隐藏单元", "keywords": "然而隐藏单元, 我们可以发现式, 连接包含了根据相邻隐藏单元变化值来反复更新当前隐藏单元的操作, 在二值稀疏编码模型中, 中描述的循环网络", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "cfe0f768-6f13-4c47-9fd1-011a740ccff0", "label": "摘要46", "info": "我们将式（19.44）重写成等价的形式来揭示一些深层的含义：", "keywords": "我们将式, 重写成等价的形式来揭示一些深层的含义", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "0f80087f-b874-403f-94bb-db4c44d25c81", "label": "摘要47", "info": "看作输入，而不是  ν；在这种新的形式中，我们可以将；。因此，我们可以把第i个单元视作给定其他单元编码时给  ν  中的剩余", "keywords": "在这种新的形式中, 我们可以将, 看作输入, 因此, 个单元视作给定其他单元编码时给", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "6c18544c-e0b9-4bd7-a3f8-048779362226", "label": "摘要48", "info": "在这个例子中，我们已经推导出了每一次更新单个结点的更新规则。如；果能够同时更新更多的结点，那会更令人满意。某些图模型，比如深度；玻尔兹曼机，我们可以同时解出  中的许多元素。不幸的是，二值稀疏", "keywords": "果能够同时更新更多的结点, 我们可以同时解出, 比如深度, 二值稀疏, 某些图模型", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "a7aa4f1e-f03b-4f8f-a871-b73eb9e3365f", "label": "摘要49", "info": "19.4.2　变分法", "keywords": "变分法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "48c43715-defd-4cc9-9a45-7cb08ada61ea", "label": "摘要50", "info": "在继续介绍变分学习之前，我们有必要简单地介绍一种变分学习中重要；的数学工具：变分法 （calculus of variations）。", "keywords": "变分法, 在继续介绍变分学习之前, 我们有必要简单地介绍一种变分学习中重要, 的数学工具", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "37c89b41-2e4e-49a2-aed9-eafab37b1aca", "label": "摘要51", "info": "许多机器学习的技巧是基于寻找一个输入向量；来最小化函；数J( θ )，使得它取到最小值。这个步骤可以利用多元微积分以及线性代", "keywords": "这个步骤可以利用多元微积分以及线性代, 来最小化函, 许多机器学习的技巧是基于寻找一个输入向量, 使得它取到最小值", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5a586b01-3463-4cfe-997f-7b08daccb1cb", "label": "摘要52", "info": "函数f的函数被称为泛函  （functional）J［f］。正如许多情况下对一个；函数求关于以向量的元素为变量的偏导数一样，我们可以使用泛函导数；（functional derivative），即在任意特定的 x 值，对一个泛函J［f］求关", "keywords": "我们可以使用泛函导数, 对一个泛函, 函数, 的函数被称为泛函, 求关", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e4375589-721a-42ed-9911-4ddb75cf96a9", "label": "摘要53", "info": "函J的关于函数f在点 x 处的泛函导数被记作", "keywords": "在点, 的关于函数, 处的泛函导数被记作", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "2f239278-08af-4526-a835-316875404d01", "label": "摘要54", "info": "。", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "79368f37-5e69-493e-9ead-7b6b59aa1187", "label": "摘要55", "info": "完整正式的泛函导数的推导不在本书的范围之内。对于我们的目标而；言，了解可微分函数f( x )以及带有连续导数的可微分函数g(y, x )就足够；了：", "keywords": "完整正式的泛函导数的推导不在本书的范围之内, 就足够, 对于我们的目标而, 以及带有连续导数的可微分函数, 了解可微分函数", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "9782fe7a-7f49-4a3b-bd82-8ef9737f6224", "label": "摘要56", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；为了使上述等式更加直观，我们可以把f( x )看作一个有着无穷不可数多；元素的向量，由一个实数向量  x  表示。在这里（看作一个不完全的介", "keywords": "表示, 在这里, 我们可以把, 看作一个有着无穷不可数多, 为了使上述等式更加直观", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "31ce7234-8ff4-4ae9-86e1-f60681e436e8", "label": "摘要57", "info": "在其他机器学习文献中的许多结果则使用了更为通用的欧拉—拉格朗日；方程  （Euler-Lagrange  Equation），它能够使得g不仅依赖于f的导数，；而且也依赖于f的值。但是在本书中我们不需要这个通用版本。", "keywords": "它能够使得, 但是在本书中我们不需要这个通用版本, 而且也依赖于, 方程, 在其他机器学习文献中的许多结果则使用了更为通用的欧拉", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "bc50c2c9-b572-428c-b0ad-3dfc21f5f2e5", "label": "摘要58", "info": "为了关于一个向量优化某个函数，我们求出了这个函数关于这个向量的；梯度，然后找这个梯度中每一个元素都为0的点。类似地，我们可以通；过寻找一个函数使得泛函导数的每个点都等于0，从而来优化一个泛", "keywords": "梯度, 我们可以通, 我们求出了这个函数关于这个向量的, 过寻找一个函数使得泛函导数的每个点都等于, 从而来优化一个泛", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "db940594-d6a4-4111-a60c-f89e9c4f8042", "label": "摘要59", "info": "下面介绍一个该过程如何运行的例子，我们考虑寻找一个定义在", "keywords": "下面介绍一个该过程如何运行的例子, 我们考虑寻找一个定义在", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "9ea57142-bbf4-412e-91e2-b1aa22200af5", "label": "摘要60", "info": "上的有最大微分熵的概率密度函数。我们回过头来看一下一", "keywords": "上的有最大微分熵的概率密度函数, 我们回过头来看一下一", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "35d75adc-9744-478a-82e8-e44d147daf33", "label": "摘要61", "info": "个概率分布P(x)的熵，定义如下：", "keywords": "的熵, 个概率分布, 定义如下", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "2666627d-41cb-4e9e-9377-0d1060606c3d", "label": "摘要62", "info": "对于连续的值，这个期望可以被看作一个积分：", "keywords": "这个期望可以被看作一个积分, 对于连续的值", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "3155e340-3bde-46a2-bedc-acf6be48fc58", "label": "摘要63", "info": "我们不能简单地仅仅关于函数P(x)最大化H［p］，因为那样的话结果可；能不是一个概率分布。为了解决这个问题，我们需要使用一个拉格朗日；乘子来添加一个分布P(x)积分值为1的约束。同样地，当方差增大时，", "keywords": "能不是一个概率分布, 积分值为, 乘子来添加一个分布, 同样地, 当方差增大时", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "2d94bf94-c5ab-418f-823b-b99afa484eb2", "label": "摘要64", "info": "为了关于p最小化拉格朗日乘子，我们令泛函导数等于0：", "keywords": "最小化拉格朗日乘子, 为了关于, 我们令泛函导数等于", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "50d74c6d-536c-461a-b22a-33bf42d787c6", "label": "摘要65", "info": "这个条件告诉我们P(x)的泛函形式。通过代数运算重组上述方程，我们；可以得到", "keywords": "可以得到, 这个条件告诉我们, 我们, 通过代数运算重组上述方程, 的泛函形式", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5c17b2df-9c3e-48c6-9567-1fefb7810ee4", "label": "摘要66", "info": "我们并没有直接假设P(x)取这种形式，而是通过最小化泛函从理论上得；到了这个P(x)的表达式。为了解决这个最小化问题，我们需要选择λ的；值来确保所有的约束都能够满足。我们有很大的自由去选择λ。因为只", "keywords": "为了解决这个最小化问题, 而是通过最小化泛函从理论上得, 因为只, 的表达式, 我们需要选择", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "2e191fed-47d6-4f93-843f-3851d596536b", "label": "摘要67", "info": "，从而得到", "keywords": "从而得到", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "70fca0fd-e91e-44e7-b34f-f85f76e0c197", "label": "摘要68", "info": "这也是当我们不知道真实的分布时，总是使用正态分布的一个原因。因；为正态分布拥有最大的熵，我们通过这个假定来保证了最小可能量的结；构。", "keywords": "这也是当我们不知道真实的分布时, 我们通过这个假定来保证了最小可能量的结, 总是使用正态分布的一个原因, 为正态分布拥有最大的熵", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "bb0929f6-151c-4a88-ae53-e6078ae0ac5b", "label": "摘要69", "info": "当寻找熵的拉格朗日泛函的临界点并且给定一个固定的方差时，我们只；能找到一个对应最大熵的临界点。那最小化熵的概率密度函数是什么样；的呢？为什么我们无法发现对应着极小点的第二个临界点呢？原因是没", "keywords": "原因是没, 我们只, 那最小化熵的概率密度函数是什么样, 当寻找熵的拉格朗日泛函的临界点并且给定一个固定的方差时, 的呢", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "105b14c1-ca7a-434b-a885-ef8cb85d3043", "label": "摘要70", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在一个收敛的概率分布的序列，收敛到权重都在两个点上。这种情况能；够退化为混合Dirac分布。因为Dirac分布并不是一个单独的概率密度函", "keywords": "因为, 够退化为混合, 分布并不是一个单独的概率密度函, 收敛到权重都在两个点上, 这种情况能", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "d4557f39-e40a-4a0a-8c8d-2b4a6b7d2231", "label": "摘要71", "info": "19.4.3　连续型潜变量", "keywords": "连续型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e893a1eb-04c1-4fbf-8f2f-b9d8ec09a998", "label": "摘要72", "info": "当我们的图模型包含连续型潜变量时，仍然可以通过最大化   进行变；分推断和变分学习。然而，我们需要使用变分法来实现关于q( h ｜ ν )最；大化  。", "keywords": "仍然可以通过最大化, 我们需要使用变分法来实现关于, 然而, 当我们的图模型包含连续型潜变量时, 大化", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "2693aeb8-e2a1-445a-a3b3-67e29d0833b2", "label": "摘要73", "info": "在大多数情况下，研究者并不需要解决任何变分法的问题。取而代之的；是，均值场固定点迭代更新有一个通用的方程。如果我们做了均值场近；似：", "keywords": "在大多数情况下, 均值场固定点迭代更新有一个通用的方程, 取而代之的, 如果我们做了均值场近, 研究者并不需要解决任何变分法的问题", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ee1dce28-fe6c-4fdb-9b94-f47bfa6b1b0f", "label": "摘要74", "info": "并且对任何的j≠i固定q(h  j  ｜ ν )，那么只需要满足分布p中任何联合分布；变量的概率值不为0，我们就可以通过归一化下面这个未归一的分布", "keywords": "我们就可以通过归一化下面这个未归一的分布, 中任何联合分布, 并且对任何的, 固定, 那么只需要满足分布", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "3bd57603-e8fa-4dd9-bf88-a7821d85f0d5", "label": "摘要75", "info": "来得到最优的q(h i ｜ ν )。在这个方程中计算期望就能得到正确的q(h i ｜；ν  )的表达式。我们只有在希望提出一种新形式的变分学习算法时才需要；使用变分法来直接推导q的函数形式。式（19.56）给出了适用于任何概", "keywords": "的函数形式, 我们只有在希望提出一种新形式的变分学习算法时才需要, 的表达式, 给出了适用于任何概, 使用变分法来直接推导", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "96d6bad0-e955-4af7-8737-f000c6ecb7b4", "label": "摘要76", "info": "式（19.56）是一个不动点方程，对每一个i它都被迭代地反复使用直到；收敛。然而，它还包含着更多的信息。它还包含了最优解取到的泛函形；式，无论我们是否能够通过不动点方程来解出它。这意味着我们可以利", "keywords": "对每一个, 它还包含了最优解取到的泛函形, 然而, 它都被迭代地反复使用直到, 它还包含着更多的信息", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "46c30c4a-5e55-4185-b93b-05385f96aac4", "label": "摘要77", "info": "我们拿一个简单的概率模型作为例子，其中潜变量满足；见变量只有一个ν。假设", "keywords": "见变量只有一个, 我们拿一个简单的概率模型作为例子, 其中潜变量满足, 假设", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e1898f92-5649-4c9b-98a8-34c482e8fcec", "label": "摘要78", "info": "，可；以及；，我们可以积掉 h  来简化这个模型，结", "keywords": "来简化这个模型, 以及, 我们可以积掉", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "0c983fcb-c5b7-4bd6-8356-20d61c33a95e", "label": "摘要79", "info": "果是关于ν的高斯分布。这个模型本身并不有趣。只是为了说明变分法；如何应用在概率建模之中，我们才构造了这个模型。", "keywords": "只是为了说明变分法, 这个模型本身并不有趣, 我们才构造了这个模型, 的高斯分布, 果是关于", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "0cca377d-6fd8-4f9d-95d2-9719901e6ec8", "label": "摘要80", "info": "忽略归一化常数时，真实的后验分布如下：", "keywords": "真实的后验分布如下, 忽略归一化常数时", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c5f4c355-5af4-4517-a3d6-3bae8c1bd7df", "label": "摘要81", "info": "在上式中，我们发现由于带有h  1  、h  2  乘积项的存在，真实的后验并不；能关于h 1 、h 2 分解。", "keywords": "能关于, 分解, 真实的后验并不, 乘积项的存在, 我们发现由于带有", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "f9bd494e-a9e0-49b2-870c-a81ddf1894c1", "label": "摘要82", "info": "应用式（19.56），我们可以得到", "keywords": "应用式, 我们可以得到", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "b9b2d7a7-fc3a-47cf-8d20-859dc216f6a5", "label": "摘要83", "info": "从这里，我们可以发现其中我们只需要从q(h  2  ｜  ν  )中获得两个有效；值：；，我们可以得到：", "keywords": "从这里, 中获得两个有效, 我们可以得到, 我们可以发现其中我们只需要从", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "93c5b5e6-b563-4f6a-a7a5-fb173e47eae1", "label": "摘要84", "info": "。把这两项记作", "keywords": "把这两项记作", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "9af9a9ea-20e4-402f-b673-8e0a541ca07a", "label": "摘要85", "info": "和", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "7fb4c939-5150-4de0-8dc9-f09d5575ca8a", "label": "摘要86", "info": "和", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "85e39d0f-d8fd-47d9-94d2-92db32cc720c", "label": "摘要87", "info": "从这里，我们可以发现   的泛函形式满足高斯分布。因此，我们可以得；，其中 µ 和对角的β是变分参数，我们可；到q( h ｜ ν )＝", "keywords": "是变分参数, 我们可, 因此, 其中, 和对角的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "dc2b4e3d-226b-4f38-89af-a0061767669b", "label": "摘要88", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；以使用任何方法来优化它。有必要再强调一下，我们并没有假设q是一；个高斯分布，这个高斯的形式是使用变分法来关于分布q最大化  而推", "keywords": "个高斯分布, 是一, 这个高斯的形式是使用变分法来关于分布, 有必要再强调一下, 而推", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "41b87317-0bbd-4fe7-817d-3c4243e86fcf", "label": "摘要89", "info": "当然，上述模型只是为了说明情况的一个简单例子。深度学习中关于变；分学习中连续型变量的实际应用可以参考Goodfellow et al. （2013f）。", "keywords": "当然, 分学习中连续型变量的实际应用可以参考, 深度学习中关于变, 上述模型只是为了说明情况的一个简单例子", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5809df15-9228-473c-830f-a1d599667f93", "label": "摘要90", "info": "19.4.4　学习和推断之间的相互作用", "keywords": "学习和推断之间的相互作用", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "dcb97a28-729e-4826-b0a3-6875547927ad", "label": "摘要91", "info": "在学习算法中使用近似推断会影响学习的过程，反过来学习的过程也会；影响推断算法的准确性。", "keywords": "在学习算法中使用近似推断会影响学习的过程, 反过来学习的过程也会, 影响推断算法的准确性", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "aad67ffd-0be2-4018-8afc-a121494bb3e7", "label": "摘要92", "info": "具体来说，训练算法倾向于朝使得近似推断算法中的近似假设变得更加；真实的方向来适应模型。当训练参数时，变分学习增加", "keywords": "变分学习增加, 具体来说, 真实的方向来适应模型, 当训练参数时, 训练算法倾向于朝使得近似推断算法中的近似假设变得更加", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ccf1968a-ab72-4c87-8274-2c4e15704ffc", "label": "摘要93", "info": "对于一个特定的 ν ，对于q( h ｜ ν )中概率很大的 h ，它增加了p( h ｜ ν；)；对于q( h ｜ ν )中概率很小的 h ，它减小了p( h ｜ ν )。", "keywords": "它减小了, 它增加了, 对于一个特定的, 中概率很大的, 中概率很小的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "3a3edcc0-1595-4805-94b6-39e201d18116", "label": "摘要94", "info": "这种行为使得我们做的近似假设变得合理。如果我们用单峰值近似后验；来训练模型，那么所得具有真实后验的模型会比我们使用精确推断训练；模型获得的模型更接近单峰值。", "keywords": "如果我们用单峰值近似后验, 那么所得具有真实后验的模型会比我们使用精确推断训练, 模型获得的模型更接近单峰值, 来训练模型, 这种行为使得我们做的近似假设变得合理", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c908d9c3-4f86-4b4b-aae6-0e908084f9ac", "label": "摘要95", "info": "因此，估计变分近似对模型的破坏程度是很困难的。存在几种估计log；p( ν )的方式。通常我们在训练模型之后估计log p( ν ； θ )，然后发现它；和   (  ν  ,  θ  ,q)的差距是很小的。从这里我们可以得出结论，对于特定", "keywords": "存在几种估计, 因此, 然后发现它, 对于特定, 的方式", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c754ce2b-d6e6-44bc-aff2-13041329f839", "label": "摘要96", "info": "。", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "8b5f7ed8-4213-428f-8203-dcc6799d2082", "label": "摘要97", "info": "≈", "keywords": "", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e542009e-ec20-4962-87c4-cc580f65cfff", "label": "摘要98", "info": "难发现的，因为只有在我们有一个能够找到  θ  ∗  的较好的学习算法时，；才能确定进行上述的比较。", "keywords": "难发现的, 才能确定进行上述的比较, 的较好的学习算法时, 因为只有在我们有一个能够找到", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "ccef06f3-8887-4aac-b63f-4726ff8ba804", "label": "摘要99", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；19.5　学成近似推断", "keywords": "学成近似推断", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "e7c2789d-ca31-496b-81f9-77ec4b243fc0", "label": "摘要100", "info": "我们已经看到了推断可以被视作一个增加函数   值的优化过程。显式；地通过迭代方法（比如不动点方程或者基于梯度的优化算法）来进行优；化的过程通常是代价很高且耗时巨大的。通过学习一个近似推断，许多", "keywords": "地通过迭代方法, 来进行优, 许多, 值的优化过程, 化的过程通常是代价很高且耗时巨大的", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "f89364ab-16c8-44ec-a26f-10ec6cdb841d", "label": "摘要101", "info": "的神经网络来近似它。", "keywords": "的神经网络来近似它", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "493da9f7-eb6a-40e8-ba38-642f7893e2cf", "label": "摘要102", "info": "19.5.1　醒眠算法", "keywords": "醒眠算法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "669426c9-3ab7-462f-b205-dffffe7292fd", "label": "摘要103", "info": "训练一个可以用 ν 来推断 h 的模型的一个主要难点在于我们没有一个监；督训练集来训练模型。给定一个 ν ，我们无法获知一个合适的 h 。从  ν；到 h 的映射依赖于模型族的选择，并且在学习过程中随着 θ 的改变而变", "keywords": "的模型的一个主要难点在于我们没有一个监, 来推断, 的改变而变, 训练一个可以用, 的映射依赖于模型族的选择", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "39ccab5d-913b-4e02-977f-bc15a95f8564", "label": "摘要104", "info": "在第18.2节中，我们看到睡眠做梦在人类和动物中作用的一个可能解释；是，做梦可以提供蒙特卡罗训练算法用于近似无向模型中对数配分函数；负梯度的负相样本。生物做梦的另一个可能解释是它提供来自p( h ， ν )", "keywords": "生物做梦的另一个可能解释是它提供来自, 我们看到睡眠做梦在人类和动物中作用的一个可能解释, 节中, 在第, 做梦可以提供蒙特卡罗训练算法用于近似无向模型中对数配分函数", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "c66c0656-1bd9-4f98-8964-9192733ad73f", "label": "摘要105", "info": "如何能够保持清醒几个小时（它们清醒的时间越长，   和log  p(  ν  )之；间的差距越大，但是   仍然是下限），并且睡眠几个小时（生成模型；本身在睡眠期间不被修改），而不损害它们的内部模型。当然，这些想", "keywords": "仍然是下限, 如何能够保持清醒几个小时, 生成模型, 而不损害它们的内部模型, 但是", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "12c68bbf-6a84-4a4f-9dad-c639274b9784", "label": "摘要106", "info": "19.5.2　学成推断的其他形式", "keywords": "学成推断的其他形式", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "92d4f84e-3533-4c9a-a156-aa18dcf148d7", "label": "摘要107", "info": "这种学成近似推断策略已经被应用到了其他模型中。Salakhutdinov  and；Larochelle（2010）证明了在学成推断网络中的单遍传递相比于在深度；玻尔兹曼机中的迭代均值场不动点方程能够得到更快的推断。其训练过", "keywords": "证明了在学成推断网络中的单遍传递相比于在深度, 玻尔兹曼机中的迭代均值场不动点方程能够得到更快的推断, 其训练过, 这种学成近似推断策略已经被应用到了其他模型中", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "8ecd6f40-8d47-4326-be4e-9cd5929f7442", "label": "摘要108", "info": "我们已经在第14.8节中看到，预测性的稀疏分解模型训练一个浅层编码；器网络，从而预测输入的稀疏编码。这可以被看作自编码器和稀疏编码；之间的混合。为模型设计概率语义是可能的，其中编码器可以被视为执", "keywords": "预测性的稀疏分解模型训练一个浅层编码, 其中编码器可以被视为执, 为模型设计概率语义是可能的, 节中看到, 这可以被看作自编码器和稀疏编码", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "7c6635c8-f52e-4f21-8d8c-76b25c6c69b8", "label": "摘要109", "info": "近来学成近似推断已经成为变分自编码器形式的生成模型中的主要方法；之一（Kingma，2013；Rezende et al. ，2014）。在这种优美的方法中，；不需要为推断网络构造显式的目标。反之，推断网络仅仅被用来定义", "keywords": "推断网络仅仅被用来定义, 近来学成近似推断已经成为变分自编码器形式的生成模型中的主要方法, 在这种优美的方法中, 不需要为推断网络构造显式的目标, 之一", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "1e3e16f7-6d2a-41b5-8a46-8f24ea1ce55f", "label": "摘要110", "info": "我们可以使用近似推断来训练和使用很多不同的模型。其中许多模型将；在下一章中描述。", "keywords": "在下一章中描述, 其中许多模型将, 我们可以使用近似推断来训练和使用很多不同的模型", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "22829fc7-e112-4258-8f11-48d2df6f461f", "label": "摘要111", "info": "19.4.1　离散型潜变量", "keywords": "离散型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "652944c5-28a7-4740-81f5-bffe40280c26", "label": "摘要112", "info": "19.4.2　变分法", "keywords": "变分法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "93697130-8a90-483d-807f-45a3a325679c", "label": "摘要113", "info": "19.4.3　连续型潜变量", "keywords": "连续型潜变量", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "4d720143-554f-4b0a-981a-c4a6ec88817b", "label": "摘要114", "info": "19.4.4　学习和推断之间；的相互作用", "keywords": "的相互作用, 学习和推断之间", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "dea98105-49ef-4357-9bca-83febeaf3bdd", "label": "19.5：学成近似推断", "level": 2, "group": "chapter-19", "type": "子章節"}, {"id": "4d2c0210-9803-4524-a994-a2b258b84d31", "label": "摘要1", "info": "19.5.1　醒眠算法", "keywords": "醒眠算法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "9f03a1af-dd49-464b-98f3-90c15e2d9f31", "label": "摘要2", "info": "19.5.2　学成推断的其他形式", "keywords": "学成推断的其他形式", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "8f7840de-3989-4831-8af4-6376856c04c8", "label": "摘要3", "info": "19.5.1　醒眠算法", "keywords": "醒眠算法", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "10790fc5-772b-4451-9a2d-48aa15a70f4d", "label": "摘要4", "info": "19.5.2　学成推断的其他；形式", "keywords": "形式, 学成推断的其他", "level": 3, "group": "chapter-19", "type": "段落"}, {"id": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "label": "第20章：深度生成模型", "level": 1, "group": "chapter-20", "type": "章節"}, {"id": "5ba200b4-e4d4-490d-acd6-ad0d387726e1", "label": "19.4：变分推断和变分学习", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "6ba50cd4-8fa7-4a90-9f78-8238bb653780", "label": "摘要1", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在本章中，我们介绍几种具体的生成模型，这些模型可以使用第16章至；第19章中出现的技术构建和训练。所有这些模型在某种程度上都代表了", "keywords": "章至, 这些模型可以使用第, 章中出现的技术构建和训练, 所有这些模型在某种程度上都代表了, 我们介绍几种具体的生成模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "label": "20.1：玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "c04fd52d-7e05-4929-8766-58c9622b1165", "label": "摘要1", "info": "玻尔兹曼机最初作为一种广义的“联结主义”引入，用来学习二值向量上；的任意概率分布（Fahlman et al. ，1983；Ackley et al. ，1985；Hinton et；al.  ，1984b；Hinton  and  Sejnowski，1986）。玻尔兹曼机的变体（包含", "keywords": "联结主义, 的任意概率分布, 包含, 引入, 玻尔兹曼机的变体", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "da7872b2-59ee-467c-bad7-5eb767a2c650", "label": "摘要2", "info": "我们在d维二值随机向量  x  ∈{0，1}  d  上定义玻尔兹曼机。玻尔兹曼机；是一种基于能量的模型（第16.2.4节），意味着我们可以使用能量函数；定义联合概率分布：", "keywords": "是一种基于能量的模型, 意味着我们可以使用能量函数, 定义联合概率分布, 维二值随机向量, 我们在", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1dd4574f-5615-4afa-9777-eb6f34b73a9c", "label": "摘要3", "info": "其中E(  x  )是能量函数，Z是确保；曼机的能量函数如下给出：", "keywords": "曼机的能量函数如下给出, 其中, 是能量函数, 是确保", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1855b6fe-7e4d-4004-a38f-854543c4e2c8", "label": "摘要4", "info": "的配分函数。玻尔兹", "keywords": "玻尔兹, 的配分函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f86d7117-7206-4e9b-93a6-abbb79c3842f", "label": "摘要5", "info": "其中 U 是模型参数的“权重”矩阵， b 是偏置向量。", "keywords": "是偏置向量, 矩阵, 其中, 权重, 是模型参数的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5da849b4-7a81-46c7-a591-b3b6d3476e29", "label": "摘要6", "info": "在一般设定下，给定一组训练样本，每个样本都是n维的。式（20.1）；描述了观察到的变量的联合概率分布。虽然这种情况显然可行，但它限；制了观察到的变量和权重矩阵描述的变量之间相互作用的类型。具体来", "keywords": "具体来, 每个样本都是, 但它限, 给定一组训练样本, 制了观察到的变量和权重矩阵描述的变量之间相互作用的类型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c11ca88f-733a-4476-8efd-5824eada9587", "label": "摘要7", "info": "当不是所有变量都能被观察到时，玻尔兹曼机变得更强大。在这种情况；下，潜变量类似于多层感知机中的隐藏单元，并模拟可见单元之间的高；阶交互。正如添加隐藏单元将逻辑回归转换为MLP，导致MLP成为函数", "keywords": "在这种情况, 并模拟可见单元之间的高, 玻尔兹曼机变得更强大, 导致, 正如添加隐藏单元将逻辑回归转换为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0636d6c-72ec-424a-9b49-3a34e6545075", "label": "摘要8", "info": "正式地，我们将单元 x 分解为两个子集：可见单元 ν 和潜在（或隐藏）；单元 h 。能量函数变为", "keywords": "能量函数变为, 分解为两个子集, 正式地, 和潜在, 可见单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b29c5138-ffcc-4900-9aba-1a0fc85a5e32", "label": "摘要9", "info": "玻尔兹曼机的学习  　玻尔兹曼机的学习算法通常基于最大似然。所有；玻尔兹曼机都具有难以处理的配分函数，因此最大似然梯度必须使用第；18章中的技术来近似。", "keywords": "章中的技术来近似, 玻尔兹曼机的学习, 玻尔兹曼机的学习算法通常基于最大似然, 所有, 玻尔兹曼机都具有难以处理的配分函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "547e6f3d-e7ea-49c9-a8c2-679473f5a01d", "label": "摘要10", "info": "玻尔兹曼机有一个有趣的性质，当基于最大似然的学习规则训练时，连；接两个单元的特定权重的更新仅取决于这两个单元在不同分布下收集的；统计信息：P model ( ν )和", "keywords": "接两个单元的特定权重的更新仅取决于这两个单元在不同分布下收集的, 当基于最大似然的学习规则训练时, 统计信息, 玻尔兹曼机有一个有趣的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d9d56341-0d93-43c4-8fe2-cc991391cee4", "label": "摘要11", "info": "不仅仅使用局部统计信息的其他学习算法似乎需要假设更多的学习机；制。例如，对于大脑在多层感知机中实现的反向传播，似乎需要维持一；个辅助通信的网络，并借此向后传输梯度信息。已经有学者（Hinton，", "keywords": "并借此向后传输梯度信息, 个辅助通信的网络, 例如, 不仅仅使用局部统计信息的其他学习算法似乎需要假设更多的学习机, 对于大脑在多层感知机中实现的反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "94b350e9-a647-4650-bdc3-9e542e0841cd", "label": "摘要12", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；从生物学的角度看，玻尔兹曼机学习中的负相阶段有点难以解释。正如；第18.2节所主张的，人类在睡眠时做梦可能是一种形式的负相采样。尽", "keywords": "玻尔兹曼机学习中的负相阶段有点难以解释, 人类在睡眠时做梦可能是一种形式的负相采样, 节所主张的, 正如, 从生物学的角度看", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "69650cae-0632-4f4c-a2fe-63884f62de42", "label": "20.2：受限玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "0179369a-195a-4efd-822c-7bf1c1b5690c", "label": "摘要1", "info": "20.2.1　条件分布", "keywords": "条件分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abf160df-9887-428d-a5a6-866daf23e7b9", "label": "摘要2", "info": "20.2.2　训练受限玻尔兹曼机", "keywords": "训练受限玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6438495a-faf5-4fde-b57d-90d8a869e39c", "label": "摘要3", "info": "受限玻尔兹曼机以簧风琴  （harmonium）之名（Smolensky，1986）面；世之后，成为了深度概率模型中最常见的组件之一。我们之前在第；16.7.1节简要介绍了RBM。在这里我们回顾以前的内容并探讨更多的细", "keywords": "在这里我们回顾以前的内容并探讨更多的细, 成为了深度概率模型中最常见的组件之一, 之名, 世之后, 节简要介绍了", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac4aaf87-519e-4685-8213-6549ed580cdf", "label": "摘要4", "info": "我们从二值版本的受限玻尔兹曼机开始，但如我们之后所见，这还可以；扩展为其他类型的可见和隐藏单元。", "keywords": "这还可以, 扩展为其他类型的可见和隐藏单元, 但如我们之后所见, 我们从二值版本的受限玻尔兹曼机开始", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3529fd4e-aaf9-4639-bb5c-db0f8630d910", "label": "摘要5", "info": "更正式地说，令观察层由一组n  ν  个二值随机变量组成，我们统称为向；量v 。我们将n h 个二值随机变量的潜在或隐藏层记为 h 。", "keywords": "我们将, 更正式地说, 个二值随机变量的潜在或隐藏层记为, 个二值随机变量组成, 我们统称为向", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a63f2c4f-c4de-4217-9b3e-873ed05b6469", "label": "摘要6", "info": "就像普通的玻尔兹曼机，受限玻尔兹曼机也是基于能量的模型，其联合；概率分布由能量函数指定：", "keywords": "概率分布由能量函数指定, 受限玻尔兹曼机也是基于能量的模型, 其联合, 就像普通的玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "50cd9636-1f1c-4d6e-a87a-47a992c6b6db", "label": "摘要7", "info": "RBM的能量函数由下给出", "keywords": "的能量函数由下给出", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "920b0af6-585e-496a-b0b6-fd11e8ad658d", "label": "摘要8", "info": "其中Z是被称为配分函数的归一化常数：", "keywords": "其中, 是被称为配分函数的归一化常数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e8b51fc-9fae-4923-8023-899b5932ac26", "label": "摘要9", "info": "从配分函数Z的定义显而易见，计算Z的朴素方法（对所有状态进行穷；举求和）计算上可能是难以处理的，除非有巧妙设计的算法可以利用概", "keywords": "的朴素方法, 的定义显而易见, 计算上可能是难以处理的, 对所有状态进行穷, 从配分函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "99f39293-4ca4-43ed-9d90-9d62601aac64", "label": "摘要10", "info": "率分布中的规则来更快地计算Z。在受限玻尔兹曼机的情况下，Long；and  Servedio（2010）正式证明配分函数Z是难解的。难解的配分函数Z；意味着归一化联合概率分布P (ν)也难以评估。", "keywords": "正式证明配分函数, 率分布中的规则来更快地计算, 难解的配分函数, 意味着归一化联合概率分布, 也难以评估", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "19db0468-c708-4912-ad10-e4f9c5bed496", "label": "摘要11", "info": "图20.1　可以用受限玻尔兹曼机构建的模型示例。（a）受限玻尔兹曼机本身是基于二分图的无；向图模型，图的一部分具有可见单元，另一部分具有隐藏单元。可见单元之间没有连接，隐藏；单元之间也没有任何连接。通常每个可见单元连接到每个隐藏单元，但也可以构造稀疏连接的", "keywords": "向图模型, 可见单元之间没有连接, 通常每个可见单元连接到每个隐藏单元, 受限玻尔兹曼机本身是基于二分图的无, 单元之间也没有任何连接", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "63f40038-facd-4864-bcce-dc186a4f675e", "label": "摘要12", "info": "20.2.1　条件分布", "keywords": "条件分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a6aa43f-fd3b-4000-9779-e6b823dc128b", "label": "摘要13", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；虽然P；布P (h | v )和P (v | h )是因子的，并且计算和采样是相对简单的。", "keywords": "是因子的, 并且计算和采样是相对简单的, 虽然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af21fc07-cb90-4339-96d2-f23d0c6fab7f", "label": "摘要14", "info": "(ν)难解，但RBM的二分图结构具有非常特殊的性质，其条件分", "keywords": "其条件分, 难解, 的二分图结构具有非常特殊的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f69bfe69-e9fa-425e-baaf-377e717310d1", "label": "摘要15", "info": "从联合分布中导出条件分布是直观的：", "keywords": "从联合分布中导出条件分布是直观的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a00d13d0-5a1f-489d-a4e9-9172579e0d22", "label": "摘要16", "info": "由于我们相对可见单元v  计算条件概率，相对于分布P  (h  |  v  )我们可以；将它们视为常数。条件分布P  (h  |  v  )因子相乘的本质，我们可以将向量；h 上的联合概率写成单独元素h  j  上（未归一化）分布的乘积。现在原问", "keywords": "我们可以, 我们可以将向量, 现在原问, 条件分布, 由于我们相对可见单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8930c715-a6b8-4699-a404-fe35540867c6", "label": "摘要17", "info": "现在我们可以将关于隐藏层的完全条件分布表达为因子形式：", "keywords": "现在我们可以将关于隐藏层的完全条件分布表达为因子形式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "392def7c-2468-48b5-b11d-4df4c8f19d81", "label": "摘要18", "info": "类似的推导将显示我们感兴趣的另一个条件分布，P  (ν  |  h  )也是因子形；式的分布：", "keywords": "也是因子形, 类似的推导将显示我们感兴趣的另一个条件分布, 式的分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c2d4436-d808-4b25-8aba-fbad03416450", "label": "摘要19", "info": "20.2.2　训练受限玻尔兹曼机", "keywords": "训练受限玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5286b08e-a385-4d73-b59c-84ca4063bafe", "label": "摘要20", "info": "的估计和微分，并且还允许高效地（以块；因为RBM允许高效计算；吉布斯采样的形式）进行MCMC采样，所以我们很容易使用第18章中训", "keywords": "因为, 所以我们很容易使用第, 以块, 吉布斯采样的形式, 采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e86faa1e-9c82-446d-8f45-98bb7572c3cd", "label": "摘要21", "info": "20.2.1　条件分布", "keywords": "条件分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6ab430f6-4ce7-46f1-a11a-c85c80d15ad2", "label": "摘要22", "info": "20.2.2　训练受限玻尔兹；曼机", "keywords": "曼机, 训练受限玻尔兹", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "label": "20.3：深度信念网络", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "a4bf0839-dede-4203-8df5-e2778701a546", "label": "摘要1", "info": "深度信念网络  （deep  belief  network，DBN）是第一批成功应用深度架；构训练的非卷积模型之一（Hinton  et  al.  ，2006a；Hinton，2007b）。；2006年深度信念网络的引入开始了当前深度学习的复兴。在引入深度信", "keywords": "年深度信念网络的引入开始了当前深度学习的复兴, 是第一批成功应用深度架, 深度信念网络, 构训练的非卷积模型之一, 在引入深度信", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "25b6e815-19bf-4526-9de7-acf586f27b33", "label": "摘要2", "info": "深度信念网络是具有若干潜变量层的生成模型。潜变量通常是二值的，；而可见单元可以是二值或实数。尽管构造连接比较稀疏的DBN是可能；的，但在一般的模型中，每层的每个单元连接到每个相邻层中的每个单", "keywords": "潜变量通常是二值的, 每层的每个单元连接到每个相邻层中的每个单, 但在一般的模型中, 而可见单元可以是二值或实数, 尽管构造连接比较稀疏的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "670cc1f1-01b3-434b-8b38-c1ddf74d2267", "label": "摘要3", "info": "具有l个隐藏层的DBN包含l个权重矩阵：；含l＋1个偏置向量：；表示的概率分布由下式给出：", "keywords": "包含, 个偏置向量, 个权重矩阵, 个隐藏层的, 具有", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "99c0153a-d881-4b9a-b9a4-a9d00c476014", "label": "摘要4", "info": "，同时也包；，其中b  (0)  是可见层的偏置。DBN", "keywords": "是可见层的偏置, 同时也包, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "41a57490-337d-427a-b2a4-a8cc7a245389", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；在实值可见单元的情况下，替换", "keywords": "在实值可见单元的情况下, 替换", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90add355-9990-4456-96d1-41d0b30cf129", "label": "摘要6", "info": "为便于处理，β  为对角形式。至少在理论上，推广到其他指数族的可见；单元是直观的。只有一个隐藏层的DBN只是一个RBM。", "keywords": "为对角形式, 只有一个隐藏层的, 至少在理论上, 只是一个, 推广到其他指数族的可见", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "95c801fa-dd41-4b1c-bd74-05f3ef1a7e44", "label": "摘要7", "info": "为了从DBN中生成样本，我们先在顶部的两个隐藏层上运行几个Gibbs；采样步骤。这个阶段主要从RBM（由顶部两个隐藏层定义）中采一个；样本。然后，我们可以对模型的其余部分使用单次原始采样，以从可见", "keywords": "由顶部两个隐藏层定义, 这个阶段主要从, 样本, 我们先在顶部的两个隐藏层上运行几个, 我们可以对模型的其余部分使用单次原始采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39000609-3e2f-4270-b7f2-e3912295405d", "label": "摘要8", "info": "深度信念网络引发许多与有向模型和无向模型同时相关的问题。", "keywords": "深度信念网络引发许多与有向模型和无向模型同时相关的问题", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "088477f4-e9d9-45f7-91de-28f76f654c87", "label": "摘要9", "info": "由于每个有向层内的相消解释效应，并且由于无向连接的两个隐藏层之；间的相互作用，深度信念网络中的推断是难解的。评估或最大化对数似；然的标准证据下界也是难以处理的，因为证据下界基于大小等于网络宽", "keywords": "由于每个有向层内的相消解释效应, 然的标准证据下界也是难以处理的, 因为证据下界基于大小等于网络宽, 评估或最大化对数似, 间的相互作用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "933b00b0-55f2-4d02-a530-f0e3a0aa843a", "label": "摘要10", "info": "评估或最大化对数似然，不仅需要面对边缘化潜变量时难以处理的推断；问题，而且还需要处理顶部两层无向模型内难处理的配分函数问题。", "keywords": "问题, 评估或最大化对数似然, 而且还需要处理顶部两层无向模型内难处理的配分函数问题, 不仅需要面对边缘化潜变量时难以处理的推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec8c389b-d579-4053-bf6c-1c1528927d18", "label": "摘要11", "info": "为训练深度信念网络，我们可以先使用对比散度或随机最大似然方法训；练RBM以最大化；。RBM的参数定义了DBN第一", "keywords": "以最大化, 第一, 我们可以先使用对比散度或随机最大似然方法训, 为训练深度信念网络, 的参数定义了", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d9d9c72c-d34d-4adc-9051-614f695657d8", "label": "摘要12", "info": "其中p (1) 是第一个RBM表示的概率分布，p (2) 是第二个RBM表示的概率；分布。换句话说，第二个RBM被训练为模拟由第一个RBM的隐藏单元；采样定义的分布，而第一个RBM由数据驱动。这个过程能无限重复，", "keywords": "表示的概率, 表示的概率分布, 被训练为模拟由第一个, 的隐藏单元, 采样定义的分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "068f8e56-352e-4e0a-a505-a2a272ee3313", "label": "摘要13", "info": "DBN下似然概率的变分下界（Hinton et al. ，2006a）。", "keywords": "下似然概率的变分下界", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "de72bb57-effd-4cca-8397-df5b7ff1fb2b", "label": "摘要14", "info": "在大多数应用中，对DBN进行贪心逐层训练后，不需要再花工夫对其进；行联合训练。然而，使用醒眠算法对其进行生成精调是可能的。", "keywords": "使用醒眠算法对其进行生成精调是可能的, 在大多数应用中, 行联合训练, 然而, 进行贪心逐层训练后", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "98100ed4-b0ec-4706-8e4d-1ae2625d2829", "label": "摘要15", "info": "训练好的DBN可以直接用作生成模型，但是DBN的大多数兴趣来自它；们改进分类模型的能力。我们可以从DBN获取权重，并使用它们定义；MLP：", "keywords": "并使用它们定义, 但是, 的大多数兴趣来自它, 我们可以从, 们改进分类模型的能力", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1ba5a0e-46b8-46b8-beb5-8009f05379f3", "label": "摘要16", "info": "利用DBN的生成训练后获得的权重和偏置初始化该MLP之后，我们可以；训练该MLP来执行分类任务。这种MLP的额外训练是判别性精调的示；例。", "keywords": "之后, 我们可以, 来执行分类任务, 训练该, 这种", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9a7cd430-793f-41a5-a338-2ebbe17ccf41", "label": "摘要17", "info": "与第19章中从基本原理导出的许多推断方程相比，这种特定选择的MLP；有些随意。这个MLP是一个启发式选择，似乎在实践中效果不错，并在；文献中一贯使用。许多近似推断技术是由它们在一些约束下，并在对数", "keywords": "似乎在实践中效果不错, 这种特定选择的, 文献中一贯使用, 有些随意, 与第", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9be5a5bf-5f21-4f06-8aa7-bc7359dc9119", "label": "摘要18", "info": "虽然DBN的对数似然是难处理的，但它可以使用AIS近似；（Salakhutdinov  and  Murray，2008）。通过近似，可以评估其作为生成；模型的质量。", "keywords": "的对数似然是难处理的, 虽然, 但它可以使用, 模型的质量, 通过近似", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "911a426b-e759-4507-8fd9-69d317e7d34a", "label": "摘要19", "info": "术语“深度信念网络”通常不正确地用于指代任意种类的深度神经网络，；甚至没有潜变量意义的网络。这个术语应特指最深层中具有无向连接，；而在所有其他连续层之间存在向下有向连接的模型。", "keywords": "甚至没有潜变量意义的网络, 而在所有其他连续层之间存在向下有向连接的模型, 术语, 深度信念网络, 这个术语应特指最深层中具有无向连接", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9df671fd-91ff-43a2-a02a-fbb53b696a74", "label": "摘要20", "info": "这个术语也可能导致一些混乱，因为术语“信念网络”有时指纯粹的有向；模型，而深度信念网络包含一个无向层。深度信念网络也与动态贝叶斯", "keywords": "因为术语, 信念网络, 而深度信念网络包含一个无向层, 模型, 这个术语也可能导致一些混乱", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db9a3d4b-d620-493f-8e20-4f6917e1f000", "label": "摘要21", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；网络（dynamic  Bayesian  networks）（Dean  and  Kanazawa，1989）共享；首字母缩写DBN，动态贝叶斯网络表示马尔可夫链的贝叶斯网络。", "keywords": "网络, 动态贝叶斯网络表示马尔可夫链的贝叶斯网络, 共享, 首字母缩写", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e7df2de-c612-4414-afb8-9e1349a34202", "label": "20.4：深度玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "c05bb7a5-e057-4b93-9861-979516641a47", "label": "摘要1", "info": "20.4.1　有趣的性质", "keywords": "有趣的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f7ccc1d7-2740-45e4-8e1a-3e5438f0b8f4", "label": "摘要2", "info": "20.4.2　DBM均匀场推断", "keywords": "均匀场推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "334ae8b8-5b59-4b8b-b57a-53c12e521673", "label": "摘要3", "info": "20.4.3　DBM的参数学习", "keywords": "的参数学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97682506-75b2-45bd-822b-6a8176e03630", "label": "摘要4", "info": "20.4.4　逐层预训练", "keywords": "逐层预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7fb6638c-0871-4634-985b-200d79f90b85", "label": "摘要5", "info": "20.4.5　联合训练深度玻尔兹曼机", "keywords": "联合训练深度玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2f0981c1-14de-4386-a9ad-902f0b0e73c1", "label": "摘要6", "info": "深度玻尔兹曼机  （Deep  Boltzmann  Machine，DBM）（Salakhutdinov；and  Hinton，2009a）是另一种深度生成模型。与深度信念网络（DBN）；不同的是，它是一个完全无向的模型。与RBM不同的是，DBM有几层", "keywords": "有几层, 不同的是, 深度玻尔兹曼机, 它是一个完全无向的模型, 是另一种深度生成模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d6273aec-a983-4035-9bcc-1996e991cf46", "label": "摘要7", "info": "图20.2　具有一个可见层（底部）和两个隐藏层的深度玻尔兹曼机的图模型。仅在相邻层的单；元之间存在连接，没有层内连接", "keywords": "仅在相邻层的单, 底部, 元之间存在连接, 和两个隐藏层的深度玻尔兹曼机的图模型, 具有一个可见层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d7614d0-6f9a-41d7-b363-0d41df1cd79f", "label": "摘要8", "info": "与RBM和DBN一样，DBM通常仅包含二值单元（正如我们为简化模型", "keywords": "一样, 通常仅包含二值单元, 正如我们为简化模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "821d57d6-b940-42f8-a8f3-b18a2fa06fde", "label": "摘要9", "info": "的演示而假设的），但很容易就能扩展到实值可见单元。", "keywords": "的演示而假设的, 但很容易就能扩展到实值可见单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0160cf6-31c7-4c97-8a09-908d02cf515a", "label": "摘要10", "info": "DBM是基于能量的模型，这意味着模型变量的联合概率分布由能量函；数E参数化。在一个深度玻尔兹曼机包含一个可见层", "keywords": "参数化, 是基于能量的模型, 这意味着模型变量的联合概率分布由能量函, 在一个深度玻尔兹曼机包含一个可见层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5899547-1aca-4ff4-9060-3cde79fdd42e", "label": "摘要11", "info": "ν  和3个隐藏层", "keywords": "个隐藏层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd363f9b-521e-48af-b82b-2dc07bf33c2e", "label": "摘要12", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccedeacc-e57c-437c-9568-f386ddf7b463", "label": "摘要13", "info": "的情况下，联合概率由下式给出：", "keywords": "联合概率由下式给出, 的情况下", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "599871a5-c1a7-4d1a-9649-ccd977266132", "label": "摘要14", "info": "为简化表示，式（20.25）省略了偏置参数。DBM能量函数定义如下：", "keywords": "为简化表示, 能量函数定义如下, 省略了偏置参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1111309d-4d79-44e3-a96d-66f6850b4e96", "label": "摘要15", "info": "与RBM的能量函数（式（20.5））相比，DBM能量函数以权重矩阵（W；(2) 和W (4) 的形式表示隐藏单元（潜变量）之间的连接。正如我们将看到；的，这些连接对模型行为以及我们如何在模型中进行推断都有重要的影", "keywords": "这些连接对模型行为以及我们如何在模型中进行推断都有重要的影, 的形式表示隐藏单元, 潜变量, 的能量函数, 能量函数以权重矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cd897e6e-9229-494f-9f9d-974eadd91dba", "label": "摘要16", "info": "与全连接的玻尔兹曼机（每个单元连接到其他每个单元）相比，DBM；提供了类似于RBM的一些优点。", "keywords": "与全连接的玻尔兹曼机, 的一些优点, 提供了类似于, 相比, 每个单元连接到其他每个单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3cd61387-1476-4d5e-8874-d7ce9246b569", "label": "摘要17", "info": "具体来说，如图20.3所示，DBM的层可以组织成一个二分图，其中奇数；层在一侧，偶数层在另一侧。容易发现，当我们条件于偶数层中的变量；时，奇数层中的变量变得条件独立。当然，当我们条件于奇数层中的变", "keywords": "当我们条件于奇数层中的变, 当我们条件于偶数层中的变量, 所示, 层在一侧, 其中奇数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1e8b5624-92e6-480d-aaf5-fba2d411359d", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图20.3　深度玻尔兹曼机，重新排列后显示为二分图结构", "keywords": "深度玻尔兹曼机, 重新排列后显示为二分图结构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9a8300d5-00d2-4adc-a039-d378c35f8f7e", "label": "摘要19", "info": "DBM的二分图结构意味着，我们可以应用之前用于RBM条件分布的相；同式子来确定DBM中的条件分布。在给定相邻层值的情况下，层内的；单元彼此条件独立，因此二值变量的分布可以由Bernoulli参数（描述每", "keywords": "参数, 因此二值变量的分布可以由, 条件分布的相, 的二分图结构意味着, 同式子来确定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e14f1dc4-1d86-40e9-99f5-1a6300feb1b7", "label": "摘要20", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5979c2d9-0312-4d06-a9a2-98da0053316a", "label": "摘要21", "info": "二分图结构使Gibbs采样能在深度玻尔兹曼机中高效采样。Gibbs采样的；方法是一次只更新一个变量。RBM允许所有可见单元以一个块的方式；更新，而所有隐藏单元在另一个块上更新。我们可以简单地假设具有l", "keywords": "更新, 采样的, 而所有隐藏单元在另一个块上更新, 我们可以简单地假设具有, 方法是一次只更新一个变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bca40e4b-666f-4126-a7ad-68a0542461ab", "label": "摘要22", "info": "训练尤其重要。", "keywords": "训练尤其重要", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8092a1f6-cd64-4f37-a8ed-601296ebdf57", "label": "摘要23", "info": "20.4.1　有趣的性质", "keywords": "有趣的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14e02f2d-9855-4883-94ef-849ca527e025", "label": "摘要24", "info": "深度玻尔兹曼机具有许多有趣的性质。", "keywords": "深度玻尔兹曼机具有许多有趣的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ae219533-6a7c-4221-8d7c-c8099ecfbec7", "label": "摘要25", "info": "DBM在DBN之后开发。与DBN相比，DBM的后验分布P  (  h  |  ν  )  更简；单。有点违反直觉的是，这种后验分布的简单性允许更加丰富的后验近；似。在DBN的情况下，我们使用启发式的近似推断过程进行分类，其中", "keywords": "更简, 这种后验分布的简单性允许更加丰富的后验近, 我们使用启发式的近似推断过程进行分类, 有点违反直觉的是, 的后验分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f44089e-e81d-41be-a8a0-748a96e2b022", "label": "摘要26", "info": "使用适当的均匀场允许DBM的近似推断过程捕获自顶向下反馈相互作；用的影响。这从神经科学的角度来看是有趣的，因为根据已知，人脑使；用许多自上而下的反馈连接。由于这个性质，DBM已被用作真实神经", "keywords": "用的影响, 的近似推断过程捕获自顶向下反馈相互作, 由于这个性质, 因为根据已知, 这从神经科学的角度来看是有趣的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ff71071-c3f0-4465-b470-b9fa46a5a99c", "label": "摘要27", "info": "DBM一个不理想的特性是从中采样是相对困难的。DBN只需要在其顶；部的一对层中使用MCMC采样。其他层仅在采样过程末尾涉及，并且只；需在一个高效的原始采样过程。要从DBM生成样本，必须在所有层中", "keywords": "只需要在其顶, 必须在所有层中, 要从, 采样, 生成样本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bee6f787-c768-4847-a3f7-78d265749e39", "label": "摘要28", "info": "20.4.2　DBM均匀场推断", "keywords": "均匀场推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "32aedde6-5854-4a6f-be33-1d88967d2502", "label": "摘要29", "info": "给定相邻层，一个DBM层上的条件分布是因子的。在有两个隐藏层的；DBM的示例中，这些分布是P (ν| h (1) )、P ( h (1) ) |ν, h (2) )和P ( h (2) | h (1)；)。因为层之间的相互作用，所有隐藏层上的分布通常不是因子的。在", "keywords": "的示例中, 这些分布是, 给定相邻层, 因为层之间的相互作用, 层上的条件分布是因子的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d93c846-f68c-4cac-8420-21204455d09d", "label": "摘要30", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；有两个隐藏层的示例中，由于 h (1) 和 h  (2)  之间的交互权重 W  (2)  使得这；些变量相互依赖，P ( h (1) |ν, h (2) )不是因子的。", "keywords": "有两个隐藏层的示例中, 些变量相互依赖, 之间的交互权重, 由于, 不是因子的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d085f8c4-4ab1-4874-ac96-f74058c04145", "label": "摘要31", "info": "与DBN的情况一样，我们还是要找出近似DBM后验分布的方法。然；而，与DBN不同，DBM在其隐藏单元上的后验分布（复杂的）很容易；用变分近似来近似（如第19.4节所讨论），具体是一个均匀场近似。均", "keywords": "的情况一样, 很容易, 节所讨论, 具体是一个均匀场近似, 我们还是要找出近似", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edba0614-74c6-4d53-b436-eacfa1f637df", "label": "摘要32", "info": "在推断的变分近似中，我们通过一些相当简单的分布族近似特定目标分；布——在这里指给定可见单元时隐藏单元的后验分布。在均匀场近似的；情况下，近似族是隐藏单元条件独立的分布集合。", "keywords": "情况下, 在均匀场近似的, 我们通过一些相当简单的分布族近似特定目标分, 在这里指给定可见单元时隐藏单元的后验分布, 在推断的变分近似中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a058148e-52c2-4a76-8011-1daf1129538a", "label": "摘要33", "info": "我们现在为具有两个隐藏层的示例推导均匀场方法。令Q ( h (1) , h  (2)  |ν)；为P ( h (1) , h (2) |ν)的近似。均匀场假设意味着", "keywords": "我们现在为具有两个隐藏层的示例推导均匀场方法, 的近似, 均匀场假设意味着", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5970682-3d6e-4dce-8aef-ba4ebcc51860", "label": "摘要34", "info": "均匀场近似试图找到这个分布族中最适合真实后验P ( h  (1)  , h  (2)  |ν)的成；员。重要的是，每次我们使用 ν  的新值时，必须再次运行推断过程以找；到不同的分布Q。", "keywords": "每次我们使用, 均匀场近似试图找到这个分布族中最适合真实后验, 到不同的分布, 的新值时, 重要的是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d3f9fad-8dcf-464c-bd44-c8ee7b3d902f", "label": "摘要35", "info": "我们可以设想很多方法来衡量Q (h |ν)与P (h |ν)的拟合程度。均匀场方法；是最小化", "keywords": "是最小化, 均匀场方法, 我们可以设想很多方法来衡量, 的拟合程度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "787ac569-8dc5-4973-b213-69442222460b", "label": "摘要36", "info": "一般来说，除了要保证独立性假设，我们不必提供参数形式的近似分；布。变分近似过程通常能够恢复近似分布的函数形式。然而，在二值隐；藏单元（我们在这里推导的情况）的均匀场假设的情况下，不会由于预", "keywords": "不会由于预, 我们不必提供参数形式的近似分, 然而, 的均匀场假设的情况下, 除了要保证独立性假设", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "33d953d8-6d5a-4a6d-bd38-739c368d5538", "label": "摘要37", "info": "我们将Q作为Bernoulli分布的乘积进行参数化，即我们将  h  (1)  每个元素", "keywords": "作为, 我们将, 每个元素, 即我们将, 分布的乘积进行参数化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe6e768e-6713-4697-8161-456a770bff1a", "label": "摘要38", "info": "的概率与一个参数相关联。具体来说，对于每个j，；，其中", "keywords": "具体来说, 对于每个, 的概率与一个参数相关联, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8d47088b-78d9-46bf-a56b-4159a4c78e5a", "label": "摘要39", "info": "。另外，对于每个k，；。因此，我们有以下近似后验：", "keywords": "因此, 对于每个, 另外, 我们有以下近似后验", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2ae27f23-0eb9-4760-9ee6-3e9b9c827d60", "label": "摘要40", "info": "，其中", "keywords": "其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "63679998-cc2e-4447-9f7c-5d287f5e41c0", "label": "摘要41", "info": "当然，对于具有更多层的DBM，近似后验的参数化可以通过明显的方；式扩展，即利用图的二分结构，遵循Gibbs采样相同的调度，同时更新；所有偶数层，然后同时更新所有奇数层。", "keywords": "即利用图的二分结构, 式扩展, 近似后验的参数化可以通过明显的方, 同时更新, 然后同时更新所有奇数层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "01760e1b-5844-4b01-9428-7743745fd3ed", "label": "摘要42", "info": "现在我们已经指定了近似分布Q的函数族，但仍然需要指定用于选择该；函数族中最适合P的成员的过程。最直接的方法是使用式（19.56）指定；的均匀场方程。这些方程是通过求解变分下界导数为零的位置而导出，", "keywords": "的函数族, 这些方程是通过求解变分下界导数为零的位置而导出, 现在我们已经指定了近似分布, 函数族中最适合, 的成员的过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "687c65c9-d412-46ff-8933-3dbf77c3196a", "label": "摘要43", "info": "应用这些一般的方程，我们得到以下更新规则（再次忽略偏置项）：", "keywords": "再次忽略偏置项, 应用这些一般的方程, 我们得到以下更新规则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "00f132a5-e96f-43a3-86b7-c95b59b6e0d8", "label": "摘要44", "info": "在该方程组的不动点处，我们具有变分下界；的局部最大值。因；此，这些不动点更新方程定义了迭代算法，其中我们交替更新   （使", "keywords": "其中我们交替更新, 在该方程组的不动点处, 我们具有变分下界, 这些不动点更新方程定义了迭代算法, 的局部最大值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "493d78c2-3fd7-48f7-9d4b-bc737bbbb994", "label": "摘要45", "info": "20.4.3　DBM的参数学习", "keywords": "的参数学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "67dc4fa4-0cf8-4a41-9413-f7912f584a06", "label": "摘要46", "info": "DBM中的学习必须面对难解配分函数的挑战（使用第18章中的技；术），以及难解后验分布的挑战（使用第19章中的技术）。", "keywords": "中的学习必须面对难解配分函数的挑战, 章中的技术, 使用第, 以及难解后验分布的挑战, 章中的技", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "705e9794-a017-4859-b803-7be97a2f0553", "label": "摘要47", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；如第20.4.2节中所描述的，变分推断允许构建近似难处理的P  (  h  |ν)的分；布Q ( h  |ν)。然后通过最大化", "keywords": "的分, 然后通过最大化, 变分推断允许构建近似难处理的, 如第, 节中所描述的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5d3c98c-07b5-4861-9f18-9e6b944aadcc", "label": "摘要48", "info": "）学习。", "keywords": "学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c838dcf4-02ee-4dcd-99cd-b91fbf3bcd83", "label": "摘要49", "info": "对于具有两个隐藏层的深度玻尔兹曼机，  由下式给出", "keywords": "对于具有两个隐藏层的深度玻尔兹曼机, 由下式给出", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "df39b71d-37d7-4dbd-ac40-0b34e9860872", "label": "摘要50", "info": "。由于深度玻尔兹曼机包含；该表达式仍然包含对数配分函数；受限玻尔兹曼机作为组件，用于计算受限玻尔兹曼机的配分函数和采样", "keywords": "受限玻尔兹曼机作为组件, 由于深度玻尔兹曼机包含, 该表达式仍然包含对数配分函数, 用于计算受限玻尔兹曼机的配分函数和采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55fb8e36-dcaa-4d41-8ee5-9c0246eb8e74", "label": "摘要51", "info": "非变分版本的随机最大似然算法已经在第18.2节讨论过。算法20.1给出；了应用于DBM的变分随机最大似然算法。回想一下，我们描述的是；DBM的简化变体（缺少偏置参数），很容易推广到包含偏置参数的情", "keywords": "节讨论过, 很容易推广到包含偏置参数的情, 算法, 非变分版本的随机最大似然算法已经在第, 的简化变体", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "83d8feef-1db4-4584-afca-e988daca225e", "label": "摘要52", "info": "20.4.4　逐层预训练", "keywords": "逐层预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa59a660-0999-4dec-9539-f75abf1c6cd3", "label": "摘要53", "info": "不幸的是，随机初始化后使用随机最大似然训练（如上所述）的DBM；通常导致失败。在一些情况下，模型不能学习如何充分地表示分布。在；其他情况下，DBM可以很好地表示分布，但是没有比仅使用RBM获得", "keywords": "模型不能学习如何充分地表示分布, 其他情况下, 获得, 如上所述, 但是没有比仅使用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1e86d102-b350-4f4c-9c5e-be1da799d1d5", "label": "摘要54", "info": "如第20.4.5节所述，目前已经开发了允许联合训练的各种技术。然而，；克服DBM的联合训练问题最初和最流行的方法是贪心逐层预训练。在；该方法中，DBM的每一层被单独视为RBM进行训练。第一层被训练为", "keywords": "目前已经开发了允许联合训练的各种技术, 该方法中, 的每一层被单独视为, 然而, 克服", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "32b1f227-9767-4f26-ad6d-97726c2c09a5", "label": "摘要55", "info": "对输入数据进行建模。每个后续RBM被训练为对来自前一RBM后验分；布的样本进行建模。在以这种方式训练了所有RBM之后，它们可以被；组合成DBM。然后可以用PCD训练DBM。通常，PCD训练将仅使模型", "keywords": "之后, 训练, 通常, 组合成, 每个后续", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f515593d-831d-4984-848e-3fc1a65e5f34", "label": "摘要56", "info": "图20.4　用于分类MNIST数据集的深度玻尔兹曼机训练过程（Salakhutdinov and Hinton，；2009a；Srivastava et al. ，2014）。（a）使用CD近似最大化log P( ν )来训练RBM。（b）训练第；二个RBM，使用CD-k近似最大化log P( h (1) ,y)来建模 h (1) 和目标类y，其中 h (1) 采自第一个", "keywords": "来训练, 用于分类, 数据集的深度玻尔兹曼机训练过程, 来建模, 近似最大化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1535e79b-beab-47df-9a5a-51230b19e28d", "label": "摘要57", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；算法20.1  　用于训练具有两个隐藏层的DBM的变分随机最大似然算；法。", "keywords": "用于训练具有两个隐藏层的, 的变分随机最大似然算, 算法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec007410-e3c0-4701-88a7-df058775aca1", "label": "摘要58", "info": "设步长  一个小正数", "keywords": "一个小正数, 设步长", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e39ec269-76b1-4b5b-b27e-6094e293939b", "label": "摘要59", "info": "设定吉布斯步数k，大到足以让；夫链能磨合（从来自", "keywords": "从来自, 大到足以让, 设定吉布斯步数, 夫链能磨合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e61c890-560c-4756-aa3f-8346d289b52c", "label": "摘要60", "info": "的样本开始）。", "keywords": "的样本开始", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2bf6b590-df25-453f-aca2-7a4867b726cd", "label": "摘要61", "info": "的马尔可", "keywords": "的马尔可", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8dbfea40-98f6-45f3-a597-2c0cabf9367f", "label": "摘要62", "info": "初始化3个矩阵，；如，来自Bernoulli分布，边缘分布大致与模型匹配）。", "keywords": "边缘分布大致与模型匹配, 个矩阵, 分布, 来自, 初始化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8eebccb9-0d28-4b0f-8e52-850d83878662", "label": "摘要63", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "790cc66d-4a24-42fb-9f94-dee400be872b", "label": "摘要64", "info": "每个都将m行设为随机值（例", "keywords": "每个都将, 行设为随机值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef79e439-cee8-49da-8931-af59dbb1b073", "label": "摘要65", "info": "while 没有收敛（学习循环）do", "keywords": "没有收敛, 学习循环", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ca23497-6873-4051-8551-cbea6a2927be", "label": "摘要66", "info": "从训练数据采包含m个样本的小批量，并将它们排列为设计矩阵  V；的行。", "keywords": "从训练数据采包含, 并将它们排列为设计矩阵, 的行, 个样本的小批量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c270d43-36ad-4b1c-98e2-42d22b653584", "label": "摘要67", "info": "初始化矩阵", "keywords": "初始化矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e19b7a14-963b-4a76-ad59-5b042fe0369e", "label": "摘要68", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "37403e65-7c2c-4da1-a0a8-dbbee42daeba", "label": "摘要69", "info": "，使其大致符合模型的边缘分布。", "keywords": "使其大致符合模型的边缘分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15ba275e-b31c-42c6-a0fa-c303c7d867c5", "label": "摘要70", "info": "while 没有收敛（均匀场推断循环）do", "keywords": "没有收敛, 均匀场推断循环", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "34015cab-1e61-45bf-963e-4df5976b674d", "label": "摘要71", "info": "end while", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ddff309b-c024-4dcf-adc0-b4159653199e", "label": "摘要72", "info": "for l＝1 to k（Gibbs采样）do", "keywords": "采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92734c90-e0dd-43df-9a7e-708b2fea37f1", "label": "摘要73", "info": "Gibbs block 1:", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a3f8f91-450f-4985-a0da-54fa94af6c28", "label": "摘要74", "info": "Gibbs block 2:", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ad85553-ce77-4580-aa9e-61d96e36a2e4", "label": "摘要75", "info": "end for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eafd1f42-41f5-45d2-ac89-f0435aee133a", "label": "摘要76", "info": "效，如具有衰减学习率的动量）", "keywords": "如具有衰减学习率的动量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3aebb518-f7a8-4edb-b5a8-4b00fb7f5612", "label": "摘要77", "info": "（这是大概的描述，实践中使用的算法更高", "keywords": "这是大概的描述, 实践中使用的算法更高", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "31406826-d193-4c18-b416-6575c4675f50", "label": "摘要78", "info": "end while", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15a143f3-96a1-418e-a325-c38586637271", "label": "摘要79", "info": "这种贪心逐层训练过程不仅仅是坐标上升，因为我们在每个步骤优化参；数的一个子集，它与坐标上升具有一些传递相似性。这两种方法是不同；的，因为贪心逐层训练过程中，我们在每个步骤都使用了不同的目标函", "keywords": "这两种方法是不同, 这种贪心逐层训练过程不仅仅是坐标上升, 因为我们在每个步骤优化参, 我们在每个步骤都使用了不同的目标函, 数的一个子集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "768e597e-88d9-4ca2-8be1-17a3f36e0f23", "label": "摘要80", "info": "DBM的贪心逐层预训练与DBN的贪心逐层预训练不同。每个单独的；RBM的参数可以直接复制到相应的DBN。在DBM的情况下，RBM的参；数在包含到DBM中之前必须修改。RBM栈的中间层仅使用自底向上的", "keywords": "的贪心逐层预训练与, 的参数可以直接复制到相应的, 中之前必须修改, 数在包含到, 栈的中间层仅使用自底向上的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1a9e1fd-2719-44bd-8b64-4d94a3e35b38", "label": "摘要81", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；输入进行训练，但在栈组合形成DBM后，该层将同时具有自底向上和；自顶向下的输入。为了解释这种效应，Salakhutdinov", "keywords": "该层将同时具有自底向上和, 但在栈组合形成, 输入进行训练, 自顶向下的输入, 为了解释这种效应", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a8ecc24d-5ab1-4d5f-b07d-fac6fd7345b8", "label": "摘要82", "info": "为了使用深度玻尔兹曼机获得最好结果，我们需要修改标准的SML算；法，即在联合PCD训练步骤的负相期间使用少量的均匀场；（Salakhutdinov  and  Hinton，2009a）。具体来说，应当相对于其中所有", "keywords": "我们需要修改标准的, 训练步骤的负相期间使用少量的均匀场, 具体来说, 应当相对于其中所有, 为了使用深度玻尔兹曼机获得最好结果", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a1a98e64-9baa-45e5-b575-139d7c4fe7ec", "label": "摘要83", "info": "et  al", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c259efae-b915-44a6-9c0c-c0d3ee88de69", "label": "摘要84", "info": "20.4.5　联合训练深度玻尔兹曼机", "keywords": "联合训练深度玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0653e47f-47ac-41b6-8100-1b0dfc3b1aef", "label": "摘要85", "info": "经典DBM需要贪心无监督预训练，并且为了更好的分类，需要在它们；提取的隐藏特征之上，使用独立的基于MLP的分类器。这种方法有一些；不理想的性质，因为我们不能在训练第一个RBM时评估完整DBM的属", "keywords": "需要在它们, 使用独立的基于, 并且为了更好的分类, 不理想的性质, 经典", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c5848f2-a593-419f-a42b-bf12ad033e4b", "label": "摘要86", "info": "主要有两种方法可以处理深度玻尔兹曼机的联合训练问题。第一个是中；心化深度玻尔兹曼机  （centered  deep  Boltzmann  machine）（Montavon；and  Muller，2012），通过重参数化模型使其在开始学习过程时代价函", "keywords": "心化深度玻尔兹曼机, 通过重参数化模型使其在开始学习过程时代价函, 第一个是中, 主要有两种方法可以处理深度玻尔兹曼机的联合训练问题", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dea3ed44-af9f-4d4d-a733-d43ed8208067", "label": "摘要87", "info": "MCMC估计梯度的问题。不幸的是，新的准则不会导致良好的似然性或；样本，但是相比MCMC方法，它确实会导致更好的分类性能和良好的推；断缺失输入的能力。", "keywords": "样本, 方法, 断缺失输入的能力, 估计梯度的问题, 它确实会导致更好的分类性能和良好的推", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a6061e1-e2f6-4a3f-8bf5-0e8a8cbe460e", "label": "摘要88", "info": "如果我们回到玻尔兹曼机的一般观点，即包括一组权重矩阵 U 和偏置 b；的单元 x ，玻尔兹曼机中心化技巧是最容易描述的。回顾式（20.2） ，；能量函数由下式给出", "keywords": "回顾式, 的单元, 玻尔兹曼机中心化技巧是最容易描述的, 如果我们回到玻尔兹曼机的一般观点, 能量函数由下式给出", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a14001a3-e951-4858-9f84-413ebcf87ce0", "label": "摘要89", "info": "在权重矩阵  U  中使用不同的稀疏模式，我们可以实现不同架构的玻尔；兹曼机，如RBM或具有不同层数的DBM。将  x  分割成可见和隐藏单；元，并将  U  中不相互作用的单元归零可以实现这些架构。中心化玻尔", "keywords": "中心化玻尔, 我们可以实现不同架构的玻尔, 中使用不同的稀疏模式, 在权重矩阵, 兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa1ea15e-0e1b-4f57-8412-8da9a72cd3d6", "label": "摘要90", "info": "通常 μ 在开始训练时固定为一个超参数。当模型初始化时，通常选择为；x  −  μ  ≈0。这种重参数化不改变模型可表示的概率分布的集合，但它确；实改变了应用于似然的随机梯度下降的动态。具体来说，在许多情况", "keywords": "在开始训练时固定为一个超参数, 通常, 实改变了应用于似然的随机梯度下降的动态, 在许多情况, 这种重参数化不改变模型可表示的概率分布的集合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96a5a863-b376-4069-8feb-827b98775639", "label": "摘要91", "info": "et", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7ccefd34-1184-4477-b770-10ed89c86fe6", "label": "摘要92", "info": "联合训练深度玻尔兹曼机的另一种方法是多预测深度玻尔兹曼机（MP-；DBM），它将均匀场方程视为定义一系列用于近似求解每个可能推断；问题的循环网络（Goodfellow et  al.  ，2013d）。模型被训练为使每个循", "keywords": "模型被训练为使每个循, 它将均匀场方程视为定义一系列用于近似求解每个可能推断, 联合训练深度玻尔兹曼机的另一种方法是多预测深度玻尔兹曼机, 问题的循环网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "df95feeb-a004-42a7-8f5a-8edfa49fb237", "label": "摘要93", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图20.5　深度玻尔兹曼机多预测训练过程的示意图。每一行指示相同训练步骤内小批量中的不；同样本。每列表示均匀场推断过程中的时间步。对于每个样本，我们对数据变量的子集进行采", "keywords": "对于每个样本, 每一行指示相同训练步骤内小批量中的不, 我们对数据变量的子集进行采, 每列表示均匀场推断过程中的时间步, 深度玻尔兹曼机多预测训练过程的示意图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3dcdd5a5-1547-44de-bb12-b1693289193b", "label": "摘要94", "info": "这种用于近似推断，通过计算图进行反向传播的一般原理已经应用于其", "keywords": "通过计算图进行反向传播的一般原理已经应用于其, 这种用于近似推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcbb67df-d90d-41fd-997f-4cb5eda12d8e", "label": "摘要95", "info": "他模型（Stoyanov et  al. ，2011；Brakel  et  al.  ，2013）。在这些模型和；MP-DBM中，最终损失不是似然的下界。相反，最终损失通常基于近似；推断网络对缺失值施加的近似条件分布。这意味着这些模型的训练有些", "keywords": "最终损失通常基于近似, 这意味着这些模型的训练有些, 推断网络对缺失值施加的近似条件分布, 在这些模型和, 他模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc4db44c-08d1-4773-9508-fb75e13c58ff", "label": "摘要96", "info": "通过推断图的反向传播有两个主要优点。首先，它以模型真正使用的方；式训练模型——使用近似推断。这意味着在MP-DBM中，进行如填充缺；失的输入或执行分类（尽管存在缺失的输入）的近似推断比在原始", "keywords": "进行如填充缺, 尽管存在缺失的输入, 式训练模型, 使用近似推断, 通过推断图的反向传播有两个主要优点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "24eb285a-83f5-4328-9ca5-6f7ffba9d91c", "label": "摘要97", "info": "MP-DBM启发了对NADE框架的扩展NADE-k（Raiko  et  al.  ，2014）  ，；我们将在第20.10.10节中描述。", "keywords": "框架的扩展, 启发了对, 我们将在第, 节中描述", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "912b6a12-33bb-4324-b66d-f051d012bc0e", "label": "摘要98", "info": "MP-DBM与Dropout有一定联系。Dropout在许多不同的计算图之间共享；相同的参数，每个图之间的差异是包括还是排除每个单元。MP-DBM还；在许多计算图之间共享参数。在MP-DBM的情况下，图之间的差异是每", "keywords": "相同的参数, 在许多不同的计算图之间共享, 每个图之间的差异是包括还是排除每个单元, 在许多计算图之间共享参数, 的情况下", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f02ec76b-8c36-4a28-be69-a60bdc72a2f0", "label": "摘要99", "info": "20.4.1　有趣的性质", "keywords": "有趣的性质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1713df67-49de-4eeb-b420-945ebf1653d8", "label": "摘要100", "info": "20.4.2　DBM均匀场推断", "keywords": "均匀场推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a772a20-3481-46d6-99a2-f93898a2cb67", "label": "摘要101", "info": "20.4.3　DBM的参数学习", "keywords": "的参数学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0c4f4e02-4267-40d9-a5e9-d259ae26ec46", "label": "摘要102", "info": "20.4.4　逐层预训练", "keywords": "逐层预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7f5cb0d7-a980-412f-a46d-4cec31d07c8b", "label": "摘要103", "info": "20.4.5　联合训练深度玻；尔兹曼机", "keywords": "尔兹曼机, 联合训练深度玻", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "label": "20.5：实值数据上的玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "aa0a640f-c1d1-4b00-b47f-08dee0661c0d", "label": "摘要1", "info": "20.5.1　Gaussian-Bernoulli RBM", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7239e606-0954-43cc-b1d8-a08c81c2211f", "label": "摘要2", "info": "20.5.2　条件协方差的无向模型", "keywords": "条件协方差的无向模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5469713-a839-4e07-85ff-0383f8615388", "label": "摘要3", "info": "虽然玻尔兹曼机最初是为二值数据而开发的，但是许多应用，例如图像；和音频建模似乎需要表示实值上概率分布的能力。在一些情况下，我们；可以将区间［0，1］中的实值数据视为表示二值变量的期望。例如，", "keywords": "可以将区间, 例如图像, 我们, 在一些情况下, 例如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88d776da-783d-4c80-a323-9318968880ac", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；率值。每个像素定义二值变量为1的概率，并且二值像素的采样都彼此；独立。这是评估灰度图像数据集上二值模型的常见过程。然而，这种方", "keywords": "并且二值像素的采样都彼此, 每个像素定义二值变量为, 然而, 这是评估灰度图像数据集上二值模型的常见过程, 这种方", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7771a79e-36d1-4e5c-8402-2f1171d4ebbc", "label": "摘要5", "info": "20.5.1　Gaussian-Bernoulli RBM", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "628789e0-b45d-40ef-bf25-4ecd9569a4cc", "label": "摘要6", "info": "受限玻尔兹曼机可以用于许多指数族的条件分布（Welling  et  al.  ，；2005）。其中，最常见的是具有二值隐藏单元和实值可见单元的；RBM，其中可见单元上的条件分布是高斯分布（均值为隐藏单元的函", "keywords": "最常见的是具有二值隐藏单元和实值可见单元的, 其中, 均值为隐藏单元的函, 受限玻尔兹曼机可以用于许多指数族的条件分布, 其中可见单元上的条件分布是高斯分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "759a60a6-1cc4-426d-b221-c4aa026d6d05", "label": "摘要7", "info": "有很多方法可以参数化Gaussian-Bernoulli  RBM。首先，我们可以选择；协方差矩阵或精度矩阵来参数化高斯分布。这里，我们介绍选择精度矩；阵的情况。我们可以通过简单的修改获得协方差的形式。我们希望条件", "keywords": "我们介绍选择精度矩, 阵的情况, 我们可以选择, 协方差矩阵或精度矩阵来参数化高斯分布, 我们可以通过简单的修改获得协方差的形式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "68388a2c-8caf-45c2-b4db-7305a7f2e2db", "label": "摘要8", "info": "通过扩展未归一化的对数条件分布可以找到需要添加到能量函数中的；项：", "keywords": "通过扩展未归一化的对数条件分布可以找到需要添加到能量函数中的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1222c686-bee6-4a3a-bf30-a43a05c2283b", "label": "摘要9", "info": "此处f封装所有的参数，但不包括模型中的随机变量。因为f的唯一作用；是归一化分布，并且我们选择的任何可作为配分函数的能量函数都能起；到这个作用，所以我们可以忽略f。", "keywords": "因为, 封装所有的参数, 的唯一作用, 到这个作用, 但不包括模型中的随机变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e9fc6b9b-73e5-4b2a-8b50-6b43e6b93af2", "label": "摘要10", "info": "如果我们在能量函数中包含式（20.39）中涉及 ν 的所有项（其符号被翻；转），并且不添加任何其他涉及 ν  的项，那么我们的能量函数就能表示；想要的条件分布p (ν| h )。", "keywords": "如果我们在能量函数中包含式, 想要的条件分布, 的所有项, 那么我们的能量函数就能表示, 中涉及", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20eb3c3a-7dac-45e5-bc3d-82d2e4e20a0e", "label": "摘要11", "info": "其他条件分布比较自由，如p ( h |ν)。注意式（20.39）包含一项", "keywords": "包含一项, 其他条件分布比较自由, 注意式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f1550a4-632c-4188-8d93-801bfbe21642", "label": "摘要12", "info": "因为该项包含h i h j 项，它不能被全部包括在内。这些对应于隐藏单元之；间的边。如果我们包括这些项，将得到一个线性因子模型，而不是受限；玻尔兹曼机。当设计我们的玻尔兹曼机时，简单地省略这些h  i  h  j  交叉", "keywords": "交叉, 简单地省略这些, 因为该项包含, 这些对应于隐藏单元之, 间的边", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac34c46a-b528-49b2-bcbb-88e76590b21d", "label": "摘要13", "info": "的事实（因为h  i  ∈{0，1}）。如果我们；在上面，我们使用了；在能量函数中包含此项（符号被翻转），则当该单元的权重较大且以高", "keywords": "因为, 的事实, 符号被翻转, 如果我们, 在上面", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f65821e5-b369-4d84-9e98-d4a247029bcd", "label": "摘要14", "info": "因此，在Gaussian-Bernoulli RBM上定义能量函数的一种方式：", "keywords": "因此, 上定义能量函数的一种方式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e2af4e08-62cc-40b7-b7c7-5f7e0963b520", "label": "摘要15", "info": "但我们还可以添加额外的项或者通过方差而不是精度参数化能量。", "keywords": "但我们还可以添加额外的项或者通过方差而不是精度参数化能量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8987e110-5491-4f39-8db2-026cbf42ca20", "label": "摘要16", "info": "在这个推导中，我们没有在可见单元上添加偏置项，但添加这样的偏置；是容易的。Gaussian-Bernoulli  RBM参数化一个最终变化的来源是如何；处理精度矩阵的选择。它可以被固定为常数（可能基于数据的边缘精度", "keywords": "它可以被固定为常数, 在这个推导中, 参数化一个最终变化的来源是如何, 可能基于数据的边缘精度, 但添加这样的偏置", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf6f82d6-b772-454a-b122-9825a9fa86c4", "label": "摘要17", "info": "20.5.2　条件协方差的无向模型", "keywords": "条件协方差的无向模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a20a6aa-b9c5-40d2-b0c1-aa312262e15c", "label": "摘要18", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；et", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9ab4e02a-d6e1-4c42-bd41-83e4592279f8", "label": "摘要19", "info": "虽然高斯RBM已成为实值数据的标准能量模型，Ranzato；al.；（2010a）认为高斯RBM感应偏置不能很好地适合某些类型的实值数据", "keywords": "感应偏置不能很好地适合某些类型的实值数据, 虽然高斯, 已成为实值数据的标准能量模型, 认为高斯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1a417e1-8e3a-4cbc-bd53-7c90617cd02a", "label": "摘要20", "info": "均值和协方差RBM 　mcRBM使用隐藏单元独立地编码所有可观察单元；的条件均值和协方差。mcRBM的隐藏层分为两组单元：均值单元和协；方差单元。建模条件均值的那组单元是简单的高斯RBM。另一半是协", "keywords": "均值和协方差, 的隐藏层分为两组单元, 使用隐藏单元独立地编码所有可观察单元, 方差单元, 均值单元和协", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "445c72c0-effe-4a2d-908a-d83af27f7627", "label": "摘要21", "info": "具体来说，在二值均值的单元  h  (m)  和二值协方差单元  h  (c)  的情况下，；mcRBM模型被定义为两个能量函数的组合：", "keywords": "模型被定义为两个能量函数的组合, 的情况下, 具体来说, 在二值均值的单元, 和二值协方差单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a0c5eec-7f23-4333-88ae-0e4736279dc7", "label": "摘要22", "info": "其中E m 为标准的Gaussian-Bernoulli RBM能量函数 (2) ，", "keywords": "为标准的, 其中, 能量函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a867c8f1-e4fd-4d80-991c-66f49605c6df", "label": "摘要23", "info": "E c 是cRBM建模条件协方差信息的能量函数：", "keywords": "建模条件协方差信息的能量函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f848e8cb-67c8-4b1d-a22c-4107154518ab", "label": "摘要24", "info": "参数 r  (j) 与  关联的协方差权重向量对应，  b  (c)  是一个协方差偏置向；量。组合后的能量函数定义联合分布，", "keywords": "参数, 组合后的能量函数定义联合分布, 是一个协方差偏置向, 关联的协方差权重向量对应", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "470ff9ef-52ff-43c4-9edd-92c106054163", "label": "摘要25", "info": "以及给定  h  (m)  和  h  (c)  后，关于观察数据相应的条件分布（为一个多元；高斯分布）：", "keywords": "为一个多元, 关于观察数据相应的条件分布, 高斯分布, 以及给定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ee97bfa-51da-4c23-8538-0c2e9057eadc", "label": "摘要26", "info": "注意协方差矩阵", "keywords": "注意协方差矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "778e6e6b-5faa-448f-a42c-304b587d571e", "label": "摘要27", "info": "是非", "keywords": "是非", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c61f08f8-a1b8-46aa-9d51-732719233d27", "label": "摘要28", "info": "对角的，且  W  是与建模条件均值的高斯RBM相关联的权重矩阵。由于；非对角的条件协方差结构，难以通过对比散度或持续性对比散度来训练；mcRBM。CD和PCD需要从 x 、 h (m) 、 h (c) 的联合分布中采样，这在标", "keywords": "需要从, 非对角的条件协方差结构, 相关联的权重矩阵, 这在标, 是与建模条件均值的高斯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ca01379-9db9-4980-a351-9223e17a2a4e", "label": "摘要29", "info": ")采样，避免了直接从条件", "keywords": "避免了直接从条件, 采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4d6fcc3-058b-4e2f-a532-6c7a9a15b254", "label": "摘要30", "info": "x", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f177ff0-c26a-41fe-aa75-e857748fadd8", "label": "摘要31", "info": "抽样。", "keywords": "抽样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c509bf8b-d2a0-4f7e-9b64-f5c557ea854d", "label": "摘要32", "info": "学生t分布均值乘积 　学生t分布均值乘积（mPoT）模型（Ranzato et al.；，2010b）以类似mcRBM扩展cRBM的方式扩展PoT模型（Welling  et  al.；，2003a），通过添加类似高斯RBM中隐藏单元的非零高斯均值来实", "keywords": "分布均值乘积, 中隐藏单元的非零高斯均值来实, 学生, 的方式扩展, 扩展", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ec1e8be-5825-47cd-9156-0f3b2b5fda5a", "label": "摘要33", "info": "是关于正实数且", "keywords": "是关于正实数且", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79e8e663-2594-4dc5-a10e-78835dc36cea", "label": "摘要34", "info": "mPoT的能量函数为", "keywords": "的能量函数为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1e3040ee-6734-4047-a83e-b38f2301726e", "label": "摘要35", "info": "其中  r  (j)  是与单元   相关联的协方差权重向量，；（20.44）所定义。", "keywords": "所定义, 其中, 是与单元, 相关联的协方差权重向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a21a5bd-d729-482d-a66f-432488f65593", "label": "摘要36", "info": "如式", "keywords": "如式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "329fd871-da0d-4183-88b9-e417c6fb242c", "label": "摘要37", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；正如mcRBM一样，mPoT模型能量函数指定一个多元高斯分布，其中关；x  的条件分布具有非对角的协方差。mPoT模型中的学习（也像", "keywords": "正如, 其中关, 一样, 模型中的学习, 也像", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c647f2c2-8324-4bb7-9c78-cf50c89c3334", "label": "摘要38", "info": "尖峰和平板RBM  　尖峰和平板RBM（spike  and  slab  RBM，ssRBM）；（Courville et  al.  ，2011b）提供对实值数据的协方差结构建模的另一种；方法。与mcRBM相比，ssRBM具有既不需要矩阵求逆也不需要哈密尔", "keywords": "提供对实值数据的协方差结构建模的另一种, 相比, 尖峰和平板, 具有既不需要矩阵求逆也不需要哈密尔, 方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "338a6c60-b250-45b9-b42c-efd1b68f4cf5", "label": "摘要39", "info": "尖峰和平板RBM有两类隐藏单元：二值尖峰  （spike）单元h  和实值平；板  （slab）单元s  。条件于隐藏单元的可见单元均值由；给", "keywords": "二值尖峰, 条件于隐藏单元的可见单元均值由, 和实值平, 尖峰和平板, 单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "04648613-a4ee-4976-b703-236826289c68", "label": "摘要40", "info": "运的是，使用Gibbs采样的对比散度和持续性对比散度仍然适用。此处；无须对任何矩阵求逆。", "keywords": "运的是, 无须对任何矩阵求逆, 使用, 采样的对比散度和持续性对比散度仍然适用, 此处", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "572a8dd6-d7f3-4bfb-bf5e-e874eb0b65d1", "label": "摘要41", "info": "形式上，ssRBM模型通过其能量函数定义：", "keywords": "形式上, 模型通过其能量函数定义", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e33e66e3-45ce-4b20-b9cf-d8cd33f47c8f", "label": "摘要42", "info": "其中b i 是尖峰h i 的偏置，Λ 是观测值 x 上的对角精度矩阵。参数α i ＞0；是实值平板变量s i 的标量精度参数。参数Φ  i  是定义 x 上的 h 调制二次；惩罚的非负对角矩阵。每个μ i 是平板变量s i 的均值参数。", "keywords": "是平板变量, 参数, 是定义, 是观测值, 调制二次", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a0d4a1f2-4b9f-486c-bc81-2e17501ba8a0", "label": "摘要43", "info": "利用能量函数定义的联合分布，能相对容易地导出ssRBM条件分布。例；如，通过边缘化平板变量 s ，给定二值尖峰变量 h ，关于观察量的条件；分布由下式给出", "keywords": "关于观察量的条件, 利用能量函数定义的联合分布, 通过边缘化平板变量, 分布由下式给出, 条件分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3361bdc-e465-4a69-96e9-c81c5d27dc83", "label": "摘要44", "info": "其中；有在协方差矩阵", "keywords": "其中, 有在协方差矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e213490-c77e-4f9b-962d-13984206f3ab", "label": "摘要45", "info": "正定时成立。", "keywords": "正定时成立", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed8e4748-0f0f-41f8-9a7b-fdbfbe091e83", "label": "摘要46", "info": "。最后的等式只", "keywords": "最后的等式只", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "34105398-0d52-4d70-8191-1d4e35e9348e", "label": "摘要47", "info": "尖峰变量选通意味着h  ⊙s  上的真实边缘分布是稀疏的。这不同于稀疏；编码，其中来自模型的样本在编码中“几乎从不”（在测度理论意义上）；包含零，并且需要MAP推断来强加稀疏性。", "keywords": "上的真实边缘分布是稀疏的, 并且需要, 编码, 这不同于稀疏, 尖峰变量选通意味着", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0dd40631-b674-4c9f-94bb-829e4d08e4de", "label": "摘要48", "info": "相比mcRBM和mPoT模型，ssRBM以明显不同的方式参数化观察量的条；件协方差。mcRBM和mPoT都通过；建模观察量的", "keywords": "都通过, 建模观察量的, 模型, 件协方差, 相比", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "250f80a3-546a-46aa-a6cb-9d8fbe497ee8", "label": "摘要49", "info": "尖峰和平板RBM的主要缺点是，参数的一些设置会对应于非正定的协；方差矩阵。这种协方差矩阵会在离均值更远的值上放置更大的未归一化；概率，导致所有可能结果上的积分发散。通常这个问题可以通过简单的", "keywords": "通常这个问题可以通过简单的, 的主要缺点是, 参数的一些设置会对应于非正定的协, 这种协方差矩阵会在离均值更远的值上放置更大的未归一化, 概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0fee9f5f-5a40-4f6a-8165-5426dcf36146", "label": "摘要50", "info": "定性地，ssRBM的卷积变体能产生自然图像的优秀样本。图16.1中展示；了一些样例。", "keywords": "了一些样例, 的卷积变体能产生自然图像的优秀样本, 定性地, 中展示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "41f97cb9-f8f1-40dc-9c95-1d66bbbf4352", "label": "摘要51", "info": "ssRBM允许几个扩展，包括平板变量的高阶交互和平均池化（Courville；et  al.  ，2014）使得模型能够在标注数据稀缺时为分类器学习到出色的", "keywords": "使得模型能够在标注数据稀缺时为分类器学习到出色的, 允许几个扩展, 包括平板变量的高阶交互和平均池化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aaa279ff-7e30-43e4-a6b7-ea089f8dda29", "label": "摘要52", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；特征。向能量函数添加一项能防止配分函数在稀疏编码模型下变得不确；定，如尖峰和平板稀疏编码（Goodfellow  et  al.  ，2013g），也称为", "keywords": "向能量函数添加一项能防止配分函数在稀疏编码模型下变得不确, 如尖峰和平板稀疏编码, 特征, 也称为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6f03617-dbdc-4310-8dbf-889159030c18", "label": "摘要53", "info": "20.5.1　Gaussian-；Bernoulli RBM", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2299ebba-5f4f-466b-881d-686f8607416e", "label": "摘要54", "info": "20.5.2　条件协方差的无；向模型", "keywords": "向模型, 条件协方差的无", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "label": "20.6：卷积玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "61ea67f4-6ff6-4989-9b92-286f218dafe8", "label": "摘要1", "info": "如第9章所示，超高维度输入（如图像）会对机器学习模型的计算、内；存和统计要求造成很大的压力。通过使用小核的离散卷积来替换矩阵乘；法是解决具有空间平移不变性或时间结构的输入问题的标准方式。", "keywords": "通过使用小核的离散卷积来替换矩阵乘, 章所示, 如图像, 法是解决具有空间平移不变性或时间结构的输入问题的标准方式, 如第", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5984fc02-df9e-4886-938e-114589706396", "label": "摘要2", "info": "深度卷积网络通常需要池化操作，使得每个连续层的空间大小减小。前；馈卷积网络通常使用池化函数，例如池化元素的最大值。目前尚不清楚；如何将其推广到基于能量的模型的设定中。我们可以在n个二值检测器", "keywords": "使得每个连续层的空间大小减小, 深度卷积网络通常需要池化操作, 例如池化元素的最大值, 个二值检测器, 馈卷积网络通常使用池化函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c275cff1-74f9-421a-a760-a8b2e67dd83c", "label": "摘要3", "info": "et", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a6f5e19-dab5-4b96-a3c5-745b22fe64a3", "label": "摘要4", "info": "al.  （2009）针对这个问题，开发了一个称为概率最大池化；Lee；（probabilistic  max  pooling）的解决方案（不要与“随机池化”混淆，“随", "keywords": "针对这个问题, 混淆, 的解决方案, 随机池化, 开发了一个称为概率最大池化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "adc947d3-41f7-43e8-a0de-da98c628e5c2", "label": "摘要5", "info": "虽然高效的概率最大池化确实能强迫检测器单元互斥，这在某些情景下；可能是有用的正则化约束，而在其他情景下是对模型容量有害的限制。；它也不支持重叠池化区域。从前馈卷积网络获得最佳性能通常需要重叠", "keywords": "可能是有用的正则化约束, 这在某些情景下, 它也不支持重叠池化区域, 从前馈卷积网络获得最佳性能通常需要重叠, 而在其他情景下是对模型容量有害的限制", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61129ccc-5e38-4c01-bc9f-c224bd1506e9", "label": "摘要6", "info": "Lee et al. （2009）证明概率最大池化可以用于构建卷积深度玻尔兹曼机", "keywords": "证明概率最大池化可以用于构建卷积深度玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bf46afb-c32c-4144-80b6-7a1cbd4b963b", "label": "摘要7", "info": "(3) 。该模型能够执行诸如填补输入缺失部分的操作。虽然这种模型在理；论上有吸引力，让它在实践中工作是具有挑战性的，作为分类器通常不；如通过监督训练的传统卷积网络。", "keywords": "作为分类器通常不, 如通过监督训练的传统卷积网络, 虽然这种模型在理, 该模型能够执行诸如填补输入缺失部分的操作, 论上有吸引力", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a5181f3f-390b-4551-ba1d-2a5d2a089985", "label": "摘要8", "info": "许多卷积模型对于许多不同空间大小的输入同样有效。对于玻尔兹曼；机，由于各种原因很难改变输入尺寸。配分函数随着输入大小的改变而；改变。此外，许多卷积网络按与输入大小成比例地缩放池化区域来实现", "keywords": "由于各种原因很难改变输入尺寸, 此外, 改变, 配分函数随着输入大小的改变而, 许多卷积模型对于许多不同空间大小的输入同样有效", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca1a3447-a095-4c4d-af99-d498c718c897", "label": "摘要9", "info": "图像边界处的像素也带来一些困难，由于玻尔兹曼机中的连接是对称的；事实而加剧。如果我们不隐式地补零输入，则将会导致比可见单元更少；的隐藏单元，并且图像边界处的可见单元将不能被良好地建模，因为它", "keywords": "并且图像边界处的可见单元将不能被良好地建模, 则将会导致比可见单元更少, 的隐藏单元, 由于玻尔兹曼机中的连接是对称的, 事实而加剧", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abf85f07-ecac-42f0-92a7-26f6e6d736ed", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；20.7　用于结构化或序列输出的玻尔兹曼机", "keywords": "用于结构化或序列输出的玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "label": "20.7：用于结构化或序列输出的玻尔兹曼", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "9d8507f1-dd92-4d1a-a690-9eda1f8c1bb6", "label": "摘要1", "info": "在结构化输出场景中，我们希望训练可以从一些输入 x 映射到一些输出；y  的模型，  y  的不同条目彼此相关，并且必须遵守一些约束。例如，在", "keywords": "并且必须遵守一些约束, 在结构化输出场景中, 映射到一些输出, 我们希望训练可以从一些输入, 的模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "535bf1c5-964b-4bd5-b5ab-9a70db44c638", "label": "摘要2", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；语音合成任务中， y 是波形，并且整个波形听起来必须像连贯的发音。", "keywords": "并且整个波形听起来必须像连贯的发音, 语音合成任务中, 是波形", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a24ec338-38a0-408d-9c9b-c709ea813f0f", "label": "摘要3", "info": "表示 y 中的条目之间关系的自然方式是使用概率分布p( y ｜ x )。扩展到；建模条件分布的玻尔兹曼机可以支持这种概率模型。", "keywords": "表示, 中的条目之间关系的自然方式是使用概率分布, 建模条件分布的玻尔兹曼机可以支持这种概率模型, 扩展到", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "89a19c4b-9103-444a-8ecd-fae7ec427bbf", "label": "摘要4", "info": "使用玻尔兹曼机条件建模的相同工具不仅可以用于结构化输出任务，还；可以用于序列建模。在后一种情况下，模型必须估计变量序列上的概率；，而不仅仅是将输入 x 映射到输出 y 。为完成这", "keywords": "可以用于序列建模, 模型必须估计变量序列上的概率, 在后一种情况下, 而不仅仅是将输入, 使用玻尔兹曼机条件建模的相同工具不仅可以用于结构化输出任务", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11f36576-de68-41b9-8e10-be7c03b6572a", "label": "摘要5", "info": "视频游戏和电影工业中一个重要序列建模任务是建模用于渲染3-D人物；骨架关节角度的序列。这些序列通常通过记录角色移动的运动捕获系统；收集。人物运动的概率模型允许生成新的（之前没见过的）但真实的动", "keywords": "这些序列通常通过记录角色移动的运动捕获系统, 人物, 人物运动的概率模型允许生成新的, 但真实的动, 之前没见过的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "06cfc48e-9a57-491d-b842-3ab646c079f8", "label": "摘要6", "info": "。该模型是", "keywords": "该模型是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d3b58d9-b7cd-4c73-ab15-9d60fe393f62", "label": "摘要7", "info": "另一个序列建模任务是对构成歌曲音符序列的分布进行建模。；Boulanger-Lewandowski et  al.  （2012）引入了RNN-RBM  序列模型并应；用于这个任务。RNN-RBM由RNN（产生用于每个时间步的RBM参数）", "keywords": "参数, 另一个序列建模任务是对构成歌曲音符序列的分布进行建模, 用于这个任务, 序列模型并应, 产生用于每个时间步的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "label": "20.8：其他玻尔兹曼机", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "d8e5fcbd-2657-44b5-86b7-794cdff7b044", "label": "摘要1", "info": "玻尔兹曼机的许多其他变种是可能的。", "keywords": "玻尔兹曼机的许多其他变种是可能的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b1623b0f-7328-4c41-bc70-74a3f5e36873", "label": "摘要2", "info": "玻尔兹曼机可以用不同的训练准则扩展。我们专注于训练为大致最大化；生成标准log p( ν )的玻尔兹曼机。相反，旨在最大化log p(y｜  ν )来训练；判别的RBM也是有可能的（Larochelle  and  Bengio，2008a）。当使用生", "keywords": "来训练, 也是有可能的, 当使用生, 旨在最大化, 判别的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a9cbadd-42dc-4934-90a5-95e86a416d66", "label": "摘要3", "info": "在实践中使用的大多数玻尔兹曼机在其能量函数中仅具有二阶相互作；用，意味着它们的能量函数是许多项的和，并且每个单独项仅包括两个；随机变量之间的乘积。这种项的一个例子是ν i W i,j h j 。我们还可以训练", "keywords": "在实践中使用的大多数玻尔兹曼机在其能量函数中仅具有二阶相互作, 这种项的一个例子是, 意味着它们的能量函数是许多项的和, 我们还可以训练, 随机变量之间的乘积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "69fab4db-851a-4af1-9655-746e0186948b", "label": "摘要4", "info": "更一般地说，玻尔兹曼机框架是一个丰富的模型空间，允许比迄今为止；已经探索的更多的模型结构。开发新形式的玻尔兹曼机相比于开发新的；神经网络层需要更多细心和创造力，因为它通常很难找到一个能保持玻", "keywords": "已经探索的更多的模型结构, 因为它通常很难找到一个能保持玻, 玻尔兹曼机框架是一个丰富的模型空间, 开发新形式的玻尔兹曼机相比于开发新的, 更一般地说", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e5deb96-8260-48bd-9ad0-6fa460904796", "label": "摘要5", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；20.9　通过随机操作的反向传播", "keywords": "通过随机操作的反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55ea90bc-4eaa-452c-88b5-c9f3a4492d70", "label": "摘要6", "info": "传统的神经网络对一些输入变量  x  施加确定性变换。当开发生成模型；时，我们经常希望扩展神经网络以实现 x 的随机变换。这样做的一个直；接方法是使用额外输入  z  （从一些简单的概率分布采样得到，如均匀或", "keywords": "的随机变换, 施加确定性变换, 如均匀或, 这样做的一个直, 传统的神经网络对一些输入变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "48225add-0077-4bf1-b6a8-4e6dfd33b907", "label": "摘要7", "info": "作为示例，让我们考虑从均值μ和方差σ 2 的高斯分布中采样y的操作：", "keywords": "让我们考虑从均值, 的高斯分布中采样, 和方差, 作为示例, 的操作", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "75b9d8be-5e36-469e-82a4-931ecc3ee81c", "label": "摘要8", "info": "因为y的单个样本不是由函数产生的，而是由一个采样过程产生，它的；输出会随我们的每次查询发生变化，所以取y相对于其分布的参数μ和σ 2；的导数似乎是违反直觉的。然而，我们可以将采样过程重写，对基本随", "keywords": "因为, 它的, 所以取, 而是由一个采样过程产生, 然而", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "843f0f2b-5ec7-4933-925a-3f604fc95c57", "label": "摘要9", "info": "进行转换以从期望的分布获得样本：", "keywords": "进行转换以从期望的分布获得样本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2666bd33-a5c4-475a-87bc-ed8eadb36674", "label": "摘要10", "info": "现在我们将其视为具有额外输入z的确定性操作，可以通过采样操作来；反向传播。至关重要的是，额外输入是一个随机变量，其分布不是任何；我们想对其计算导数的变量的函数。如果我们可以用相同的z值再次重", "keywords": "我们想对其计算导数的变量的函数, 现在我们将其视为具有额外输入, 的确定性操作, 其分布不是任何, 可以通过采样操作来", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "216690c1-4e5f-4567-92f2-d8a681964a47", "label": "摘要11", "info": "能够通过该采样操作反向传播允许我们将其并入更大的图中。我们可以；在采样分布的输出之上构建图元素。例如，我们可以计算一些损失函数；J(y)的导数。我们还可以构建这样的图元素，其输出是采样操作的输入", "keywords": "我们可以, 我们还可以构建这样的图元素, 在采样分布的输出之上构建图元素, 例如, 能够通过该采样操作反向传播允许我们将其并入更大的图中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1b1ed431-a41e-4475-b812-4601765cce81", "label": "摘要12", "info": "构建更大", "keywords": "构建更大", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abeb7299-9ce0-4965-a78e-6d381563badf", "label": "摘要13", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cedbd97a-aef3-4d50-9e94-685ae4445355", "label": "摘要14", "info": "。", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0b2b897-4b3c-4152-9bc7-4dbe27afa67b", "label": "摘要15", "info": "在该高斯采样示例中使用的原理能更广泛地应用。我们可以将任何形为；，其中   是同时包；p(y;  θ )或p(y｜ x  ; θ  )的概率分布表示为", "keywords": "在该高斯采样示例中使用的原理能更广泛地应用, 的概率分布表示为, 其中, 我们可以将任何形为, 是同时包", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6a59f15-e2a2-4cf8-a0b5-5570553f9df5", "label": "摘要16", "info": "含参数 θ 和输入 x  的变量（如果适用的话）。给定从分布；样的值y（其中  可以是其他变量的函数），我们可以将", "keywords": "含参数, 如果适用的话, 给定从分布, 我们可以将, 可以是其他变量的函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4dba5878-5cb9-4737-8e79-3f4fb4c68217", "label": "摘要17", "info": "采", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5b84d4e-84e1-4f48-b7e9-69897998b417", "label": "摘要18", "info": "重写为", "keywords": "重写为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2dedc941-6592-4cd4-ae2c-5ac6e94bda21", "label": "摘要19", "info": "其中  z  是随机性的来源。只要f是几乎处处连续可微的，我们就可以使；用传统工具（例如应用于f的反向传播算法）计算y相对于   的导数。；至关重要的是，  不能是 z 的函数，且 z 不能是  的函数。这种技术", "keywords": "用传统工具, 是随机性的来源, 的反向传播算法, 相对于, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d25c386-97aa-4c45-8ff8-f85b0944fd8a", "label": "摘要20", "info": "要求f是连续可微的，当然需要  y  是连续的。如果我们希望通过产生离；散值样本的采样过程进行反向传播，则可以使用强化学习算法（如；REINFORCE算法（Williams，1992）的变体）来估计   上的梯度，这", "keywords": "要求, 算法, 的变体, 则可以使用强化学习算法, 当然需要", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2862143b-7eaf-4535-a0e8-d684805be7b7", "label": "摘要21", "info": "在神经网络应用中，我们通常选择从一些简单的分布中采样  z  ，如单位；均匀分布或单位高斯分布，并通过网络的确定性部分重塑其输入来实现；更复杂的分布。", "keywords": "均匀分布或单位高斯分布, 在神经网络应用中, 更复杂的分布, 如单位, 并通过网络的确定性部分重塑其输入来实现", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "655de17b-bc96-4193-98dd-55c9c5429fb2", "label": "摘要22", "info": "通过随机操作扩展梯度或优化的想法可追溯到20世纪中叶（Price，；1958；Bonnet，1964），并且首先在强化学习（Williams，1992）的情；景下用于机器学习。最近，它已被应用于变分近似（Opper", "keywords": "世纪中叶, 的情, 通过随机操作扩展梯度或优化的想法可追溯到, 并且首先在强化学习, 最近", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc50e231-0c8a-44e3-933a-afbd3203554f", "label": "摘要23", "info": "20.9.1　通过离散随机操作的反向传播", "keywords": "通过离散随机操作的反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "533e56c5-4a57-4f3b-bb36-1f9521abc989", "label": "摘要24", "info": "当模型发射离散变量  y  时，重参数化技巧不再适用。假设模型采用输入", "keywords": "假设模型采用输入, 重参数化技巧不再适用, 当模型发射离散变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f9c9fab8-a195-4fdb-a4cf-323d875ed265", "label": "摘要25", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；x 和参数 θ  ，两者都封装在向量   中，并且将它们与随机噪声  z  组合；以产生 y ：", "keywords": "以产生, 并且将它们与随机噪声, 和参数, 组合, 两者都封装在向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97da71b4-b9f8-4050-ac89-4fc480b30a12", "label": "摘要26", "info": "因为  y  是离散的，f必须是一个阶跃函数。阶跃函数的导数在任何点都；是没用的。在每个阶跃边界，导数是未定义的，但这是一个小问题。大；问题是导数在阶跃边界之间的区域几乎处处为零。因此，任何代价函数", "keywords": "因为, 但这是一个小问题, 必须是一个阶跃函数, 在每个阶跃边界, 因此", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88fa6a5a-0a9a-4f79-8428-8a337fe07c79", "label": "摘要27", "info": "REINFORCE算法（REward；Increment  ＝  nonnegative  Factor×Offset；Reinforcement×Characteristic  Eligibility）提供了定义一系列简单而强大", "keywords": "提供了定义一系列简单而强大, 算法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c89fe78-4f7e-44b3-81fd-102522d2bf61", "label": "摘要28", "info": "是具有无用导数的阶跃函数，期望代价；通常是服从梯度下降的光滑函数。虽然当  y  是高维；（或者是许多离散随机决策组合的结果）时，该期望通常是难解的，但", "keywords": "是高维, 或者是许多离散随机决策组合的结果, 虽然当, 期望代价, 通常是服从梯度下降的光滑函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4b228a8e-74a4-4733-9d69-a481fb4556a3", "label": "摘要29", "info": "通过简单地微分期望成本，我们可以推导出REINFORCE最简单的版；本：", "keywords": "我们可以推导出, 最简单的版, 通过简单地微分期望成本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49569209-bbfb-4495-be0e-36f04959c919", "label": "摘要30", "info": "式（20.60）依赖于J不直接引用   的假设。放松这个假设来扩展该方；法是简单的。式（20.61）利用对数的导数规则，", "keywords": "不直接引用, 依赖于, 放松这个假设来扩展该方, 利用对数的导数规则, 法是简单的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5deb1abe-c2f5-4449-b8fc-c017f59753ec", "label": "摘要31", "info": "。式（20.62）给出了该梯度的无偏蒙", "keywords": "给出了该梯度的无偏蒙", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f392d21c-daa6-47e4-aa97-11272f0b6807", "label": "摘要32", "info": "特卡罗估计。", "keywords": "特卡罗估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9fa59c22-8a73-4996-89a4-a8d6e44d379d", "label": "摘要33", "info": "在本节中我们写的", "keywords": "在本节中我们写的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "67057cda-cbed-4e59-8bc6-f233ba224074", "label": "摘要34", "info": "，可以等价地写成", "keywords": "可以等价地写成", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bfeed1f5-5f1c-42cf-a54e-abdae4a81b97", "label": "摘要35", "info": "。这是因为", "keywords": "这是因为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9afcda2b-477a-4eef-bb44-d41b587fb97b", "label": "摘要36", "info": "由", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e83d1a4b-7563-41b4-b96d-7a15d4cec6e3", "label": "摘要37", "info": "参数化，并且如果 x 存在，则", "keywords": "并且如果, 参数化, 存在", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0669b0e5-2d26-4a97-8ca9-606f5266d67a", "label": "摘要38", "info": "包含 θ 和 x 两者。", "keywords": "两者, 包含", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "08e181de-bd53-45cc-951d-ffedc85ced48", "label": "摘要39", "info": "简单REINFORCE估计的一个问题是其具有非常高的方差，需要采  y  的；许多样本才能获得对梯度的良好估计，或者等价地，如果仅绘制一个样；本，则SGD将收敛得非常缓慢并将需要较小的学习率。通过使用方差减", "keywords": "许多样本才能获得对梯度的良好估计, 如果仅绘制一个样, 简单, 需要采, 将收敛得非常缓慢并将需要较小的学习率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6ef6373-9f2b-40ce-b8d0-114ecaf10f7b", "label": "摘要40", "info": "这意味着", "keywords": "这意味着", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a3e0a67-92a9-47bb-8c66-fbc4e7d4a4c7", "label": "摘要41", "info": "此外，我们可以通过计算", "keywords": "此外, 我们可以通过计算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a20c15d-f0b0-42a6-afb8-2bfa41f07720", "label": "摘要42", "info": "关于p( y )的方差，并关于；最佳基线", "keywords": "最佳基线, 并关于, 关于, 的方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49468c0d-0e37-4102-9024-3e42b4c9372b", "label": "摘要43", "info": "对于向量", "keywords": "对于向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bde6c473-0be8-44fa-874c-584c452c1a83", "label": "摘要44", "info": "最小化获得最优；的每个元素ω i 是不同的：", "keywords": "最小化获得最优, 的每个元素, 是不同的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "574af17b-b738-4f8c-8903-12e3e806b9da", "label": "摘要45", "info": "。我们发现这个", "keywords": "我们发现这个", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b48ee6b-058a-4632-9d3d-cc73589ee62f", "label": "摘要46", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；相对于ω i 的梯度估计则变为", "keywords": "的梯度估计则变为, 相对于", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8959be29-dad2-4b9b-8d05-f3de49aaebd7", "label": "摘要47", "info": "其中；神经网络，并训练新输出对", "keywords": "神经网络, 并训练新输出对, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2fea4b4f-95f2-42bf-81bc-7d90315be28e", "label": "摘要48", "info": "估计上述", "keywords": "估计上述", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6bcb0e18-a874-4fe0-a82b-efba6001a76f", "label": "摘要49", "info": "。获得估计b通常需要将额外输出添加到；的每个元素估计", "keywords": "获得估计, 通常需要将额外输出添加到, 的每个元素估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc5df8ee-1b31-4196-bd88-3ccabef4e375", "label": "摘要50", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a8e26b1-ca24-4649-9513-18b5a821a314", "label": "摘要51", "info": "。这", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2878d5c5-daf1-480f-a7fd-8386eb81fd22", "label": "摘要52", "info": "些额外的输出可以用均方误差目标训练，对于给定的", "keywords": "对于给定的, 些额外的输出可以用均方误差目标训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "01012835-9cfc-4e50-9e7a-5981f1e92770", "label": "摘要53", "info": "，从p(  y  )采", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b935bd98-fda0-4ec4-8b72-3d86f6ca9eb5", "label": "摘要54", "info": "样  y  时，分别用", "keywords": "分别用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "91783241-db9d-4013-bd14-6953784f03ab", "label": "摘要55", "info": "和", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "045318aa-d478-4b44-8584-79b386a5570e", "label": "摘要56", "info": "作目标。然", "keywords": "作目标", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2f50a22-0165-419f-a8a9-33cd059f61b9", "label": "摘要57", "info": "后可以将这些估计代入式（20.68）就能恢复估计b。Mnih；Gregor（2014）倾向于使用通过目标J(  y", "keywords": "倾向于使用通过目标, 后可以将这些估计代入式, 就能恢复估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "87869ad1-649e-4195-9b4c-e95c467a301a", "label": "摘要58", "info": "and；)训练的单个共享输出（跨越", "keywords": "跨越, 训练的单个共享输出", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90e528f1-860d-44dd-aa76-e2fdf4552132", "label": "摘要59", "info": "的所有元素i），并使用", "keywords": "并使用, 的所有元素", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "984e2757-0b08-4037-8822-bfb75702b53d", "label": "摘要60", "info": "作为基线。", "keywords": "作为基线", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "486f530d-e06c-4ef1-bb42-d1212a994ba5", "label": "摘要61", "info": "在强化学习背景下引入的方差减小方法（Sutton  et  al.  ，2000；Weaver；and  Tao，2001），Dayan（1990）推广了二值奖励的前期工作。可以参；考Bengio  et  al.  （2013b）、Mnih  and  Gregor（2014）、Ba  et  al.", "keywords": "可以参, 推广了二值奖励的前期工作, 在强化学习背景下引入的方差减小方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49d42f5a-30b0-4670-9753-9b8775a72c5b", "label": "摘要62", "info": "，Mnih  and  Gregor（2014）发现可以在训练期间调整；的尺度（即除以训练期间的移动平均估计的标准；差），即作为一种适应性学习率，可以抵消训练过程中该量大小发生的", "keywords": "的尺度, 可以抵消训练过程中该量大小发生的, 发现可以在训练期间调整, 即除以训练期间的移动平均估计的标准, 即作为一种适应性学习率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "00e3db42-1032-48c6-8db3-8dc3f9e13f74", "label": "摘要63", "info": "基于REINFORCE的估计器可以被理解为将  y  的选择与J(  y  )的对应值相；关联来估计梯度。如果在当前参数化下不太可能出现 y  的良好值，则可；能需要很长时间来偶然获得它，并且获得所需信号的配置应当被加强。", "keywords": "如果在当前参数化下不太可能出现, 则可, 的对应值相, 的估计器可以被理解为将, 能需要很长时间来偶然获得它", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e821fa93-7cca-43ca-981e-4124a6bec684", "label": "20.9：通过随机操作的反向传播", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "e309f28e-c0f5-4145-ba5c-aad0be9d6779", "label": "摘要1", "info": "20.9.1　通过离散随机操作的反向传播", "keywords": "通过离散随机操作的反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "398bf631-fc48-4915-b749-73c87de888ce", "label": "摘要2", "info": "20.9.1　通过离散随机操；作的反向传播", "keywords": "通过离散随机操, 作的反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "label": "20.10：有向生成网络", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "b6afa81d-d158-481b-95af-55e3476df0d8", "label": "摘要1", "info": "20.10.1　sigmoid信念网络", "keywords": "信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f969bab9-9d5b-44dd-b3f1-687d2c4eac25", "label": "摘要2", "info": "20.10.2　可微生成器网络", "keywords": "可微生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4583208f-55b6-41da-bc81-fc16fb37cc30", "label": "摘要3", "info": "20.10.3　变分自编码器", "keywords": "变分自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f84836a4-333a-4387-aee7-8c05b6daee27", "label": "摘要4", "info": "20.10.4　生成式对抗网络", "keywords": "生成式对抗网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5dbe8f4-85a4-4552-bb1c-e31c4007e260", "label": "摘要5", "info": "20.10.5　生成矩匹配网络", "keywords": "生成矩匹配网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0ec2849-a349-4923-aa55-42dea3f772e9", "label": "摘要6", "info": "20.10.6　卷积生成网络", "keywords": "卷积生成网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "714de004-757b-4b5d-b77e-2e3a2d29e032", "label": "摘要7", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；20.10.7　自回归网络", "keywords": "自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e724d383-bca5-4462-9be4-708634dace03", "label": "摘要8", "info": "20.10.8　线性自回归网络", "keywords": "线性自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7fd4849b-046f-456e-a5a0-35c3f0a83666", "label": "摘要9", "info": "20.10.9　神经自回归网络", "keywords": "神经自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2006ea62-f48c-4704-b993-acfe22c969b4", "label": "摘要10", "info": "20.10.10　NADE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61f3b5a0-b503-4080-a27e-b3e92af48c51", "label": "摘要11", "info": "如第16章所讨论的，有向图模型构成了一类突出的图模型。虽然有向图", "keywords": "虽然有向图, 章所讨论的, 如第, 有向图模型构成了一类突出的图模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e980fd2-ed34-4a37-90f1-79cd654ee631", "label": "摘要12", "info": "模型在更大的机器学习社群中非常流行，但在较小的深度学习社群中，；大约直到2013年它们都掩盖在无向模型（如RBM）的光彩之下。", "keywords": "大约直到, 年它们都掩盖在无向模型, 的光彩之下, 但在较小的深度学习社群中, 模型在更大的机器学习社群中非常流行", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0dab2cd2-3752-4586-a06e-39f136cc63a3", "label": "摘要13", "info": "在本节中，我们回顾一些传统上与深度学习社群相关的标准有向图模；型。", "keywords": "在本节中, 我们回顾一些传统上与深度学习社群相关的标准有向图模", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39fc2299-3734-4e2d-96c6-530ddac09e33", "label": "摘要14", "info": "我们已经描述过部分有向的模型——深度信念网络。我们还描述过可以；被认为是浅度有向生成模型的稀疏编码模型。尽管在样本生成和密度估；计方面表现不佳，在深度学习的背景下它们通常被用作特征学习器。我", "keywords": "我们已经描述过部分有向的模型, 我们还描述过可以, 在深度学习的背景下它们通常被用作特征学习器, 尽管在样本生成和密度估, 深度信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0439ab2d-53aa-4eb0-8f5c-61e17ade8198", "label": "摘要15", "info": "20.10.1　sigmoid信念网络", "keywords": "信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d029aaa2-3d04-4841-930d-e3c6df7d4ba8", "label": "摘要16", "info": "sigmoid信念网络（Neal，1990）是一种具有特定条件概率分布的有向图；模型的简单形式。一般来说，我们可以将sigmoid信念网络视为具有二；值向量的状态s ，其中状态的每个元素都受其祖先影响：", "keywords": "我们可以将, 信念网络视为具有二, 信念网络, 模型的简单形式, 一般来说", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b0d72b1e-edf0-4bad-9a78-61b3b9fa06f0", "label": "摘要17", "info": "sigmoid信念网络最常见的结构是被分为许多层的结构，其中原始采样；通过一系列多个隐藏层进行，然后最终生成可见层。这种结构与深度信；念网络非常相似，但它们在采样过程开始时的单元彼此独立，而不是从", "keywords": "然后最终生成可见层, 念网络非常相似, 其中原始采样, 但它们在采样过程开始时的单元彼此独立, 而不是从", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12474f75-ea2c-49df-a59d-91df055c05c1", "label": "摘要18", "info": "虽然生成可见单元的样本在sigmoid信念网络中是非常高效的，但是其；他大多数操作不是很高效。给定可见单元，对隐藏单元的推断是难解；的。因为变分下界涉及对包含整个层的团求期望，均匀场推断也是难以", "keywords": "给定可见单元, 虽然生成可见单元的样本在, 他大多数操作不是很高效, 均匀场推断也是难以, 但是其", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e809ce24-c629-48c6-b4cb-0896ca645561", "label": "摘要19", "info": "在sigmoid信念网络中执行推断的一种方法是构造专用于sigmoid信念网；络的不同下界（Saul  et  al.  ，1996）。这种方法只适用于非常小的网；络。另一种方法是使用学成推断机制，如第19.5节中描述的。Helmholtz", "keywords": "节中描述的, 另一种方法是使用学成推断机制, 如第, 络的不同下界, 信念网", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af5dda23-a3ec-463e-bebe-8bc1058a0a62", "label": "摘要20", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；机（Dayan et  al. ，1995；Dayan and Hinton，1996）结合了一个sigmoid；信念网络与一个预测隐藏单元上均匀场分布参数的推断网络。sigmoid", "keywords": "结合了一个, 信念网络与一个预测隐藏单元上均匀场分布参数的推断网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0678b3e-c7e5-4c91-b4a1-60c06b5a8532", "label": "摘要21", "info": "sigmoid信念网络的一种特殊情况是没有潜变量的情况。在这种情况下；学习是高效的，因为没有必要将潜变量边缘化到似然之外。一系列称为；自回归网络的模型将这个完全可见的信念网络泛化到其他类型的变量", "keywords": "自回归网络的模型将这个完全可见的信念网络泛化到其他类型的变量, 因为没有必要将潜变量边缘化到似然之外, 在这种情况下, 一系列称为, 学习是高效的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9487284b-d0d4-4d59-a513-0f45f2a9f6f6", "label": "摘要22", "info": "20.10.2　可微生成器网络", "keywords": "可微生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "415275ce-0323-4783-8fba-92e29e848d7d", "label": "摘要23", "info": "许多生成模型基于使用可微生成器网络  （generator  network）的想法。；将潜变量z  的样本变换为样本x  或样；这种模型使用可微函数", "keywords": "的想法, 的样本变换为样本, 许多生成模型基于使用可微生成器网络, 这种模型使用可微函数, 将潜变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2acd478e-0b2f-489f-9bc9-23cb89913e5d", "label": "摘要24", "info": "生成器网络本质上仅是用于生成样本的参数化计算过程，其中的体系结；构提供了从中采样的可能分布族以及选择这些族内分布的参数。", "keywords": "构提供了从中采样的可能分布族以及选择这些族内分布的参数, 其中的体系结, 生成器网络本质上仅是用于生成样本的参数化计算过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e32b26cc-b42f-47a3-aca7-387e814822bc", "label": "摘要25", "info": "作为示例，从具有均值 μ 和协方差Σ 的正态分布绘制样本的标准过程是；将来自零均值和单位协方差的正态分布的样本  z  馈送到非常简单的生成；器网络中。这个生成器网络只包含一个仿射层：", "keywords": "和协方差, 的正态分布绘制样本的标准过程是, 作为示例, 馈送到非常简单的生成, 这个生成器网络只包含一个仿射层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d2e8add-8b47-4dc3-bf6e-d46ac15b958c", "label": "摘要26", "info": "其中 L 由Σ 的Cholesky分解给出。", "keywords": "分解给出, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "40d43d69-b2e1-490d-a1b6-c1673a54aea4", "label": "摘要27", "info": "伪随机数发生器也可以使用简单分布的非线性变换。例如，逆变换采样；（inverse transform sampling）（Devroye，2013）从U(0,1)中采一个标量", "keywords": "伪随机数发生器也可以使用简单分布的非线性变换, 中采一个标量, 例如, 逆变换采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a7e601c-7416-4e44-913b-eb6de0c61d70", "label": "摘要28", "info": "z，并且对标量x应用非线性变换。在这种情况下，g(z)由累积分布函数", "keywords": "并且对标量, 由累积分布函数, 在这种情况下, 应用非线性变换", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "71289ccf-cd59-4084-8cff-e8a22f80e0f4", "label": "摘要29", "info": "的反函数给出。如果我们能够指定P(x)，在x上积；分，并取所得函数的反函数，我们不用通过机器学习就能从P(x)进行采；样。", "keywords": "的反函数给出, 进行采, 我们不用通过机器学习就能从, 如果我们能够指定, 上积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6adea3b8-04f8-4250-aadd-1ec3177f838e", "label": "摘要30", "info": "为了从更复杂的分布（难以直接指定、难以积分或难以求所得积分的反；函数）中生成样本，我们使用前馈网络来表示非线性函数g的参数族，；并使用训练数据来推断参数以选择所期望的函数。", "keywords": "并使用训练数据来推断参数以选择所期望的函数, 为了从更复杂的分布, 函数, 的参数族, 我们使用前馈网络来表示非线性函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b890c11d-33e8-4fe6-869a-7a47ce2e1bac", "label": "摘要31", "info": "我们可以认为g提供了变量的非线性变化，将z 上的分布变换成x  上想要；的分布。", "keywords": "上想要, 提供了变量的非线性变化, 上的分布变换成, 的分布, 我们可以认为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2e767d2-460c-46b5-a030-1edafa2bf4f6", "label": "摘要32", "info": "回顾式（3.47），对于可求反函数的、可微的、连续的g，", "keywords": "回顾式, 可微的, 连续的, 对于可求反函数的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d9395c4-9e02-4246-be11-47e84327b384", "label": "摘要33", "info": "这隐含地对x 施加概率分布：", "keywords": "施加概率分布, 这隐含地对", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "01397be1-956b-4921-9b5b-8c39ccb83e33", "label": "摘要34", "info": "当然，取决于g的选择，这个公式可能难以评估，因此我们经常需要使；用间接学习g的方法，而不是直接尝试最大化log p( x )。", "keywords": "取决于, 而不是直接尝试最大化, 的选择, 因此我们经常需要使, 的方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7904aa15-5845-4387-ad7e-a463c1bed719", "label": "摘要35", "info": "在某些情况下，我们使用g来定义 x 上的条件分布，而不是使用g直接提；x  的样本。例如，我们可以使用一个生成器网络，其最后一层由；供", "keywords": "而不是使用, 我们可以使用一个生成器网络, 我们使用, 直接提, 例如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8c0c778e-eb07-4624-82c7-6cc462857961", "label": "摘要36", "info": "在这种情况下，我们使用g来定义p( x ｜z  )时，通过边缘化  z  来对  x  施；加分布：", "keywords": "通过边缘化, 我们使用, 加分布, 来对, 在这种情况下", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f154c7c5-5b43-4e5b-a3c7-ab2f85e214d9", "label": "摘要37", "info": "两种方法都定义了一个分布p  g  (  x  )，并允许我们使用第20.9节中的重参；数化技巧来训练p g 的各种评估准则。", "keywords": "节中的重参, 的各种评估准则, 两种方法都定义了一个分布, 并允许我们使用第, 数化技巧来训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bdfc512b-d01a-48c5-b825-89de1f64a1be", "label": "摘要38", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；表示生成器网络的两种不同方法（发出条件分布的参数相对直接发射样；品）具有互补的优缺点。当生成器网络在 x 上定义条件分布时，它不但", "keywords": "表示生成器网络的两种不同方法, 上定义条件分布时, 当生成器网络在, 发出条件分布的参数相对直接发射样, 它不但", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c18b9568-e5db-4ef2-9b48-ac85ec46e11c", "label": "摘要39", "info": "基于可微生成器网络的方法是由分类可微前馈网络中梯度下降的成功应；用而推动的。在监督学习的背景中，基于梯度训练学习的深度前馈网络；在给定足够的隐藏单元和足够的训练数据的情况下，在实践中似乎能保", "keywords": "基于梯度训练学习的深度前馈网络, 在监督学习的背景中, 基于可微生成器网络的方法是由分类可微前馈网络中梯度下降的成功应, 在实践中似乎能保, 用而推动的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a83961f3-6089-4e5b-bc0e-d1ca8979c24b", "label": "摘要40", "info": "生成式建模似乎比分类或回归更困难，因为学习过程需要优化难以处理；的准则。在可微生成器网络的情况中，准则是难以处理的，因为数据不；指定生成器网络的输入 z 和输出 x 。在监督学习的情况下，输入 x 和输", "keywords": "在监督学习的情况下, 生成式建模似乎比分类或回归更困难, 输入, 的准则, 和输", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f031def9-0161-4bad-9c97-18a3be526b66", "label": "摘要41", "info": "Dosovitskiy et  al.  （2015）研究了一个简化问题，其中  z  和  x  之间的对；应关系已经给出。具体来说，训练数据是计算机渲染的椅子图。潜变量；z  是渲染引擎的参数，描述了椅子模型的选择、椅子的位置以及影响图", "keywords": "是渲染引擎的参数, 应关系已经给出, 潜变量, 描述了椅子模型的选择, 其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ee4ef90-6142-4144-9021-f155a6c1740f", "label": "摘要42", "info": "在接下来的章节中，我们讨论仅给出 x 的训练样本，训练可微生成器网；络的几种方法。", "keywords": "络的几种方法, 的训练样本, 我们讨论仅给出, 在接下来的章节中, 训练可微生成器网", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "38032a37-6089-41f6-a8eb-6f928f4f0d2a", "label": "摘要43", "info": "20.10.3　变分自编码器", "keywords": "变分自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11b87c89-0659-4aaa-8f98-ed9d0ba506de", "label": "摘要44", "info": "auto-encoder，VAE）（Kingma，2013；；变分自编码器  （variational；Rezende et  al. ，2014）是一个使用学好的近似推断的有向模型，可以纯", "keywords": "是一个使用学好的近似推断的有向模型, 变分自编码器, 可以纯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "053fa0af-06a1-4d84-86b7-abf7741b95aa", "label": "摘要45", "info": "粹地使用基于梯度的方法进行训练。", "keywords": "粹地使用基于梯度的方法进行训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49b53910-2c01-4858-9701-c4fb29656cca", "label": "摘要46", "info": "为了从模型生成样本，VAE首先从编码分布；后使样本通过可微生成器网络g(；z", "keywords": "为了从模型生成样本, 首先从编码分布, 后使样本通过可微生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e0c6f50b-d981-49d6-befc-edc3bb00a95b", "label": "摘要47", "info": "间，近似推断网络（或编码器）", "keywords": "近似推断网络, 或编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cedd0114-dac4-4f1c-8d2f-a036c3e06f79", "label": "摘要48", "info": "则被视为解码器网络。", "keywords": "则被视为解码器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "81766f45-bfa7-4311-9bc6-d4f35691aa1f", "label": "摘要49", "info": "中采样 z 。然；)。最后，从分布；中采样  x  。然而在训练期", "keywords": "从分布, 最后, 然而在训练期, 中采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cb88d45e-0c4b-4bd4-9de6-342a744ff66b", "label": "摘要50", "info": "用于获得", "keywords": "用于获得", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c29e0563-61a1-471b-9ead-214190d09175", "label": "摘要51", "info": "变分自编码器背后的关键思想是，它们可以通过最大化与数据点 x 相关；联的变分下界", "keywords": "联的变分下界, 相关, 它们可以通过最大化与数据点, 变分自编码器背后的关键思想是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b7dcf6e3-6bf0-4afd-ad25-372ce03ccc67", "label": "摘要52", "info": "来训练：", "keywords": "来训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "52b358e1-7bed-4d2f-880a-734c49c3f686", "label": "摘要53", "info": "在式（20.76）中，我们将第一项视为潜变量的近似后验下可见和隐藏；变量的联合对数似然性（正如EM一样，不同的是我们使用近似而不是；精确后验）。第二项则可视为近似后验的熵。当q被选择为高斯分布，", "keywords": "精确后验, 我们将第一项视为潜变量的近似后验下可见和隐藏, 在式, 被选择为高斯分布, 正如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9170781-9dc9-427f-9fdf-bee6ebcf59d5", "label": "摘要54", "info": "彼此", "keywords": "彼此", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed2adaf5-fde7-4465-b6fe-72377251213d", "label": "摘要55", "info": "变分推断和学习的传统方法是通过优化算法推断q，通常是迭代不动点；方程（第19.4节）。这些方法是缓慢的，并且通常需要以闭解形式计算；。变分自编码器背后的主要思想是训练产", "keywords": "方程, 这些方法是缓慢的, 通常是迭代不动点, 变分自编码器背后的主要思想是训练产, 变分推断和学习的传统方法是通过优化算法推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "244fbaba-1afb-4c13-b1e2-f0766364be43", "label": "摘要56", "info": "变分自编码器方法是优雅的，理论上令人愉快的，并且易于实现。它也", "keywords": "并且易于实现, 变分自编码器方法是优雅的, 理论上令人愉快的, 它也", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efdda2e5-c373-4df9-a729-f65a8740394d", "label": "摘要57", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；获得了出色的结果，是生成式建模中的最先进方法之一。它的主要缺点；是从在图像上训练的变分自编码器中采样的样本往往有些模糊。这种现", "keywords": "这种现, 它的主要缺点, 是生成式建模中的最先进方法之一, 获得了出色的结果, 是从在图像上训练的变分自编码器中采样的样本往往有些模糊", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cfb5a0a3-9247-48b5-b8ab-041922e1371a", "label": "摘要58", "info": "et", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8ab7dd30-a8ff-4acc-878b-2f12c2ef72bb", "label": "摘要59", "info": "VAE框架可以直接扩展到大范围的模型架构。相比玻尔兹曼机，这是关；键的优势，因为玻尔兹曼机需要非常仔细地设计模型来保持易解性。；VAE可以与广泛的可微算子族一起良好工作。一个特别复杂的VAE是深", "keywords": "相比玻尔兹曼机, 因为玻尔兹曼机需要非常仔细地设计模型来保持易解性, 是深, 框架可以直接扩展到大范围的模型架构, 一个特别复杂的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1a9b7031-6fa5-4844-9d42-a9a7c51e1a61", "label": "摘要60", "info": "VAE框架已不仅仅扩展到传统的变分下界，还有重要加权自编码器；（importance-weighted autoencoder）（Burda et al. ，2015）的目标：", "keywords": "框架已不仅仅扩展到传统的变分下界, 的目标, 还有重要加权自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0cd3e108-9487-49cd-b984-d1ed99e65a38", "label": "摘要61", "info": "这个新的目标在k＝1时等同于传统的下界   。然而，它也可以被解释；的重要采样而形成的真实；为基于提议分布", "keywords": "它也可以被解释, 这个新的目标在, 然而, 时等同于传统的下界, 的重要采样而形成的真实", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff540799-92e6-462b-8b56-ed09fe526ed2", "label": "摘要62", "info": "中", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aff23301-63af-4350-8697-e6538daa68b3", "label": "摘要63", "info": "z", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "329123ef-74f7-41db-91fa-cf0de6e3a0e7", "label": "摘要64", "info": "估计。重要加权自编码器目标也是", "keywords": "估计, 重要加权自编码器目标也是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "794966b4-b7a8-4f56-bc71-ee5d25853890", "label": "摘要65", "info": "的下界，并且随着k增加而变得更紧。", "keywords": "并且随着, 增加而变得更紧, 的下界", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a076f14c-44cd-4469-b5ef-b44a352a318f", "label": "摘要66", "info": "变分自编码器与MP-DBM和其他涉及通过近似推断图的反向传播方法有；一些有趣的联系（Goodfellow  et  al.  ，2013d；Stoyanov  et  al.  ，2011；；Brakel et al. ，2013）。这些以前的方法需要诸如均匀场不动点方程的推", "keywords": "和其他涉及通过近似推断图的反向传播方法有, 这些以前的方法需要诸如均匀场不动点方程的推, 一些有趣的联系, 变分自编码器与", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "facbc9d4-7a58-4e27-a213-aaf6b4431dbf", "label": "摘要67", "info": "变分自编码器的一个非常好的特性是，同时训练参数编码器与生成器网；络的组合迫使模型学习一个编码器可以捕获的可预测的坐标系。这使得；它成为一个优秀的流形学习算法。图20.6展示了由变分自编码器学到的", "keywords": "这使得, 同时训练参数编码器与生成器网, 它成为一个优秀的流形学习算法, 展示了由变分自编码器学到的, 络的组合迫使模型学习一个编码器可以捕获的可预测的坐标系", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9725a3aa-e0c2-469c-9487-65b66d63a9c4", "label": "摘要68", "info": "图20.6　由变分自编码器学习的高维流形在二维坐标系中的示例（Kingma and Welling，", "keywords": "由变分自编码器学习的高维流形在二维坐标系中的示例", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b036e77d-0913-4ab1-bda9-f5aa78b7d1be", "label": "摘要69", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；2014a）。我们可以在纸上直接绘制两个可视化的维度，因此可以使用二维潜在编码训练模型来；了解模型的工作原理（即使我们认为数据流形的固有维度要高得多）。图中所示的图像不是来", "keywords": "即使我们认为数据流形的固有维度要高得多, 图中所示的图像不是来, 我们可以在纸上直接绘制两个可视化的维度, 了解模型的工作原理, 因此可以使用二维潜在编码训练模型来", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1b7ffbec-b89d-438e-957e-51a6d2743301", "label": "摘要70", "info": "20.10.4　生成式对抗网络", "keywords": "生成式对抗网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcd2dd22-185f-4a09-89d4-50b9c6e9e4fa", "label": "摘要71", "info": "生成式对抗网络  （generative  adversarial  network，GAN）（Goodfellow；et al. ，2014c）是基于可微生成器网络的另一种生成式建模方法。", "keywords": "是基于可微生成器网络的另一种生成式建模方法, 生成式对抗网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "639e3362-ea0a-4f98-bb30-93cb8cacb7e6", "label": "摘要72", "info": "生成式对抗网络基于博弈论场景，其中生成器网络必须与对手竞争。生；成器网络直接产生样本；。其对手，判别器网络", "keywords": "生成式对抗网络基于博弈论场景, 成器网络直接产生样本, 其对手, 判别器网络, 其中生成器网络必须与对手竞争", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39afe640-5ab0-4025-aafb-34cf52b0fe6d", "label": "摘要73", "info": "形式化表示生成式对抗网络中学习的最简单方式是零和游戏，其中函数；作为它自；己的收益。在学习期间，每个玩家尝试最大化自己的收益，因此收敛在", "keywords": "己的收益, 在学习期间, 其中函数, 形式化表示生成式对抗网络中学习的最简单方式是零和游戏, 每个玩家尝试最大化自己的收益", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21deba6a-e7f5-4e0d-aaea-7e62ca56b246", "label": "摘要74", "info": "确定判别器的收益。生成器接收", "keywords": "确定判别器的收益, 生成器接收", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2564eb75-f21c-4180-8a28-405dcc72d77c", "label": "摘要75", "info": "v的默认选择是", "keywords": "的默认选择是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8356b2f2-d12c-4756-bdc1-3e84bcce4fbc", "label": "摘要76", "info": "这驱使判别器试图学习将样品正确地分类为真的或伪造的。同时，生成；器试图欺骗分类器以让其相信样本是真实的。在收敛时，生成器的样本", "keywords": "同时, 器试图欺骗分类器以让其相信样本是真实的, 在收敛时, 这驱使判别器试图学习将样品正确地分类为真的或伪造的, 生成", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5fcfcb98-0d79-4f5e-af57-a328d33a4744", "label": "摘要77", "info": "与实际数据不可区分，并且判别器处处都输出   。然后就可以丢弃判", "keywords": "并且判别器处处都输出, 与实际数据不可区分, 然后就可以丢弃判", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb594c20-1c53-4211-916b-e8ff10fcf808", "label": "摘要78", "info": "别器。", "keywords": "别器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1279d805-3788-4156-8ca6-ecec00c2a101", "label": "摘要79", "info": "设计GAN的主要动机是学习过程既不需要近似推断，也不需要配分函数；梯度的近似。当max  d  ν(g ,d )在 θ  (g)  中是凸的（例如，在概率密度函数；的空间中直接执行优化的情况）时，该过程保证收敛并且是渐近一致", "keywords": "该过程保证收敛并且是渐近一致, 在概率密度函数, 例如, 梯度的近似, 设计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9b6984ac-df6e-497f-a88c-1260dd065190", "label": "摘要80", "info": "的。", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c893731-819a-4971-97e3-9641ac9ab3e9", "label": "摘要81", "info": "不幸的是，在实践中由神经网络表示的g和d以及max  d  ν(g  ,d)  不凸时，；GAN中的学习可能是困难的。Goodfellow（2014）认为不收敛可能会引；起GAN的欠拟合问题。一般来说，同时对两个玩家的成本梯度下降不能", "keywords": "同时对两个玩家的成本梯度下降不能, 的欠拟合问题, 认为不收敛可能会引, 在实践中由神经网络表示的, 不幸的是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc5b5d4b-5083-4bc8-8e64-6523b3e06ef6", "label": "摘要82", "info": "Goodfellow（2014）确定了另一种替代的形式化收益公式，其中博弈不；再是零和，每当判别器最优时，具有与最大似然学习相同的预期梯度。；因为最大似然训练收敛，这种GAN博弈的重述在给定足够的样本时也应", "keywords": "确定了另一种替代的形式化收益公式, 具有与最大似然学习相同的预期梯度, 这种, 因为最大似然训练收敛, 博弈的重述在给定足够的样本时也应", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "572fcccc-8c58-4530-a401-9277ac3d6bfc", "label": "摘要83", "info": "在真实实验中，GAN博弈的最佳表现形式既不是零和，也不等价于最大；似然，而是Good-fellow et al. （2014c）引入的带有启发式动机的不同形；式化。在这种最佳性能的形式中，生成器旨在增加判别器发生错误的对", "keywords": "而是, 式化, 在这种最佳性能的形式中, 引入的带有启发式动机的不同形, 似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9ba325d2-e86a-4fa4-b89b-fe18486c7de4", "label": "摘要84", "info": "稳定GAN学习仍然是一个开放的问题。幸运的是，当仔细选择模型架构；和超参数时，GAN学习效果很好。Radford et al. （2015）设计了一个深；度卷积GAN（DCGAN），在图像合成的任务上表现非常好，并表明其", "keywords": "在图像合成的任务上表现非常好, 学习效果很好, 学习仍然是一个开放的问题, 稳定, 和超参数时", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea53814d-c5fd-454d-9534-ee49355d3ae2", "label": "摘要85", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图20.7 在LSUN数据集上训练后，由GAN生成的图像。（左）由DCGAN模型生成的卧室图像，；经Radford et al. （2015）许可转载。（右）由LAPGAN模型生成的教堂图像，经Denton et al.", "keywords": "许可转载, 模型生成的卧室图像, 模型生成的教堂图像, 生成的图像, 数据集上训练后", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c463f28-d382-4d27-9da6-8ef89614cc5a", "label": "摘要86", "info": "GAN学习问题也可以通过将生成过程分成许多级别的细节来简化。我们；可以训练有条件的GAN（Mirza and Osindero，2014），并学习从分布p(；x  ｜  y  )中采样，而不是简单地从边缘分布p(  x  )中采样。Denton  et  al.", "keywords": "可以训练有条件的, 学习问题也可以通过将生成过程分成许多级别的细节来简化, 我们, 并学习从分布, 而不是简单地从边缘分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b02212fa-2341-4000-a62e-f4f20411fe16", "label": "摘要87", "info": "GAN训练过程中一个不寻常的能力是它可以拟合向训练点分配零概率的；概率分布。生成器网络学习跟踪特定点在某种程度上类似于训练点的流；形，而不是最大化该点的对数概率。有点矛盾的是，这意味着模型可以", "keywords": "生成器网络学习跟踪特定点在某种程度上类似于训练点的流, 概率分布, 训练过程中一个不寻常的能力是它可以拟合向训练点分配零概率的, 有点矛盾的是, 而不是最大化该点的对数概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47c0d86d-87fe-487b-8345-79a0484c2f51", "label": "摘要88", "info": "Dropout似乎在判别器网络中很重要。特别地，在计算生成器网络的梯；度时，单元应当被随机地丢弃。使用权重除以二的确定性版本的判别器", "keywords": "使用权重除以二的确定性版本的判别器, 特别地, 似乎在判别器网络中很重要, 度时, 在计算生成器网络的梯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9684df4-d926-4937-b2e8-faf538dfe695", "label": "摘要89", "info": "其梯度似乎不是那么有效。同样，从不使用Dropout似乎会产生不良的；结果。", "keywords": "从不使用, 似乎会产生不良的, 结果, 其梯度似乎不是那么有效, 同样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ddf1fda0-83fc-499d-ab9f-8a8a366b3925", "label": "摘要90", "info": "虽然GAN框架被设计为用于可微生成器网络，但是类似的原理可以用于；训练其他类型的模型。例如，自监督提升 （self-supervised boosting）可；al.  ，", "keywords": "虽然, 训练其他类型的模型, 自监督提升, 例如, 框架被设计为用于可微生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a7efbff-23e1-4fce-becd-02002d7876d1", "label": "摘要91", "info": "et", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d66c5047-b466-4291-ac8c-d24edc056c78", "label": "摘要92", "info": "20.10.5　生成矩匹配网络", "keywords": "生成矩匹配网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2110a81-4d5c-4ac9-b6e5-7289fcea2cc1", "label": "摘要93", "info": "生成矩匹配网络  （generative  moment  matching  network）（Li  et  al.  ，；2015；Dziugaite  et  al.  ，2015）是另一种基于可微生成器网络的生成模；型。与VAE和GAN不同，它们不需要将生成器网络与任何其他网络配", "keywords": "不同, 生成矩匹配网络, 它们不需要将生成器网络与任何其他网络配, 是另一种基于可微生成器网络的生成模", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42f6a348-2e1d-4808-b7e0-3c0698329b62", "label": "摘要94", "info": "生成矩匹配网络使用称为矩匹配  （moment  matching）的技术训练。矩；匹配背后的基本思想是以如下的方式训练生成器——令模型生成的样本；的许多统计量尽可能与训练集中的样本相似。在此情景下，矩", "keywords": "匹配背后的基本思想是以如下的方式训练生成器, 生成矩匹配网络使用称为矩匹配, 的许多统计量尽可能与训练集中的样本相似, 的技术训练, 在此情景下", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e66ec2a7-f9b4-47bb-a9a6-e1ef7c2db276", "label": "摘要95", "info": "其中", "keywords": "其中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d208c70a-5858-4546-936a-27ed90a2af67", "label": "摘要96", "info": "是一个非负整数的向量。", "keywords": "是一个非负整数的向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "23484c7e-9b9b-4337-87b9-f77ade2adcd7", "label": "摘要97", "info": "在第一次检查时，这种方法似乎在计算上是不可行的。例如，如果我们；想匹配形式为x i x j 的所有矩，那么我们需要最小化在 x 的维度上是二次；的多个值之间的差。此外，甚至匹配所有第一和第二矩将仅足以拟合多", "keywords": "这种方法似乎在计算上是不可行的, 的所有矩, 如果我们, 的维度上是二次, 此外", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4174beac-d379-4313-aaa0-a2a9c80d5849", "label": "摘要98", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；相反，我们可以通过最小化一个被称为最大平均偏差  （maximum  mean；discrepancy，MMD）（Schölkopf  and  Smola，2002；Gretton  et  al.  ，", "keywords": "我们可以通过最小化一个被称为最大平均偏差, 相反", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a35cb57-ecfc-4112-a417-aeb38fcfa936", "label": "摘要99", "info": "从可视化方面看，来自生成矩匹配网络的样本有点令人失望。幸运的；是，它们可以通过将生成器网络与自编码器组合来改进。首先，训练自；编码器以重构训练集。接下来，自编码器的编码器用于将整个训练集转", "keywords": "来自生成矩匹配网络的样本有点令人失望, 接下来, 自编码器的编码器用于将整个训练集转, 从可视化方面看, 它们可以通过将生成器网络与自编码器组合来改进", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a64e337d-59a4-4af9-a151-83d581b44928", "label": "摘要100", "info": "与GAN不同，代价函数仅关于一批同时来自训练集和生成器网络的实例；定义。我们不可能将训练更新作为一个训练样本或仅来自生成器网络的；一个样本的函数，这是因为必须将矩计算为许多样本的经验平均值。当", "keywords": "定义, 一个样本的函数, 这是因为必须将矩计算为许多样本的经验平均值, 我们不可能将训练更新作为一个训练样本或仅来自生成器网络的, 不同", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4f7a37d-caa4-4197-b94b-de94810eb76b", "label": "摘要101", "info": "与GAN一样，即使生成器网络为训练点分配零概率，也可以使用MMD；训练生成器网络。", "keywords": "一样, 也可以使用, 即使生成器网络为训练点分配零概率, 训练生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6629c3f7-1dc9-456e-8acf-b6590b32ef19", "label": "摘要102", "info": "20.10.6　卷积生成网络", "keywords": "卷积生成网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4b85978c-fdd8-4e58-8f06-b31065f0fce7", "label": "摘要103", "info": "当生成图像时，将卷积结构引入生成器网络通常是有用的（见；Goodfellow  et  al.  （2014c）或Dosovitskiy  et  al.  （2015）的例子）。为；此，我们使用卷积算子的“转置”，如第9.5节所述。这种方法通常能产生", "keywords": "将卷积结构引入生成器网络通常是有用的, 当生成图像时, 我们使用卷积算子的, 的例子, 如第", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d2e7d41-9e78-413f-81a5-8fce5c12e6e8", "label": "摘要104", "info": "用于识别任务的卷积网络具有从图像到网络顶部的某些概括层（通常是；类标签）的信息流。当该图像通过网络向上流动时，随着图像的表示变；得对于有害变换保持不变，信息也被丢弃。在生成器网络中，情况恰恰", "keywords": "当该图像通过网络向上流动时, 在生成器网络中, 类标签, 的信息流, 得对于有害变换保持不变", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f8df9a7-159b-4bf0-98a2-a6f46812e8de", "label": "摘要105", "info": "本身（具有对象位置、姿势、纹理以及明暗）。在卷积识别网络中丢弃；信息的主要机制是池化层，而生成器网络似乎需要添加信息。由于大多；数池化函数不可逆，我们不能将池化层求逆后放入生成器网络。更简单", "keywords": "本身, 姿势, 由于大多, 具有对象位置, 信息的主要机制是池化层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5058e1fc-90ea-4102-b616-ef02c7fab3b3", "label": "摘要106", "info": "20.10.7　自回归网络", "keywords": "自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46c59ac5-5003-4d37-95bb-2d0450d1c34c", "label": "摘要107", "info": "自回归网络是没有潜在随机变量的有向概率模型。这些模型中的条件概；率分布由神经网络表示（有时是极简单的神经网络，例如逻辑回归）。；这些模型的图结构是完全图。它们可以通过概率的链式法则分解观察变", "keywords": "例如逻辑回归, 率分布由神经网络表示, 自回归网络是没有潜在随机变量的有向概率模型, 它们可以通过概率的链式法则分解观察变, 有时是极简单的神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4fdae50b-99dd-4921-9f55-5a0ff6d86c1a", "label": "摘要108", "info": "20.10.8　线性自回归网络", "keywords": "线性自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6038996d-f42e-4819-b502-83ec39f1761c", "label": "摘要109", "info": "自回归网络的最简单形式是没有隐藏单元、没有参数或特征共享的形；式。每个；据的线性回归，对于二值数据的逻辑回归，对于离散数据的softmax回", "keywords": "没有参数或特征共享的形, 对于离散数据的, 自回归网络的最简单形式是没有隐藏单元, 据的线性回归, 每个", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3bd2756b-774e-4614-942e-19540f1ecb6f", "label": "摘要110", "info": "被参数化为线性模型（对于实值数", "keywords": "被参数化为线性模型, 对于实值数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c64ff34f-13f7-4a27-b633-d2c52b7f6024", "label": "摘要111", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；有", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15a82e2e-a68b-43dd-8b0b-597572134ab3", "label": "摘要112", "info": "个参数，如图20.8所示。", "keywords": "如图, 所示, 个参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eed26829-e48d-4d35-9c54-064a3dbbedab", "label": "摘要113", "info": "图20.8　完全可见的信念网络从前i−1个变量预测第i个变量。（上）FVBN的有向图模型。；（下）对数FVBN相应的计算图，其中每个预测由线性预测器作出", "keywords": "相应的计算图, 的有向图模型, 个变量, 其中每个预测由线性预测器作出, 个变量预测第", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dcf99e33-0a79-42cb-bc1d-ba0cc343c8c4", "label": "摘要114", "info": "如果变量是连续的，线性自回归网络只是表示多元高斯分布的另一种方；式，只能捕获观察变量之间线性的成对相互作用。", "keywords": "如果变量是连续的, 线性自回归网络只是表示多元高斯分布的另一种方, 只能捕获观察变量之间线性的成对相互作用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c7bbccc7-84a6-4065-9142-8655271a00b2", "label": "摘要115", "info": "线性自回归网络本质上是线性分类方法在生成式建模上的推广。因此，；它们具有与线性分类器相同的优缺点。像线性分类器一样，它们可以用；凸损失函数训练，并且有时允许闭解形式（如在高斯情况下）。像线性", "keywords": "它们可以用, 像线性分类器一样, 它们具有与线性分类器相同的优缺点, 并且有时允许闭解形式, 因此", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa84cae5-201e-44a4-8287-dc3270e23eff", "label": "摘要116", "info": "20.10.9　神经自回归网络", "keywords": "神经自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a57b3ff-3982-4bd5-b7bb-1b079fe7f45d", "label": "摘要117", "info": "神经自回归网络（Bengio  and  Bengio，2000a，b）具有与逻辑自回归网；络相同的从左到右的图模型（见图20.8），但在该图模型结构内采用不", "keywords": "络相同的从左到右的图模型, 但在该图模型结构内采用不, 神经自回归网络, 具有与逻辑自回归网, 见图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14541594-9656-4318-9081-85c5f67840a7", "label": "摘要118", "info": "同的条件分布参数。新的参数化更强大，它可以根据需要随意增加容；量，并允许近似任意联合分布。新的参数化还可以引入深度学习中常见；的参数共享和特征共享原理来改进泛化能力。设计这些模型的动机是避", "keywords": "并允许近似任意联合分布, 同的条件分布参数, 新的参数化还可以引入深度学习中常见, 它可以根据需要随意增加容, 设计这些模型的动机是避", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3ae541e-ff11-4793-8414-0bb816dc8671", "label": "摘要119", "info": "（1）通过具有(i−1)×k个输入和k个输出的神经网络（如果变量是离散的；并有k个值，使用one-hot编码）参数化每个；，让我们不需要指数量级参数（和样本）的情况下就能估计条件概率，", "keywords": "个输入和, 通过具有, 如果变量是离散的, 让我们不需要指数量级参数, 个输出的神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "00549f9e-d682-47e3-9d26-24c825f28821", "label": "摘要120", "info": "（2）不需要对预测每个x  i  使用不同的神经网络，如图20.9所示的从左；到右连接，允许将所有神经网络合并成一个。等价地，它意味着为预测；x  i  所计算的隐藏层特征可以重新用于预测x  i＋k  （k＞0）。因此隐藏单", "keywords": "不需要对预测每个, 因此隐藏单, 等价地, 到右连接, 所示的从左", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "08ebe1c6-0f5d-4bf2-a014-2e051cb27a4f", "label": "摘要121", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；图20.9　神经自回归网络从前i−1个变量预测第i个变量x i ，但经参数化后，作为x 1 ，…，x i 函；数的特征（表示为h i 的隐藏单元的组）可以在预测所有后续变量x i＋1 ，x i＋2 ，…，x d 时重", "keywords": "作为, 可以在预测所有后续变量, 神经自回归网络从前, 个变量, 表示为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ca3f744-a9ab-4f2b-b190-dc97092bd2b1", "label": "摘要122", "info": "如在第6.2.2.1节中讨论的，使神经网络的输出预测x  i  条件分布的参数，；就可以表示一个条件分布。虽然原始神；每个", "keywords": "条件分布的参数, 虽然原始神, 使神经网络的输出预测, 如在第, 节中讨论的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b534f622-6978-4b55-9118-66a7400c3ff7", "label": "摘要123", "info": "20.10.10　NADE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ed3553a-89ac-47bb-b234-6fffef819a4e", "label": "摘要124", "info": "神经自回归密度估计器  （neural  auto-regressive  density  estimator，；NADE）是最近非常成功的神经自回归网络的一种形式（Larochelle  and；Murray，2011）。与Bengio  and  Bengio（2000b）的原始神经自回归网", "keywords": "的原始神经自回归网, 是最近非常成功的神经自回归网络的一种形式, 神经自回归密度估计器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1bc04093-0ce7-44ac-a3aa-a0b4ad581a25", "label": "摘要125", "info": "图20.10　神经自回归密度估计器（NADE）的示意图。隐藏单元被组织在组 h (j) 中，使得只有；输入x 1 ，…，x i 参与计算 h (i) 和预测；用特定的权重共享模式区别于早期的神经自回归网络：", "keywords": "和预测, 神经自回归密度估计器, 使得只有, 的示意图, 用特定的权重共享模式区别于早期的神经自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "732e86a4-2610-4a7b-a4eb-90602f716173", "label": "摘要126", "info": "（对于j＞i）。NADE使；被共享于所有从x i 到任", "keywords": "对于, 到任, 被共享于所有从", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e22fbc7a-19a0-4dd3-a92a-afc75797b325", "label": "摘要127", "info": "何j≥i组中第k个单元的权重（在图中使用相同的线型表示复制权重的每个实例）。注意向量", "keywords": "个单元的权重, 组中第, 在图中使用相同的线型表示复制权重的每个实例, 注意向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e84cc5a-2bb3-4723-b68d-11c3f3b4a12a", "label": "摘要128", "info": "记为", "keywords": "记为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1f0443f-189d-4311-a876-00ad6a085d68", "label": "摘要129", "info": "从第i个输入x i 到第j组隐藏单元的第k个元素；组内共享的：", "keywords": "组隐藏单元的第, 到第, 个输入, 从第, 个元素", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f472b1df-4524-4c2b-b186-3b9d778326d2", "label": "摘要130", "info": "的权重", "keywords": "的权重", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59d5970e-1e8f-478b-93cb-e635ba7e8b4e", "label": "摘要131", "info": "是", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96e17db6-614a-438e-9558-dedcce348e82", "label": "摘要132", "info": "其余j＜i的权重为0。", "keywords": "其余, 的权重为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "33219e9e-74a3-4cae-8462-da694d6d96b2", "label": "摘要133", "info": "Larochelle and  Murray（2011）选择了这种共享方案，使得NADE模型中；的正向传播与在均匀场推断中执行的计算大致相似，以填充RBM中缺；失的输入。这个均匀场推断对应于运行具有共享权重的循环网络，并且", "keywords": "模型中, 的正向传播与在均匀场推断中执行的计算大致相似, 中缺, 这个均匀场推断对应于运行具有共享权重的循环网络, 并且", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f12db879-4814-4ea3-8efe-dc407d6c3cbe", "label": "摘要134", "info": "如前所述，自回归网络可以被扩展成处理连续数据。用于参数化连续密；i  （组i的系数或先验概；度的特别强大和通用的方法是混合权重为α", "keywords": "如前所述, 的系数或先验概, 自回归网络可以被扩展成处理连续数据, 用于参数化连续密, 度的特别强大和通用的方法是混合权重为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9cf58e9-c512-4753-90e0-e032924521c2", "label": "摘要135", "info": "另一个非常有趣的神经自回归架构的扩展摆脱了为观察到的变量选择任；意顺序的需要（Murray  and  Larochelle，2014）。在自回归网络中，该；想法是训练网络能够通过随机采样顺序来处理任何顺序，并将信息提供", "keywords": "在自回归网络中, 并将信息提供, 想法是训练网络能够通过随机采样顺序来处理任何顺序, 意顺序的需要, 另一个非常有趣的神经自回归架构的扩展摆脱了为观察到的变量选择任", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eafa22b0-7cd4-4b23-899f-1c5895936715", "label": "摘要136", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；最后，由于变量的许多顺序是可能的（对于n个变量是n!），并且变量；的每个顺序o产生不同的p(x ｜o)，我们可以组成许多o值模型的集成：", "keywords": "由于变量的许多顺序是可能的, 我们可以组成许多, 值模型的集成, 的每个顺序, 对于", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85f625d7-afa4-4336-ac0a-3265bae42fd9", "label": "摘要137", "info": "这个集成模型通常能更好地泛化，并且为测试集分配比单个排序定义的；单个模型更高的概率。", "keywords": "单个模型更高的概率, 并且为测试集分配比单个排序定义的, 这个集成模型通常能更好地泛化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "033f3bbf-be39-430e-a6e3-c4e3c5e901e6", "label": "摘要138", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6c6b7bdb-1ebf-4fad-98a1-7b26b794ca7e", "label": "摘要139", "info": "在同一篇文章中，作者提出了深度版本的架构，但不幸的是，这立即使；计算成本像原始神经自回归网络一样高（Bengio；Bengio，", "keywords": "在同一篇文章中, 计算成本像原始神经自回归网络一样高, 作者提出了深度版本的架构, 这立即使, 但不幸的是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26f4c237-625c-4c47-b971-07254e567aaf", "label": "摘要140", "info": "。；（假设在每个层存在n组h", "keywords": "假设在每个层存在", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a5a35ac-5d58-41a5-a0de-73583683d41e", "label": "摘要141", "info": "20.10.1　sigmoid信念网；络", "keywords": "信念网", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5dca1c64-fdc9-4d10-84e3-cac41c76a4b1", "label": "摘要142", "info": "20.10.2　可微生成器网络", "keywords": "可微生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc5c5c26-7e4e-4713-84ff-92964954355a", "label": "摘要143", "info": "20.10.3　变分自编码器", "keywords": "变分自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2deae15c-0ea1-45c2-b637-3eb73de17d77", "label": "摘要144", "info": "20.10.4　生成式对抗网络", "keywords": "生成式对抗网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "975f8684-a616-4c24-ad8c-0293fc5b1e96", "label": "摘要145", "info": "20.10.5　生成矩匹配网络", "keywords": "生成矩匹配网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "17b3a00b-9827-4e19-817a-6f14da19b323", "label": "摘要146", "info": "20.10.6　卷积生成网络", "keywords": "卷积生成网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a260c9f6-99d8-46e5-bab2-614ac158927d", "label": "摘要147", "info": "20.10.7　自回归网络", "keywords": "自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dca7bfa1-1d5e-4c5a-bdd3-e399ad82b100", "label": "摘要148", "info": "20.10.8　线性自回归网络", "keywords": "线性自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f983d72f-f156-464b-822b-7e195380139b", "label": "摘要149", "info": "20.10.9　神经自回归网络", "keywords": "神经自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "539f0350-b2a3-4963-8d89-70c12c04d11b", "label": "摘要150", "info": "20.10.10　NADE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b11bf143-b2cb-4263-afa1-361f8e29a436", "label": "20.11：从自编码器采样", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "f8dcb302-a770-4229-ac35-592eee1d1bda", "label": "摘要1", "info": "20.11.1　与任意去噪自编码器相关的马尔可夫链", "keywords": "与任意去噪自编码器相关的马尔可夫链", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9c0448d-d5a0-4b0a-a5d0-0419a838be98", "label": "摘要2", "info": "20.11.2　夹合与条件采样", "keywords": "夹合与条件采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f8a8d58d-b38d-4714-ba5b-0309c8eb74d2", "label": "摘要3", "info": "20.11.3　回退训练过程", "keywords": "回退训练过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28a624e0-857e-433d-96ce-33a784682512", "label": "摘要4", "info": "在第14章中，我们看到许多种学习数据分布的自编码器。得分匹配、去；噪自编码器和收缩自编码器之间有着密切的联系。这些联系表明某些类；型的自编码器以某些方式学习数据分布。我们还没有讨论如何从这样的", "keywords": "章中, 我们还没有讨论如何从这样的, 噪自编码器和收缩自编码器之间有着密切的联系, 得分匹配, 我们看到许多种学习数据分布的自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "94580d45-07a5-40f9-907e-4eace2e6a15c", "label": "摘要5", "info": "某些类型的自编码器，例如变分自编码器，明确地表示概率分布并且允；许直接的原始采样。而大多数其他类型的自编码器则需要MCMC采样。", "keywords": "例如变分自编码器, 某些类型的自编码器, 采样, 而大多数其他类型的自编码器则需要, 明确地表示概率分布并且允", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "01f0e759-31a5-409c-a382-a3830258c955", "label": "摘要6", "info": "收缩自编码器被设计为恢复数据流形切面的估计。这意味着使用注入噪；声的重复编码和解码将引起沿着流形表面的随机游走（Rifai  et  al.  ，；2012；Mesnil  et  al.  ，2012）。这种流形扩散技术是马尔可夫链的一", "keywords": "这种流形扩散技术是马尔可夫链的一, 收缩自编码器被设计为恢复数据流形切面的估计, 声的重复编码和解码将引起沿着流形表面的随机游走, 这意味着使用注入噪", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c554e9c-1d36-483e-a260-acede11e66b0", "label": "摘要7", "info": "更一般的马尔可夫链还可以从任何去噪自编码器中采样。", "keywords": "更一般的马尔可夫链还可以从任何去噪自编码器中采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eff60450-8818-4b6f-b1da-7152d70f344e", "label": "摘要8", "info": "20.11.1　与任意去噪自编码器相关的马尔可夫链", "keywords": "与任意去噪自编码器相关的马尔可夫链", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d9687f9f-deb4-472a-80ad-e2370ce12dff", "label": "摘要9", "info": "上述讨论留下了一个开放问题——注入什么噪声和从哪获得马尔可夫链；（可以根据自编码器估计的分布生成样本）。Bengio et al.  （2013c）展；示了如何构建这种用于广义去噪自编码器  （generalized", "keywords": "可以根据自编码器估计的分布生成样本, 注入什么噪声和从哪获得马尔可夫链, 上述讨论留下了一个开放问题, 示了如何构建这种用于广义去噪自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f63ddde1-43dc-4811-afc8-e8927bcd2247", "label": "摘要10", "info": "根据估计分布生成的马尔可夫链的每个步骤由以下子步骤组成，如图；20.11所示。", "keywords": "如图, 根据估计分布生成的马尔可夫链的每个步骤由以下子步骤组成, 所示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "722fa632-e47a-4d8e-89d8-be6edc7a89b3", "label": "摘要11", "info": "图20.11　马尔可夫链的每个步骤与训练好的去噪自编码器相关联，根据由去噪对数似然准则隐；式训练的概率模型生成样本。每个步骤包括：（a）通过损坏过程C向状态 x 注入噪声产生；（b）用函数f对其编码，产生", "keywords": "通过损坏过程, 马尔可夫链的每个步骤与训练好的去噪自编码器相关联, 注入噪声产生, 根据由去噪对数似然准则隐, 每个步骤包括", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0fa8d34b-692d-4b16-9697-eb39bf681340", "label": "摘要12", "info": "；；；（c）用函数g解码结果，产生用于重构分布的参", "keywords": "用函数, 解码结果, 产生用于重构分布的参", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "40a291f9-20e7-47b1-b7d7-269140593406", "label": "摘要13", "info": "，损坏包括添加高斯噪声，并且从", "keywords": "损坏包括添加高斯噪声, 并且从", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b3eeebda-1940-4335-a649-41459a2c9d75", "label": "摘要14", "info": "，从重构分布", "keywords": "从重构分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d33343a9-65c4-42bf-a98f-d6bc9ec96f92", "label": "摘要15", "info": "采样新状态。在典型的平", "keywords": "在典型的平, 采样新状态", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef943b65-ad82-45ec-b844-0f26c9df4eb1", "label": "摘要16", "info": "，并估计", "keywords": "并估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "23afc194-33cf-4b90-9ea9-8da3fa2c4a9b", "label": "摘要17", "info": "的采样包括第二次向重构", "keywords": "的采样包括第二次向重构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5e8e03ab-71f6-4b39-9330-94e6cdf9d39a", "label": "摘要18", "info": "添加高斯噪声。后者的噪声水平应对应于重构的均方误；差，而注入的噪声是控制混合速度以及估计器平滑经验分布程度的超参数（Vincent，2011）。；在所示的例子中，只有C和p条件是随机步骤（f和g是确定性计算），我们也可以在自编码器内", "keywords": "是确定性计算, 在所示的例子中, 我们也可以在自编码器内, 而注入的噪声是控制混合速度以及估计器平滑经验分布程度的超参数, 后者的噪声水平应对应于重构的均方误", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59122db3-206a-43de-a95c-14232732dec6", "label": "摘要19", "info": "（1）从先前状态 x 开始，注入损坏噪声，从", "keywords": "从先前状态, 开始, 注入损坏噪声", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f982c93-0558-425f-8ef1-5b71d27507eb", "label": "摘要20", "info": "中采样  。", "keywords": "中采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d85fabf1-cee9-448a-bc15-af79cc620575", "label": "摘要21", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（2）将  编码为", "keywords": "编码为", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "89059221-8da8-4329-9831-3fde160aa6a0", "label": "摘要22", "info": "。", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59a822e9-a6db-4e78-9e10-624587e9dc70", "label": "摘要23", "info": "（3）解码h以获得", "keywords": "解码, 以获得", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bfff7359-53bf-412e-9ddd-8ab263118895", "label": "摘要24", "info": "。", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aea8806c-6dd9-4d13-a9b8-38e84802848f", "label": "摘要25", "info": "（4）从", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "16fae81f-8711-4f49-a073-55b99483f2f3", "label": "摘要26", "info": "的参数", "keywords": "的参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0b32488d-9cc4-4292-8179-ed00faafec5a", "label": "摘要27", "info": "采样下一状态 x 。", "keywords": "采样下一状态", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "588a1df2-7c68-4341-83e6-c87fa79f6b69", "label": "摘要28", "info": "Bengio  et  al.  （2014）表明，如果自编码器；件分布的一致估计量，则上述马尔可夫链的平稳分布形成数据生成分；布x 的一致估计量（虽然是隐式的）。", "keywords": "件分布的一致估计量, 虽然是隐式的, 的一致估计量, 如果自编码器, 表明", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c1ec541-a420-425f-8d15-16839a7ddf51", "label": "摘要29", "info": "形成对应真实条", "keywords": "形成对应真实条", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5ffe131-9b32-42f9-aa89-edf72ecf9afe", "label": "摘要30", "info": "20.11.2　夹合与条件采样", "keywords": "夹合与条件采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6ae10b1-a178-42a1-b77b-4911643a9cec", "label": "摘要31", "info": "与玻尔兹曼机类似，去噪自编码器及其推广（例如下面描述的GSN）可；用于从条件分布；中采样，只需夹合观察单元x  f  并在给定x", "keywords": "与玻尔兹曼机类似, 只需夹合观察单元, 例如下面描述的, 用于从条件分布, 去噪自编码器及其推广", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c7eb709f-80c7-4326-a4f5-ca75c7dd9bdc", "label": "摘要32", "info": "在图20.12中展示了夹合一半像素（图像的右部分）并在另一半上运行；马尔可夫链的实验。", "keywords": "在图, 马尔可夫链的实验, 中展示了夹合一半像素, 图像的右部分, 并在另一半上运行", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec3f9528-8fe5-43f0-8aec-7d047d69d02e", "label": "摘要33", "info": "图20.12　在每步仅重采样左半部分，夹合图像的右半部分并运行马尔可夫链的示意图。这些样；本来自重构MNIST数字的GSN（每个时间步使用回退过程）", "keywords": "本来自重构, 夹合图像的右半部分并运行马尔可夫链的示意图, 这些样, 每个时间步使用回退过程, 数字的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c72bacf-e80f-4cf7-a67f-062469e9ee8a", "label": "摘要34", "info": "20.11.3　回退训练过程", "keywords": "回退训练过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5445b3b-928f-4e5b-b20a-547c1f37a38e", "label": "摘要35", "info": "回退训练过程由Bengio et  al.  （2013c）等人提出，作为一种加速去噪自；编码器生成训练收敛的方法。不像执行一步编码-解码重建，该过程有；代替的多个随机编码-解码步骤组成（如在生成马尔可夫链中），以训", "keywords": "编码器生成训练收敛的方法, 如在生成马尔可夫链中, 代替的多个随机编码, 作为一种加速去噪自, 该过程有", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f96b638f-8675-4683-9e28-2cdf755de86e", "label": "摘要36", "info": "训练k个步骤与训练一个步骤是等价的（在实现相同稳态分布的意义；上），但是实际上可以更有效地去除来自数据的伪模式。", "keywords": "训练, 但是实际上可以更有效地去除来自数据的伪模式, 个步骤与训练一个步骤是等价的, 在实现相同稳态分布的意义", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "216abebe-bee1-4a25-b3da-1c4fc02a4025", "label": "摘要37", "info": "20.11.1　与任意去噪自编；码器相关的马尔可夫链", "keywords": "与任意去噪自编, 码器相关的马尔可夫链", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0717a96d-56ba-453e-8207-08119aecd0ad", "label": "摘要38", "info": "20.11.2　夹合与条件采样", "keywords": "夹合与条件采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "799c3e79-c508-43a7-9f25-739bfe6137e9", "label": "摘要39", "info": "20.11.3　回退训练过程", "keywords": "回退训练过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c1061e81-8d07-45e0-a7c8-24f379317d17", "label": "20.12：生成随机网络", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "f1a165d9-ad85-4526-9016-6e9115be8659", "label": "摘要1", "info": "20.12.1　判别性GSN", "keywords": "判别性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edeee891-ece3-4927-8ecd-3c331c28eb04", "label": "摘要2", "info": "生成随机网络 （generative stochastic network，GSN）（Bengio et al. ，；2014）是去噪自编码器的推广，除可见变量（通常表示为x  ）之外，在；生成马尔可夫链中还包括潜变量h 。", "keywords": "生成随机网络, 生成马尔可夫链中还包括潜变量, 是去噪自编码器的推广, 通常表示为, 除可见变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9b48caf-66f5-4444-a88f-0f3c28a362e3", "label": "摘要3", "info": "GSN由两个条件概率分布参数化，指定马尔可夫链的一步。", "keywords": "由两个条件概率分布参数化, 指定马尔可夫链的一步", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7d897331-c5b3-441b-ba6d-01f6c7b04404", "label": "摘要4", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；（1）；变量。这种“重建分布”也可以在去噪自编码器、RBM、DBN和DBM中", "keywords": "这种, 也可以在去噪自编码器, 重建分布, 变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b36893e5-c265-46d1-8ed8-735d0a84c006", "label": "摘要5", "info": "指示在给定当前潜在状态下如何产生下一个可见", "keywords": "指示在给定当前潜在状态下如何产生下一个可见", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e86a35aa-b811-4143-b21a-8ff82bcc01f3", "label": "摘要6", "info": "（2）；量下如何更新潜在状态变量。", "keywords": "量下如何更新潜在状态变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dafa0eb7-d7f1-428d-9ee9-707ae76e742a", "label": "摘要7", "info": "指示在给定先前的潜在状态和可见变", "keywords": "指示在给定先前的潜在状态和可见变", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac7ebda6-2e2c-46e5-a5b4-6be49e683157", "label": "摘要8", "info": "去噪自编码器和GSN不同于经典的概率模型（有向或无向），它们自己；参数化生成过程，而不是通过可见和潜变量的联合分布的数学形式。相；反，后者如果存在则隐式地定义为生成马尔可夫链的稳态分布。存在稳", "keywords": "有向或无向, 参数化生成过程, 后者如果存在则隐式地定义为生成马尔可夫链的稳态分布, 它们自己, 而不是通过可见和潜变量的联合分布的数学形式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e07d1c9c-2fad-413b-8916-a91544f58260", "label": "摘要9", "info": "我们可以想象GSN不同的训练准则。由Bengio  et  al.  （2014）提出和评；估的只对可见单元上对数概率的重建，如应用于去噪自编码器。通过；将x (0) ＝ x 夹合到观察到的样本并且在一些后续时间步处使生成  x 的概", "keywords": "夹合到观察到的样本并且在一些后续时间步处使生成, 提出和评, 我们可以想象, 不同的训练准则, 估的只对可见单元上对数概率的重建", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3de91d72-fed1-4b72-99b0-1e02ad678b02", "label": "摘要10", "info": "从链中采样。为了估计相对于模型其他部分的；的梯度，Bengio  et  al.  （2014）使用了在第", "keywords": "为了估计相对于模型其他部分的, 从链中采样, 使用了在第, 的梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "082e4b4b-2de3-4948-9a8a-7c0e546030c2", "label": "摘要11", "info": "，其中给定", "keywords": "其中给定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0b30f1d-8a67-4b38-b3c4-fcb022d01a10", "label": "摘要12", "info": "(k)", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0b11ee58-bdd5-4607-a229-96c7d138db97", "label": "摘要13", "info": "20.9节中介绍的重参数化技巧。", "keywords": "节中介绍的重参数化技巧", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d4af2926-5653-49fe-a42d-42d3f7cb7f84", "label": "摘要14", "info": "回退训练过程（在第20.11.3节中描述）可以用来改善训练GSN的收敛性；（Bengio et al. ，2014）。", "keywords": "可以用来改善训练, 的收敛性, 在第, 回退训练过程, 节中描述", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e5af12e-754c-42ed-8391-055b32a6081f", "label": "摘要15", "info": "20.12.1　判别性GSN", "keywords": "判别性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb9bf095-9d67-4a54-bbb5-4937638c33f0", "label": "摘要16", "info": "GSN的原始公式（Bengio et  al. ，2014）用于无监督学习和对观察数据x；的p(x )的隐式建模，但是我们可以修改框架来优化p(y ｜ x )。", "keywords": "的原始公式, 但是我们可以修改框架来优化, 用于无监督学习和对观察数据, 的隐式建模", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "538db44b-96e0-4beb-8e17-c5a9835d0f13", "label": "摘要17", "info": "例如，Zhou  and  Troyanskaya（2014）以如下方式推广GSN：只反向传；播输出变量上的重建对数概率，并保持输入变量固定。他们将这种方式；成功应用于建模序列（蛋白质二级结构），并在马尔可夫链的转换算子", "keywords": "播输出变量上的重建对数概率, 蛋白质二级结构, 成功应用于建模序列, 他们将这种方式, 以如下方式推广", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8309a196-0ee6-46b6-a088-57a29fd3f91a", "label": "摘要18", "info": "其他层的值（例如下面一个和上面一个）的输入。", "keywords": "其他层的值, 的输入, 例如下面一个和上面一个", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1505d56-401e-4b4f-aaed-3e17ca74aacd", "label": "摘要19", "info": "因此，马尔可夫链确实不只是输出变量（与更高层的隐藏层相关联），；并且输入序列仅用于条件化该链，其中反向传播使得它能够学习输入序；列如何条件化由马尔可夫链隐含表示的输出分布。因此这是在结构化输", "keywords": "其中反向传播使得它能够学习输入序, 与更高层的隐藏层相关联, 因此, 马尔可夫链确实不只是输出变量, 因此这是在结构化输", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1213f842-e42f-4c12-b633-f237069be6cb", "label": "摘要20", "info": "and  Pernkopf（2014）引入了一个混合模型，通过简单地添加；Zöhrer；（使用不同的权重）监督和非监督成本即y  和x  的重建对数概率，组合", "keywords": "通过简单地添加, 引入了一个混合模型, 监督和非监督成本即, 的重建对数概率, 组合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7459b7ca-66f2-4f18-8980-c19c77d9315a", "label": "摘要21", "info": "20.12.1　判别性GSN", "keywords": "判别性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "091371a3-dff7-49ae-84c9-131644fc746b", "label": "20.13：其他生成方案", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "b033aa12-8f12-45ad-8eae-f46505b7341e", "label": "摘要1", "info": "目前为止我们已经描述的方法，使用MCMC采样、原始采样或两者的一；些混合来生成样本。虽然这些是生成式建模中最流行的方法，但它们绝；不是唯一的方法。", "keywords": "原始采样或两者的一, 虽然这些是生成式建模中最流行的方法, 目前为止我们已经描述的方法, 些混合来生成样本, 不是唯一的方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aca5c7d9-4be6-483c-9840-7fe93a2eb8bc", "label": "摘要2", "info": "Sohl-Dickstein  et  al.  （2015）开发了一种基于非平衡热力学学习生成模；型的扩散反演  （diffusion  inversion）训练方案。该方法基于我们希望从；中采样的概率分布具有结构的想法。这种结构会被递增地使概率分布具", "keywords": "该方法基于我们希望从, 开发了一种基于非平衡热力学学习生成模, 型的扩散反演, 训练方案, 中采样的概率分布具有结构的想法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f9e2f8a-e338-4fa3-875e-7a3a6a3830ae", "label": "摘要3", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；处出现的假性模式。", "keywords": "处出现的假性模式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c7a77a69-17c5-40c0-bb9d-43598f4f1f17", "label": "摘要4", "info": "样本生成的另一种方法是近似贝叶斯计算  （approximate；Bayesian；computation，ABC）框架（Rubin et al. ，1984）。在这种方法中，样本", "keywords": "样本生成的另一种方法是近似贝叶斯计算, 样本, 框架, 在这种方法中", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd5c7d35-b6e4-4321-a49e-30e49b6f2a35", "label": "摘要5", "info": "我们期待更多等待发现的其他生成式建模方法。", "keywords": "我们期待更多等待发现的其他生成式建模方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "label": "20.14：评估生成模型", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "b6a06a87-870d-481b-a5e5-6b884e102aca", "label": "摘要1", "info": "研究生成模型的研究者通常需要将一个生成模型与另一个生成模型比；较，通常是为了证明新发明的生成模型比之前存在的模型更能捕获一些；分布。", "keywords": "通常是为了证明新发明的生成模型比之前存在的模型更能捕获一些, 分布, 研究生成模型的研究者通常需要将一个生成模型与另一个生成模型比", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "31cfd2ef-72d8-43af-b9bf-b0ad9c64e82b", "label": "摘要2", "info": "这可能是一个困难且微妙的任务。通常，我们不能实际评估模型下数据；的对数概率，但仅可以评估一个近似。在这些情况下，重要的是思考和；沟通清楚正在测量什么。例如，假设我们可以评估模型A对数似然的随", "keywords": "沟通清楚正在测量什么, 通常, 这可能是一个困难且微妙的任务, 但仅可以评估一个近似, 的对数概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "290fcf1e-ce5c-4c4e-9265-a51724689dce", "label": "摘要3", "info": "评估生成模型的另一个微妙之处是，评估指标往往是自身困难的研究问；题。可能很难确定模型是否被公平比较。例如，假设我们使用AIS来估；计log  Z，以便为我们刚刚发明的新模型计算", "keywords": "来估, 评估生成模型的另一个微妙之处是, 可能很难确定模型是否被公平比较, 以便为我们刚刚发明的新模型计算, 例如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "870af129-a380-4e69-bc63-fe28bcaecf68", "label": "摘要4", "info": "。因此可能难以判断高似然估计是否是良好模", "keywords": "因此可能难以判断高似然估计是否是良好模", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "37c20f55-0d6d-4402-86df-bdc4255ec596", "label": "摘要5", "info": "。", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af277c11-2fc4-4d10-924e-2f3d2f6913ac", "label": "摘要6", "info": "机器学习的其他领域通常允许在数据预处理中有一些变化。例如，当比", "keywords": "机器学习的其他领域通常允许在数据预处理中有一些变化, 当比, 例如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a94cf33b-a68b-4fe5-9d2d-c51115635496", "label": "摘要7", "info": "较对象识别算法的准确性时，通常可接受的是对每种算法略微不同地预；处理输入图像（基于每种算法具有何种输入要求）。而因为预处理的变；化，会导致生成式建模的不同，甚至非常小和微妙的变化也是完全不可", "keywords": "通常可接受的是对每种算法略微不同地预, 会导致生成式建模的不同, 而因为预处理的变, 基于每种算法具有何种输入要求, 甚至非常小和微妙的变化也是完全不可", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dee9d891-373c-4d2b-b357-d5be3711da86", "label": "摘要8", "info": "预处理的问题通常在基于MNIST数据集上的生成模型产生，MNIST数；据集是非常受欢迎的生成式建模基准之一。MNIST由灰度图像组成。一；些模型将MNIST图像视为实向量空间中的点，而其他模型将其视为二", "keywords": "而其他模型将其视为二, 由灰度图像组成, 预处理的问题通常在基于, 数据集上的生成模型产生, 图像视为实向量空间中的点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2b39edf-0e79-4ac0-ab06-710fb0597bcb", "label": "摘要9", "info": "因为从数据分布生成真实样本是生成模型的目标之一，所以实践者通常；通过视觉检查样本来评估生成模型。在最好的情况下，这不是由研究人；员本身，而是由不知道样品来源的实验受试者完成（Denton  et  al.  ，", "keywords": "所以实践者通常, 因为从数据分布生成真实样本是生成模型的目标之一, 而是由不知道样品来源的实验受试者完成, 这不是由研究人, 员本身", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0255e9d-f568-44bc-a420-cc494d872bb0", "label": "摘要10", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；的。在更实际的设定中，在具有数万个模式的数据上训练后的生成模型；可以忽略少数模式，并且人类观察者不能容易地检查或记住足够的图像", "keywords": "在更实际的设定中, 并且人类观察者不能容易地检查或记住足够的图像, 可以忽略少数模式, 在具有数万个模式的数据上训练后的生成模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "737d53ca-8f61-4ad1-80a5-687824226242", "label": "摘要11", "info": "由于样本的视觉质量不是可靠的标准，所以当计算可行时，我们通常还；评估模型分配给测试数据的对数似然。不幸的是，在某些情况下，似然；性似乎不可能测量我们真正关心的模型的任何属性。例如，MNIST的实", "keywords": "由于样本的视觉质量不是可靠的标准, 评估模型分配给测试数据的对数似然, 我们通常还, 似然, 例如", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d19409c-7698-44da-ad03-1e636d0ab223", "label": "摘要12", "info": "Theis  et  al.  （2015）回顾了评估生成模型所涉及的许多问题，包括上述；的许多想法。他们强调了生成模型有许多不同的用途，并且指标的选择；必须与模型的预期用途相匹配。例如，一些生成模型更好地为大多数真", "keywords": "包括上述, 回顾了评估生成模型所涉及的许多问题, 他们强调了生成模型有许多不同的用途, 并且指标的选择, 的许多想法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa7d36a4-d288-49b2-b524-e5df980062a2", "label": "摘要13", "info": "还是", "keywords": "还是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e9639d9-2dd8-4ede-b71e-54444186a73e", "label": "摘要14", "info": "，如图3.6所；示。不幸的是，即使我们将每个指标的使用限制在最适合的任务上，目；前使用的所有指标仍存在严重的缺陷。因此，生成式建模中最重要的研", "keywords": "前使用的所有指标仍存在严重的缺陷, 即使我们将每个指标的使用限制在最适合的任务上, 因此, 不幸的是, 如图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "510c0569-37f0-4f0c-8600-114a083ae502", "label": "20.15：结论", "level": 2, "group": "chapter-20", "type": "子章節"}, {"id": "d1ca6de4-c438-4ad2-9864-ec7c32556aa8", "label": "摘要1", "info": "参考文献", "keywords": "参考文献", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9434a4ec-cc5b-4503-a7e3-3ee61c0936e8", "label": "摘要2", "info": "索引", "keywords": "索引", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b455b21f-d9f6-4c95-952a-b7080e311579", "label": "摘要3", "info": "为了让模型理解基于给定训练数据表示的大千世界，训练具有隐藏单元；和表示；的生成模型是一种有力方法。通过学习模型", "keywords": "为了让模型理解基于给定训练数据表示的大千世界, 和表示, 通过学习模型, 训练具有隐藏单元, 的生成模型是一种有力方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a3594096-7b12-4c1c-9e7c-4cc91973c6bf", "label": "摘要4", "info": "————————————————————", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b86b299-cbcd-44df-b66b-19635b19689a", "label": "摘要5", "info": "(1)  术语“mcRBM”根据字母M-C-R-B-M发音；“mc”不是“McDonald's”中的“Mc”的发音。", "keywords": "的发音, 发音, 根据字母, 术语, 不是", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b7df26fa-743e-4eba-a376-ca1c418325f3", "label": "摘要6", "info": "(2)    这个版本的Gaussian-Bernoulli  RBM能量函数假定图像数据的每个像素具有零均值。考虑非；零像素均值时，可以简单地将像素偏移添加到模型中。", "keywords": "可以简单地将像素偏移添加到模型中, 零像素均值时, 这个版本的, 考虑非, 能量函数假定图像数据的每个像素具有零均值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7cb41fcd-83e0-418f-ab77-86feb7cc3ab2", "label": "摘要7", "info": "(3)    该论文将模型描述为“深度信念网络”，但因为它可以被描述为纯无向模型（具有易处理逐；层均匀场不动点更新），所以它最适合深度玻尔兹曼机的定义。", "keywords": "所以它最适合深度玻尔兹曼机的定义, 该论文将模型描述为, 层均匀场不动点更新, 深度信念网络, 但因为它可以被描述为纯无向模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d110b516-abec-4fd6-8fea-d8b085563c0d", "label": "摘要8", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；参考文献", "keywords": "参考文献", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1915cbc5-7194-4605-8be4-83e971ec2b12", "label": "摘要9", "info": "S.，Davis，A.，Dean，J.，Devin，M.，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa419d4c-5ebe-4ffa-b34d-b570a700edad", "label": "摘要10", "info": "Abadi，M.，Agarwal，A.，Barham，P.，Brevdo，E.，Chen，Z.，；Citro，C.，Corrado，G.；Ghemawat，S.，Goodfellow，I.，Harp，A.，Irving，G.，Isard，M.，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f8ae59e0-b33b-4dea-8784-0598752b7b92", "label": "摘要11", "info": "Ackley，D.  H.，Hinton，G.  E.，and  Sejnowski，T.  J.（1985）.  A；learning  algorithm  for  Boltzmann  machines.  Cognitive Science  ，9  ，147–；169.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4b2668c-ff16-4575-91dc-0454efdd7e52", "label": "摘要12", "info": "Alain，G.  and  Bengio，Y.（2013）.  What  regularized  auto-encoders  learn；from the data generating distribution. In ICLR'2013，arXiv:1211.4246 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aed5e3ba-f89b-44ac-b33a-1fcd55d3657e", "label": "摘要13", "info": "Alain，G.，Bengio，Y.，Yao，L.，Éric  Thibodeau-Laufer，Yosinski，；J.，and  Vincent，P.（2015）.  GSNs:  Generative  stochastic  networks.；arXiv:1503.05571.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "852eb35a-bb84-483f-b92e-32e33c13cbee", "label": "摘要14", "info": "Anderson，E.（1935）.  The  Irises  of  the  Gaspé  Peninsula.  Bulletin  of  the；American Iris Society ，59 ，2–5.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb2cc655-e612-4738-bf32-c51f25fa8a7d", "label": "摘要15", "info": "Ba，J.，Mnih，V.，and  Kavukcuoglu，K.（2014）.  Multiple  object；recognition with visual attention. arXiv:1412.7755 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "33c35fc6-9d63-4e10-a474-91e6c9fbca1b", "label": "摘要16", "info": "Bachman，P.  and  Precup，D.（2015）.  Variational  generative  stochastic；networks  with  collaborative  shaping.  In  Proceedings  of；the  32nd", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eedb2735-b16d-40f8-9c60-8841cb9f90ca", "label": "摘要17", "info": "Precup，D.（2015）.；Bacon，P.-L.，Bengio，E.，Pineau，J.，and；Conditional  computation  in  neural  networks  using  a  decision-theoretic", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a91b8c62-ddc1-44f7-87e8-420d0b9f5cb1", "label": "摘要18", "info": "Bagnell，J. A. and Bradley，D. M.（2009）. Differentiable sparse coding.；In NIPS'2009 ，pages 113–120.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a3ff3af2-b3ab-486d-94d3-780590930f76", "label": "摘要19", "info": "Bahdanau，D.，Cho，K.，and  Bengio，Y.（2015）.  Neural  machine；translation  by  jointly  learning  to  align  and  translate.  In  ICLR'2015，；arXiv:1409.0473 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "147549a2-37a3-4d44-a49d-ba353b3ae830", "label": "摘要20", "info": "Bahl，L. R.，Brown，P.，de Souza，P. V.，and Mercer，R. L.（1987）.；Speech  recognition  with  continuous-parameter  hidden  Markov  models.；Computer，Speech and Language ，2 ，219–234.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35aa39e4-642b-4f06-8d81-331016d4b315", "label": "摘要21", "info": "Baldi，P.  and  Hornik，K.（1989）.  Neural  networks  and  principal；component  analysis:Learning  from  examples  without  local  minima.  Neural；Networks ，2 ，53–58.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28e042e9-6732-4625-8337-801d230203c2", "label": "摘要22", "info": "Pollastri，G.；Baldi，P.，Brunak，S.，Frasconi，P.，Soda，G.，and；（1999）.  Exploiting  the  past  and  the  future  in  protein  secondary  structure", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eacc632d-036c-4386-9576-70e408e1f601", "label": "摘要23", "info": "Baldi，P.，Sadowski，P.，and  Whiteson，D.（2014）.  Searching；exotic  particles；communications ，5 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "40725b2a-afa3-4518-aced-45d8be6d727c", "label": "摘要24", "info": "in  high-energy  physics  with  deep", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a518cc6-2c8e-4963-839d-26db35ac1f52", "label": "摘要25", "info": "for；learning.  Nature", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef8e9640-ed2a-483d-bbff-be6df281a52d", "label": "摘要26", "info": "Ballard，D.  H.，Hinton，G.  E.，and  Sejnowski，T.  J.（1983）.  Parallel；vision computation. Nature .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e575651e-a20b-469e-9460-359ae8e03a6b", "label": "摘要27", "info": "Barlow，H.  B.（1989）.  Unsupervised  learning.  Neural  Computation  ，1；，295–311.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c70b1f68-69c9-43db-bf13-f07e2fcf71a8", "label": "摘要28", "info": "Barron，A. E.（1993）. Universal approximation bounds for superpositions；of  a  sigmoidal  function.  IEEE  Trans.  on  Information  Theory  ，39  ，930–；945.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e490c2f0-bf71-4bb4-83d9-431b1d459507", "label": "摘要29", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bartholomew，D. J.（1987）. Latent variable models and factor analysis  .；Oxford University Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d7f5715-c7c7-4e4d-a191-b246d1c6fb02", "label": "摘要30", "info": "Basilevsky，A.（1994）.  Statistical  Factor  Analysis  and  Related；Methods:Theory and Applications . Wiley.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4541d277-c1ec-4ae8-911c-209cd794a21a", "label": "摘要31", "info": "Bastien，F.，Lamblin，P.，Pascanu，R.，Bergstra，J.，Goodfellow，；I.，Bergeron，A.，Bouchard，N.，Warde-Farley，D.，and  Bengio，Y.；（2012a）.  Theano:new  features  and  speed  improvements.  Submited  to  the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e2dd2ad-5dbf-4ad1-96b2-fa1b0c0cf933", "label": "摘要32", "info": "Bastien，F.，Lamblin，P.，Pascanu，R.，Bergstra，J.，Goodfellow，I.；J.，Bergeron，A.，Bouchard，N.，and；Theano:new  features  and  speed", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c930598c-de85-4a00-98ed-c479d915f370", "label": "摘要33", "info": "Bengio，Y.（2012b）.；improvements.  Deep  Learning  and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7aabf9d2-19b5-4389-949a-b4c893085416", "label": "摘要34", "info": "Basu，S.  and  Christensen，J.（2013）.  Teaching  classification  boundaries；to humans. In AAAI'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7be28ec0-96b2-4f3e-a3e7-66450e6ba6c5", "label": "摘要35", "info": "International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a4bf290b-cf9d-4906-a7bf-a6f569d83cf1", "label": "摘要36", "info": "Baxter，J.（1995）. Learning internal representations. In Proceedings of the；8th；Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cdab84d3-26e2-42c8-a6a4-c8378e5facae", "label": "摘要37", "info": "Computational", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "105a4050-4c5b-46cc-a33e-b2688e642412", "label": "摘要38", "info": "Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3027efd3-3f0b-4202-96a9-e31756d287f4", "label": "摘要39", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8dfc751-231e-49c8-8de0-076432960046", "label": "摘要40", "info": "Bayer，J.  and  Osendorfer，C.（2014）.  Learning  stochastic  recurrent；networks. ArXiv e-prints .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7db10503-3c12-4b26-8ece-f10beefd38c3", "label": "摘要41", "info": "Becker，S. and Hinton，G.（1992）. A self-organizing neural network that；discovers surfaces in random-dot stereograms. Nature ，355 ，161–163.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6145a3a-9257-4e4d-8a0e-e407614b0e4b", "label": "摘要42", "info": "Behnke，S.（2001）.  Learning  iterative  image  reconstruction  in  the  neural；abstraction pyramid. Int. J. Computational Intelligence and Applications ，1；（4），427–438.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4f07e24-af46-4dbf-9154-392fb160a8a1", "label": "摘要43", "info": "Beiu，V.，Quintana，J.  M.，and  Avedillo，M.；threshold；implementations  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "62243b06-0634-4bfa-a4fa-b74df13ea87c", "label": "摘要44", "info": "J.（2003）.  VLSI；logic-a  comprehensive  survey.  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a9b89fd-8292-42e0-8be5-d1bdb0ecec6e", "label": "摘要45", "info": "Networks，IEEE Transactions on ，14 （5），1217–1243.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef00b035-6597-4062-920b-8e94811423b0", "label": "摘要46", "info": "Belkin，M.  and  Niyogi，P.（2002）.  Laplacian  eigenmaps  and  spectral；techniques  for  embedding  and  clustering.  In  T.  Dietterich，S.  Becker，and；Z.  Ghahramani，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f1d0518-611b-489d-aa6c-d528692d793c", "label": "摘要47", "info": "and  Niyogi，P.（2003a）.  Laplacian", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d11e1e72-2370-414f-bfc3-ebd3fd73eba2", "label": "摘要48", "info": "Belkin，M.；for；dimensionality reduction and  data representation. Neural  Computation ，15", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8889dcf9-e897-4eac-ae4d-842383b58aaf", "label": "摘要49", "info": "eigenmaps", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9a90459-b93a-46d5-ac26-bec4b2f8e1cd", "label": "摘要50", "info": "Belkin，M.  and  Niyogi，P.（2003b）.  Using  manifold  structure  for；In  S.  Becker，S.  Thrun，and  K.；partially", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "13b6c075-2e11-4d77-8d4f-8a2fe9b16c0e", "label": "摘要51", "info": "labeled  classification.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "91aefe66-4f0c-4c7e-8e1e-c314b3068788", "label": "摘要52", "info": "Bengio，E.，Bacon，P.-L.，Pineau，J.，and；Conditional；arXiv:1511.06297.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "65f44f20-26c5-4d0c-9b32-a70170b8b7bd", "label": "摘要53", "info": "computation", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "765ef07a-c6b9-47b3-8340-a0f102458b61", "label": "摘要54", "info": "in  neural  networks", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "579a3192-f1f7-43d2-a77a-9258fb4b3882", "label": "摘要55", "info": "Precup，D.（2015a）.；faster  models.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a9a5d87-742a-463a-a9bc-dd6bd4dc0e4c", "label": "摘要56", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1236c589-7970-43f8-a405-190f3418147e", "label": "摘要57", "info": "Bengio，S.  and  Bengio，Y.（2000a）.  Taking  on；the  curse  of；dimensionality", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e344d7b-763e-4acc-bef4-2822971b1d36", "label": "摘要58", "info": "joint  distributions  using  neural  networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "932903e5-7031-4986-abac-51c6a0a93c6c", "label": "摘要59", "info": "in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "942a9be1-d827-49d5-b9e4-2baccc1ea349", "label": "摘要60", "info": "Bengio，S.，Vinyals，O.，Jaitly，N.，and；Shazeer，N.（2015b）.；Scheduled sampling for sequence prediction with recurrent neural networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a019e357-e57b-479e-b272-af63f7b7f39f", "label": "摘要61", "info": "Bengio，Y.（1991）.  Artificial  Neural  Networks  and  their  Application  to；Sequence  Recognition.  Ph.D.  thesis，McGill  University  ，（Computer；Science），Montreal，Canada.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dd235aa2-3b6e-4ff0-80bf-9c0434fa918d", "label": "摘要62", "info": "Bengio，Y.（2000）.  Gradient-based  optimization  of  hyperparameters.；Neural Computation ，12 （8），1889–1900.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b987882a-4936-4f96-9163-ac6e6e7e0566", "label": "摘要63", "info": "Bengio，Y.（2002）.  New  distributed  probabilistic", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a784bc9d-276c-4f41-979f-4a9f019cfd85", "label": "摘要64", "info": "language  models.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2b307fa7-29dd-4979-b696-5ad7325dcfdb", "label": "摘要65", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Technical Report 1215，Dept. IRO，Université de Montréal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4c332ea-c17a-48a2-86ec-a8cc76fd8544", "label": "摘要66", "info": "Bengio，Y.（2009）. Learning deep architectures for AI . Now Publishers.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea513f2c-d8be-4091-8f0e-04dc2c59c4bb", "label": "摘要67", "info": "Bengio，Y.（2013）. Deep learning of representations: looking forward. In；Statistical Language and Speech Processing ，volume 7978 of Lecture Notes；in  Computer  Science  ，pages  1–37.  Springer，also", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6c99abb-1361-4fc0-8291-7d84c38051e3", "label": "摘要68", "info": "Bengio，Y.（2015）. Early inference in energy-based models approximates；back-propagation.  Technical  Report  arXiv:1510.02777，Universite  de；Montreal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61dfa7a0-cce6-4f48-a1b8-d84627d0019a", "label": "摘要69", "info": "Bengio，Y. and Bengio，S.（2000b）. Modeling high-dimensional discrete；data  with  multi-layer  neural  networks.  In  NIPS  12  ，pages  400–406.  MIT；Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8db4375e-3f01-4dfc-b1bd-141fa6acaa9a", "label": "摘要70", "info": "Bengio，Y.  and  Delalleau，O.（2009）.  Justifying  and  generalizing；contrastive divergence. Neural Computation ，21 （6），1601–1621.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "079f78f9-bf35-4374-926a-a04cd2e7385f", "label": "摘要71", "info": "Bengio，Y.  and  Grandvalet，Y.（2004）.  No  unbiased  estimator  of  the；variance of k-fold cross-validation. In JML（1），pages 1089–1105.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "622ea381-7399-401e-8497-bf84c439ef21", "label": "摘要72", "info": "Bengio，Y. and LeCun，Y.（2007a）. Scaling learning algorithms towards；AI. In Large Scale Kernel Machines .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1918833b-dbbe-4c1c-b5ad-25d738467075", "label": "摘要73", "info": "Bengio，Y. and LeCun，Y.（2007b）. Scaling learning algorithms towards；J.  Weston，；AI.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c818560-9332-42bd-b8b6-28234081a99b", "label": "摘要74", "info": "In  L.  Bottou，O.  Chapelle，D.  DeCoste，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "746b10fe-e255-4b68-804e-e0cbf405ab65", "label": "摘要75", "info": "Bengio，Y.  and  Monperrus，M.（2005）.  Non-local  manifold  tangent；learning.  In  L.  Saul，Y.  Weiss，and  L.  Bottou，editors，Advances  in；Neural  Information  Processing  Systems  17（NIPS'04）  ，pages  129–136.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f809b202-9cc7-49bb-9e85-e4bea1ca431b", "label": "摘要76", "info": "Bengio，Y.  and  Sénécal，J.-S.（2003）.  Quick  training  of  probabilistic；neural nets by importance sampling. In Proceedings of AISTATS 2003 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7e72c67-1907-43c0-8936-eae09789c937", "label": "摘要77", "info": "Bengio，Y.  and  Sénécal，J.-S.（2008）.  Adaptive  importance  sampling  to；accelerate  training  of  a  neural  probabilistic  language  model.  IEEE  Trans.；Neural Networks ，19 （4），713–722.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "367fc427-e521-4716-92fb-ab0511a5c46d", "label": "摘要78", "info": "Bengio，Y.，De  Mori，R.，Flammia，G.，and  Kompe，R.（1991）.；speech；Phonetically  motivated  acoustic  parameters", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ca80ae4-cd2c-4384-b732-d96045afae7e", "label": "摘要79", "info": "for  continuous", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a36e44ca-0651-4046-9ca7-28f9fd34ea7d", "label": "摘要80", "info": "Bengio，Y.，De  Mori，R.，Flammia，G.，and  Kompe，R.（1992）.；Neural  network-Gaussian  mix-ture  hybrid  for  speech  recognition  or  density；estimation. In NIPS 4 ，pages 175–182. Morgan Kaufmann.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cd3e3b1a-e5be-4d02-a149-e5dc1c677f5c", "label": "摘要81", "info": "Bengio，Y.，Frasconi，P.，and  Simard，P.（1993）.  The  problem  of；learning long-term dependencies in recurrent networks. In IEEE International；Conference on Neural Networks，pages 1183–1195 ，San Francisco. IEEE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "38a6d065-0825-4051-9a60-f7f23021a0b5", "label": "摘要82", "info": "Bengio，Y.，Simard，P.，and  Frasconi，P.（1994a）.  Learning；term dependencies with gradient descent is difficult. IEEE Tr. Neural Nets .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92f5e9db-3d0c-4fd8-b794-3dcb5386b4e0", "label": "摘要83", "info": "long-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "558d7c54-2d72-4d94-b12b-0ee654d2a9c1", "label": "摘要84", "info": "Bengio，Y.，Simard，P.，and  Frasconi，P.（1994b）.  Learning；long-；term  dependencies  with  gradient  descent  is  difficult.  IEEE  Transactions  on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e68954b0-01cb-44d4-97d1-b9d16c52f4e8", "label": "摘要85", "info": "Bengio，Y.，Simard，P.，and  Frasconi，P.（1994c）.  Learning；long-；term  dependencies  with  gradient  descent  is  difficult.  IEEE  Transactions  on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b7be88e-0388-48b7-9837-a1d354ca40b1", "label": "摘要86", "info": "Bengio，Y.，Latendresse，S.，and  Dugas，C.（1999）.  Gradient-based；learning of hyper-parameters. In Learning Conference .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ef63336-cf24-451d-8805-d4d978c182a7", "label": "摘要87", "info": "Bengio，Y.，Ducharme，R.，and  Vincent，P.（2001a）.  A；neural；probabilistic  language  model.  In  T.  Leen，T.  Dietterich，and  V.  Tresp，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4cdcbf54-18d5-4b9d-81a4-d6196461d569", "label": "摘要88", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0341e172-a981-42f7-a09d-5d1978535342", "label": "摘要89", "info": "Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "978060ea-e949-4307-973e-afdf9e90de57", "label": "摘要90", "info": "Processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "be57c1af-3ee8-47ef-8920-b78bea9451d8", "label": "摘要91", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bengio，Y.，Ducharme，R.，and  Vincent，P.（2001b）.  A；neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f021a2f-bdd7-4d9e-842b-c66a98f7fa4d", "label": "摘要92", "info": "Bengio，Y.，Ducharme，R.，Vincent，P.，and  Jauvin，C.（2003）.  A；neural probabilistic language model. JMLR ，3 ，1137–1155.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7ccfdf23-4f7a-4d6f-a012-cbe33cfabf74", "label": "摘要93", "info": "Bengio，Y.，Delalleau，O.，and  Le  Roux，N.（2006a）.  The  curse  of；highly variable functions for local kernel machines. In NIPS'2005 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "44b885c2-c145-4e4c-840d-b34c0e6d3a69", "label": "摘要94", "info": "Bengio，Y.，Larochelle，H.，and  Vincent，P.（2006b）.  Non-local；manifold Parzen windows. In NIPS'2005 . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "17a039f4-9de1-4545-b2bd-7d1070d04c60", "label": "摘要95", "info": "Bengio，Y.，Lamblin，P.，Popovici，D.，and；（2007a）. Greedy layer-wise training of deep networks. In NIPS'2006 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b69a0b3d-b8bd-46a7-8cef-1d8977877adc", "label": "摘要96", "info": "Larochelle，H.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab8eff68-7952-4fe8-adc7-43645ec3b8c3", "label": "摘要97", "info": "Bengio，Y.，Lamblin，P.，Popovici，D.，and；Larochelle，H.；（2007b）. Greedy layer-wise training of deep networks. In B. Schölkopf，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2dabba2-f71e-48bc-93a8-f8e76937bcd4", "label": "摘要98", "info": "Bengio，Y.，Lamblin，P.，Popovici，D.，and；Larochelle，H.；（2007c）. Greedy layer-wise training of deep networks. In Adv. Neural Inf.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f459f051-9b89-4888-a141-635b208ecaae", "label": "摘要99", "info": "Bengio，Y.，Lamblin，P.，Popovici，D.，and；Larochelle，H.；（2007d）.  Greedy  layer-wise  training  of  deep  networks.  In  NIPS  19  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96b32d06-e9d4-407f-94ac-0a173ea943bc", "label": "摘要100", "info": "Bengio，Y.，Louradour，J.，Collobert，R.，and  Weston，J.（2009）.；Curriculum learning. In ICML'09 . ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed38a95c-3e3e-49e0-9210-f6343a6f04de", "label": "摘要101", "info": "Bengio，Y.，Mesnil，G.，Dauphin，Y.，and  Rifai，S.（2013a）.  Better；mixing via deep representa-tions. In ICML'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f59a5dd-9ba5-4480-b543-ca3081c3b6b2", "label": "摘要102", "info": "Bengio，Y.，Léonard，N.，and  Courville，A.（2013b）.  Estimating  or；conditional；propagating  gradients", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f91b30d-0f7e-47f5-b117-945865797dc1", "label": "摘要103", "info": "stochastic  neurons", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79fb35d7-eae8-4e03-a742-c80cd545e195", "label": "摘要104", "info": "through", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a34506c0-b074-40b5-8dff-81fff5ce287e", "label": "摘要105", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a2633753-6157-49cb-8ca8-f5b858e52147", "label": "摘要106", "info": "computation. arXiv:1308.3432.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6827336-3233-419d-a501-5bd44b468205", "label": "摘要107", "info": "Bengio，Y.，Yao，L.，Alain，G.，and；Generalized denoising auto-encoders as generative models. In NIPS'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7dd8c1c7-fdc8-4131-892b-5575ae0115ec", "label": "摘要108", "info": "Vincent，P.（2013c）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d13bf0e-a9e4-4c36-bd4d-4439acb4c0f1", "label": "摘要109", "info": "Bengio，Y.，Courville，A.，and  Vincent，P.（2013d）.  Representation；learning:  A  review  and  new  perspectives.  Pattern  Analysis  and  Machine；Intelligence，IEEE Transactions on ，35 （8），1798–1828.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "905de49c-1528-4385-b901-b95e19c9c096", "label": "摘要110", "info": "Bengio，Y.，Thibodeau-Laufer，E.，Alain，G.，and；Yosinski，J.；（2014）.  Deep  generative  stochastic  networks  trainable  by  backprop.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0bdf7eab-0340-4edc-bb86-f350f77a5b94", "label": "摘要111", "info": "Bennett，C.（1976）.  Efficient  estimation  of  free  energy  differences  from；Monte Carlo data. Journal of Computational Physics ，22 （2），245–268.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a798912c-0bfd-4bb7-9308-6762957aa6e7", "label": "摘要112", "info": "Bennett，J. and Lanning，S.（2007）. The Netflix prize.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b816f65a-d479-43d9-851f-f43277a3c03d", "label": "摘要113", "info": "Berger，A.  L.，Della  Pietra，V.  J.，and  Della  Pietra，S.  A.（1996）.  A；maximum  entropy  approach  to  natural  language  processing.  Computational；Linguistics ，22 ，39–71.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1615517e-ac63-411d-b66a-16e7dd22e3c1", "label": "摘要114", "info": "Berglund，M.  and  Raiko，T.（2013）.  Stochastic  gradient  estimate；variance  in  contrastive  diver-gence  and  persistent  contrastive  divergence.；CoRR ，abs/1312.6002 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7467e15d-4c1e-4548-9d33-5a398878061c", "label": "摘要115", "info": "Bergstra，J.（2011）.  Incorporating  Complex  Cells  into  Neural  Networks；for Pattern Classification . Ph.D. thesis，Université de Montréal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fadf53b1-1a3e-42a6-a96b-a8c46bf455a5", "label": "摘要116", "info": "Bergstra，J.  and  Bengio，Y.（2009）.  Slow，decorrelated  features  for；pretraining  complex  cell-like  networks.  In  NIPS  22  ，pages  99–107.  MIT；Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "216013d2-d0ea-483a-b25a-ac4bbdc48504", "label": "摘要117", "info": "Bergstra，J. and Bengio，Y.（2011）. Random search for hyper-parameter；optimization. The Learning Workshop ，Fort Lauderdale，Florida.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14b0ed66-dbce-4c85-9086-9c899158a6bb", "label": "摘要118", "info": "Bergstra，J. and Bengio，Y.（2012）. Random search for hyper-parameter", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90fe7cf7-ab33-4547-883c-3c019f038f9c", "label": "摘要119", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；optimization. J. Machine Learning Res. ，13 ，281–305.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c08ae35c-f109-4ea2-8542-a83f9d26975c", "label": "摘要120", "info": "Bergstra，J.，Breuleux，O.，Bastien，F.，Lamblin，P.，Pascanu，R.，；Bengio，Y.；Desjardins，G.，Turian，J.，Warde-Farley，D.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b926b1cc-28a0-4be9-98e2-e1cde1a168e3", "label": "摘要121", "info": "Bergstra，J.，Breuleux，O.，Bastien，F.，Lamblin，P.，Pascanu，R.，；Desjardins，G.，Turian，J.，Warde-Farley，D.，and；Bengio，Y.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b96971e7-2281-415b-a451-4e0615b11b74", "label": "摘要122", "info": "Bergstra，J.，Breuleux，O.，Bastien，F.，Lamblin，P.，Pascanu，R.，；Bengio，Y.；Desjardins，G.，Turian，J.，Warde-Farley，D.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "13a97942-750b-44d0-b51c-ba995aafbc4c", "label": "摘要123", "info": "Bergstra，J.，Bardenet，R.，Bengio，Y.，and；Algorithms for hyper-parameter optimization. In NIPS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "878046e8-3805-46c9-b064-9fdbc2eeece9", "label": "摘要124", "info": "Kégl，B.（2011）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5fd877a-2495-407c-b27f-9c2682a0605e", "label": "摘要125", "info": "Berkes，P.  and  Wiskott，L.（2005）.  Slow  feature  analysis  yields  a  rich；repertoire  of  complex  cell  properties.  Journal  of  Vision  ，5  （6），579–；602.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb180cb5-ce61-43a7-a155-67a8005318c9", "label": "摘要126", "info": "Bertsekas，D. P. and Tsitsiklis，J.（1996）. Neuro-Dynamic Programming；. Athena Scientific.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab6f9e80-4f95-46c5-aa56-3f52014d509d", "label": "摘要127", "info": "Besag，J.（1975）.  Statistical  analysis  of  non-lattice  data.  The Statistician；，24 （3），179–195.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee80ceeb-bffe-4add-aedc-2a5bb3a7c582", "label": "摘要128", "info": "Bishop，C. M.（1994）. Mixture density networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "18ee684b-22bc-41ac-ba55-031175940344", "label": "摘要129", "info": "Bishop，C.  M.（1995a）.  Regularization  and  complexity  control  in  feed-；forward  networks.  In  Proceedings  International  Conference  on  Artificial；Neural Networks ICANN'95 ，volume 1，page 141–148.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2df60063-d1de-45bc-9c7b-cd63fe9fe621", "label": "摘要130", "info": "Bishop，C.  M.（1995b）.  Training  with  noise  is  equivalent  to  Tikhonov；regularization. Neural Computation ，7 （1），108–116.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5486ece5-a734-4b23-a8b3-af71f79c3ef3", "label": "摘要131", "info": "Bishop，C.  M.（2006）.  Pattern  Recognition  and  Machine  Learning  .；Springer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6814550-8b48-4f0e-a516-18a3fd152405", "label": "摘要132", "info": "Blum，A. L. and Rivest，R. L.（1992）. Training a 3-node neural network；is NP-complete.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea1f49b4-3097-4fec-8c0b-23f938e5d80d", "label": "摘要133", "info": "Blumer，A.，Ehrenfeucht，A.，Haussler，D.，and  Warmuth，M.  K.；（1989）. Learnability and the Vapnik–Chervonenkis dimension. Journal of；the ACM ，36 （4），865–929.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c54dd257-d762-4919-a30b-5420f2f07bd8", "label": "摘要134", "info": "Bonnet，G.（1964）.  Transformations  des  signaux  aléatoires  à  travers  les；systèmes non linéaires sans mémoire. Annales des Télécommunications ，19；（9–10），203–220.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "016252e4-9ce4-4818-ada0-85e806b11e92", "label": "摘要135", "info": "Bordes，A.，Weston，J.，Collobert，R.，and；Learning structured embeddings of knowledge bases. In AAAI 2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92d8f65e-e01e-4415-8700-53d0620cea09", "label": "摘要136", "info": "Bengio，Y.（2011）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e6e1e27-1200-4638-9f6c-7146676a9f76", "label": "摘要137", "info": "Bordes，A.，Glorot，X.，Weston，J.，and  Bengio，Y.（2012）.  Joint；learning  of  words  and  meaning  representations  for  open-text  semantic；parsing. AISTATS'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1626eb3-4ebf-4356-8a22-5fde7ed4b4d9", "label": "摘要138", "info": "Bordes，A.，Glorot，X.，Weston，J.，and  Bengio，Y.（2013a）.  A；semantic  matching  energy  func-tion  for  learning  with  multi-relational  data.；Machine Learning: Special Issue on Learning Semantics .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb5c3282-e649-4d80-a07b-19942255f2f4", "label": "摘要139", "info": "Bordes，A.，Usunier，N.，Garcia-Duran，A.，Weston，J.，and；Yakhnenko，O.（2013b）.  Translating  embeddings  for  modeling  multi-；relational  data.  In  C.  Burges，L.  Bottou，M.  Welling，Z.  Ghahramani，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "50624163-0ec0-424a-8051-53298cccddb9", "label": "摘要140", "info": "Bornschein，J.  and  Bengio，Y.（2015）.  Reweighted  wake-sleep.  In；ICLR'2015，arXiv:1406.2751 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "89177513-4300-4469-8886-605db97b87ba", "label": "摘要141", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bornschein，J.，Shabanian，S.，Fischer，A.，and  Bengio，Y.（2015）.；report，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61da8540-797e-45f9-bdc6-6f1e40cb5c82", "label": "摘要142", "info": "Boser，B.  E.，Guyon，I.  M.，and  Vapnik，V.  N.（1992）.  A  training；algorithm for optimal margin classifiers. In COLT '92: Proceedings of thefifth；annual workshop on Computational learning theory ，pages 144–152，New", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "06c70ff7-fcf9-464b-a953-409b385777d8", "label": "摘要143", "info": "Bottou，L.（1998）.  Online  algorithms  and  stochastic  approximations.  In；D.  Saad，editor，Online  Learning  in  Neural  Networks；.  Cambridge", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "350283b0-4972-4b90-9878-61ac28eb7dc4", "label": "摘要144", "info": "Bottou，L.（2011）.  From  machine；Technical report，arXiv.1102.1808.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "542aee8d-0d2b-4582-b588-ac51973bc837", "label": "摘要145", "info": "learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "710518fc-07ee-44dc-8a67-7d32cc9c2685", "label": "摘要146", "info": "to  machine  reasoning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f290ac1-447a-45cc-afe7-8b223177d16a", "label": "摘要147", "info": "Bottou，L.（2015）.  Multilayer  neural  networks.  Deep  Learning  Summer；School.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f419233-f245-4dd9-ac35-8cc6ee0c1005", "label": "摘要148", "info": "Bottou，L.  and  Bousquet，O.（2008a）.  The  tradeoffs  of  large  scale；learning.  In  J.  Platt，D.  Koller，Y.  Singer，and  S.  Roweis，editors，；Advances  in  Neural  Information  Processing  Systems  20（NIPS'07）  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb941abc-0e8d-4eaf-be3e-ea031cce0215", "label": "摘要149", "info": "Bottou，L.  and  Bousquet，O.（2008b）.  The  tradeoffs  of  large  scale；learning. In NIPS'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f04bcf7f-6a06-43cf-aaf8-94a99a5515bd", "label": "摘要150", "info": "Boulanger-Lewandowski，N.，Bengio，Y.，and  Vincent，P.（2012）.；Modeling；sequences:", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6300c32-315b-44b0-98c0-778ed6f0d8b8", "label": "摘要151", "info": "temporal  dependen-cies", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2bc1c6e-f64f-4d40-add2-e97a748d40ed", "label": "摘要152", "info": "in  high-dimensional", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4d0a777-2cff-4a95-bbdc-3ff42f51518e", "label": "摘要153", "info": "Boureau，Y.，Ponce，J.，and LeCun，Y.（2010）. A theoretical analysis；of feature pooling in vision algorithms. In Proc. International Conference on；Machine learning（ICML'10） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bfb22cf7-118c-4d2f-bb59-3018e3fbcd73", "label": "摘要154", "info": "Boureau，Y.，Le  Roux，N.，Bach，F.，Ponce，J.，and  LeCun，Y.；（2011）. Ask the locals: multi-way local pooling for image recognition. In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2b4b6340-25a0-4ca7-96e6-6977ec3be147", "label": "摘要155", "info": "Proc. International Conference on Computer Vision（ICCV'11） . IEEE.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5863a1e3-ca00-4640-98be-1e5b12cd8cbd", "label": "摘要156", "info": "Bourlard，H.  and  Kamp，Y.（1988）.  Auto-association  by  multilayer；perceptrons  and  singular  value  decomposition.  Biological Cybernetics  ，59；，291–294.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f7145cb8-4737-410f-ba91-910fc21c6ee3", "label": "摘要157", "info": "Bourlard，H.  and  Wellekens，C.（1989）.  Speech  pattern  discrimination；and multi-layered percep-trons. Computer Speech and Language ，3 ，1–19.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bffe1a28-133e-40fd-a086-24ab433bb27e", "label": "摘要158", "info": "Boyd，S.  and  Vandenberghe，L.（2004）.  Convex  Optimization；Cambridge University Press，New York，NY，USA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6ba5adb2-223b-4aca-ade1-3d66a2d78ba9", "label": "摘要159", "info": ".", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "698d2156-2929-4f65-a004-1366e0649b2a", "label": "摘要160", "info": "L.，Raghavan，R.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57d06413-8ca8-4ab2-99c2-243b7c355e48", "label": "摘要161", "info": "Brady，M.；Back-；propagation fails to separate where perceptrons succeed. IEEE Transactions", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21b082f0-8c82-45b7-9cf4-3bc0c41a4bb8", "label": "摘要162", "info": "Slawny，J.（1989）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc0d2d5f-a5ed-4976-86ab-4940f3c30837", "label": "摘要163", "info": "Brakel，P.，Stroobandt，D.，and；Schrauwen，B.（2013）.  Training；energy-based  models  for  time-series  imputation.  Journal  of  Machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f4934de-9793-42c2-8dfd-7afb5be85187", "label": "摘要164", "info": "Brand，M.（2003a）.  Charting  a  manifold.  In  S.  Becker，S.  Thrun，and；K.  Obermayer，editors，Advances；in  Neural  Information  Processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6344d2d6-4cca-4c56-b492-955a8a3b202b", "label": "摘要165", "info": "Brand，M.（2003b）. Charting a manifold. In NIPS'2002 ，pages 961–968.；MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "476341ec-0dd2-4c50-af9e-8153b3001eeb", "label": "摘要166", "info": "Breiman，L.（1994）.  Bagging  predictors.  Machine  Learning  ，24；（2），123–140.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c0e404f-82e6-49f7-8c3b-b124b1b721a4", "label": "摘要167", "info": "Breiman，L.，Friedman，J.  H.，Olshen，R.  A.，and  Stone，C.；J.；（1984）.  Classification  and  Regression  Trees  .  Wadsworth  International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7910c3b7-579e-40a3-aa6b-b59156d2c94b", "label": "摘要168", "info": "Bridle，J. S.（1990）.  Alphanets: a recurrent ‘neural’ network architecture；with  a  hidden  Markov  model  interpretation.  Speech  Communication  ，9；（1），83–92.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2268d4b7-75ef-4065-9c62-f751d5eda68c", "label": "摘要169", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；N.，and；Briggman，K.，Denk，W.，Seung，S.，Helmstaedter，M.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12f9e7cd-7b68-4d8b-b2ad-59aa588b8826", "label": "摘要170", "info": "Brown，P.  F.，Cocke，J.，Pietra，S.  A.  D.，Pietra，V.  J.  D.，Jelinek，；F.，Lafferty，J.  D.，Mercer，R.  L.，and  Roossin，P.  S.（1990）.  A；statistical  approach  to  machine  translation.  Computational  linguistics  ，16", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cb2d47eb-6223-43c5-8b64-6554bfea869a", "label": "摘要171", "info": "Brown，P.  F.，Pietra，V.  J.  D.，DeSouza，P.  V.，Lai，J.  C.，and；Mercer，R.  L.（1992）.  Class-based  n  -gram  models  of  natural  language.；Computational Linguistics ，18 ，467–479.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8c57ebcb-1d54-4cd0-a8f5-b9d3c4896b77", "label": "摘要172", "info": "Bryson，A. and Ho，Y.（1969）. Applied optimal control: optimization，；estimation，and control . Blaisdell Pub. Co.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6a63f0ea-1371-4345-b407-d67dc4412ef5", "label": "摘要173", "info": "Bryson，Jr.，A.  E.  and  Denham，W.  F.（1961）.  A  steepest-ascent；method for solving optimum programming problems. Technical Report BR-；1303，Raytheon Company，Missle and Space Division.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "99881361-0d90-4cec-9b9c-ecdc62e0b8f0", "label": "摘要174", "info": "Buciluǎ，C.，Caruana，R.，and  Niculescu-Mizil，A.（2006）.  Model；compression.  In  Proceedings  of  the  12th  ACM  SIGKDD  international；conference  on  Knowledge  discovery  and  data  mining  ，pages  535–541.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d964fe22-fd62-4b98-a5c9-f7c2ccc6e341", "label": "摘要175", "info": "Burda，Y.，Grosse，R.，and  Salakhutdinov，R.（2015）.；weighted autoencoders. arXiv preprint arXiv:1509.00519 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c44d8529-6198-4a1a-a18c-bbacbaa4d554", "label": "摘要176", "info": "Importance", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ad96089a-32b1-48dc-9703-c47f472f685d", "label": "摘要177", "info": "speech", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8ed5e0ba-b3a1-459e-96a2-5decf5b2fb14", "label": "摘要178", "info": "Cai，M.，Shi，Y.，and  Liu，J.（2013）.  Deep  maxout  neural  networks；In  Automatic  Speech  Recognition  and；for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21bfe57b-87c3-42a3-a183-c82f8f52d6e7", "label": "摘要179", "info": "recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d3fe327-8a22-4377-9911-3b81eafbe18b", "label": "摘要180", "info": "Carreira-Perpiñan，M.  A.  and  Hinton，G.  E.（2005）.  On  contrastive；divergence learning. In AISTATS'2005 ，pages 33–40.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbc7e130-ff70-4d32-88ff-16aca88ce428", "label": "摘要181", "info": "Caruana，R.（1993）.  Multitask  connectionist  learning.  In  Proceedings  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "002132d4-0a7d-443b-b32e-c6b02686fb95", "label": "摘要182", "info": "the 1993 Connectionist Models Summer School ，pages 372–379.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d498a3d6-8319-4242-8f2e-66d1e2835b83", "label": "摘要183", "info": "Cauchy，A.（1847）.  Méthode  générale  pour  la  résolution  de  systèmes；d'équations  simultanées.  In  Compte  rendu  des  séances  de  l'académie  des；sciences ，pages 536–538.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8119230-7aa9-4630-9d28-20d549cd2c14", "label": "摘要184", "info": "Cayton，L.（2005）.  Algorithms  for  manifold  learning.  Technical  Report；CS2008-0923，UCSD.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb448ae3-8924-4546-86b5-d4d5264d8614", "label": "摘要185", "info": "Chandola，V.，Banerjee，A.，and；detection: A survey. ACM computing surveys（CSUR） ，41 （3），15.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8469a28d-5f3a-456d-8699-78e583ca0eaa", "label": "摘要186", "info": "Kumar，V.（2009）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "acc16f2c-b637-44b1-989a-deace6fe0719", "label": "摘要187", "info": "Anomaly", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "832951dd-8836-4eb0-b198-df24befe3b23", "label": "摘要188", "info": "Chapelle，O.，Weston，J.，and  Schölkopf，B.（2003）.  Cluster  kernels；for semi-supervised learning. In S. Becker，S. Thrun，and K. Obermayer，；editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "057e163d-3a4b-4b01-b84c-a58554724404", "label": "摘要189", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c7b4c2b-d577-4865-a9f5-26be1444cbaa", "label": "摘要190", "info": "Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8cc55668-7b3c-4c52-9cfd-5111dc3b4a37", "label": "摘要191", "info": "Chapelle，O.，Schölkopf，B.，and  Zien，A.，editors（2006）.  Semi-；Supervised Learning . MIT Press，Cambridge，MA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3bd1f93-07a9-41ee-917f-81131e8d9262", "label": "摘要192", "info": "Chellapilla，K.，Puri，S.，and  Simard，P.（2006）.  High  Performance；Convolutional Neural Net-works for Document Processing. In Guy Lorette，；editor，Tenth", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "be804bfa-cbb1-4767-b06c-3be57b788ea3", "label": "摘要193", "info": "Chen，B.，Ting，J.-A.，Marlin，B.  M.，and  de  Freitas，N.（2010）.；Deep  learning  of  invariant  spatio-temporal  features  from  video.  NIPS*2010；Deep Learning and Unsupervised Feature Learning Workshop.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "da1c052b-4d17-4b5a-ab9b-4f349525488d", "label": "摘要194", "info": "Chen，S.  F.  and  Goodman，J.  T.（1999）.  An  empirical  study  of；smoothing  techniques  for  language  modeling.  Computer，Speech  and；Language ，13 （4），359–393.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46590df4-49eb-4bfe-bb70-1ad5baa61d9d", "label": "摘要195", "info": "Chen，T.，Du，Z.，Sun，N.，Wang，J.，Wu，C.，Chen，Y.，and；Temam，O.（2014a）.  DianNao:  A；small-footprint  high-throughput", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e57de46-a821-4235-a606-1037ca418d7a", "label": "摘要196", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；international  conference  on  Architectural  support；languages and operating systems ，pages 269–284. ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "332d312d-0555-4aa6-a8f8-71ac0d39dd7a", "label": "摘要197", "info": "for  programming", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "03852dce-082e-4890-919b-991778f921c3", "label": "摘要198", "info": "Chen，T.，Li，M.，Li，Y.，Lin，M.，Wang，N.，Wang，M.，；Xiao，T.，Xu，B.，Zhang，C.，and  Zhang，Z.（2015）.  MXNet:  A；flexible and  efficient machine learning library for heterogeneous distributed", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a7cd845-0af0-4db7-a1be-c1b70c84a7dc", "label": "摘要199", "info": "Chen，Y.，Luo，T.，Liu，S.，Zhang，S.，He，L.，Wang，J.，Li，；L.，Chen，T.，Xu，Z.，Sun，N.，et  al.  （2014b）.  DaDianNao:  A；machine-learning  supercomputer.  In  Microarchitecture（MICRO），2014", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "34e33e5a-592d-4c45-8620-c6b51a23eee5", "label": "摘要200", "info": "Kalyanaraman，K.；Chilimbi，T.，Suzue，Y.，Apacible，J.，and；（2014）.  Project  Adam:  Building  an  efficient  and  scalable  deep  learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "258a3d67-79d0-4376-a699-86e335ec0811", "label": "摘要201", "info": "Cho，K.，Raiko，T.，and；is；efficient  for  learning  restricted  Boltzmann  machines.  In  Proceedings  of  the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef9f0e0c-35a9-48c0-8f39-8abd9a52147f", "label": "摘要202", "info": "Ilin，A.（2010a）.  Parallel", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e3c2d48-632a-49ac-8f0d-81f239d240bb", "label": "摘要203", "info": "tempering", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7860071d-d791-4ffa-a4aa-4100e104ad10", "label": "摘要204", "info": "Cho，K.，Raiko，T.，and；efficient for learning restricted Boltzmann machines. In IJCNN'2010.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6736d79-43a7-4bd7-914a-fa7d5cf07858", "label": "摘要205", "info": "Ilin，A.（2010b）.  Parallel", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1c5c8aa0-55c5-4db9-80d5-ed5fbf8723b8", "label": "摘要206", "info": "tempering", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa332e0b-d8ab-4d09-a447-dc07038305c9", "label": "摘要207", "info": "is", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bab2b06a-20b3-4181-9212-837b84e624d4", "label": "摘要208", "info": "Cho，K.，Raiko，T.，and  Ilin，A.（2011）.  Enhanced  gradient  and；adaptive  learning  rate  for  training  restricted  Boltzmann  machines.  In；ICML'2011 ，pages 105–112.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ecb1e42a-4434-4edc-874b-501874431e0c", "label": "摘要209", "info": "Merriënboer，B.，Gülçehre，Ç.，Bahdanau，D.，；Cho，K.，Van；Bougares，F.，Schwenk，H.，and Bengio，Y.（2014a）. Learning phrase", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b406b570-82c1-4922-b65c-b01b57512f53", "label": "摘要210", "info": "Merriënboer，B.，Gulcehre，C.，Bougares，F.，；Cho，K.，van；Schwenk，H.，and Bengio，Y.（2014b）. Learning phrase representations", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a4083288-e5af-4e91-a393-e24c9460912c", "label": "摘要211", "info": "the  Empiricial  Methods", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3467591-7ff3-4f16-8842-8efaeb3953c8", "label": "摘要212", "info": "for  statistical  machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "810286db-9db8-4e75-ae82-521d1db1b510", "label": "摘要213", "info": "translation.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe6b6bcd-c1c3-4c44-81e7-06ec95d646ef", "label": "摘要214", "info": "Cho，K.，Van  Merriënboer，B.，Bahdanau，D.，and；Bengio，Y.；（2014c）. On the properties of neural machine translation: Encoder-decoder", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "655543a2-e08d-4bf6-a248-750444af1ec5", "label": "摘要215", "info": "Choromanska，A.，Henaff，M.，Mathieu，M.，Arous，G.；LeCun，Y.（2014）. The loss surface of multilayer networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ff13e4f-44f3-4eb8-8048-ccf6b8395da8", "label": "摘要216", "info": "B.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0d984aa-17a7-4bb9-b78b-a76220dd4926", "label": "摘要217", "info": "Chorowski，J.，Bahdanau，D.，Cho，K.，and；Bengio，Y.（2014）.；End-to-end  continuous  speech  recognition  using  attention-based  recurrent", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db950230-3c06-48ae-80b9-8adba2829876", "label": "摘要218", "info": "Christianson，B.（1992）.  Automatic  Hessians  by  reverse  accumulation.；IMA Journal of Numerical Analysis ，12 （2），135–150.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4b9f79d9-eaa9-4ee9-b55c-07cc10904bff", "label": "摘要219", "info": "Chrupala，G.，Kadar，A.，and Alishahi，A.（2015）. Learning language；through pictures. arXiv 1506.03694.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eed83a95-6ce6-47e4-af8e-9a90679a7746", "label": "摘要220", "info": "Bengio，Y.（2014）.；Chung，J.，Gulcehre，C.，Cho，K.，and；Empirical  evaluation  of  gated  recurrent  neural  networks  on  sequence", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6967cde1-4ecc-40b4-a5fd-e4f6c4c92e7f", "label": "摘要221", "info": "Chung，J.，Gülçehre，Ç.，Cho，K.，and  Bengio，Y.（2015a）.  Gated；feedback recurrent neural networks. In ICML'15 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "236565d6-41dd-4b02-b82c-15a126b1ef28", "label": "摘要222", "info": "Chung，J.，Kastner，K.，Dinh，L.，Goel，K.，Courville，A.，and；Bengio，Y.（2015b）. A recurrent latent variable model for sequential data.；In NIPS'2015 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "76e80402-719a-4206-bcd2-08252b43e0c8", "label": "摘要223", "info": "Schmidhuber，J.（2012）.；Ciresan，D.，Meier，U.，Masci，J.，and；Multi-column  deep  neural  network  for  traffic  sign  classification.  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7efbdc6-a60b-4537-ade6-7bd6e9c9064b", "label": "摘要224", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Ciresan，D.  C.，Meier，U.，Gambardella，L.  M.，and  Schmidhuber，J.；（2010）.  Deep  big  simple  neural  nets  for  handwritten  digit  recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1c9e7ec4-c934-43d9-85b3-dcb32fcd3a47", "label": "摘要225", "info": "Coates，A.  and  Ng，A.  Y.（2011）.  The  importance  of  encoding  versus；training with sparse coding and vector quantization. In ICML'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0699bfd-6c50-44a4-a429-24878a9a5fcb", "label": "摘要226", "info": "Coates，A.，Lee，H.，and  Ng，A.  Y.（2011）.  An  analysis  of  single-；layer  networks  in  unsuper-vised  feature  learning.  In  Proceedings  of  the；Thirteenth", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "606a1064-fe87-463c-929f-632f9a87f67a", "label": "摘要227", "info": "International  Conference  on  Artificial", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88784f4f-c20e-4119-b9db-6aedea1373f7", "label": "摘要228", "info": "Coates，A.，Huval，B.，Wang，T.，Wu，D.，Catanzaro，B.，and；Andrew，N.（2013）.  Deep  learning  with  COTS  HPC  systems.  In  S.；and  D.  McAllester，editors，Proceedings  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5953b4c7-d25b-4aab-bc42-52a77032529e", "label": "摘要229", "info": "Cohen，N.，Sharir，O.，and  Shashua，A.（2015）.  On  the  expressive；power of deep learning: A tensor analysis. arXiv:1509.05009.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4958503b-69ca-42d7-94e8-fba4dc679fbe", "label": "摘要230", "info": "Collobert，R.（2004）.  Large  Scale  Machine  Learning  .  Ph.D.  thesis，；Université de Paris VI，LIP6.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b826b4ff-dba6-43b3-8750-5e0ada76af44", "label": "摘要231", "info": "Collobert，R.（2011）.  Deep  learning  for  efficient  discriminative  parsing.；In AISTATS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e85af87f-517f-4881-8535-00b10adf83b9", "label": "摘要232", "info": "Collobert，R.  and Weston，J.（2008a）. A unified architecture for natural；language  processing:  Deep  neural  networks  with  multitask  learning.  In；ICML'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1f3b985f-c1c6-4420-a4b9-f1eb3a54ec6f", "label": "摘要233", "info": "Collobert，R. and Weston，J.（2008b）. A unified architecture for natural；language  processing:  Deep  neural  networks  with  multitask  learning.  In；ICML'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d04b4229-82a7-430c-8823-9c8b0e9ff6d3", "label": "摘要234", "info": "Collobert，R.，Bengio，S.，and Bengio，Y.（2001）. A parallel mixture；of SVMs for very large scale problems. Technical Report 12，IDIAP.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9c08e92-eed3-40a2-abaa-6e6db0d1297a", "label": "摘要235", "info": "Collobert，R.，Bengio，S.，and Bengio，Y.（2002）. Parallel mixture of；SVMs for very large scale problem. Neural Computation .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce9e9385-2cf4-4126-951d-794fc51ca3ce", "label": "摘要236", "info": "Collobert，R.，Weston，J.，Bottou，L.，Karlen，M.，Kavukcuoglu，；K.，and  Kuksa，P.（2011a）.  Natural  language  processing（almost）；from  scratch.  The  Journal  of  Machine  Learning  Research  ，12  ，2493–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9097d801-48f3-4dc5-9ede-ea61571bfb05", "label": "摘要237", "info": "Collobert，R.，Kavukcuoglu，K.，and  Farabet，C.（2011b）.  Torch7:  A；In  BigLearn，NIPS；Matlab-like  environment", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e5f494c-a8f6-4064-acdc-f60597374249", "label": "摘要238", "info": "for  machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcc80631-cde2-41b5-a3a2-e21d12c47628", "label": "摘要239", "info": "learning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c7f0b0e5-0f68-479c-8860-28d558bda31c", "label": "摘要240", "info": "Comon，P.（1994）.；concept？Signal Processing ，36 ，287–314.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b0eaae5-5439-4869-89d0-4f33a6b58a7c", "label": "摘要241", "info": "Independent", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abe83164-9186-4485-b0e4-d5b0113861df", "label": "摘要242", "info": "component", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1fbdd2ce-d9f1-49c3-8200-d47c308c0a64", "label": "摘要243", "info": "analysis-a", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0079693-8df9-4524-ac17-eea16b5ff72b", "label": "摘要244", "info": "new", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "208b5110-2bab-47aa-97da-8a18e37f20bd", "label": "摘要245", "info": "Cortes，C.  and  Vapnik，V.（1995）.  Support  vector  networks.  Machine；Learning ，20 ，273–297.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c93f1a6-d582-4244-a1e8-076e4d115640", "label": "摘要246", "info": "Couprie，C.，Farabet，C.，Najman，L.，and；LeCun，Y.（2013）.；Indoor  semantic  segmentation  using  depth  information.  In  International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11aa7fdf-dda6-4aff-89f2-1841127efc97", "label": "摘要247", "info": "Courbariaux，M.，Bengio，Y.，and David，J.-P.（2015）. Low precision；arithmetic for deep learning. In Arxiv:1412.7024，ICLR'2015 Workshop .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0240f8bf-fd48-40f1-b2b8-8efb0cb2f468", "label": "摘要248", "info": "Courville，A.，Bergstra，J.，and  Bengio，Y.（2011a）.  Unsupervised；models of images by spike-and-slab RBMs. In ICML'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9d3958d-d3f0-44ff-8f03-c1de21d44cb7", "label": "摘要249", "info": "Courville，A.，Bergstra，J.，and  Bengio，Y.（2011b）.  Unsupervised；models of images by spike-and-slab RBMs. In ICM（1b）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "06361cba-bf28-46be-a267-559d06ae6718", "label": "摘要250", "info": "Courville，A.，Desjardins，G.，Bergstra，J.，and  Bengio，Y.（2014）.；The  spike-and-slab  RBM  and  extensions  to  discrete  and  sparse  data；Intelligence，IEEE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c32242fb-bed4-42ee-aa18-1bec6b0d6e1f", "label": "摘要251", "info": "and  Machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b681f0df-e440-4c9c-a03b-0e8d3dd9e886", "label": "摘要252", "info": "Cover，T.  M.  and  Thomas，J.  A.（2006）.  Elements  of  Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6673a64-732f-407a-a225-038bc08f4250", "label": "摘要253", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Theory，2nd Edition . Wiley-Interscience.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db1c20e5-37d4-44c5-8b0b-473461a79690", "label": "摘要254", "info": "Cox，D.  and  Pinto，N.（2011）.  Beyond  simple  features:  A  large-scale；feature search approach to unconstrained face recognition. In Automatic Face；&  Gesture  Recognition  and  Workshops（FG  2011），2011", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "801163d9-ed3b-424b-9a4a-4258f0b3ff29", "label": "摘要255", "info": "Cramér，H.（1946）.  Mathematical  methods  of  statistics；University Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6acb3e36-efa6-43b4-be04-3bc9d7332619", "label": "摘要256", "info": ".  Princeton", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "80b8d7c3-0c72-4d63-8eaa-c160282fa63f", "label": "摘要257", "info": "Crick，F. H. C. and Mitchison，G.（1983）. The function of dream sleep.；Nature ，304 ，111–114.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46de96ae-e9f1-4962-8509-05f8c664a7cf", "label": "摘要258", "info": "Cybenko，G.（1989）.  Approximation  by  superpositions  of  a  sigmoidal；function. Mathematics of Control，Signals，and Systems ，2 ，303–314.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2134a31f-af94-420d-8778-5178edd4edce", "label": "摘要259", "info": "E.，Ranzato，M.，Mohamed，A.，and  Hinton，G.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d7bd14f-de28-413e-91b8-729ea83304bb", "label": "摘要260", "info": "Dahl，G.；E.；（2010）. Phone recognition with the mean-covariance restricted Boltzmann", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "25195b51-e378-4c1b-b6e9-c6a94aba0b00", "label": "摘要261", "info": "Dahl，G.  E.，Yu，D.，Deng，L.，and  Acero，A.（2012）.  Context-；dependent  pre-trained  deep  neural  networks  for  large  vocabulary  speech；IEEE  Transactions  on  Audio，Speech，and  Language", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab166451-8d8b-4c02-a9a2-be52c37fef86", "label": "摘要262", "info": "Dahl，G.  E.，Sainath，T.  N.，and  Hinton，G.  E.（2013）.  Improving；deep neural networks for LVCSR using rectified linear units and dropout. In；ICASSP'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35c9ffc0-8958-432f-9050-0a8b6142d04f", "label": "摘要263", "info": "Dahl，G.  E.，Jaitly，N.，and  Salakhutdinov，R.（2014）.  Multi-task；neural networks for QSAR predictions. arXiv:1406.1231.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f548d127-97f8-426c-800c-41e851630088", "label": "摘要264", "info": "Dauphin，Y. and Bengio，Y.（2013）. Stochastic ratio matching of RBMs；for sparse high-dimensional inputs. In NIP（1）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "be803f6a-3eea-4ca5-907c-c35f5aa9622c", "label": "摘要265", "info": "Dauphin，Y.，Glorot，X.，and；learning of embeddings with recon-struction sampling. In ICML'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e0bd3490-cb55-45f1-96f5-f4736bfafeb9", "label": "摘要266", "info": "Bengio，Y.（2011）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef0e14c7-e045-414b-bbaf-d5091d11bcb0", "label": "摘要267", "info": "Large-scale", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd689eec-01d3-47bb-9148-7e1194baf753", "label": "摘要268", "info": "Dauphin，Y.，Pascanu，R.，Gulcehre，C.，Cho，K.，Ganguli，S.，；and  Bengio，Y.（2014）.  Identifying  and  attacking  the  saddle  point；problem in high-dimensional non-convex optimization. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "69e2ab19-d770-44e9-838c-19c82904ba52", "label": "摘要269", "info": "Davis，A.，Rubinstein，M.，Wadhwa，N.，Mysore，G.，Durand，F.，；and Freeman，W. T.（2014）. The visual microphone: Passive recovery of；sound  from  video.  ACM  Transactions  on  Graphics（Proc.  SIGGRAPH）", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f9663024-4604-44f5-86d6-5cb690cf450f", "label": "摘要270", "info": "Dayan，P.（1990）.  Reinforcement  comparison.  In  Connectionist  Models:；Proceedings of the 1990 Connectionist Summer School ，San Mateo，CA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "881b9d14-f9fe-458f-b6c2-99971d5deecc", "label": "摘要271", "info": "Dayan，P.  and  Hinton，G.  E.（1996）.  Varieties  of  Helmholtz  machine.；Neural Networks ，9 （8），1385–1403.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd04f356-3b46-44d7-a0c2-7e3959a182ef", "label": "摘要272", "info": "Dayan，P.，Hinton，G.  E.，Neal，R.  M.，and  Zemel，R.  S.（1995）.；The Helmholtz machine. Neural computation ，7 （5），889–904.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26df16e1-a34e-45af-a6ca-5541b141b389", "label": "摘要273", "info": "Dean，J.，Corrado，G.，Monga，R.，Chen，K.，Devin，M.，Le，；Q.，Mao，M.，Ranzato，M.，Senior，A.，Tucker，P.，Yang，K.，and；Ng，A. Y.（2012）. Large scale distributed deep networks. In NIPS'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f7c95cf-428f-47fe-96de-8bc5ee122028", "label": "摘要274", "info": "Dean，T.  and  Kanazawa，K.（1989）.  A  model  for  reasoning  about；persistence and causation. Computational Intelligence ，5 （3），142–150.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "692cfc9c-4a65-44e0-a194-bea104e9b326", "label": "摘要275", "info": "Deerwester，S.，Dumais，S.  T.，Furnas，G.  W.，Landauer，T.  K.，and；Harshman，R.（1990）. Indexing by latent semantic analysis. Journal of the；American Society for Information Science ，41 （6），391–407.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3fd4c45b-28be-4e61-a282-7ed3d61af3aa", "label": "摘要276", "info": "Delalleau，O.  and  Bengio，Y.（2011）.  Shallow  vs.  deep  sum-product；networks. In NIPS .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5368585d-c180-4498-8024-16cf04ede703", "label": "摘要277", "info": "Deng，J.，Dong，W.，Socher，R.，Li，L.-J.，Li，K.，and  Fei-Fei，L.；（2009）.  ImageNet:  A  Large-Scale  Hierarchical  Image  Database.  In；CVPR09 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "277d45cf-603f-43de-8940-645a7fcd757b", "label": "摘要278", "info": "Deng，J.，Berg，A.  C.，Li，K.，and  Fei-Fei，L.（2010a）.  What  does", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4dc95af-1f0f-4acc-bc62-2d2622b34c6c", "label": "摘要279", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；classifying  more  than  10，000  image  categories  tell  us?  In  Proceedings  of；the  11th  European  Conference  on  Computer  Vision:  Part  V  ，ECCV'10，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e0caae4f-9a63-483a-8057-3e6e60f4f350", "label": "摘要280", "info": "Deng，L.  and  Yu，D.（2014）.  Deep  learning–methods  and  applications.；Foundations and Trends in Signal Processing .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "53cf31d3-2056-44a4-8e50-9e044a3edaeb", "label": "摘要281", "info": "Deng，L.，Seltzer，M.，Yu，D.，Acero，A.，Mohamed，A.，and；Hinton，G.（2010b）.  Binary  coding  of  speech  spectrograms  using  a  deep；auto-encoder. In Interspeech 2010 ，Makuhari，Chiba，Japan.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d989e8f-ffa7-47f3-b378-1e9e22b12377", "label": "摘要282", "info": "Denil，M.，Bazzani，L.，Larochelle，H.，and  de  Freitas，N.（2012）.；Learning where to attend with deep architectures for image tracking. Neural；Computation ，24 （8），2151–2184.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7af92d44-fe0d-435d-b480-a92668f66b8d", "label": "摘要283", "info": "Denton，E.，Chintala，S.，Szlam，A.，and  Fergus，R.（2015）.  Deep；generative image models using a Laplacian pyramid of adversarial networks.；NIPS .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5e1ca5d2-335b-4e39-aa7e-f6e892545beb", "label": "摘要284", "info": "Desjardins，G.  and  Bengio，Y.（2008）.  Empirical  evaluation  of；convolutional  RBMs  for  vision.  Technical  Report  1327，Département；d'Informatique et de Recherche Opérationnelle，Université de Montréal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "84e24f5c-40bb-4a04-bedb-c067ad9064c2", "label": "摘要285", "info": "C.，Bengio，Y.，Vincent，P.，and；Desjardins，G.，Courville，A.；Delalleau，O.（2010）.  Tempered  Markov  chain  Monte  Carlo  for  training", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f8a2507-407c-4cae-ac86-3edeb24fe98d", "label": "摘要286", "info": "Desjardins，G.，Courville，A.，and  Bengio，Y.（2011）.  On  tracking；the partition function. In NIPS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "41f06694-7e9a-4e95-9d9e-a45eb8d862b1", "label": "摘要287", "info": "Devlin，J.，Zbib，R.，Huang，Z.，Lamar，T.，Schwartz，R.，and；Makhoul，J.（2014）.  Fast  and  robust  neural  network  joint  models  for；statistical machine translation. In Proc. ACL'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e4d4584-acf5-4240-9ed5-8b2431df7311", "label": "摘要288", "info": "Devroye，L.（2013）.  Non-Uniform  Random  Variate  Generation；SpringerLink: Bücher. Springer New York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ee7277b-787a-4c8e-b24a-37db6d4687ce", "label": "摘要289", "info": ".", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61ede7dd-2d84-415e-a1c2-f17d731b2dfc", "label": "摘要290", "info": "J.（2013）.  Mechanisms；DiCarlo，J.；recognition:Humans vs. neurons vs. machines. NIPS Tutorial.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9df3549b-2ecf-4960-96c1-4aaa9668b627", "label": "摘要291", "info": "underlying", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7ae48a2b-0db5-48ee-8156-03a4ad7d5e8b", "label": "摘要292", "info": "visual", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0c03d54f-2a24-4bda-86db-c2be4ae31174", "label": "摘要293", "info": "object", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "04985514-1aa8-4e8e-819a-60cc00c07e19", "label": "摘要294", "info": "Dinh，L.，Krueger，D.，and  Bengio，Y.（2014）.  NICE:  Non-linear；independent components esti-mation. arXiv:1410.8516.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6944c0e3-8e1d-47c7-b399-9bd9b3b025f1", "label": "摘要295", "info": "A.，Guadarrama，S.，Rohrbach，M.，；Donahue，J.，Hendricks，L.；Venugopalan，S.，Saenko，K.，and  Darrell，T.（2014）.  Long-term", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6f225454-014e-48f2-b83f-d860a3265111", "label": "摘要296", "info": "Donoho，D. L.  and Grimes，C.（2003）. Hessian eigenmaps: new locally；linear  embedding  tech-niques  for  high-dimensional  data.  Technical  Report；2003-08，Dept. Statistics，Stanford University.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db547ad8-a5b2-4afa-961d-c226139fb4a1", "label": "摘要297", "info": "Dosovitskiy，A.，Springenberg，J.  T.，and  Brox，T.（2015）.  Learning；to generate chairs with convolutional neural networks. In Proceedings of the；IEEE  Conference  on  Computer  Vision  and  Pattern  Recognition  ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd7671d4-5911-45bd-b9f6-96220c2e3126", "label": "摘要298", "info": "Doya，K.（1993）.  Bifurcations  of  recurrent  neural  networks  in  gradient；descent learning. IEEE Transactions on Neural Networks ，1 ，75–80.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "51f85681-ff6a-4508-9cb9-36bbbeee5ba9", "label": "摘要299", "info": "Dreyfus，S.  E.（1962）.  The  numerical  solution  of  variational  problems.；Journal of Mathematical Analysis and Applications ，5 （1），30–45.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4bd59de-676c-446d-8b07-8a278bb02bfd", "label": "摘要300", "info": "Dreyfus，S.  E.（1973）.  The  computational  solution  of  optimal  control；problems  with  time  lag.  IEEE  Transactions  on  Automatic  Control  ，18；（4），383–385.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "857958ba-1fb3-4252-b10a-95690aafffc2", "label": "摘要301", "info": "and  LeCun，Y.（1992）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "be68dd2e-6ec1-4012-9e9b-b2692baa9323", "label": "摘要302", "info": "Drucker，H.；generalisation；performance  using  double  back-propagation.  IEEE  Transactions  on  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5f9c773-5650-4c69-b193-e455f7270003", "label": "摘要303", "info": "Improving", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d49eace2-5318-49a3-b5a1-99fdbec7c362", "label": "摘要304", "info": "Duchi，J.，Hazan，E.，and  Singer，Y.（2011）.  Adaptive  subgradient；methods for online learning and stochastic optimization. Journal of Machine；Learning Research .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "448d5815-8504-4cc8-af53-c076de779d01", "label": "摘要305", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Dudik，M.，Langford，J.，and  Li，L.（2011）.  Doubly  robust  policy；evaluation and learning. In Proceedings of the 28th International Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "64fe9912-babc-4538-b3f5-c567c4c543f4", "label": "摘要306", "info": "Dugas，C.，Bengio，Y.，Bélisle，F.，and；Nadeau，C.（2001）.；Incorporating second-order functional knowledge for better option pricing. In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9cfb6c9d-eb16-4f9d-ae5a-8896fb410e9f", "label": "摘要307", "info": "Dziugaite，G.  K.，Roy，D.  M.，and  Ghahramani，Z.（2015）.  Training；generative  neural  networks  via  maximum  mean  discrepancy  optimization.；arXiv preprint arXiv:1505.03906 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "48095291-8680-4041-8d70-a8df1913262d", "label": "摘要308", "info": "El  Hihi，S.  and  Bengio，Y.（1996）.  Hierarchical  recurrent  neural；networks for long-term depen-dencies. In NIPS 8 . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea28393c-bc89-4c55-97a4-e7c444ef847c", "label": "摘要309", "info": "Elkahky，A.  M.，Song，Y.，and  He，X.（2015）.  A  multi-view  deep；learning  approach  for  cross  domain  user  modeling  in  recommendation；systems. In Proceedings of the 24th International Conference on World Wide", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb8f7e74-ecdd-43b2-b2a0-b66e45dd7306", "label": "摘要310", "info": "Elman，J.  L.（1993）.  Learning  and  development  in  neural  networks:  The；importance of starting small. Cognition ，48 ，781–799.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5aef522b-e3ca-4f81-8250-de3cef5e982b", "label": "摘要311", "info": "Erhan，D.，Manzagol，P.-A.，Bengio，Y.，Bengio，S.，and  Vincent，；P.（2009）.  The  difficulty  of  training  deep  architectures  and  the  effect  of；unsupervised pre-training. In AISTATS'2009 ，pages 153–160.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac7d4f56-9400-409d-addd-a693a89c11c5", "label": "摘要312", "info": "Erhan，D.，Bengio，Y.，Courville，A.，Manzagol，P.，Vincent，P.，；and  Bengio，S.（2010）.  Why  does  unsupervised  pre-training  help  deep；learning? J. Machine Learning Res .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f7205d4-e16a-40e6-86db-0ca68f4621cc", "label": "摘要313", "info": "Fahlman，S.  E.，Hinton，G.  E.，and  Sejnowski，T.；J.（1983）.；Massively  parallel  architectures  for  AI:  NETL，thistle，and  Boltzmann", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd4520e5-e485-4491-84d9-be2d672d4cbb", "label": "摘要314", "info": "Fang，H.，Gupta，S.，Iandola，F.，Srivastava，R.，Deng，L.，；Dollár，P.，Gao，J.，He，X.，Mitchell，M.，Platt，J.  C.，Zitnick，C.；L.，and  Zweig，G.（2015）.  From  captions  to  visual  concepts  and  back.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2d042b8-a5eb-410e-aa97-2b4d888c1fb6", "label": "摘要315", "info": "Farabet，C.，LeCun，Y.，Kavukcuoglu，K.，Culurciello，E.，；Martini，B.，Akselrod，P.，and  Talay，S.（2011）.  Large-scale  FPGA-；based  convolutional  networks.  In  R.  Bekkerman，M.  Bilenko，and  J.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7d7263b1-9da2-42d4-860a-17e946322aa3", "label": "摘要316", "info": "LeCun，Y.（2013）.；Farabet，C.，Couprie，C.，Najman，L.，and；Learning  hierarchical  features  for  scene  labeling.  IEEE  Transactions  on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85f91175-2d41-4fd9-98be-80e740e8bd7b", "label": "摘要317", "info": "Fei-Fei，L.，Fergus，R.，and  Perona，P.（2006）.  One-shot  learning  of；object  categories.  IEEE  Transactions  on  Pattern  Analysis  and  Machine；Intelligence，28 （4），594–611.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd0248d9-0f0b-4197-b61d-8ae37022c9d5", "label": "摘要318", "info": "Finn，C.，Tan，X.；Abbeel，P.（2015）.  Learning  visual；manipulation  with", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0454c497-084f-4b73-8100-602a1d982535", "label": "摘要319", "info": "Y.，Duan，Y.，Darrell，T.，Levine，S.，and；robotic；preprint", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f03ca3f-5e27-47e3-918a-7ad8f5d9aee6", "label": "摘要320", "info": "feature；autoencoders.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "52eafbf8-4a1a-4994-b2d9-59804cb5d99a", "label": "摘要321", "info": "spaces", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5e581e0-6bcf-490b-b2d0-89c8a9f37b8b", "label": "摘要322", "info": "spatial", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "62cfcced-7f66-402d-a3ed-2aa3126c304f", "label": "摘要323", "info": "arXiv", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "94f64844-672a-4c50-8ae6-09dfb83f61dc", "label": "摘要324", "info": "deep", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "986ebc0c-047c-49a0-b2c5-1dc510e0c178", "label": "摘要325", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b470b75-a757-4068-8b10-a127610caa2b", "label": "摘要326", "info": "Fisher，R.  A.（1936）.  The  use  of  multiple  measurements  in  taxonomic；problems. Annals of Eugenics ，7 ，179–188.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ebe0626a-4c31-4e9c-a515-509b74cf5715", "label": "摘要327", "info": "Földiák，P.（1989）.  Adaptive  network；feature；extraction. In International Joint Conference on Neural Networks（IJCNN）", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "feb3b721-4f6e-42ff-92ca-ec0e3da2db99", "label": "摘要328", "info": "for  optimal", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc6a4ff4-2340-4836-bb26-03575413e7f2", "label": "摘要329", "info": "linear", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c646880-3f6d-4012-856f-fcc827529847", "label": "摘要330", "info": "Franzius，M.，Sprekeler，H.，and  Wiskott，L.（2007）.  Slowness  and；sparseness lead to place，head-direction，and spatial-view cells.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1c925112-7364-4578-868a-b483d785f60f", "label": "摘要331", "info": "Franzius，M.，Wilbert，N.，and  Wiskott，L.（2008）.  Invariant  object；recognition  with  slow  feature  analysis.  In  Proceedings  of  the  18th；international  conference  on  Artificial  Neural  Networks，Part  I  ，ICANN", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6b35ad8-d7df-4928-8b3d-73bf7e3086ec", "label": "摘要332", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；'08，pages 961–970，Berlin，Heidelberg. Springer-Verlag.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5e6d641-61d5-4bbf-ae63-0ccadae86ce9", "label": "摘要333", "info": "Frasconi，P.，Gori，M.，and  Sperduti，A.（1997）.  On  the  efficient；classification of data structures by neural networks. In Proc. Int. Joint Conf.；on Artificial Intelligence .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "54176966-d87f-49d8-9bd7-7c48ff11cd29", "label": "摘要334", "info": "Frasconi，P.，Gori，M.，and；general；framework for adaptive processing of data structures. IEEE Transactions on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "de24102d-77a6-4713-9cbf-e24c492fe964", "label": "摘要335", "info": "Sperduti，A.（1998）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a190bbb9-e2d6-4a6a-ad80-d7a094b944cd", "label": "摘要336", "info": "A", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c392168-4fbd-4dce-a607-a22a50dd5620", "label": "摘要337", "info": "Freund，Y.  and  Schapire，R.  E.（1996a）.  Experiments  with  a  new；boosting  algorithm.  In  Machine  Learning:  Proceedings  of  Thirteenth；International Conference ，pages 148–156，USA. ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7682d612-aa65-4c36-8749-6c6e7775936d", "label": "摘要338", "info": "theory，on-line；Freund，Y.  and  Schapire，R.  E.（1996b）.  Game；prediction and boosting. In Proceedings of the Ninth Annual Conference  on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "945b2194-320a-42d2-9b83-3a7ba70fd4c2", "label": "摘要339", "info": "Frey，B.  J.（1998）.  Graphical  models  for  machine  learning  and  digital；communication . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e04aac6f-4a87-4274-b8af-8b280f45825f", "label": "摘要340", "info": "Frey，B.  J.，Hinton，G.  E.，and  Dayan，P.（1996）.  Does  the  wake-；sleep  algorithm  learn  good  density  estimators?  In  D.  Touretzky，M.；Mozer，and  M.  Hasselmo，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d4d78b9-7258-4f4b-b5a0-a0ea09780e7d", "label": "摘要341", "info": "Frobenius，G.（1908）.  Über  matrizen  aus  positiven  elementen，s.  B.；Preuss. Akad. Wiss. Berlin，Germany .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9baf9915-d0d2-45b0-94a9-f3eb669d9277", "label": "摘要342", "info": "Fukushima，K.（1975）.  Cognitron:  A  self-organizing  multilayered  neural；network. Biological Cybernetics ，20 ，121–136.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7e318268-7fd1-477f-b2bd-85a039bd1dee", "label": "摘要343", "info": "Fukushima，K.（1980）.  Neocognitron:  A  self-organizing  neural  network；model for a mechanism of pattern recognition unaffected by shift in position.；Biological Cybernetics ，36 ，193–202.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "999d4043-ad39-40ac-b29e-375c71068106", "label": "摘要344", "info": "Gal，Y.  and  Ghahramani，Z.（2015）.  Bayesian  convolutional  neural；networks  with  Bernoulli  approximate  variational  inference.  arXiv  preprint；arXiv:1506.02158 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5da42cc2-0660-4861-9342-d3c6d42dd600", "label": "摘要345", "info": "Gallinari，P.，LeCun，Y.，Thiria，S.，and；（1987）.  Memoires；COGNITIVA 87 ，Paris，La Villette.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b2a90027-18ee-433e-a169-6d13235088d5", "label": "摘要346", "info": "associatives  distribuees.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eece3b94-a6ac-4b91-9a68-6823dfd9f25d", "label": "摘要347", "info": "Fogelman-Soulie，F.；In  Proceedings  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6fc649bf-67d6-4831-8d19-dd8863a242fc", "label": "摘要348", "info": "Grandvalet，Y.；Garcia-Duran，A.，Bordes，A.，Usunier，N.，and；（2015）.  Combining  two  and  three-way  embeddings  models  for  link", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "54fc279a-1a0b-4ee2-bc1a-a86daf72ef73", "label": "摘要349", "info": "Garofolo，J.  S.，Lamel，L.  F.，Fisher，W.  M.，Fiscus，J.  G.，and；Pallett，D.  S.（1993）.  Darpa  timit  acoustic-phonetic  continous  speech；corpus cd-rom. nist speech disc 1-1.1. NASA STI/Recon Technical Report N", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9f0c7fd-58e9-42c4-a2ff-18c7c48d70c0", "label": "摘要350", "info": "Garson，J.（1900）.  The  metric  system  of  identification  of  criminals，as；used  in  Great  Britain  and  Ireland.  The  Journal  of  the  Anthropological；Institute of Great Britain and Ireland ，（2），177–227.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "72eeed3e-c787-41d8-a607-5f98e5308cc3", "label": "摘要351", "info": "Gers，F.  A.，Schmidhuber，J.，and  Cummins，F.（2000）.  Learning  to；forget: Continual prediction with LSTM. Neural computation ，12 （10），；2451–2471.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a9780bf-624c-4831-8d5b-31ecd6a7a84f", "label": "摘要352", "info": "Ghahramani，Z.  and  Hinton，G.  E.（1996）.  The  EM  algorithm  for；mixtures  of  factor  analyzers.  Technical  Report  CRG-TR-96-1，Dpt.  of；Comp. Sci.，Univ. of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d977084f-5012-4421-8d31-0d99a50cb271", "label": "摘要353", "info": "Gillick，D.，Brunk，C.，Vinyals，O.，and  Subramanya，A.（2015）.；Multilingual；preprint", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4aed8761-45a1-41b2-b70e-39bb46f22106", "label": "摘要354", "info": "processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "495105b0-c999-4564-8d7e-baae8a7be674", "label": "摘要355", "info": "language", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "110e60bd-61c9-4042-b654-07f575d1b640", "label": "摘要356", "info": "bytes.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a0f253a1-8dfd-4899-b2ed-03f856d1e5d4", "label": "摘要357", "info": "arXiv", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "69282ef7-ed63-49a7-8b4c-7ae81eac5a7f", "label": "摘要358", "info": "from", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c3ebdb13-f1e7-4f3f-96f8-918e524e6424", "label": "摘要359", "info": "Girshick，R.，Donahue，J.，Darrell，T.，and；Malik，J.（2015）.；Region-based  convolutional  networks  for  accurate  object  detection  and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2141fc68-d7a6-43d1-87b1-f1774a43a3aa", "label": "摘要360", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Giudice，M. D.，Manera，V.，and Keysers，C.（2009）. Programmed to；learn? The ontogeny of mirror neurons. Dev. Sci. ，12 （2），350–363.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "afd2c1aa-a448-4cba-918c-96a58f6dc292", "label": "摘要361", "info": "Glorot，X.  and  Bengio，Y.（2010）.  Understanding  the  difficulty  of；training deep feedforward neural networks. In AISTATS'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "190667b7-eda1-42c2-9a45-a872580c001c", "label": "摘要362", "info": "Glorot，X.，Bordes，A.，and Bengio，Y.（2011a）. Deep sparse rectifier；neural networks. In AISTATS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fecc95b7-4139-4920-9eca-dfd283148ff7", "label": "摘要363", "info": "Glorot，X.，Bordes，A.，and  Bengio，Y.（2011b）.  Domain  adaptation；for  large-scale  sentiment  classification:  A  deep  learning  approach.  In；ICML'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6509afc7-4bfa-4d90-bc16-9b2afe5271b9", "label": "摘要364", "info": "Glorot，X.，Bordes，A.，and  Bengio，Y.（2011c）.  Domain  adaptation；for  large-scale  sentiment  classification:  A  deep  learning  approach.  In；ICM（1b），pages 97–110.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb1cbf15-8c1c-4fd8-8204-aae639c28d13", "label": "摘要365", "info": "Goldberger，J.，Roweis，S.，Hinton，G.  E.，and  Salakhutdinov，R.；（2005）. Neighbourhood components analysis. In L. Saul，Y. Weiss，and；L.  Bottou，editors，Advances  in  Neural  Information  Processing  Systems", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8c9c8512-d4c0-4a47-98b6-51a20e605c89", "label": "摘要366", "info": "Gong，S.，McKenna，S.，and  Psarrou，A.（2000）.  Dynamic  Vision:；From Images to Face Recognition . Imperial College Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "346d8d7b-9468-4d29-912b-5e3361248395", "label": "摘要367", "info": "Goodfellow，I.，Le，Q.，Saxe，A.，and  Ng，A.（2009）.  Measuring；In  Y.  Bengio，D.  Schuurmans，C.；invariances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd3cc355-53b2-4835-a116-9822fba65e7e", "label": "摘要368", "info": "in  deep  networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "754709ed-1061-49e1-9246-7e1007e93cb1", "label": "摘要369", "info": "Goodfellow，I.，Koenig，N.，Muja，M.，Pantofaru，C.，Sorokin，；A.，and Takayama，L.（2010）. Help me help you: Interfaces for personal；robots.  In  Proc.  of  Human  Robot  Interaction（HRI）  ，Osaka，Japan.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc28c358-88f3-4557-9ba3-1af13af17053", "label": "摘要370", "info": "Goodfellow，I.，Mirza，M.，Xiao，D.，Courville，A.，and Bengio，Y.；（2014a）. An empirical inves-tigation of catastrophic forgetting in gradient-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cde3b958-b852-4332-8e4b-4bb826893210", "label": "摘要371", "info": "based neural networks. In ICLR'14 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c205868c-9526-4cd2-9c73-4556fdb7a4fd", "label": "摘要372", "info": "Goodfellow，I.；report:Multidimensional，；downsampled convolution for autoencoders. Technical report，Université de", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcdc9d6c-a386-4a67-bd15-f654ca13c10a", "label": "摘要373", "info": "J.（2010）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c26a5c26-6990-40e3-ba72-19673c2103ef", "label": "摘要374", "info": "Technical", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2d4cba2-c5b2-4116-bedc-360100f82766", "label": "摘要375", "info": "Goodfellow，I.  J.（2014）.  On  distinguishability  criteria  for  estimating；generative  models.；Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "67145436-3481-479d-93bc-edcbe7011f14", "label": "摘要376", "info": "International  Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7dc81ffe-a449-4138-88d5-089f9d5b02ff", "label": "摘要377", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4ba4fe5-cb18-445b-b250-fb2368c20f01", "label": "摘要378", "info": "In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7e7c56c0-1a5b-48d1-8cba-1ac2d69341b2", "label": "摘要379", "info": "Goodfellow，I.  J.，Courville，A.，and  Bengio，Y.（2011）.  Spike-and-；slab sparse coding for unsu-pervised feature discovery. In NIPS Workshop on；Challenges in Learning Hierarchical Models .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1bcfd405-b781-41c6-81d6-85b93a16e544", "label": "摘要380", "info": "Goodfellow，I.  J.，Warde-Farley，D.，Mirza，M.，Courville，A.，and；Bengio，Y.（2013a）. Maxout networks. In ICML'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e796fc1e-a50d-4867-997b-f3ae1ec5b42b", "label": "摘要381", "info": "Goodfellow，I.  J.，Warde-Farley，D.，Mirza，M.，Courville，A.，and；Bengio，Y.（2013b）.  Maxout  networks.  In  ICM（1c），pages  1319–；1327.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79b90a12-9a4f-4015-af34-2315e89223b2", "label": "摘要382", "info": "Goodfellow，I.  J.，Warde-Farley，D.，Mirza，M.，Courville，A.，and；Bengio，Y.（2013c）.  Maxout；Report", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e396cfb-ea41-4635-8741-03736f461bee", "label": "摘要383", "info": "Technical", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab981c8d-d8df-4978-8fa6-d05c09f32032", "label": "摘要384", "info": "networks.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2cf84268-71d6-48fb-b859-bfa928bab7c4", "label": "摘要385", "info": "Goodfellow，I.；（2013d）. Multi-prediction deep Boltzmann machines. In NIP（1）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b332446-3de4-43e5-82ed-266a4ef57c55", "label": "摘要386", "info": "J.，Mirza，M.，Courville，A.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "02374c63-ad40-40bd-b243-356ebfc3b272", "label": "摘要387", "info": "Bengio，Y.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "64cd39c6-8f05-47f7-949c-b6544d86641d", "label": "摘要388", "info": "Goodfellow，I.；J.，Warde-Farley，D.，Lamblin，P.，Dumoulin，V.，；Mirza，M.，Pascanu，R.，Bergstra，J.，Bastien，F.，and  Bengio，Y.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bfc4c636-5f11-4bc0-9521-254b249faefa", "label": "摘要389", "info": "Goodfellow，I.  J.，Courville，A.，and  Bengio，Y.（2013f）.  Scaling  up；spike-and-slab  models  for  unsupervised  feature  learning.  IEEE  T.  PAMI ，；pages 1902–1914.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc700391-a50c-4428-8a0a-a0eb4b532b1b", "label": "摘要390", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Goodfellow，I. J.，Courville，A.，and Bengio，Y.（2013g）. Scaling  up；spike-and-slab models for un-supervised feature learning. IEEE Transactions", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f4b1abd8-21e9-4846-a27e-9d33fdb53f2e", "label": "摘要391", "info": "Goodfellow，I.  J.，Shlens，J.，and  Szegedy，C.（2014b）.  Explaining；and harnessing adversarial examples. CoRR ，abs/1412.6572 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "521b0de5-7d42-4fcb-b509-a2597b104b36", "label": "摘要392", "info": "Goodfellow，I.；Farley，D.，Ozair，S.，Courville，A.，and；Generative adversarial networks. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5775069d-8e8b-4d13-8797-8d74da448e05", "label": "摘要393", "info": "J.，Pouget-Abadie，J.，Mirza，M.，Xu，B.，Warde-；Bengio，Y.（2014c）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "44c96d0c-1ba1-43f9-ab59-7ea62de3cb5c", "label": "摘要394", "info": "Goodfellow，I.  J.，Bulatov，Y.，Ibarz，J.，Arnoud，S.，and  Shet，V.；（2014d）. Multi-digit number recognition from Street View imagery using；deep convolutional neural networks. In International Conference on Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8fb6f7b2-dacc-416d-8084-660b25c72a15", "label": "摘要395", "info": "Goodfellow，I. J.，Vinyals，O.，and Saxe，A. M.（2015）. Qualitatively；characterizing  neural  network  optimization  problems.  In  International；Conference on Learning Representations .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6b3258b-5e95-428a-9feb-c7a80817d9c4", "label": "摘要396", "info": "Goodman，J.（2001）.  Classes  for  fast  maximum  entropy  training.  In；International；Signal", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e8cf9cb6-4b77-4488-abf8-74d4ba1f5f5f", "label": "摘要397", "info": "Acoustics，Speech", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f7932641-ff92-4e7e-84b2-befa57807a59", "label": "摘要398", "info": "Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b7626451-6256-46d1-99b7-26be124f9d35", "label": "摘要399", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bd15bc5-5b0b-436e-8965-b92e6d8300d7", "label": "摘要400", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ee26ae4-2ab7-4497-864a-ad518bdf1014", "label": "摘要401", "info": "Gori，M.  and  Tesi，A.（1992）.  On  the  problem  of  local  minima  in；backpropagation.  IEEE  Transactions  on  Pattern  Analysis  and  Machine；Intelligence ，PAMI-14 （1），76–86.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf672f4f-ff11-4b8a-86e6-6e4c89a99089", "label": "摘要402", "info": "Gosset，W.  S.（1908）.  The  probable  error  of  a  mean.  Biometrika  ，6；（1），1–25. Originally published under the pseudonym“Student”.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "845b8652-82a7-48e8-84cf-66fedbd6e795", "label": "摘要403", "info": "Gouws，S.，Bengio，Y.，and  Corrado，G.（2014）.  BilBOWA:  Fast；bilingual  distributed  representations  without  word  alignments.  Technical；report，arXiv:1410.2455.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "81250811-e30e-4094-a2c2-1ebf8c24a467", "label": "摘要404", "info": "Graf，H.  P.  and  Jackel，L.  D.（1989）.  Analog  electronic  neural  network；circuits. Circuits and Devices Magazine，IEEE ，5 （4），44–49.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bba9e571-b8f3-4e2f-af96-74122e9c8a01", "label": "摘要405", "info": "Graves，A.（2011）. Practical variational inference for neural networks. In；NIPS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a9a4e6d-770e-468d-9392-d1a84ebda035", "label": "摘要406", "info": "Graves，A.（2012）. Supervised Sequence Labelling with Recurrent Neural；Networks . Studies in Computational Intelligence. Springer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "994a1ea1-10b2-4212-a44c-bf959f0382d0", "label": "摘要407", "info": "Graves，A.（2013）. Generating sequences with recurrent neural networks.；Technical report，arXiv:1308.0850.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c83e3476-5b87-4091-8086-34d5475e2d83", "label": "摘要408", "info": "Graves，A.；recognition with recurrent neural networks. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e717cfc-feff-4066-83eb-5e9b2be9cad6", "label": "摘要409", "info": "Jaitly，N.（2014）.  Towards", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "485b13b6-5d72-4bbc-98f2-d43de40684c5", "label": "摘要410", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f4e76ba2-fc2f-415d-b575-caa9c663094f", "label": "摘要411", "info": "end-to-end", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca79927c-358d-4ac3-9a8b-f7364e0b6e00", "label": "摘要412", "info": "speech", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efdc4231-27b0-4f7b-a453-ad98c7155786", "label": "摘要413", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f7cebf3-64de-4fe7-b49d-55634caf6b84", "label": "摘要414", "info": "Graves，A.；phoneme；classification  with  bidirectional  LSTM  and  other  neural  network", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9fd35091-f269-4bbe-afbd-5d6e70d11d78", "label": "摘要415", "info": "Schmidhuber，J.（2005）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db162b25-628b-4e0f-ad07-c47a5d50d5dd", "label": "摘要416", "info": "Framewise", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70d82fd1-a7b4-439f-99e7-aec03af41f67", "label": "摘要417", "info": "Graves，A. and Schmidhuber，J.（2009）. Offine handwriting recognition；with  multidimensional  recurrent  neural  networks.  In  D.  Koller，D.；Schuurmans，Y.  Bengio，and  L.  Bottou，editors，NIPS'2008  ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d001aefb-637b-40ec-bc26-ff8d6d28b90a", "label": "摘要418", "info": "Graves，A.，Fernández，S.，Gomez，F.，and；Schmidhuber，J.；（2006）.  Connectionist  temporal  classification:  Labelling  unsegmented", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a4b68f9-9006-400c-950a-16983aca4ab5", "label": "摘要419", "info": "Graves，A.，Liwicki，M.，Bunke，H.，Schmidhuber，J.，and；Fernández，S.（2008）.  Unconstrained  on-line  handwriting  recognition；with  recurrent  neural  networks.  In  J.  Platt，D.  Koller，Y.  Singer，and  S.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "812f2b4b-e421-4a02-a39f-722474c3b26c", "label": "摘要420", "info": "Graves，A.，Liwicki，M.，Fernández，S.，Bertolami，R.，Bunke，；H.，and  Schmidhuber，J.（2009）.  A  novel  connectionist  system  for；unconstrained  handwriting  recognition.  Pattern  Analysis  and  Machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1763e944-efb4-4b0c-9bb4-cc4fc5d7b61c", "label": "摘要421", "info": "Graves，A.，Mohamed，A.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccd80220-c7cf-40e7-82b1-b81727dd97fb", "label": "摘要422", "info": "Hinton，G.（2013）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6f5a3cbe-6ca9-4d63-a4a2-e97266f70d6d", "label": "摘要423", "info": "Speech", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "09b0d7d6-b6cb-4861-b547-2a5d4a81b15d", "label": "摘要424", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；recognition  with  deep  recurrent  neural  networks.  In  ICASSP'2013  ，pages；6645–6649.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "05d84d83-fbb6-401b-9685-516d401de5fe", "label": "摘要425", "info": "Graves，A.，Wayne，G.，and  Danihelka，I.（2014）.  Neural  Turing；machines. arXiv:1410.5401.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b02573e6-98e8-4505-b3b8-f9bcaa74dfac", "label": "摘要426", "info": "Grefenstette，E.，Hermann，K.  M.，Suleyman，M.，and  Blunsom，P.；（2015）. Learning to transduce with unbounded memory. In NIPS'2015 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bacce4f0-11d6-4810-8485-5da51297768e", "label": "摘要427", "info": "Greff，K.，Srivastava，R.  K.，Koutník，J.，Steunebrink，B.  R.，and；Schmidhuber，J.（2015）.  LSTM:  a  search  space  odyssey.  arXiv  preprint；arXiv:1503.04069 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1e842290-ca5a-4252-8c0b-4b13f688ccf1", "label": "摘要428", "info": "Gregor，K. and LeCun，Y.（2010a）. Emergence of complex-like cells in；a  temporal  product  network  with  local  receptivefields.  Technical  report，；arXiv:1006.0448.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fef6b78d-229e-4179-8655-39a24af404e0", "label": "摘要429", "info": "Gregor，K.  and  LeCun，Y.（2010b）.  Learning  fast  approximations  of；sparse  coding.  In  L.  Bottou  and  M.  Littman，editors，Proceedings  of  the；Twenty-seventh  International  Conference  on  Machine  Learning（ICML-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7e63da56-e69d-40f3-83ce-2ace30bed47e", "label": "摘要430", "info": "Gregor，K.，Danihelka，I.，Mnih，A.，Blundell，C.，and Wierstra，D.；（2014）.  Deep  autoregressive  networks.  In  International  Conference  on；Machine Learning（ICML'2014） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a86581a-d3b5-4cce-8a38-12dceaf0e88d", "label": "摘要431", "info": "Gregor，K.，Danihelka，I.，Graves，A.，and  Wierstra，D.（2015）.；DRAW:  A  recurrent  neural  network  for  image  generation.  arXiv  preprint；arXiv:1502.04623 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "52983bd1-1b16-463f-ad79-9462b5ba224f", "label": "摘要432", "info": "Gretton，A.，Borgwardt，K.  M.，Rasch，M.  J.，Schölkopf，B.，and；Smola，A.（2012）.  A  kernel  two-sample  test.  The  Journal  of  Machine；Learning Research ，13 （1），723–773.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed3ed082-9fe6-4473-903e-f3ee7e8645a2", "label": "摘要433", "info": "Guillaume  Desjardins，Karen  Simonyan，R.  P.  K.  K.（2015）.  Natural；neural networks. Technical report，arXiv:1507.00210.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1fce9b26-390f-4a33-a97d-18a7e5cbab9a", "label": "摘要434", "info": "Gulcehre，C. and Bengio，Y.（2013）. Knowledge matters: Importance of；prior  information  for  optimization.  Technical  Report  arXiv:1301.4083，；Universite de Montreal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2035b5cc-619d-4c1a-b6a6-e2f31f8973c1", "label": "摘要435", "info": "Guo，H.  and  Gelfand，S.  B.（1992）.  Classification  trees  with  neural；network  feature  extraction.  Neural  Networks，IEEE  Transactions  on  ，3；（6），923–933.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c77593b8-d0ba-46c3-96ad-ae028284558f", "label": "摘要436", "info": "Gupta，S.，Agrawal，A.，Gopalakrishnan，K.，and；（2015）.  Deep；learning  with", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85216a23-3a52-49f4-bf07-85ca8ae2e9a0", "label": "摘要437", "info": "Narayanan，P.；limited  numerical  precision.  CoRR", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "22d9f154-dc67-4f32-810c-68e51280de18", "label": "摘要438", "info": "Gutmann，M.  and  Hyvarinen，A.（2010）.  Noise-contrastive  estimation:；A  new  estimation  princi-ple  for  unnormalized  statistical  models.  In；Proceedings  of  The  Thirteenth  International  Conference  on  Artificial", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1a9ef593-17d5-47ed-8b01-e726b9c0d858", "label": "摘要439", "info": "Hadsell，R.，Sermanet，P.，Ben，J.，Erkan，A.，Han，J.，Muller，；U.，and  LeCun，Y.（2007）.  Online  learning  for  offroad  robots:  Spatial；label  propagation  to  learn  long-range  traversability.  In  Proceedings  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "60f8146e-b28a-4835-9e78-7359e7742c8d", "label": "摘要440", "info": "Hajnal，A.，Maass，W.，Pudlak，P.，Szegedy，M.，and；Turan，G.；（1993）. Threshold circuits of bounded depth. J. Comput. System. Sci. ，46", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "41130a1b-70ec-4897-b078-2751992150f4", "label": "摘要441", "info": "Håstad，J.（1986）. Almost optimal lower bounds for small depth circuits.；In Proceedings of the 18th annual ACM Symposium on Theory of Computing；，pages 6–20，Berkeley，California. ACM Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1f461bec-0a78-4783-ba15-da9e49007c63", "label": "摘要442", "info": "Håstad，J.  and  Goldmann，M.（1991）.  On  the  power  of  small-depth；threshold circuits. Computational Complexity ，1 ，113–129.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "796ae6f6-45f7-4f60-ba64-093f8076d3f3", "label": "摘要443", "info": "Hastie，T.，Tibshirani，R.，and  Friedman，J.（2001）.  The  elements  of；statistical learning: data mining，inference and prediction . Springer Series；in Statistics. Springer Verlag.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "78ffb7a8-05bd-4b0e-ae5f-ffde0e5b994e", "label": "摘要444", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；He，K.，Zhang，X.，Ren，S.，and  Sun，J.（2015）.  Delving  deep  into；rectifiers:  Surpassing  human-level  performance  on  ImageNet  classification.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26e1ec4d-8eef-4b6b-99a3-6d8523e28fe6", "label": "摘要445", "info": "Hebb，D. O.（1949）. The Organization of Behavior . Wiley，New York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4701766-e175-4df1-86d8-71b4c1d202be", "label": "摘要446", "info": "Henaff，M.，Jarrett，K.，Kavukcuoglu，K.，and  LeCun，Y.（2011）.；Unsupervised learning of sparse features for scalable audio classification. In；ISMIR'11 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "538631f9-ff48-43d3-8535-6abf32a2cc5e", "label": "摘要447", "info": "Henderson，J.（2003）. Inducing history representations for broad coverage；statistical parsing. In HLT-NAACL ，pages 103–110.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d796a84-241f-4675-9d9e-ab40aa78ca5f", "label": "摘要448", "info": "Henderson，J.（2004）.  Discriminative；training  of  a  neural  network；statistical parser. In Proceedings of the 42nd Annual Meeting on Association", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2fecc78a-b6ed-4f8b-a793-1cfaf8999ef4", "label": "摘要449", "info": "Henniges，M.，Puertas，G.，Bornschein，J.，Eggert，J.，and Lücke，J.；（2010）.  Binary  sparse  coding.  In  Latent  Variable  Analysis  and  Signal；Separation ，pages 450–457. Springer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c891489b-5f91-4d9a-9e6e-a541959d1c07", "label": "摘要450", "info": "Herault，J.  and  Ans，B.（1984）.  Circuits  neuronaux  à  synapses；modifiables:  Décodage  de  messages  composites  par  apprentissage  non；supervisé. Comptes Rendus de l'Académie des Sciences ，299（III-13） ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70e4263d-d6a3-4245-bb81-b18869b69541", "label": "摘要451", "info": "Hinton，G.，Deng，L.，Dahl，G.；Senior，A.，Vanhoucke，V.，Nguyen，P.，Sainath，T.，and；Kingsbury，B.（2012a）.  Deep  neural  networks  for  acoustic  modeling  in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8bd9a941-e053-4bbe-9da0-4112d14ce55c", "label": "摘要452", "info": "E.，Mohamed，A.，Jaitly，N.，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1886a39-e58f-4797-a408-2f106d6330fe", "label": "摘要453", "info": "Hinton，G.，Vinyals，O.，and  Dean，J.（2015）.  Distilling；knowledge in a neural network. arXiv preprint arXiv:1503.02531 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4df745d-c092-4295-9346-7f7ed58c705a", "label": "摘要454", "info": "the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9265481b-37cd-43f1-8304-4f1c3a1b4eab", "label": "摘要455", "info": "Hinton，G.  E.（1989）.  Connectionist；Intelligence ，40 ，185–234.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "081e8e8f-c3ab-4443-bac9-3a46e1d6305e", "label": "摘要456", "info": "learning  procedures.  Artificial", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0eaba158-dbe6-4bb1-a8c1-c675a3eea6cb", "label": "摘要457", "info": "Hinton，G. E.（1990）.  Mapping part-whole hierarchies into connectionist；networks. Artificial Intelligence ，46 （1），47–75.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd9de90c-ce71-47d3-ae92-ed4402d4c65c", "label": "摘要458", "info": "Hinton，G.  E.（1999）.  Products  of  experts.  In  Proceedings  of  the  Ninth；International  Conference  on  Artificial  Neural  Networks（ICANN）  ，；volume 1，pages 1–6，Edinburgh，Scotland. IEE.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42a84d1b-2661-4f2d-baa9-cdf80f6bd14c", "label": "摘要459", "info": "Hinton，G.  E.（2000）.  Training  products  of  experts  by  minimizing；contrastive  divergence.  Technical  Report  GCNU  TR  2000-004，Gatsby；Unit，University College London.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a6074a9-0eb6-4e31-98e9-98252044b373", "label": "摘要460", "info": "Hinton，G.  E.（2006）.  To  recognize  shapes，first  learn  to  generate；images. Technical Report UTML TR 2006-003，University of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "582af15c-ab5e-4bfb-a1f4-2fac480c6f45", "label": "摘要461", "info": "Hinton，G. E.（2007a）. How to do backpropagation in a brain. Invited talk；at the NIPS'2007 Deep Learning Workshop.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b503ad8a-bd03-414e-9413-d7f6cee589f4", "label": "摘要462", "info": "Hinton，G. E.（2007b）. Learning multiple layers of representation. Trends；in cognitive sciences ，11 （10），428–434.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90da5f68-ed53-4ab3-81a6-1bb5d3a772f3", "label": "摘要463", "info": "Hinton，G.  E.（2010）.  A  practical  guide  to  training  restricted  Boltzmann；machines.  Technical  Report  UTML  TR  2010-003，Comp.  Sc.，University；of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "405a7491-1d8a-4142-ad29-1eff5d3b1dab", "label": "摘要464", "info": "Hinton，G. E.（2012）. Tutorial on deep learning. IPAM Graduate Summer；School: Deep Learning，Feature Learning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bba5b5c-2b22-4a5e-988e-d76f8e8b70a1", "label": "摘要465", "info": "Hinton，G.  E.  and  Ghahramani，Z.（1997）.  Generative  models  for；discovering sparse distributed representations. Philosophical Transactions of；the Royal Society of London .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bdd43ea7-328e-4b91-8db6-fe0ffbd713a0", "label": "摘要466", "info": "Hinton，G. E. and McClelland，J. L.（1988）. Learning representations by；recirculation. In NIPS'1987 ，pages 358–366.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c02b1f4d-d6d8-4b0f-8009-d19cd00a5cba", "label": "摘要467", "info": "Hinton，G. E. and Roweis，S.（2003）. Stochastic neighbor embedding. In；NIPS'2002 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cac75e5d-6724-42d9-ab98-fcd8821f8c45", "label": "摘要468", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Hinton，G.  E.；the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b59f410f-b1e2-46df-9717-d91c20b90bb9", "label": "摘要469", "info": "Salakhutdinov，R.（2006）.  Reducing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e386d13-c215-41e4-8294-ea70f1853dec", "label": "摘要470", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7becd120-620f-45a8-b140-7f47ab741cae", "label": "摘要471", "info": "Hinton，G.  E.  and  Sejnowski，T.  J.（1986）.  Learning  and  relearning  in；Boltzmann  machines.  In  D.  E.  Rumelhart  and  J.  L.  McClelland，；editors，Parallel  Distributed  Processing  ，volume  1，chapter  7，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a1c0670-3096-4e58-b94d-d30abd0e1bfa", "label": "摘要472", "info": "Hinton，G.  E.  and  Sejnowski，T.  J.（1999）.  Unsupervised  learning:；foundations of neural computation . MIT press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6c0c8e53-eb00-4b1b-93c5-4abc76799727", "label": "摘要473", "info": "Hinton，G.  E.  and  Shallice，T.（1991）.  Lesioning  an  attractor  network:；investigations of acquired dyslexia. Psychological review ，98 （1），74.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab6d138e-2fd3-4c50-8193-0ac4b3010373", "label": "摘要474", "info": "Hinton，G.  E.  and  Zemel，R.  S.（1994）.  Autoencoders，minimum；description length，and Helmholtz free energy. In NIPS'1993 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f023cf4-4e71-4560-b630-8500e75053bb", "label": "摘要475", "info": "Hinton，G.  E.，Sejnowski，T.；J.，and  Ackley，D.  H.（1984a）.；Boltzmann  machines:  Constraint  satisfaction  networks  that  learn.  Technical", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "54f8d37e-6422-4fc2-9a44-4fde2ae417c0", "label": "摘要476", "info": "J.，and  Ackley，D.  H.（1984b）.；Hinton，G.  E.，Sejnowski，T.；Boltzmann  machines:  Constraint  satisfaction  networks  that  learn.  Technical", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e40d840d-eb02-42ce-a5bf-4be262e0b809", "label": "摘要477", "info": "Hinton，G. E.，McClelland，J.，and Rumelhart，D.（1986）. Distributed；representations. In D. E. Rumelhart and J. L. McClelland，editors，Parallel；Distributed  Processing:  Explorations  in  the  Microstructure  of  Cognition ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49138223-c3f6-45a7-a451-a8e224f65a09", "label": "摘要478", "info": "Hinton，G.  E.，Revow，M.，and  Dayan，P.（1995a）.  Recognizing；handwritten  digits  using  mixtures  of  linear  models.  In  G.  Tesauro，D.；Touretzky，and  T.  Leen，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d79eeeab-9bf8-4dc0-b104-0a861ebb1ad2", "label": "摘要479", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "088af560-f64d-4994-96cb-540c7617c1a3", "label": "摘要480", "info": "Cambridge，MA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ffb5c2c5-406a-47a2-a4a6-45fd444f5f57", "label": "摘要481", "info": "Hinton，G.  E.，Dayan，P.，Frey，B.  J.，and  Neal，R.  M.（1995b）.；The  wake-sleep  algorithm  for  unsupervised  neural  networks.  Science ，268；，1558–1161.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6bd3b749-5550-4103-914e-ce3f9cfc7e4e", "label": "摘要482", "info": "Hinton，G.  E.，Dayan，P.，and  Revow，M.（1997）.  Modelling  the；manifolds  of  images  of  hand-written  digits.  IEEE  Transactions  on  Neural；Networks ，8 ，65–74.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ce3ae93-bd5a-470e-8f0b-c847d0d981e0", "label": "摘要483", "info": "Hinton，G.  E.，Welling，M.，Teh，Y.  W.，and  Osindero，S.（2001）.；A  new  view  of  ICA.  In  Proceedings  of  3rd  International  Conference  on；Independent Component Analysis and Blind Signal Separation（ICA'01） ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dbabe366-d7c6-453c-864b-fe283b0b78c2", "label": "摘要484", "info": "Hinton，G.  E.，Osindero，S.，and  Teh，Y.（2006a）.  A  fast  learning；algorithm for deep belief nets. Neural Computation ，18 ，1527–1554.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "040d587f-bc05-436d-9b50-2f361786f2e1", "label": "摘要485", "info": "Hinton，G. E.，Osindero，S.，and Teh，Y.-W.（2006b）. A fast learning；algorithm for deep belief nets. Neural Computation ，18 ，1527–1554.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dba28983-cbb4-4558-889c-e417621d0262", "label": "摘要486", "info": "Hinton，G.  E.，Deng，L.，Yu，D.，Dahl，G.  E.，Mohamed，A.，；Jaitly，N.，Senior，A.，Vanhoucke，V.，Nguyen，P.，Sainath，T.；N.，and  Kingsbury，B.（2012b）.  Deep  neural  networks  for  acoustic", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a02cd2e5-103d-4a1c-87f0-f95785698fca", "label": "摘要487", "info": "Hinton，G.；E.，Srivastava，N.，Krizhevsky，A.，Sutskever，I.，and；Salakhutdinov，R.（2012c）. Improving neural networks by preventing co-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cadafd0e-8f8e-4517-bb9f-af70978120bd", "label": "摘要488", "info": "Hinton，G.；E.，Srivastava，N.，Krizhevsky，A.，Sutskever，I.，and；Salakhutdinov，R.（2012d）. Improving neural networks by preventing co-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b838172-748c-4e86-bc87-6e14a7b0ad62", "label": "摘要489", "info": "Hinton，G.  E.，Vinyals，O.，and  Dean，J.（2014）.  Dark  knowledge.；Invited talk at the BayLearn Bay Area Machine Learning Symposium.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b37d839e-b489-4bb9-9d1f-90c9d624345e", "label": "摘要490", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Hochreiter，S.（1991a）.  Untersuchungen  zu  dynamischen  neuronalen；Netzen. Diploma thesis，T.U. München.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e84dea9-67fc-4085-b97c-c6a46eae0ef5", "label": "摘要491", "info": "Hochreiter，S.（1991b）.  Untersuchungen  zu  dynamischen  neuronalen；Netzen.  Diploma  thesis，Institut  für  Informatik，Lehrstuhl  Prof.  Brauer，；Technische Universität München.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6f162b5-cb04-4d34-ab76-3cf65f33bd76", "label": "摘要492", "info": "Hochreiter，S.  and  Schmidhuber，J.（1995）.  Simplifying  neural  nets  by；discoveringflat  minima.  In  Advances  in  Neural  Information  Processing；Systems 7 ，pages 529–536. MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "27db8c74-11e5-4424-b93b-8b6154a9a4fd", "label": "摘要493", "info": "Hochreiter，S.  and  Schmidhuber，J.（1997）.  Long  short-term  memory.；Neural Computation ，9 （8），1735–1780.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "577468f2-7008-4959-948c-5e577cc062a2", "label": "摘要494", "info": "Hochreiter，S.，Bengio，Y.，and  Frasconi，P.（2001）.  Gradientflow  in；recurrent nets: the difficulty of learning long-term dependencies. In J. Kolen；and  S.  Kremer，editors，Field  Guide  to  Dynamical  Recurrent  Networks  .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0c509e7f-31b8-4439-acf9-4f22a6ccc972", "label": "摘要495", "info": "Holi，J.  L.  and  Hwang，J.-N.（1993）.  Finite  precision  error  analysis  of；neural  network  hardware  implementations.  Computers，IEEE  Transactions；on ，42 （3），281–290.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "511db899-19a6-44af-a49e-3615d13e8b80", "label": "摘要496", "info": "Holt，J. L. and Baker，T. E.（1991）. Back propagation simulations using；limited  precision  calculations.  In  Neural  Networks，1991.，IJCNN-91-；Seattle  International  Joint  Conference  on  ，volume  2，pages  121–126.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc1eb4bc-e9d2-4eca-8cdc-df4ffb747724", "label": "摘要497", "info": "Hornik，K.，Stinchcombe，M.，and  White，H.（1989）.  Multilayer；feedforward networks are universal approximators. Neural Networks ，2  ，；359–366.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0b16ca79-bce5-4640-a639-3980ceaa4ec5", "label": "摘要498", "info": "Hornik，K.，Stinchcombe，M.，and  White，H.（1990）.  Universal；approximation  of  an  unknown  mapping  and  its  derivatives  using  multilayer；feedforward networks. Neural networks ，3 （5），551–560.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a01836f-5213-42a7-8487-f34b1c3925be", "label": "摘要499", "info": "Hsu，F.-H.（2002）.  Behind  Deep  Blue:  Building  the  Computer  That", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0541279c-781f-4eed-bfab-0c74cbecf160", "label": "摘要500", "info": "Defeated  the  World  Chess  Champion  .  Princeton  University  Press，；Princeton，NJ，USA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f3ab4b5f-6f6c-4892-9f52-b434de15b5a8", "label": "摘要501", "info": "and  Ogata，Y.（2002）.  Generalized  pseudo-likelihood；Huang，F.；estimates  for  Markov  random  fields  on  lattice.  Annals  of  the  Institute  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b54c1676-3602-4a9c-8a3e-d0d0fb1159a1", "label": "摘要502", "info": "Huang，P.-S.，He，X.，Gao，J.，Deng，L.，Acero，A.，and Heck，L.；（2013）.  Learning  deep  structured  semantic  models  for  web  search  using；clickthrough data. In Proceedings of the 22nd ACM international conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39f5c70a-e670-4f68-a979-b06ab6ef6fc5", "label": "摘要503", "info": "Hubel，D.  and  Wiesel，T.（1968）.  Receptivefields  and；functional；architecture  of  monkey  striate  cortex.  Journal  of  Physiology（London）", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c27cf2be-90a8-4fb5-9f87-fe0062295676", "label": "摘要504", "info": "Hubel，D.  H.  and  Wiesel，T.  N.（1959）.  Receptivefields  of  single；neurons in the cat's striate cortex. Journal of Physiology ，148 ，574–591.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1141b853-d6cc-4a38-833a-b5c3b27ab5eb", "label": "摘要505", "info": "Hubel，D.  H.  and  Wiesel，T.  N.（1962）.  Receptivefields，binocular；interaction，and functional architecture in the cat's visual cortex. Journal of；Physiology（London） ，160 ，106–154.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5b58bab-5f84-46df-94bd-514c1243279a", "label": "摘要506", "info": "Huszar，F.（2015）. How（not） to train your generative model: schedule；sampling，likelihood，adversary? arXiv:1511.05101 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "da9af60f-f3f6-468e-b34b-77332edcd9b9", "label": "摘要507", "info": "Hutter，F.，Hoos，H.，and；Sequential；model-based  optimization  for  general  algorithm  configuration.  In  LION-5  .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9073712-5cbc-47da-ba9b-5457fd07b0db", "label": "摘要508", "info": "Leyton-Brown，K.（2011）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "928307d5-d565-4b34-a1f1-ac1e1a6d1e98", "label": "摘要509", "info": "Hyotyniemi，H.（1996）.  Turing  machines  are  recurrent  neural  networks.；In STeP'96 ，pages 13–24.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b45ba5e-05d9-4c8a-aa3b-771790ff274d", "label": "摘要510", "info": "Hyvärinen，A.（1999）.  Survey  on；Neural Computing Surveys ，2 ，94–128.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "54b43a2b-85cf-4ba3-ab80-aba187da89ff", "label": "摘要511", "info": "independent  component  analysis.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a99a3e21-98f6-45ac-9376-a04f7ef1a4ae", "label": "摘要512", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Hyvärinen，A.（2005a）.  Estimation  of  non-normalized  statistical  models；using  score  matching.  Journal  of  Machine  Learning  Research  ，6  ，695–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dcb1dc71-8d0d-4e80-9fe6-41f2e90e492b", "label": "摘要513", "info": "Hyvärinen，A.（2005b）.  Estimation  of  non-normalized  statistical  models；using score matching. J. Machine Learning Res. ，6 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3c58ac0-e8ed-48b5-b80f-0cbff318c976", "label": "摘要514", "info": "Hyvärinen，A.（2007a）.  Connections；contrastive  divergence，and  pseu-dolikelihood；variables. IEEE Transactions on Neural Networks ，18 ，1529–1531.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "05dda31a-e31f-445b-9d24-baefb472300b", "label": "摘要515", "info": "score  matching，；for  continuous-valued", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0b5d82e3-b26e-4828-9b7d-918421713499", "label": "摘要516", "info": "between", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4bdab45f-da3c-47cf-ab2d-7cf74040e049", "label": "摘要517", "info": "Hyvärinen，A.（2007b）.；Computational Statistics and Data Analysis ，51 ，2499–2512.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b0a3325b-585d-4109-975d-d1ab6266b6c3", "label": "摘要518", "info": "extensions", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb0c7595-acd9-4f9b-9e5b-922ef61bedf5", "label": "摘要519", "info": "Some", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "296b919b-57b8-4c8f-a6f2-f9841c67366b", "label": "摘要520", "info": "of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cdbaa112-bbd3-429d-93c1-f188e8b3d237", "label": "摘要521", "info": "score  matching.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a8cb3449-a203-4b78-9f3b-80a9f5021665", "label": "摘要522", "info": "Hyvärinen，A.  and  Hoyer，P.  O.（1999）.  Emergence  of  topography  and；complex cell properties from natural images using extensions of ica. In NIPS；，pages 827–833.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "07e2ca1f-9871-4986-9eb1-fcd7ee99d31d", "label": "摘要523", "info": "Hyvärinen，A.；independent；component analysis: Existence and uniqueness results. Neural Networks ，12", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4421b65-2d78-4987-bead-59a0700d9773", "label": "摘要524", "info": "and  Pajunen，P.（1999）.  Nonlinear", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e38ee92c-2d5f-4b61-bdb4-777ee9b7b341", "label": "摘要525", "info": "Hyvärinen，A.，Karhunen，J.，and  Oja，E.（2001a）.；Component Analysis . Wiley-Interscience.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "131a494a-9516-4d85-899d-e253d3d5246c", "label": "摘要526", "info": "Independent", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3de19145-efd1-4acc-8cc4-09a376a1ef24", "label": "摘要527", "info": "Hyvärinen，A.，Hoyer，P.  O.，and  Inki，M.  O.（2001b）.  Topographic；independent  component  analysis.  Neural  Computation  ，13  （7），1527–；1558.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cdd7c4f0-3952-42a9-9642-f262f462864e", "label": "摘要528", "info": "Hyvärinen，A.，Hurri，J.，and  Hoyer，P.  O.（2009）.  Natural  Image；Statistics: A probabilistic approach to early computational vision . Springer-；Verlag.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85ef6e2a-e669-4468-b0cf-39e396fd6a3a", "label": "摘要529", "info": "Iba，Y.（2001）. Extended ensemble Monte Carlo. International Journal of；Modern Physics ，C12 ，623–656.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d67e262c-4e16-49cf-b28a-d68d56be6146", "label": "摘要530", "info": "Inayoshi，H.  and  Kurita，T.（2005）.  Improved  generalization  by  adding", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "471308f7-1f02-4bd6-bbf8-3405fa1b36a5", "label": "摘要531", "info": "both  auto-association  and  hidden-layer  noise  to  neural-network-based-；classifiers. IEEE  Workshop  on  Machine  Learning  for  Signal  Processing  ，；pages 141–146.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "83cf94e8-79ac-4b11-833f-cf2e4331e430", "label": "摘要532", "info": "Ioffe，S.  and  Szegedy，C.（2015）.  Batch  normalization:  Accelerating；deep network training by reducing internal covariate shift.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8235a677-5e8a-4e21-b8a8-e6c5c6c27855", "label": "摘要533", "info": "Jacobs，R.  A.（1988）.  Increased  rates  of  convergence  through  learning；rate adaptation. Neural networks ，1 （4），295–307.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7899302a-5085-4c54-9f43-4b44f393affe", "label": "摘要534", "info": "Jacobs，R.  A.，Jordan，M.  I.，Nowlan，S.  J.，and  Hinton，G.  E.；（1991）.  Adaptive  mixtures  of  local  experts.  Neural  Computation ，3  ，；79–87.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b3ce20c1-c896-4ffb-a37c-2020146a0b08", "label": "摘要535", "info": "Jaeger，H.（2003）.  Adaptive  nonlinear  system  identification  with  echo；state networks. In Advances in Neural Information Processing Systems 15 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "48313e69-5300-41df-abc9-8212d0bb5f25", "label": "摘要536", "info": "Jaeger，H.（2007a）.  Discovering  multiscale  dynamical  features  with；hierarchical echo state networks. Technical report，Jacobs University.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90256c1a-1d11-4c62-8fc8-7d2ab4714de6", "label": "摘要537", "info": "Jaeger，H.（2007b）. Echo state network. Scholarpedia ，2 （9），2330.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8cbc2a42-c3d0-4765-943e-b66816a03bcf", "label": "摘要538", "info": "Jaeger，H.（2012）.  Long  short-term  memory  in  echo  state  networks:；Details  of  a  simulation  study.  Technical  report，Technical  report，Jacobs；University Bremen.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1b078d24-4c3b-408f-85e1-440457c7ac2e", "label": "摘要539", "info": "Jaeger，H.  and  Haas，H.（2004）.  Harnessing  nonlinearity:  Predicting；chaotic systems and saving energy in wireless communication. Science ，304；（5667），78–80.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eafe2af3-941f-4803-8e2c-c1f9c2730dea", "label": "摘要540", "info": "Jaeger，H.，Lukosevicius，M.，Popovici，D.，and；Siewert，U.；（2007）. Optimization and applications of echo state networks with leaky-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc74a9cf-1190-41b9-9fcd-f2516a1b93e5", "label": "摘要541", "info": "Jain，V.，Murray，J.；F.，Roth，F.，Turaga，S.，Zhigulin，V.，；Briggman，K.  L.，Helmstaedter，M.  N.，Denk，W.，and  Seung，H.  S.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42938016-af0f-4d0f-bd71-dcd68fa0d852", "label": "摘要542", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；networks. In Computer  Vision，2007.  ICCV  2007.  IEEE  11th  International；Conference on ，pages 1–8. IEEE.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eae37aef-9999-4bcb-b55d-9e5e02965fb0", "label": "摘要543", "info": "Jaitly，N.  and  Hinton，G.（2011）.  Learning  a  better  representation  of；speech  soundwaves  using  restricted  Boltzmann  machines.  In  Acoustics，；Speech  and  Signal  Processing（ICASSP），2011  IEEE  International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7f4abbb2-467f-4b57-85be-eabd5e35fc35", "label": "摘要544", "info": "Jaitly，N.；tract；perturbation（VTLP） improves speech recognition. In ICML'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8cf016c9-2a05-4c24-8468-d5ffbab71e61", "label": "摘要545", "info": "E.（2013）.  Vocal", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa4fec72-63e3-4a32-af61-388bd93fc6f1", "label": "摘要546", "info": "and  Hinton，G.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "76eba7b4-8bf8-4cf6-8d4b-31fd97867fea", "label": "摘要547", "info": "length", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "313b1ffb-ce8e-4495-a6e0-65e27d814a3c", "label": "摘要548", "info": "LeCun，Y.；Jarrett，K.，Kavukcuoglu，K.，Ranzato，M.，and；（2009a）. What is the best multi-stage architecture for object recognition?", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ff26254-f6e8-4fb9-964c-2f8c1a5d0ebe", "label": "摘要549", "info": "Jarrett，K.，Kavukcuoglu，K.，Ranzato，M.，and；LeCun，Y.；（2009b）. What is the best multi-stage architecture for object recognition?", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a31b227-f206-4c6d-a343-6738056e01df", "label": "摘要550", "info": "Jarzynski，C.（1997）. Nonequilibrium equality for free energy differences.；Phys. Rev. Lett. ，78 ，2690–2693.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "074a93a6-7ed9-41b3-9e79-4ed41488e7ad", "label": "摘要551", "info": "Jaynes，E.  T.（2003）.  Probability  Theory:  The  Logic  of  Science；Cambridge University Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c55bc37-3281-4e17-8a99-b5feba73dfab", "label": "摘要552", "info": ".", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b1231f5a-53ac-4b54-afc8-2b06d1ea0cf4", "label": "摘要553", "info": "Jean，S.，Cho，K.，Memisevic，R.，and  Bengio，Y.（2014）.  On；using  very；translation.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4c23618-aade-496b-ab65-70fc94686b7f", "label": "摘要554", "info": "target  vocabulary  for  neural  machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bffff4aa-f2fe-457e-8952-4731ef23c1db", "label": "摘要555", "info": "large", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fbc61709-c9b3-48e0-9da4-d1834e991a19", "label": "摘要556", "info": "Jelinek，F. and Mercer，R. L.（1980）. Interpolated estimation of Markov；source  parameters  from  sparse  data.  In  E.  S.  Gelsema  and  L.  N.  Kanal，；editors，Pattern Recognition in Practice . North-Holland，Amsterdam.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e61eb2d4-cc0c-471a-90c3-63506f98e086", "label": "摘要557", "info": "Jia，Y.（2013）.  Caffe:An  open  source  convolutional  architecture  for  fast；feature embedding. http://caffe.berkeleyvision.org/.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0bb872f8-025a-472e-8670-b02f4c52b0c1", "label": "摘要558", "info": "Jia，Y.，Huang，C.，and  Darrell，T.（2012）. Beyond spatial pyramids:；Receptivefield  learning  for  pooled  image  features.  In  Computer  Vision  and；Pattern  Recognition（CVPR），2012  IEEE  Conference  on ，pages  3370–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "25053729-c446-45b5-9ce2-33424ce6028c", "label": "摘要559", "info": "Jim，K.-C.，Giles，C.  L.，and  Horne，B.  G.（1996）.  An  analysis  of；noise  in  recurrent  neural  networks:  convergence  and  generalization.  IEEE；Transactions on Neural Networks ，7 （6），1424–1438.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96edd576-80ac-4083-acaf-4626ae2966d2", "label": "摘要560", "info": "Jordan，M.  I.（1998）.  Learning；Dordrecht，Netherlands.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cee1bae8-af39-4fbb-96f4-086194767bc0", "label": "摘要561", "info": "in  Graphical  Models", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "245d3e1e-8099-4b07-bf30-df2abd4549e8", "label": "摘要562", "info": ".  Kluwer，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe29d3ef-66c6-48c5-9549-5a0c2fd43d1c", "label": "摘要563", "info": "Joulin，A.  and  Mikolov，T.（2015）.  Inferring  algorithmic  patterns  with；stack-augmented recurrent nets. arXiv preprint arXiv:1503.01007 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f302f408-d6f6-4018-aa84-c3093acabd96", "label": "摘要564", "info": "Jozefowicz，R.，Zaremba，W.，and Sutskever，I.（2015）. An empirical；evaluation of recurrent network architectures. In ICML'2015 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6a323dc0-f8d8-46b6-ae65-1d75af7b457a", "label": "摘要565", "info": "Judd，J.  S.（1989）.  Neural  Network  Design  and  the  Complexity  of；Learning . MIT press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb860a74-3f85-462c-b708-a0a6d0a841c5", "label": "摘要566", "info": "Jutten，C. and Herault，J.（1991）. Blind separation of sources，part I: an；adaptive  algorithm  based  on  neuromimetic  architecture.  Signal  Processing；，24 ，1–10.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fdc6a62b-b3fe-4218-8cfe-42bdfa57ca51", "label": "摘要567", "info": "E.，Pal，C.，Bouthillier，X.，Froumenty，P.，Gülçehre，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5cb5ecb0-05ac-4928-bfb5-de7cf179ac0d", "label": "摘要568", "info": "Kahou，S.；c.，Memisevic，R.，Vincent，P.，Courville，A.，Bengio，Y.，；Ferrari，R.  C.，Mirza，M.，Jean，S.，Carrier，P.  L.，Dauphin，Y.，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "379d3ba5-2323-4660-bc5b-965e0808d03e", "label": "摘要569", "info": "Kalchbrenner，N.  and  Blunsom，P.（2013）.  Recurrent  continuous；translation models. In EMNLP'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "08f52353-bcd4-4887-b079-c66472cbfc51", "label": "摘要570", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Kalchbrenner，N.，Danihelka，I.，and  Graves，A.（2015）.  Grid  long；short-term memory. arXiv preprint arXiv:1507.01526 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9543d44f-b9b8-44b5-9094-92e569c0d19e", "label": "摘要571", "info": "Kamyshanska，H. and Memisevic，R.（2015）. The potential energy of an；autoencoder.  IEEE  Transactions  on  Pattern  Analysis  and  Machine；Intelligence .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a8643ee-43af-4db7-80b0-28518a475b1f", "label": "摘要572", "info": "Karpathy，A. and Li，F.-F.（2015）. Deep visual-semantic alignments for；generating image de-scriptions. In CVPR'2015 . arXiv:1412.2306.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aaa4d13c-b11c-4956-a5be-c25eea7796a5", "label": "摘要573", "info": "Karpathy，A.，Toderici，G.，Shetty，S.，Leung，T.，Sukthankar，；R.，and  Fei-Fei，L.（2014）.  Large-scale  video  classification  with；convolutional neural networks. In CVPR .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79ced9e3-eb28-479e-bf80-1462570b2da2", "label": "摘要574", "info": "Karush，W.（1939）.  Minima  of  Functions  of  Several  Variables  with；Inequalities  as  Side  Constraints.  Master's  thesis ，Dept.  of  Mathematics，；Univ. of Chicago.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f813b2d8-d5f9-4fff-b870-4a8eb50a38b1", "label": "摘要575", "info": "Katz，S.  M.（1987）.  Estimation  of  probabilities  from  sparse  data  for  the；language  model  compo-nent  of  a  speech  recognizer.  IEEE  Transactions  on；Acoustics，Speech，and Signal Processing ，ASSP-35 （3），400–401.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "68e7c984-c0c4-4a86-835a-fd59998c86f3", "label": "摘要576", "info": "Kavukcuoglu，K.，Ranzato，M.，and；Fast；inference in sparse coding algorithms with applications to object recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "569ab5ab-6782-4297-8542-56346fda73ba", "label": "摘要577", "info": "LeCun，Y.（2008）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efce8520-5320-4fef-8790-0389aa1f87c3", "label": "摘要578", "info": "Kavukcuoglu，K.，Ranzato，M.-A.，Fergus，R.，and；LeCun，Y.；（2009）.  Learning  invariant  features  through  topographicfilter  maps.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5c422fcc-e502-4a6c-bf16-e0e58d4ff5f3", "label": "摘要579", "info": "Kavukcuoglu，K.，Sermanet，P.，Boureau，Y.-L.，Gregor，K.，；Mathieu，M.，and  LeCun，Y.（2010）.  Learning  convolutional  feature；hierarchies for visual recognition. In NIPS'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f49bd2b2-73df-4171-92fe-6a49a08f2e5f", "label": "摘要580", "info": "Kelley，H. J.（1960）. Gradient theory of optimalflight paths. ARS Journal；，30 （10），947–954.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3fcb88e0-82c0-49a9-beca-fe2eae63040d", "label": "摘要581", "info": "Khan，F.，Zhu，X.，and Mutlu，B.（2011）. How do humans teach: On；curriculum  learning  and  teaching  dimension.  In  Advances  in  Neural；Information Processing Systems 24（NIPS'11） ，pages 1449–1457.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "07fe8ad6-a7de-46df-83b1-852cc042932f", "label": "摘要582", "info": "Kim，S.  K.，McAfee，L.  C.，McMahon，P.  L.，and  Olukotun，K.；（2009）.  A  highly  scalable  restricted  Boltzmann  machine  FPGA；implementation. In Field Programmable Logic and Applications，2009. FPL", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "370e8a60-53e1-432e-a699-09042f37d4fd", "label": "摘要583", "info": "Kindermann，R.（1980）.  Markov；Random；Applications（Contemporary  Mathe-matics；V.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "62b4f904-46b3-4a25-ad57-e551239db41d", "label": "摘要584", "info": "Fields；1）", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26196d0f-edaf-4681-917f-cc3f4a7a5d94", "label": "摘要585", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "761fa902-8212-4e0b-ad24-c4d9f1657a24", "label": "摘要586", "info": "Their；.  American", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26ac41ce-5478-46c7-9bc6-2cbc201465d4", "label": "摘要587", "info": "Kingma，D.  and  Ba，J.（2014）.  Adam:  A  method  for  stochastic；optimization. arXiv preprint arXiv:1412.6980 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "de4f4a78-c3b7-4f35-83d1-af32df92da73", "label": "摘要588", "info": "Kingma，D.  and  LeCun，Y.（2010a）.  Regularized  estimation  of  image；statistics by score matching. In NIPS'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "93fd2b47-2c4f-445a-b908-5ac862a6ec15", "label": "摘要589", "info": "Kingma，D.  and  LeCun，Y.（2010b）.  Regularized  estimation  of  image；statistics  by  score  matching.  In  J.  Lafferty，C.  K.  I.  Williams，J.  Shawe-；Taylor，R.  Zemel，and  A.  Culotta，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0b87138-f485-4c79-a5e1-052bc365391f", "label": "摘要590", "info": "Kingma，D.，Rezende，D.，Mohamed，S.，and  Welling，M.（2014）.；Semi-supervised learning with deep generative models. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2cb443c5-7ae2-4d26-b2b2-45eb9493990d", "label": "摘要591", "info": "Kingma，D.  P.（2013）.  Fast  gradient-based  inference  with  continuous；latent variable models in auxiliary form. Technical report，arxiv:1306.0733.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "87f378b7-9b1f-4696-9997-c7c87ee974a6", "label": "摘要592", "info": "Kingma，D.  P.  and  Welling，M.（2014a）.  Auto-encoding  variational；bayes.  In  Proceedings  of  the  International  Conference  on  Learning；Representations（ICLR） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "51bf364d-9b0a-49b4-9107-9e7284603115", "label": "摘要593", "info": "Kingma，D.  P.  and  Welling，M.（2014b）.  Efficient  gradient-based；inference  through  transforma-tions  between  bayes  nets  and  neural  nets.；Technical report，arxiv:1402.0480.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1006def5-72af-4a65-b31e-b3b03960ac89", "label": "摘要594", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Kirkpatrick，S.，Jr.，C.  D.  G.，and  Vecchi，M.；Optimization by simulated annealing. Science ，220 ，671–680.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96be4292-c185-421b-bd12-52ef3d6e0548", "label": "摘要595", "info": "P.（1983）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd103523-ae88-4bd8-b580-a6a2266f2fd1", "label": "摘要596", "info": "Kiros，R.，Salakhutdinov，R.，and  Zemel，R.（2014a）.  Multimodal；neural language models. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42dfe928-58ea-4999-a178-397973c256b6", "label": "摘要597", "info": "Zemel，R.（2014b）.  Unifying；Kiros，R.，Salakhutdinov，R.，and；visual-semantic embeddings with multimodal neural language models. arXiv", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "098222c2-1385-4406-ab6e-3469a7b266b0", "label": "摘要598", "info": "Klementiev，A.，Titov，I.，and；Inducing；crosslingual distributed representations of words. In Proceedings of COLING", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "be98bb5d-78af-4f54-869e-8ac949603e9a", "label": "摘要599", "info": "Bhattarai，B.（2012）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7de21fac-c9b6-42f4-b982-615d3992c06f", "label": "摘要600", "info": "Knowles-Barley，S.，Jones，T.  R.，Morgan，J.，Lee，D.，Kasthuri，；N.，Lichtman，J.  W.，and  Pfister，H.（2014）.  Deep  learning  for  the；connectome. GPU Technology Conference .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7de89386-64e0-4e24-afcf-c569a2efaf37", "label": "摘要601", "info": "Koller，D.  and  Friedman，N.（2009）.  Probabilistic  Graphical  Models:；Principles and Techniques . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "23d801d4-b4dc-4ed9-8db7-f54bcd43b077", "label": "摘要602", "info": "Konig，Y.，Bourlard，H.，and Morgan，N.（1996）. REMAP:Recursive；estimation  and  maxi-mization  of  a  posteriori  probabilities–application  to；transition-based  connectionist  speech  recognition.  In  D.  Touretzky，M.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9ec19bfa-e0e2-48bf-a23f-45efd75e7244", "label": "摘要603", "info": "Koren，Y.（2009）. The BellKor solution to the Netflix grand prize.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3b6ab179-504a-447e-bfa9-8c37c54aa17b", "label": "摘要604", "info": "Kotzias，D.，Denil，M.，de Freitas，N.，and Smyth，P.（2015）. From；group to individual labels using deep features. In ACM SIGKDD .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce1cf0d9-4b5f-41ec-bf33-7570370f59fc", "label": "摘要605", "info": "Koutnik，J.，Greff，K.，Gomez，F.，and  Schmidhuber，J.（2014）.  A；clockwork RNN. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb8e5063-c13c-42b6-b451-312b1d869c5b", "label": "摘要606", "info": "Kočiský，T.，Hermann，K.  M.，and  Blunsom，P.（2014）.  Learning；In；Bilingual  Word  Representations  by  Marginalizing  Alignments.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2832d77c-6acf-41c2-ba4f-5b709e521c84", "label": "摘要607", "info": "Proceedings of ACL .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "38501de8-74a2-43af-9be1-8e843566c1c1", "label": "摘要608", "info": "Krause，O.，Fischer，A.，Glasmachers，T.，and；Igel，C.（2013）.；Approximation properties of DBNs with binary hidden units and real-valued", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b602e866-3c35-4d7c-bad8-6c4ba5a16424", "label": "摘要609", "info": "Krizhevsky，A.（2010）.  Convolutional  deep  belief  networks  on  CIFAR-；10.  Technical  report，Uni-versity  of  Toronto.  Unpublished  Manuscript:；http://www.cs.utoronto.ca/kriz/conv-cifar10-aug2010.pdf.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "870173e0-c6d1-432b-b94c-59884eb70ea9", "label": "摘要610", "info": "Krizhevsky，A.  and  Hinton，G.（2009）.  Learning  multiple  layers  of；features from tiny images. Technical report，University of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc52324f-0419-4080-9b5e-5ff706ff5584", "label": "摘要611", "info": "Krizhevsky，A. and Hinton，G. E.（2011）. Using very deep autoencoders；for content-based image retrieval. In ESANN .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c04c2e6e-c4b6-4edc-b2ec-5f2fc8881df2", "label": "摘要612", "info": "Krizhevsky，A.，Sutskever，I.，and  Hinton，G.（2012a）.；classification with deep convo-lutional neural networks. In NIPS'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8464a0d-246c-4f5a-8148-43742f544f30", "label": "摘要613", "info": "ImageNet", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2dc32422-f66d-4bf9-a913-69ee8396265f", "label": "摘要614", "info": "Krizhevsky，A.，Sutskever，I.，and  Hinton，G.（2012b）.；ImageNet；classification  with  deep  convolutional  neural  networks.  In  Advances  in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aacd5402-de15-4643-9c9d-d80ad0ce1298", "label": "摘要615", "info": "Krueger，K. A. and Dayan，P.（2009）. Flexible shaping: how learning in；small steps helps. Cognition ，110 ，380–394.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9df2f0e4-36b3-4470-a379-3803fca624bf", "label": "摘要616", "info": "Kuhn，H.  W.  and  Tucker，A.  W.（1951）.  Nonlinear  programming.  In；Proceedings of the Sec-ond Berkeley Symposium on Mathematical Statistics；and  Probability  ，pages  481–492，Berkeley，Calif.  University  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bf1134d-b33d-4fcd-8e41-051c980053b6", "label": "摘要617", "info": "Kumar，A.，Irsoy，O.，Ondruska，P.，Iyyer，M.，Bradbury，J.，；Gulrajani，I.，and  Socher，R.（2015a）.  Ask  me  anything:  Dynamic；memory  networks  for  natural  language  processing.  Technical  report，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96da28ba-54de-487c-a31a-de3f323a8579", "label": "摘要618", "info": "Kumar，A.，Irsoy，O.，Su，J.，Bradbury，J.，English，R.，Pierce，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9a243f8d-7cf6-4333-8a30-8c27e1a69782", "label": "摘要619", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Socher，R.；B.，Ondruska，P.，Iyyer，M.，Gulrajani，I.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e72d59cf-edfa-4522-bcaf-e146e23ecbbd", "label": "摘要620", "info": "Kumar，M. P.，Packer，B.，and Koller，D.（2010）. Self-paced learning；for  latent  variable  models.  In  J.  Lafferty，C.  K.  I.  Williams，J.  Shawe-；Taylor，R.  Zemel，and  A.  Culotta，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "43f84ebb-0f0b-412a-a944-7d956b6a2726", "label": "摘要621", "info": "Lang，K.  J.  and  Hinton，G.  E.（1988）.  The  development  of  the  time-；delay  neural  network  archi-tecture  for  speech  recognition.  Technical  Report；CMU-CS-88-152，Carnegie-Mellon University.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2215f602-c429-4866-a4a5-f1e298c96481", "label": "摘要622", "info": "Lang，K.  J.，Waibel，A.  H.，and  Hinton，G.  E.（1990）.  A  time-delay；neural  network  architecture  for  isolated  word  recognition.  Neural  networks；，3 （1），23–43.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c974117f-cc68-4202-a979-2c787fc37022", "label": "摘要623", "info": "Langford，J.  and  Zhang，T.（2008）.  The  epoch-greedy  algorithm  for；contextual multi-armed bandits. In NIPS'2008 ，pages 1096–1103.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6260794b-11da-46e7-832c-09515cfe8a65", "label": "摘要624", "info": "Lappalainen，H.，Giannakopoulos，X.，Honkela，A.，and Karhunen，J.；（2000）.  Nonlinear  independent  component  analysis  using  ensemble；learning: Experiments and discussion. In Proc. ICA. Citeseer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "24bbc21c-b7d5-42f2-b1cc-98a4d38c11f2", "label": "摘要625", "info": "Larochelle，H.；discriminative restricted Boltzmann machines. In ICML'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a5b129f7-cdbd-49ef-a3b6-33a13492cd99", "label": "摘要626", "info": "and  Bengio，Y.（2008a）.  Classification", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35ffd7d3-968f-427a-81db-3363df0de495", "label": "摘要627", "info": "using", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2339a603-d065-4aa9-aaab-c73ef8b150e3", "label": "摘要628", "info": "Larochelle，H.；using；discriminative  restricted  Boltzmann  machines.  In  ICM（1a），pages  536–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42762836-fc99-4063-9bcd-1f22a78dc045", "label": "摘要629", "info": "and  Bengio，Y.（2008b）.  Classification", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e1b7d5a-7669-4ab0-a67a-c531812ef47b", "label": "摘要630", "info": "Larochelle，H.  and  Hinton，G.  E.（2010）.  Learning  to  combine  foveal；glimpses  with  a  third-order  Boltzmann  machine.  In  Advances  in  Neural；Information Processing Systems 23 ，pages 1243–1251.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4b061e2e-a3eb-4613-acc0-144e0ba84307", "label": "摘要631", "info": "Larochelle，H.  and  Murray，I.（2011）.  The  Neural  Autoregressive；Distribution Estimator. In AISTATS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7737e182-80a0-4e4d-b828-7344e5445df6", "label": "摘要632", "info": "Larochelle，H.，Erhan，D.，and Bengio，Y.（2008）. Zero-data learning；of new tasks. In AAAI Conference on Artificial Intelligence .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1a1ebb9-1733-4277-bf39-ea3216bd3580", "label": "摘要633", "info": "Larochelle，H.，Bengio，Y.，Louradour，J.，and Lamblin，P.（2009）.；Exploring strategies for training deep neural networks. In JML（1），pages；1–40.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca301adc-2675-446c-97ad-0908e1b08ba2", "label": "摘要634", "info": "Lasserre，J.  A.，Bishop，C.  M.，and  Minka，T.  P.（2006）.  Principled；hybrids  of  generative  and  discriminative  models.  In  Proceedings  of  the；Computer Vision and Pattern Recognition Conference（CVPR'06） ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b23b1f2f-2deb-4a6e-8535-267502bbb703", "label": "摘要635", "info": "Le，Q.，Ngiam，J.，Chen，Z.，hao  Chia，D.  J.，Koh，P.  W.，and；Ng，A.（2010）. Tiled convolutional neural networks. In J. Lafferty，C. K.；I.  Williams，J.  Shawe-Taylor，R.  Zemel，and  A.  Culotta，editors，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1b6a366f-7608-4ff6-9012-fb998a297f23", "label": "摘要636", "info": "Le，Q.，Ngiam，J.，Coates，A.，Lahiri，A.，Prochnow，B.，and；Ng，A.（2011）.  On  optimization  methods  for  deep  learning.  In  Proc.；ICML'2011 . ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "77293f3c-c936-440f-af13-7bd4f10339f8", "label": "摘要637", "info": "Le，Q.，Ranzato，M.，Monga，R.，Devin，M.，Corrado，G.，Chen，；K.，Dean，J.，and  Ng，A.（2012）.  Building  high-level  features  using；large scale unsupervised learning. In ICML'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "faf66f77-35ad-4440-9a59-8daebb3fbde9", "label": "摘要638", "info": "Le  Roux，N.  and  Bengio，Y.（2008）.  Representational  power  of；restricted  Boltzmann  machines  and  deep  belief  networks.  Neural；Computation ，20 （6），1631–1649.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0bdc47b7-2a2b-45e5-8ab2-a76d9f78d59b", "label": "摘要639", "info": "Le Roux，N. and Bengio，Y.（2010）. Deep belief networks are compact；universal approximators. Neural Computation ，22 （8），2192–2207.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8750a137-a56a-4b9e-b5a9-ac12c445f921", "label": "摘要640", "info": "LeCun，Y.（1985）.  Une  procédure  d'apprentissage  pour  Réseau  à  seuil；assymétrique. In Cognitiva 85: A la Frontière de l'Intelligence Artificielle，；des  Sciences  de  la  Connaissance  et  des  Neurosciences ，pages  599–604，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "273cd2fe-4733-42e0-a718-75d410b15754", "label": "摘要641", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；LeCun，Y.（1986）.  Learning  processes  in  an  asymmetric  threshold；network.  In  E.  Bienenstock，F.  Fogelman-Soulié，and  G.  Weisbuch，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc203b5d-b5e3-47a3-a405-ac66f33596fa", "label": "摘要642", "info": "LeCun，Y.（1987）.  Modèles  connexionistes  de  l'apprentissage  .  Ph.D.；thesis，Université de Paris VI.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9e966ad-d41e-41ea-b29d-4f6eef551027", "label": "摘要643", "info": "LeCun，Y.（1989）.  Generalization  and  network  design  strategies.；Technical Report CRG-TR-89-4，University of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7924974e-f628-4c46-8434-bcd22c77869a", "label": "摘要644", "info": "LeCun，Y.，Jackel，L.  D.，Boser，B.，Denker，J.  S.，Graf，H.  P.，；Guyon，I.，Henderson，D.，Howard，R.；Hubbard，W.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0be47b38-0a6b-4a6b-8beb-5aa027a7a8c9", "label": "摘要645", "info": "E.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8b62ee2-48a1-4935-8497-365b8b0d8949", "label": "摘要646", "info": "LeCun，Y.，Bottou，L.，Orr，G.  B.，and  Müller，K.-R.（1998a）.；Efficient  backprop.  In  Neural  Networks，Tricks  of  the  Trade  ，Lecture；Notes in Computer Science LNCS 1524. Springer Verlag.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c081d789-3468-4731-a0c1-61ee8f1a8a56", "label": "摘要647", "info": "LeCun，Y.，Bottou，L.，Orr，G.；Efficient backprop. In Neural Networks，Tricks of the Trade .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eed0180c-d0b4-4365-9869-af0c258bf307", "label": "摘要648", "info": "B.，and  Müller，K.（1998b）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ffef63f4-7680-475b-9f1c-a0495a6e8092", "label": "摘要649", "info": "LeCun，Y.，Bottou，L.，Bengio，Y.，and；Gradient based learning applied to document recognition. Proc. IEEE .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47fecc3a-2d07-4210-bb45-1534087a575b", "label": "摘要650", "info": "Haffner，P.（1998c）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0a14ffa-4a18-4301-9bcb-4f44230f4d2e", "label": "摘要651", "info": "LeCun，Y.，Kavukcuoglu，K.，and  Farabet，C.（2010）.  Convolutional；networks  and  applications  in  vision.  In  Circuits  and  Systems（ISCAS），；Proceedings  of  2010  IEEE  International  Symposium  on  ，pages  253–256.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "82ad4f04-bffe-4b37-ae13-11fbe7a318f7", "label": "摘要652", "info": "L'Ecuyer，P.（1994）.  Efficiency  improvement  and  variance  reduction.  In；Proceedings of the 1994 Winter Simulation Conference ，pages 122–132.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1cba289a-4893-4c1e-87a1-0b820f135930", "label": "摘要653", "info": "Lee，C.-Y.，Xie，S.，Gallagher，P.，Zhang，Z.，and  Tu，Z.（2014）.；Deeply-supervised nets. arXiv preprint arXiv:1409.5185 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a078db6-e96a-490c-bc08-b6e19fe92f44", "label": "摘要654", "info": "Lee，H.，Battle，A.，Raina，R.，and  Ng，A.（2007）.  Efficient  sparse；coding  algorithms.  In  B.  Schölkopf，J.  Platt，and  T.  Hoffman，editors，；Advances in Neural Information Processing Systems 19（NIPS'06） ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a4dd784-8661-44a6-93c5-8c59f08eed76", "label": "摘要655", "info": "Lee，H.，Ekanadham，C.，and  Ng，A.（2008）.  Sparse  deep  belief  net；model for visual area V2. In NIPS'07 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "888b0e25-0d8a-4429-a7bb-7d1775f3b3d8", "label": "摘要656", "info": "Y.（2009）.；Lee，H.，Grosse，R.，Ranganath，R.，and；Convolutional  deep  belief  net-works  for  scalable  unsupervised  learning  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d8e61da-f0ba-4e3c-823f-5db0a819eec6", "label": "摘要657", "info": "Ng，A.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7bf0cf1-7b98-40bd-9326-16214c016249", "label": "摘要658", "info": "Lee，Y.  J.  and  Grauman，K.（2011）.  Learning  the  easy  thingsfirst:  self-；paced visual category discovery. In CVPR'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "696c39ff-4e4c-4671-b82d-9dec256fd33f", "label": "摘要659", "info": "Leibniz，G.  W.（1676）.  Memoir  using  the  chain  rule.（Cited  in  TMME；7:2&3 p 321-332，2010）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70f4e133-8179-4c1e-ab28-fe7fdacc656d", "label": "摘要660", "info": "Lenat，D.  B.  and  Guha，R.  V.（1989）.  Building  large  knowledge-based；systems；representation and inference in the Cyc project . Addison-Wesley；Longman Publishing Co.，Inc.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efb463aa-7bb8-4257-a8f1-eacfc52eac22", "label": "摘要661", "info": "Leshno，M.，Lin，V.  Y.，Pinkus，A.，and  Schocken，S.（1993）.；Multilayer  feedforward  networks  with  a  nonpolynomial  activation  function；can approximate any function. Neural Networks ，6 ，861–867.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46f8a36f-4051-4d6c-85db-d089b5eba4ef", "label": "摘要662", "info": "Levenberg，K.（1944）.  A  method  for  the  solution  of  certain  non-linear；problems  in  least  squares.  Quarterly  Journal  of  Applied  Mathematics  ，II；（2），164–168.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "228af6ec-7b03-48d3-81b1-6b448444caf3", "label": "摘要663", "info": "L'Hôpital，G.  F.  A.（1696）.  Analyse  des；l'intelligence des lignes courbes . Paris: L'Imprimerie Royale.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e13dd717-bc2e-4dd2-a44a-26a655d73a8a", "label": "摘要664", "info": "infiniment  petits，pour", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb77ed52-d7f4-4c11-9e95-666bc4f7ef89", "label": "摘要665", "info": "Li，Y.，Swersky，K.，and  Zemel，R.  S.（2015）.  Generative  moment；matching networks. CoRR ，abs/1502.02761 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec2e16d5-2531-464b-b8c5-255eb246f5ca", "label": "摘要666", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Lin，T.，Horne，B.  G.，Tino，P.，and  Giles，C.  L.（1996）.  Learning；long-term  dependencies  is  not  as  difficult  with  NARX  recurrent  neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a934b339-0732-418c-b76b-9bdfae2f9130", "label": "摘要667", "info": "Lin，Y.，Liu，Z.，Sun，M.，Liu，Y.，and Zhu，X.（2015）. Learning；entity  and  relation  embeddings  for  knowledge  graph  completion.  In  Proc.；AAAI'15 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a45ccc69-311d-4229-9d4a-22180b8ae455", "label": "摘要668", "info": "Linde，N.（1992）.  The  machine  that  changed  the  world，episode  3.；Documentary miniseries.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0002268b-df21-42cc-89de-6fa2536d5bf8", "label": "摘要669", "info": "Lindsey，C.  and  Lindblad，T.（1994）.  Review  of  hardware  neural；networks: a user's perspective. In Proc. Third Workshop on Neural Networks:；From  Biology  to  High  Energy  Physics  ，pages  195–202，Isola  d'Elba，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9fc6e4e5-ddb9-4ce2-8f63-fbd645d31690", "label": "摘要670", "info": "Linnainmaa，S.（1976）.  Taylor  expansion  of  the  accumulated  rounding；error. BIT Numerical Mathematics ，16 （2），146–160.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "16569334-0aa9-44da-81e2-5ce9d0bde1c3", "label": "摘要671", "info": "LISA（2008）.  Deep  learning  tutorials:Restricted  Boltzmann  machines.；Technical report，LISA Lab，Université de Montréal.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f3cc6fdb-1d47-4ab4-801b-22b1b1b623b1", "label": "摘要672", "info": "Long，P. M. and Servedio，R. A.（2010）. Restricted Boltzmann machines；are  hard  to  approximately  evaluate  or  simulate.  In  Proceedings  of  the  27th；International Conference on Machine Learning（ICML'10） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "928f6384-4244-4c8a-b724-25500dd66aaa", "label": "摘要673", "info": "Lotter，W.，Kreiman，G.，and Cox，D.（2015）. Unsupervised learning；of  visual  structure  using  predictive  generative  networks.  arXiv  preprint；arXiv:1511.06380 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c5456a61-1566-41ef-88b4-f5180cb340dd", "label": "摘要674", "info": "Lovelace，A.（1842）.  Notes  upon  L.  F.  Menabrea's“Sketch  of  the；Analytical Engine invented by Charles Babbage”.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "73a14d61-f433-45aa-979d-e8e15c5ace1e", "label": "摘要675", "info": "Lu，L.，Zhang，X.，Cho，K.，and  Renals，S.（2015）.  A  study  of  the；recurrent  neural  network  encoder-decoder  for  large  vocabulary  speech；recognition. In Proc. Interspeech .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "75ae5f65-d7e5-4ff2-b1fb-b30a13953822", "label": "摘要676", "info": "Lu，T.，Pál，D.，and Pál，M.（2010）. Contextual multi-armed bandits.；In International Conference  on Artificial Intelligence and Statistics ，pages；485–492.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bf62521f-027e-4239-9161-41944a937941", "label": "摘要677", "info": "Luenberger，D. G.（1984）. Linear and Nonlinear Programming . Addison；Wesley.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a16dcd7-13cd-43d0-be71-e7f040638733", "label": "摘要678", "info": "Lukoševičius，M.；computing；approaches  to  recurrent  neural  network  training.  Computer  Science  Review", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "63e36dbc-2b18-47fa-99a1-1e7d9b3f41f4", "label": "摘要679", "info": "Jaeger，H.（2009）.  Reservoir", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed257d73-1af9-4a49-804f-43379db812b8", "label": "摘要680", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f53114ca-7c26-4313-8d36-645bbf5e17cd", "label": "摘要681", "info": "Luo，H.，Shen，R.，Niu，C.，and Ullrich，C.（2011）. Learning class-；relevant features and class-irrelevant features via a hybrid third-order RBM.；In International  Conference on Artificial Intelligence and Statistics ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "326abab5-1eef-4603-b005-7fa240c7fc8f", "label": "摘要682", "info": "Luo，H.，Carrier，P.  L.，Courville，A.，and  Bengio，Y.（2013）.；Texture  modeling  with  convolutional  spike-and-slab  RBMs  and  deep；extensions. In AISTATS'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "da397531-f513-4d11-b82c-104abb5f9884", "label": "摘要683", "info": "Lyu，S.（2009）.  Interpretation  and  generalization  of  score  matching.  In；Proceedings  of  the  Twenty-fifth  Conference  in  Uncertainty  in  Artificial；Intelligence（UAI'09） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9d912eb-ddc4-41eb-ac07-4310229f6db7", "label": "摘要684", "info": "Ma，J.，Sheridan，R.  P.，Liaw，A.，Dahl，G.  E.，and  Svetnik，V.；（2015）.  Deep  neural  nets  as  a  method  for  quantitative  structure–activity；relationships. J. Chemical information and modeling .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abafd816-2899-47fe-b2ed-5636699400c2", "label": "摘要685", "info": "Maas，A.  L.，Hannun，A.  Y.，and  Ng，A.  Y.（2013）.  Rectifier；nonlinearities  improve  neural  network  acoustic  models.  In  ICML  Workshop；on Deep Learning for Audio，Speech，and Language Processing .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1e8dea8-32ce-4533-a80f-292be8d756fd", "label": "摘要686", "info": "Maass，W.（1992）.  Bounds  for  the  computational  power  and  learning；complexity of analog neural nets（extended abstract）. In Proc. of the 25th；ACM Symp. Theory of Computing ，pages 335–344.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90385686-c707-4245-b028-808f7b727cc1", "label": "摘要687", "info": "Maass，W.，Schnitger，G.，and  Sontag，E.  D.（1994）.  A  comparison", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f06bc8ff-00e3-45e9-a778-28f72884cd84", "label": "摘要688", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；of  the  computational  power  of  sigmoid  and  Boolean  threshold  circuits.；Theoretical  Advances  in  Neural  Computation  and  Learning  ，pages  127–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edc610aa-a851-4fda-8fb5-eef95c1faebd", "label": "摘要689", "info": "Maass，W.，Natschlaeger，T.，and  Markram，H.（2002）.  Real-time；computing  without  stable  states:  A  new  framework  for  neural  computation；based on perturbations. Neural Computation ，14 （11），2531–2560.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9c3eb56-fa15-4d62-9b33-1f3c2798a06f", "label": "摘要690", "info": "MacKay，D.（2003）.；Algorithms . Cambridge University Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f14a11b-150c-4f7b-af3e-d21d923e0d68", "label": "摘要691", "info": "Information  Theory，Inference  and  Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ccf637c-69a4-47a5-a5fc-d0e72dcb62d0", "label": "摘要692", "info": "Maclaurin，D.，Duvenaud，D.，and  Adams，R.  P.（2015）.  Gradient-；based  hyperparameter  optimization  through  reversible  learning.  arXiv；preprint arXiv:1502.03492 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "93573b7c-5fca-4dd7-a398-2f9543ad060d", "label": "摘要693", "info": "Mao，J.，Xu，W.，Yang，Y.，Wang，J.，and；Yuille，A.（2014）.；Deep  captioning  with  multimodal  recurrent  neural  networks（m-rnn）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "02df418f-2490-4d13-b52d-99a2879e0b3e", "label": "摘要694", "info": "Marcotte，P.  and  Savard，G.（1992）.  Novel  approaches；the；discrimination problem. Zeitschrift für Operations Research（Theory） ，36", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f21b44d-6431-4ee7-8beb-723d0d31f749", "label": "摘要695", "info": "to", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8bffce91-6bfd-4d15-9d3d-3af9f9a9316e", "label": "摘要696", "info": "Marlin，B.  and  de  Freitas，N.（2011）.  Asymptotic  efficiency  of；deterministic  estimators  for  discrete  energy-based  models:  Ratio  matching；and pseudolikelihood. In UAI'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1dd596e6-c150-4f53-b988-f06ddf44736e", "label": "摘要697", "info": "Marlin，B.，Swersky，K.，Chen，B.，and；Inductive  principles；AISTATS'2010 ，pages 509–516.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a73ad598-9b34-45f0-a40c-e8742730f1f4", "label": "摘要698", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d572d80-83cc-41e2-aa65-649cd1a933df", "label": "摘要699", "info": "restricted  Boltzmann  machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee432024-f60c-4d3e-9f5b-e9e9ef2b0921", "label": "摘要700", "info": "de", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec2cbfc0-dced-4d2b-a117-455a2e1f2ac5", "label": "摘要701", "info": "Freitas，N.（2010）.；In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "60c7dadc-6534-4d3d-ad7f-c025540f6c35", "label": "摘要702", "info": "learning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57e63622-df50-479e-935b-da77ac48cf74", "label": "摘要703", "info": "Marquardt，D.  W.（1963）.  An  algorithm  for  least-squares  estimation  of；non-linear  parameters.  Journal  of  the  Society  of  Industrial  and  Applied；Mathematics ，11 （2），431–441.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e1f9363-925e-4d2c-ab15-b6fe8cbe49fa", "label": "摘要704", "info": "Marr，D.  and  Poggio，T.（1976）.  Cooperative  computation  of  stereo；disparity. Science ，194 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2d229e2-7cd9-415d-a8bb-86ae5e83556b", "label": "摘要705", "info": "Martens，J.（2010）.  Deep  learning  via  Hessian-free  optimization.  In；ICML'2010 ，pages 735–742.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bff7ba6e-74f2-4895-82c0-b22576d7a178", "label": "摘要706", "info": "Martens，J. and Medabalimi，V.（2014）. On the expressive efficiency of；sum product networks. arXiv:1411.7717 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9b285a0f-22dc-4801-a6ac-f117418f57a4", "label": "摘要707", "info": "Martens，J. and Sutskever，I.（2011）. Learning recurrent neural networks；with Hessian-free optimization. In Proc. ICML'2011 . ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "918d4a6b-5011-4129-9a75-c874868b5e00", "label": "摘要708", "info": "Mase，S.（1995）.  Consistency  of；the  maximum  pseudo-likelihood；estimator  of  continuous  state  space  Gibbsian  processes.  The  Annals  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a07a240-45c6-4b61-903d-63f51935ea85", "label": "摘要709", "info": "McClelland，J.，Rumelhart，D.，and Hinton，G.（1995）. The appeal of；parallel distributed processing. In Computation & intelligence ，pages  305–；341. American Association for Artificial Intelligence.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "411af478-c0f6-48bf-902a-c43f3774a719", "label": "摘要710", "info": "McCulloch，W.  S.  and  Pitts，W.（1943）.  A  logical  calculus  of  ideas；immanent  in  nervous  activity.  Bulletin  of  Mathematical  Biophysics  ，5  ，；115–133.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9977399c-3a2c-4135-92e3-c960ac551974", "label": "摘要711", "info": "Mead，C. and Ismail，M.（2012）. Analog VLSI implementation of neural；systems ，volume 80. Springer Science & Business Media.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7234caa3-fc14-4961-bf11-e0ae2d005e1a", "label": "摘要712", "info": "Melchior，J.，Fischer，A.，and  Wiskott，L.（2013）.  How  to  center；binary deep Boltzmann machines. arXiv preprint arXiv:1311.1354 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3fcd05a2-95ee-4bdc-a1a4-4e0f3a25d8b2", "label": "摘要713", "info": "Memisevic，R.  and  Hinton，G.  E.（2007）.  Unsupervised  learning  of；image  transformations.  In  Proceedings  of  the  Computer  Vision  and  Pattern；Recognition Conference（CVPR'07） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d4eee254-f2b7-48ce-a56b-fd274a7c5ef2", "label": "摘要714", "info": "Memisevic，R.  and  Hinton，G.  E.（2010）.  Learning  to  represent  spatial；transformations  with  factored  higher-order  Boltzmann  machines.  Neural；Computation ，22 （6），1473–1492.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f8e32710-da28-4d80-bbad-f5c4a7d592e9", "label": "摘要715", "info": "Mesnil，G.，Dauphin，Y.，Glorot，X.，Rifai，S.，Bengio，Y.，；Goodfellow，I.，Lavoie，E.，Muller，X.，Desjardins，G.，Warde-", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39573a3c-87f9-4adc-9808-d3609dc219ce", "label": "摘要716", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bergstra，J.（2011）.；Farley，D.，Vincent，P.，Courville，A.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55adf4f4-a171-401a-a8bf-3f6b2be00418", "label": "摘要717", "info": "Mesnil，G.，Rifai，S.，Dauphin，Y.，Bengio，Y.，and；（2012）. Surfing on the manifold. Learning Workshop，Snowbird.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a97985bb-55c0-458f-8b3b-744bb97a80ff", "label": "摘要718", "info": "Vincent，P.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e15d33e6-b999-4ff1-a6a2-dbf7698266a2", "label": "摘要719", "info": "Miikkulainen，R.  and  Dyer，M.  G.（1991）.  Natural  language  processing；with modular PDP networks and distributed lexicon. Cognitive Science ，15；，343–399.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a467b3d0-11b1-480f-b351-f207b87270f0", "label": "摘要720", "info": "Mikolov，T.（2012）.  Statistical  Language  Models  based  on  Neural；Networks . Ph.D. thesis，Brno University of Technology.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9284a414-cb91-49f9-b84d-e2a365b3595a", "label": "摘要721", "info": "Mikolov，T.，Deoras，A.，Kombrink，S.，Burget，L.，and Cernocky，；J.（2011a）.  Empirical  evaluation  and  combination  of  advanced  language；modeling  techniques.  In  Proc.  12th  annual  conference  of  the  international", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee4aae85-848d-4a58-94d0-230b7f8114bd", "label": "摘要722", "info": "Mikolov，T.，Deoras，A.，Povey，D.，Burget，L.，and  Cernocky，J.；（2011b）.  Strategies  for  training  large  scale  neural  network  language；models. In Proc. ASRU'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3249a29a-99d6-4c8e-9148-cfc4ca132fa4", "label": "摘要723", "info": "Dean，J.（2013a）.；Mikolov，T.，Chen，K.，Corrado，G.，and；Efficient estimation of word representations in vector space. In International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8ab14c53-3712-4d0f-9306-00a43c6a7df7", "label": "摘要724", "info": "Mikolov，T.，Le，Q.  V.，and  Sutskever，I.（2013b）.  Exploiting；similarities  among  languages  for  machine  translation.  Technical  report，；arXiv:1309.4168.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bd1da4a-29f2-4f8c-9c59-af6f49d6e336", "label": "摘要725", "info": "Minka，T.（2005）.  Divergence  measures  and  message  passing.  Microsoft；Research Cambridge UK Tech Rep MSRTR2005173 ，72 （TR-2005-173）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "894a9644-6d67-4937-9f5c-6fd3e4a2c019", "label": "摘要726", "info": "Minsky，M.  L.  and  Papert，S.  A.（1969）.  Perceptrons  .  MIT  Press，；Cambridge.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b30dabe-7988-48e0-84b3-f5933ad670a8", "label": "摘要727", "info": "Mirza，M.  and  Osindero，S.（2014）.  Conditional  generative  adversarial；nets. arXiv preprint arXiv:1411.1784 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1fe119f1-7be8-4ebe-b803-deb716c6797e", "label": "摘要728", "info": "Mishkin，D.  and  Matas，J.（2015）.  All  you  need  is  a  good  init.  arXiv；preprint arXiv:1511.06422 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a5468038-d531-438a-a0d8-219b76ed046b", "label": "摘要729", "info": "Misra，J. and Saha，I.（2010）. Artificial neural networks in hardware: A；survey of two decades of progress. Neurocomputing ，74 （1），239–255.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a9ba6ee-9ec3-4fa5-9cad-3c1846656f50", "label": "摘要730", "info": "Mitchell，T. M.（1997）. Machine Learning . McGraw-Hill，New York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "58d45b86-ff5b-45ef-9f9a-1a884fdd5474", "label": "摘要731", "info": "Ishii，S.；Miyato，T.，Maeda，S.，Koyama，M.，Nakae，K.，and；（2015）. Distributional smoothing with virtual adversarial training. In ICLR", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c148e9d3-bddc-433c-888d-9b010e3ca5d1", "label": "摘要732", "info": "Mnih，A.  and  Gregor，K.（2014）.  Neural  variational  inference  and；learning in belief networks. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac03baa0-75e0-4858-990e-e242ccad7fe5", "label": "摘要733", "info": "Mnih，A.  and  Hinton，G.  E.（2007）.  Three  new  graphical  models  for；statistical  language  mod-elling.  In  Z.  Ghahramani，editor，Proceedings  of；Machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1afc13aa-10f2-4699-9f5b-f9b2db587557", "label": "摘要734", "info": "Twenty-fourth", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ba53266c-40c2-4823-80b6-172161c4689d", "label": "摘要735", "info": "International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b7a556d7-a90f-4d60-805e-6b90ab455063", "label": "摘要736", "info": "Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb8c7ccc-cba7-497e-9b5d-fd88f61ac523", "label": "摘要737", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb2f3764-5893-4095-8bb9-5c732adc64f9", "label": "摘要738", "info": "Mnih，A.  and  Hinton，G.  E.（2009）.  A  scalable  hierarchical  distributed；language  model.  In  D.  Koller，D.  Schuurmans，Y.  Bengio，and  L.；Bottou，editors，Advances  in  Neural  Information  Processing  Systems", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc11afca-1ba0-44d5-8983-7bb45d7a6172", "label": "摘要739", "info": "Mnih，A.  and  Kavukcuoglu，K.（2013）.  Learning  word  embeddings；efficiently  with  noise-contrastive  estimation.  In  C.  Burges，L.  Bottou，M.；Welling，Z.  Ghahramani，and  K.  Weinberger，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f3011899-308d-46db-8e61-11954bc686b6", "label": "摘要740", "info": "Mnih，A.  and  Teh，Y.  W.（2012）.  A  fast  and  simple  algorithm  for；training neural probabilistic language models. In ICML'2012 ，pages  1751–；1758.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d4a17ca-5688-4557-bffc-fc289347eb8e", "label": "摘要741", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Mnih，V.  and  Hinton，G.（2010）.  Learning  to  detect  roads  in  high-；resolution aerial images. In Proceedings of the 11th European Conference on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55814098-8d36-489c-8075-75f8c99bc417", "label": "摘要742", "info": "Mnih，V.，Larochelle，H.，and；Conditional；restricted Boltzmann machines for structure output prediction. In Proc. Conf.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e38c3e9b-364f-4f4b-b2b8-0f82277bdc0c", "label": "摘要743", "info": "Hinton，G.（2011）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3cac73ef-0f06-458c-ab73-85649142114b", "label": "摘要744", "info": "Mnih，V.，Kavukcuoglo，K.，Silver，D.，Graves，A.，Antonoglou，；I.，and  Wierstra，D.（2013）.  Playing  Atari  with  deep  reinforcement；learning. Technical report，arXiv:1312.5602.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb2b148a-348f-44a0-8fcc-1bb643402aa8", "label": "摘要745", "info": "Mnih，V.，Heess，N.，Graves，A.，and；Kavukcuoglu，K.（2014）.；Recurrent  models  of  visual  attention.  In  Z.  Ghahramani，M.  Welling，C.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5466001a-436f-43c8-bfc2-ce90f5f23ca7", "label": "摘要746", "info": "Mnih，V.，Kavukcuoglo，K.，Silver，D.，Rusu，A.  A.，Veness，J.，；Bellemare，M.  G.，Graves，A.，Riedmiller，M.，Fidgeland，A.  K.，；Ostrovski，G.，Petersen，S.，Beattie，C.，Sadik，A.，Antonoglou，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f2a97b3-7a4b-4b9c-9950-8b3c7bcf1555", "label": "摘要747", "info": "Mobahi，H.  and  Fisher，III，J.  W.（2015）.  A  theoretical  analysis  of；optimization by Gaussian continuation. In AAAI'2015 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7cad9256-eda3-4ac3-9026-c162ea43bee5", "label": "摘要748", "info": "Mobahi，H.，Collobert，R.，and  Weston，J.（2009）.  Deep；learning；from  temporal  coherence  in  video.  In  L.  Bottou  and  M.  Littman，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6512396e-7d52-4827-b130-defc84af4b41", "label": "摘要749", "info": "Mohamed，A.，Dahl，G.，and  Hinton，G.（2009）.  Deep；networks for phone recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2da64a3c-3476-485e-b18d-17d5b57ef5e5", "label": "摘要750", "info": "belief", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e6501641-c6d0-4c47-b7ad-48e658781e64", "label": "摘要751", "info": "Mohamed，A.，Sainath，T.；N.，Dahl，G.，Ramabhadran，B.，；Hinton，G. E.，and Picheny，M. A.（2011）. Deep belief networks using", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb90ced6-88ab-45ee-9ae8-7cb12efd54b5", "label": "摘要752", "info": "discriminative  features  for  phone  recognition.  In  Acoustics，Speech  and；Signal Processing（ICASSP），2011 IEEE International Conference on ，；pages 5060–5063. IEEE.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "818e69c0-2f35-41e9-8421-9ef5566e3586", "label": "摘要753", "info": "Mohamed，A.，Dahl，G.，and Hinton，G.（2012a）. Acoustic modeling；using  deep  belief  networks.  IEEE  Trans.  on  Audio，Speech  and  Language；Processing ，20 （1），14–22.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d8933c7-427c-401e-8338-0389fa20e110", "label": "摘要754", "info": "Mohamed，A.，Hinton，G.，and  Penn，G.（2012b）.  Understanding；how deep belief networks perform acoustic modelling. In Acoustics，Speech；and  Signal  Processing（ICASSP），2012  IEEE  International  Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a774ae1-b8c2-4297-bdda-25ff404a9b06", "label": "摘要755", "info": "Moller，M.（1993）. Efficient Training of Feed-Forward Neural Networks；. Ph.D. thesis，Aarhus University，Aarhus，Denmark.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "217d7be9-3c44-4939-91ef-75bd5021710d", "label": "摘要756", "info": "Montavon，G. and Muller，K.-R.（2012）. Deep Boltzmann machines and；the centering trick. In G. Montavon，G. Orr，and K.-R. Müller，editors，；Neural  Networks:  Tricks  of  the  Trade，volume  7700  of  Lecture  Notes  in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6c28aefe-efc5-44e3-9469-bf2ea308d6e9", "label": "摘要757", "info": "621–637.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3bfc3bc3-540c-483f-b0c1-9cefacf6d343", "label": "摘要758", "info": "Science", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f70c9201-6b2a-4053-a7b1-87cdcb8a5f86", "label": "摘要759", "info": "Montúfar，G.（2014）. Universal approximation depth and errors of narrow；belief networks with discrete units. Neural Computation ，26 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bba41b09-bdca-456e-ba48-bd43a4ecd65a", "label": "摘要760", "info": "Montúfar，G.；and  Ay，N.（2011）.  Refinements；universal", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9697e4c0-0e37-4ff8-91a1-0ab3059f241a", "label": "摘要761", "info": "of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a32676a-0293-4ef1-8cc1-89ceedcf2e7c", "label": "摘要762", "info": "Montufar，G. F.，Pascanu，R.，Cho，K.，and Bengio，Y.（2014）. On；the number of linear regions of deep neural networks. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "309a03dd-5ff5-44b1-a697-4902f8c6d124", "label": "摘要763", "info": "Mor-Yosef，S.，Samueloff，A.，Modan，B.，Navot，D.，and；Schenker，J.  G.（1990）.  Ranking  the  risk  factors  for  cesarean:  logistic；regression analysis of a nationwide study. Obstet Gynecol ，75 （6），944–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb298215-2079-45e9-ba4f-a00a2da50771", "label": "摘要764", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Morin，F.  and  Bengio，Y.（2005）.  Hierarchical  probabilistic  neural；network language model. In AISTATS'2005 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "94234d07-11c4-44b1-a00b-436c5f05ec41", "label": "摘要765", "info": "Mozer，M.  C.（1992）.  The  induction  of  multiscale  temporal  structure.  In；J.  M.  S.  Hanson  and  R.  Lippmann，editors，Advances；in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "00df4187-c98d-42e9-87ce-28f5a5ebc5f9", "label": "摘要766", "info": "Murphy，K.  P.（2012）.  Machine  Learning:  a  Probabilistic  Perspective  .；MIT Press，Cambridge，MA，USA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f2eb256-a8a5-477b-9824-2f1ed53ed5ff", "label": "摘要767", "info": "Murray，B. U. I. and Larochelle，H.（2014）. A deep and tractable density；estimator. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59691d62-182e-4b81-ad5e-279f41605a6a", "label": "摘要768", "info": "Nair，V.  and  Hinton，G.（2010a）.  Rectified；restricted Boltzmann machines. In ICML'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "16ac96d8-5e09-4cd1-b0b9-0dc6125b1a0a", "label": "摘要769", "info": "linear  units", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "64af77f2-7c2c-46b2-a012-63d0047e0166", "label": "摘要770", "info": "improve", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8d86525a-bf27-4409-9ae0-7ba838e4b170", "label": "摘要771", "info": "Nair，V.  and  Hinton，G.  E.（2009）.  3d  object  recognition  with  deep；belief  nets.  In  Y.  Bengio，D.  Schuurmans，J.  D.  Lafferty，C.  K.  I.；Williams，and  A.  Culotta，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a2ff8a23-b3bc-45d4-928f-c8d152679580", "label": "摘要772", "info": "Nair，V.  and  Hinton，G.  E.（2010b）.  Rectified  linear  units  improve；restricted  Boltzmann  machines.  In  L.  Bottou  and  M.  Littman，editors，；Proceedings  of  the  Twenty-seventh  International  Conference  on  Machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "58b62cc1-508e-4dd4-a16b-f50b13d92892", "label": "摘要773", "info": "Narayanan，H.  and  Mitter，S.（2010）.  Sample  complexity  of  testing  the；manifold  hypothesis.  In  J.  Lafferty，C.  K.  I.  Williams，J.  Shawe-Taylor，；R.  Zemel，and  A.  Culotta，editors，Advances  in  Neural  Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e502b22-f141-4ceb-8d12-265c057258aa", "label": "摘要774", "info": "Naumann，U.（2008）.  Optimal  Jacobian  accumulation  is  NP-complete.；Mathematical Programming ，112 （2），427–441.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e6bd3a0-c0a1-48c8-9e20-a1faa8479e5a", "label": "摘要775", "info": "Navigli，R. and Velardi，P.（2005）. Structural semantic interconnections:；a  knowledge-based  approach  to  word  sense  disambiguation.  IEEE  Trans.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4c68832-b9e7-465f-9a47-f1e44a2195f5", "label": "摘要776", "info": "Pattern Analysis and Machine Intelligence ，27 （7），1075–1086.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f789b26d-8a5e-4a21-98b6-b693e9051b41", "label": "摘要777", "info": "Neal，R.  and  Hinton，G.（1999）.  A  view  of  the  EM  algorithm  that；incremental，sparse，and  other  variants.  In  M.  I.  Jordan，；justifies", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5fce4cb4-80f5-4042-b846-2049f2af0160", "label": "摘要778", "info": "Neal，R. M.（1990）. Learning stochastic feedforward networks. Technical；report.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a0bfe36b-05b3-4114-934c-0b7d469b6eee", "label": "摘要779", "info": "Neal，R.  M.（1993）.  Probabilistic  inference  using  Markov  chain  Monte-；Carlo  methods.  Technical  Report  CRG-TR-93-1，Dept.  of  Computer；Science，University of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d5c82bd-e9d2-4534-adba-eb934f9032d2", "label": "摘要780", "info": "Neal，R.  M.（1994）.  Sampling  from  multimodal  distributions  using；tempered transitions. Technical Report 9421，Dept. of Statistics，University；of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "45c05fd4-99d8-4238-b2b6-fb8408071b85", "label": "摘要781", "info": "Neal，R.  M.（1996）.  Bayesian  Learning  for  Neural  Networks  .  Lecture；Notes in Statistics. Springer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0fb51779-8559-4d0a-9129-2f61866b1d78", "label": "摘要782", "info": "Neal，R.  M.（2001）.  Annealed  importance  sampling.  Statistics  and；Computing ，11 （2），125–139.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0f038b17-36e2-41dd-b622-106e19ca8b7b", "label": "摘要783", "info": "Neal，R.  M.（2005）.  Estimating  ratios  of  normalizing  constants  using；linked importance sampling.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "31350b89-3abf-4cd8-b02e-6c29d4f1ee17", "label": "摘要784", "info": "Nesterov，Y.（1983）.  A  method  of  solving  a  convex  programming；problem  with  convergence  rate  O（1/k  2  ）.  Soviet  Mathematics  Doklady；，27 ，372–376.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2909f2e3-cc31-40c5-bbee-18afd79ba968", "label": "摘要785", "info": "Nesterov，Y.（2004）.  Introductory  lectures  on  convex  optimization:  a；basic  course  .  Applied  optimization.  Kluwer  Academic  Publ.，Boston，；Dordrecht，London.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "56860e80-bd10-441b-ad23-5637f4e6b22b", "label": "摘要786", "info": "Netzer，Y.，Wang，T.，Coates，A.，Bissacco，A.，Wu，B.，and；Ng，A.  Y.（2011）.  Reading  digits  in  natural  images  with  unsupervised；feature  learning.  Deep  Learning  and  Unsupervised  Feature  Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d53a4559-08ee-4a3d-a186-da07bb95d73e", "label": "摘要787", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Workshop，NIPS.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dbeb9d3a-9330-4477-858d-c6173b227578", "label": "摘要788", "info": "Ney，H.  and  Kneser，R.（1993）.  Improved  clustering  techniques  for；class-based  statistical  language  modelling.  In  European  Conference  on；Speech Communication and Technology（Eurospeech） ，pages 973–976，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8485945e-f111-4aba-844c-72fd767bfbe1", "label": "摘要789", "info": "Ng，A.（2015）.；https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e64514c-4ecd-481d-9091-76580e7e0fb7", "label": "摘要790", "info": "applying", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b4eae1d-0724-4b55-90ac-ce0e3c894ac7", "label": "摘要791", "info": "Advice", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "74d30897-90ac-4d5f-b84f-24c12eb0673e", "label": "摘要792", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66fd37ad-d9e2-49f4-938f-071f78545012", "label": "摘要793", "info": "machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8bf412c2-7b57-499e-8e57-affaf21412aa", "label": "摘要794", "info": "learning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9fb1d25-962d-40fe-b706-76c5f60a9bcf", "label": "摘要795", "info": "Niesler，T.  R.，Whittaker，E.  W.  D.，and  Woodland，P.  C.（1998）.；Comparison  of  part-of-speech  and  automatically  derived  category-based；language  models  for  speech  recognition.  In  International  Conference  on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dfc940f4-f2f9-40db-b25d-29d26dd5b776", "label": "摘要796", "info": "Ning，F.，Delhomme，D.，LeCun，Y.，Piano，F.，Bottou，L.，and；Barbano，P.  E.（2005）.  To-ward  automatic  phenotyping  of  developing；embryos  from  videos.  Image  Processing，IEEE  Transactions  on  ，14", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3999502e-0527-4354-99fd-652df97ef215", "label": "摘要797", "info": "Nocedal，J. and Wright，S.（2006）. Numerical Optimization . Springer.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5238f8a8-826e-4170-9743-3efe32dedb4a", "label": "摘要798", "info": "Norouzi，M. and Fleet，D.  J.（2011）. Minimal loss hashing for compact；binary codes. In ICML'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "62de9671-f6bb-4551-8eb3-c8df073d0f13", "label": "摘要799", "info": "Nowlan，S.  J.（1990）.  Competing experts: An experimental investigation；of associative mixture models. Technical Report CRG-TR-90-5，University；of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "defc4f85-7e1d-4426-a5f5-190c2f811cd9", "label": "摘要800", "info": "Nowlan，S.  J.  and  Hinton，G.  E.（1992）.  Adaptive  soft  weight  tying；using  Gaussian  mixtures.  In  J.  M.  S.  Hanson  and  R.  Lippmann，editors，；Advances in Neural Information Processing Systems 4（NIPS'91） ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "29bcd34b-55b1-4808-9138-2d20cdaa8301", "label": "摘要801", "info": "Olshausen，B.  and  Field，D.  J.（2005）.  How  close  are  we；understanding V1? Neural Computation ，17 ，1665–1699.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "73a15000-efdf-4431-8022-34701469bbce", "label": "摘要802", "info": "to", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2e3f117-492f-48cc-9460-458d2ab006ba", "label": "摘要803", "info": "Olshausen，B.  A.  and  Field，D.  J.（1996）.  Emergence  of  simple-cell；receptivefield properties by learning a sparse code for natural images. Nature；，381 ，607–609.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "346af852-2f13-4eda-98f0-e1c6a2a52e56", "label": "摘要804", "info": "Olshausen，B. A.，Anderson，C. H.，and Van Essen，D. C.（1993）. A；neurobiological  model  of  visual  attention  and  invariant  pattern  recognition；based on dynamic routing of information. J. Neurosci. ，13 （11），4700–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b91e72ab-f4da-4ed8-84c6-38f4419aa49a", "label": "摘要805", "info": "Opper，M.  and  Archambeau，C.（2009）.  The  variational  Gaussian；approximation revisited. Neural computation ，21 （3），786–792.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b870af44-00f3-4cd1-a4e3-09b0d11deb92", "label": "摘要806", "info": "Oquab，M.，Bottou，L.，Laptev，I.，and  Sivic，J.（2014）.  Learning；and  transferring  mid-level  image  representations  using  convolutional  neural；networks.  In  Computer  Vision  and  Pattern  Recognition（CVPR），2014", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aadaa803-499a-4ef4-8fda-ca7a109e6b7f", "label": "摘要807", "info": "Osindero，S.  and  Hinton，G.  E.（2008）.  Modeling  image  patches  with  a；directed  hierarchy  of  Markov  randomfields.  In  J.  Platt，D.  Koller，Y.；Singer，and  S.  Roweis，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "34524b52-1b2a-4120-9f56-1529632938c2", "label": "摘要808", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf2e3c6b-9da9-45d1-839b-f00b4cabbd0d", "label": "摘要809", "info": "Ovid and Martin，C.（2004）. Metamorphoses . W.W. Norton.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d9b02f1c-1be3-4641-9714-2ea65ba13379", "label": "摘要810", "info": "Paccanaro，A.  and  Hinton，G.  E.（2000）.  Extracting  distributed；representations  of  concepts  and  relations  from  positive  and  negative；propositions.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c5b45cce-f60c-40cd-b5a0-1a3b24e4c2e9", "label": "摘要811", "info": "Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5e49b93-4867-48c6-818a-7f0f50c1f4d8", "label": "摘要812", "info": "Joint", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7106685-669b-4fb3-8a43-7e4b367ab9d5", "label": "摘要813", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2470617-95ea-4caf-afdf-867622ce12ee", "label": "摘要814", "info": "In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "599f83a1-c2f0-4528-b591-f67fa3eb2c04", "label": "摘要815", "info": "Paine，T.  L.，Khorrami，P.，Han，W.，and  Huang，T.  S.（2014）.  An；analysis  of  unsupervised  pre-training  in  light  of  recent  advances.  arXiv；preprint arXiv:1412.6597 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aab81041-bba1-4b69-ade8-41407d70dade", "label": "摘要816", "info": "Palatucci，M.，Pomerleau，D.，Hinton，G.  E.，and  Mitchell，T.  M.；（2009）. Zero-shot learning with semantic output codes. In Y. Bengio，D.；Schuurmans，J.  D.  Lafferty，C.  K.  I.  Williams，and  A.  Culotta，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "03beac6b-e379-4f51-8f6b-f70f88b9d579", "label": "摘要817", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；editors，Advances  in  Neural  Information  Processing  Systems  22  ，pages；1410–1418. Curran Associates，Inc.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b105d8e-8337-4043-a363-ba371ef5c405", "label": "摘要818", "info": "Parker，D.  B.（1985）.  Learning-logic.  Technical  Report  TR-47，Center；for Comp. Research in Economics and Management Sci.，MIT.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "323eafb4-63df-4416-a341-262a12b22652", "label": "摘要819", "info": "Pascanu，R.，Mikolov，T.，and  Bengio，Y.（2013a）.  On  the  difficulty；of training recurrent neural networks. In ICML'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "abc32962-a382-496b-b31c-b06b30b51044", "label": "摘要820", "info": "Pascanu，R.，Mikolov，T.，and  Bengio，Y.（2013b）.  On  the  difficulty；of training recurrent neural networks. In ICM（1c）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9a7d791-729a-416d-bcfd-e8c4f021fe44", "label": "摘要821", "info": "Pascanu，R.，Gulcehre，C.，Cho，K.，and  Bengio，Y.（2014a）.  How；to construct deep recurrent neural networks. In ICLR .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "131ad22d-2b36-477b-bfa7-39b35e1b257f", "label": "摘要822", "info": "Pascanu，R.，Montufar，G.，and  Bengio，Y.（2014b）.  On  the  number；of  inference  regions  of  deep  feed  forward  networks  with  piece-wise  linear；activations. In ICL（1）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f9d5afca-7503-4b92-a316-8486921d3376", "label": "摘要823", "info": "Pati，Y.，Rezaiifar，R.，and  Krishnaprasad，P.（1993）.  Orthogonal；matching  pursuit:Recursive  function  approximation  with  applications  to；wavelet  decomposition.  In  Proceedings  of  the  27  th  Annual  Asilomar", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88ae028b-ddf9-46ae-bb33-dd1ddd217135", "label": "摘要824", "info": "Pearl，J.（1985）.  Bayesian  networks:  A  model  of  self-activated  memory；for  evidential  reasoning.  In  Proceedings  of  the  7th  Conference  of  the；Cognitive  Science  Society，University  of  California，Irvine  ，pages  329–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec8bc53d-933b-42e4-ae43-fbb3569d95f1", "label": "摘要825", "info": "Pearl，J.（1988）. Probabilistic Reasoning in Intelligent Systems: Networks；of Plausible Inference . Morgan Kaufmann.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a923cbf7-13ba-4297-98ad-3f59f16171e3", "label": "摘要826", "info": "Perron，O.（1907）.  Zur  theorie  der  matrices.  Mathematische  Annalen；，64 （2），248–263.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7f6e18c-f5cb-4e3b-83af-1349ee71de00", "label": "摘要827", "info": "Petersen，K.  B.  and  Pedersen，M.  S.（2006）.  The  matrix  cookbook.；Version 20051003.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f53e56a-8bf0-4a44-b4a0-809a3312a7c0", "label": "摘要828", "info": "Peterson，G.  B.（2004）.  A  day  of  great  illumination:  B.  F.  Skinner's；discovery of shaping. Journal of the Experimental Analysis of Behavior ，82；（3），317–328.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a636acca-a09f-4009-87bc-16f90220ed1d", "label": "摘要829", "info": "Pham，D.-T.，Garat，P.，and；Jutten，C.（1992）.  Separation  of  a；mixture of independent sources through a maximum likelihood approach. In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "93b710c8-3308-4263-83f2-244ba467e193", "label": "摘要830", "info": "Pham，P.-H.，Jelaca，D.，Farabet，C.，Martini，B.，LeCun，Y.，and；Culurciello，E.（2012）. Neu-Flow: dataflow vision processing system-on-；a-chip.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbb39d30-cbba-498b-a735-36478f084d9f", "label": "摘要831", "info": "In  Circuits  and  Systems（MWSCAS），2012", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efde423d-6cce-4ab8-a514-4384684be129", "label": "摘要832", "info": "Pinheiro，P.  H.  O.  and  Collobert，R.（2014）.  Recurrent  convolutional；neural networks for scene labeling. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a885a47f-b5db-4e54-8461-a9b37245e338", "label": "摘要833", "info": "Pinheiro，P. H. O. and Collobert，R.（2015）. From image-level to pixel-；level  labeling  with  con-volutional  networks.  In  Conference  on  Computer；Vision and Pattern Recognition（CVPR） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7dfb5220-1adf-4b95-98a9-9a7516d81fa9", "label": "摘要834", "info": "Pinto，N.，Cox，D.  D.，and  DiCarlo，J.  J.（2008）.  Why  is  real-world；visual object recognition hard? PLoS Comput Biol ，4 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "51456cf2-3985-48e5-b175-93ce37f137a8", "label": "摘要835", "info": "Pinto，N.，Stone，Z.，Zickler，T.，and  Cox，D.（2011）.  Scaling  up；biologically-inspired  computer  vision:  A  case  study  in  unconstrained  face；recognition  on  facebook.  In  Computer  Vision  and  Pattern  Recognition", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c455a286-0940-49d0-9f88-393142ff09aa", "label": "摘要836", "info": "Pollack，J.  B.（1990）.  Recursive  distributed  representations.  Artificial；Intelligence ，46 （1），77–105.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb0a05e6-5b24-41c6-9ad2-1f28ae35034a", "label": "摘要837", "info": "Polyak，B.  and；stochastic；approximation  by  averaging.  SIAM  J.  Control  and  Optimization  ，30", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1186283d-3017-41dd-924b-cfb055373ffc", "label": "摘要838", "info": "Juditsky，A.（1992）.  Acceleration  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "212082e1-4826-448a-9063-e3fec9c88c23", "label": "摘要839", "info": "Polyak，B.  T.（1964）.  Some  methods  of  speeding  up  the  convergence  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e0fe7bcf-4000-4ef4-af89-071351f9d492", "label": "摘要840", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；iteration  methods.  USSR  Computational  Mathematics  and  Mathematical；Physics ，4 （5），1–17.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7ed810ab-fe27-451b-8755-7f1595821aaa", "label": "摘要841", "info": "Poole，B.，Sohl-Dickstein，J.，and  Ganguli，S.（2014）.  Analyzing；noise in autoencoders and deep networks. CoRR ，abs/1406.1831 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f96774f1-ac07-4cda-a625-2a4b6a1d7634", "label": "摘要842", "info": "Poon，H.  and  Domingos，P.（2011）.  Sum-product  networks  for  deep；learning. In Learning Workshop ，Fort Lauderdale，FL.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5953b6df-153b-4e7f-a5a2-beec5b991ec2", "label": "摘要843", "info": "Presley，R. K. and Haggard，R. L.（1994）. Afixed point implementation；of  the  backpropaga-tion  learning  algorithm.  In  Southeastcon  '94.  Creative；Technology  Transfer-A  Global  Affair.，Proceedings  of  the  1994  IEEE  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f9b4f87-c2bc-479f-b282-f4550b8192d1", "label": "摘要844", "info": "Price，R.（1958）. A useful theorem for nonlinear devices having Gaussian；inputs. IEEE Transactions on Information Theory ，4 （2），69–72.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5e916ae-aca0-43bb-9952-c043deafa7f3", "label": "摘要845", "info": "Quiroga，R.  Q.，Reddy，L.，Kreiman，G.，Koch，C.，and  Fried，I.；（2005）.  Invariant  visual  representation  by  single  neurons  in  the  human；brain. Nature ，435 （7045），1102–1107.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "19e1a56a-90c9-49e0-a70d-2e306bbb1e19", "label": "摘要846", "info": "Radford，A.，Metz，L.，and；Unsupervised；representation  learning  with  deep  convolutional  generative  adversarial", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3b89ff6-6bf2-475a-a392-bf8be8dba394", "label": "摘要847", "info": "Chintala，S.（2015）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0c0f5d7e-da5f-4496-8924-5706c362f758", "label": "摘要848", "info": "Raiko，T.，Yao，L.，Cho，K.，and  Bengio，Y.（2014）.；Iterative；neural autoregressive distribution estimator（NADE-k）. Technical report，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5b5b5da-a795-40a7-9dba-d2dccb8eec6b", "label": "摘要849", "info": "Raina，R.，Madhavan，A.，and  Ng，A.  Y.（2009a）.  Large-scale  deep；unsupervised  learning  using  graphics  processors.  In  L.  Bottou  and  M.；Littman，editors，Proceedings of the Twenty-sixth International Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f0069497-4022-401f-a443-e75f0667e7ac", "label": "摘要850", "info": "Raina，R.，Madhavan，A.，and  Ng，A.  Y.（2009b）.  Large-scale  deep；unsupervised learning using graphics processors. In ICML'2009 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dcb3309b-e11d-4921-af63-7d4c604a20e5", "label": "摘要851", "info": "Ramsey，F.  P.（1926）.  Truth  and  probability.  In  R.  B.  Braithwaite，；editor，The Foundations of Mathematics and other Logical Essays ，chapter；7，pages  156–198.  McMaster  University  Archive  for  the  History  of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9295dd0e-5a40-46ae-96e1-9ffb203f25fd", "label": "摘要852", "info": "Ranzato，M.  and  Hinton，G.  H.（2010）.  Modeling  pixel  means  and；covariances using factorized third-order Boltzmann machines. In CVPR'2010；，pages 2551–2558.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "98224d58-be43-4778-b527-ef258b51cafd", "label": "摘要853", "info": "Ranzato，M.，Poultney，C.，Chopra，S.，and；LeCun，Y.（2007a）.；Efficient  learning  of  sparse  representations  with  an  energy-based  model.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c24c75b6-2e91-49b7-ad01-4c5b46c877a6", "label": "摘要854", "info": "Ranzato，M.，Poultney，C.，Chopra，S.，and；LeCun，Y.（2007b）.；Efficient learning of sparse representations with an energy-based model. In B.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dbdc3786-a225-48ad-8cfe-a42161e6a7ee", "label": "摘要855", "info": "Ranzato，M.，Huang，F.，Boureau，Y.，and；LeCun，Y.（2007c）.；Unsupervised  learning  of  invariant  feature  hierarchies  with  applications  to", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20a7004f-91e3-4438-983a-70787e09b4e3", "label": "摘要856", "info": "Ranzato，M.，Boureau，Y.，and  LeCun，Y.（2008）.  Sparse  feature；learning for deep belief networks. In NIPS'2007 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12f86a4c-4581-47c1-800a-041658235a35", "label": "摘要857", "info": "Ranzato，M.，Krizhevsky，A.，and Hinton，G. E.（2010a）. Factored 3-；way  restricted  Boltzmann  machines  for  modeling  natural  images.  In；Proceedings of AISTATS 2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d9111ea-f479-4359-8b39-2f5c732eda5c", "label": "摘要858", "info": "Ranzato，M.，Mnih，V.，and  Hinton，G.（2010b）.  Generating  more；realistic images using gated MRFs. In NIPS'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f905225-53b9-485f-be62-fc9623abe77b", "label": "摘要859", "info": "Rao，C.（1945）. Information and the accuracy attainable in the estimation；of statistical param-eters. Bulletin of the Calcutta Mathematical Society ，37；，81–89.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "86f094ac-8539-4705-b382-693be1f07c46", "label": "摘要860", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Rasmus，A.，Valpola，H.，Honkala，M.，Berglund，M.，and  Raiko，；T.（2015）.  Semi-supervised  learning  with  ladder  network.  arXiv  preprint", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "22f08e24-4590-4a15-9c4e-a01fa6695165", "label": "摘要861", "info": "Recht，B.，Re，C.，Wright，S.，and  Niu，F.（2011）.  Hogwild:  A；lock-free approach to parallelizing stochastic gradient descent. In NIPS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c584591-b8c9-424b-ada7-fcdd805dc6d2", "label": "摘要862", "info": "Reichert，D.  P.，Seriès，P.，and  Storkey，A.  J.（2011）.  Neuronal；in  perceptual；adaptation", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2637070f-a1d1-42bb-afb9-ed4fdbc6d370", "label": "摘要863", "info": "for  sampling-based  probabilistic", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5e11a6f1-0997-409d-9396-466e2124237a", "label": "摘要864", "info": "inference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4dd6da57-0c1c-4634-8c8d-1e6df31292a2", "label": "摘要865", "info": "Rezende，D.  J.，Mohamed，S.，and  Wierstra，D.（2014）.  Stochastic；backpropagation  and  approx-imate  inference  in  deep  generative  models.  In；ICML'2014 . Preprint:arXiv:1401.4082.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "774f5a57-b235-4553-a43d-a28c83491ad4", "label": "摘要866", "info": "Rifai，S.，Vincent，P.，Muller，X.，Glorot，X.，and；Bengio，Y.；（2011a）.  Contractive  auto-encoders:  Explicit  invariance  during  feature", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12251a69-20ae-4861-aef9-0476a9b04252", "label": "摘要867", "info": "Rifai，S.，Mesnil，G.，Vincent，P.，Muller，X.，Bengio，Y.，；Dauphin，Y.，and  Glorot，X.（2011b）.  Higher  order  contractive  auto-；encoder. In ECML PKDD .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd18c165-143e-44b4-b0c3-3b55b73c876d", "label": "摘要868", "info": "Rifai，S.，Dauphin，Y.，Vincent，P.，Bengio，Y.，and  Muller，X.；（2011c）. The manifold tangent classifier. In NIPS'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "24092809-f151-4297-a531-0b7a82e32ce3", "label": "摘要869", "info": "Rifai，S.，Dauphin，Y.，Vincent，P.，Bengio，Y.，and  Muller，X.；（2011d）.  The  manifold  tangent  classifier.  In  NIPS'2011  .  Student  paper；award.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "146cc79e-7195-4fbe-9236-89ed90c9d325", "label": "摘要870", "info": "Rifai，S.，Bengio，Y.，Dauphin，Y.，and  Vincent，P.（2012）.  A；generative process for sampling contractive auto-encoders. In ICML'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8ce0d06f-9403-45d2-86d3-f6a4c0836ccb", "label": "摘要871", "info": "and  Shapley，R.（2004）.  Reverse；Ringach，D.；neurophysiology. Cognitive Science ，28 （2），147–166.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3953d11a-38d9-4b99-b78b-7d060c38679b", "label": "摘要872", "info": "correlation", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ae4796f-eb33-4cc5-a161-88ff7f9eca73", "label": "摘要873", "info": "in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ad6ccda9-ed01-45b3-8252-5d3e5a8fdc86", "label": "摘要874", "info": "Roberts，S.  and  Everson，R.（2001）.  Independent  component  analysis:；principles and practice . Cambridge University Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b75966cf-a30d-41f3-9eb7-3fa244e5b385", "label": "摘要875", "info": "Robinson，A.  J.  and  Fallside，F.（1991）.  A  recurrent  error  propagation；network  speech  recognition  system.  Computer  Speech  and  Language  ，5；（3），259–274.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b244ad12-0127-46c9-a78c-070ed2e81a24", "label": "摘要876", "info": "Rockafellar，R.  T.（1997）.  Convex  analysis.  princeton  landmarks  in；mathematics.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9ceef5c7-cb0d-43d2-8c62-ec8e71931f16", "label": "摘要877", "info": "Romero，A.，Ballas，N.，Ebrahimi Kahou，S.，Chassang，A.，Gatta，；C.，and  Bengio，Y.（2015）.  Fitnets:Hints  for；thin  deep  nets.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "719738a5-ca12-4270-8929-16fb5941239b", "label": "摘要878", "info": "Rosen，J.  B.（1960）.  The  gradient  projection  method  for  nonlinear；programming. part i. linear constraints. Journal of the Society for Industrial；and Applied Mathematics ，8 （1），pp. 181–217.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f42b7e38-e59e-4cb2-b45f-b33d704444f2", "label": "摘要879", "info": "Rosenblatt，F.（1958）.  The  perceptron:  A  probabilistic  model  for；information storage and organization in the brain. Psychological Review ，65；，386–408.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ac8aa73-7b86-4527-b095-cbe0dd39f2f4", "label": "摘要880", "info": "Rosenblatt，F.（1962）.  Principles  of  Neurodynamics  .  Spartan，New；York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "109e819c-584d-4afe-bbc9-4ded18e249e6", "label": "摘要881", "info": "Rosenblatt，M.（1956）.  Remarks  on  some  nonparametric  estimates  of  a；density  function.  The  Annals  of  Mathematical  Statistics ，27  （3），832–；837.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc0a7f0e-833b-4d42-92d2-fd565dd578b2", "label": "摘要882", "info": "Roweis，S.  and  Saul，L.  K.（2000）.  Nonlinear  dimensionality  reduction；by locally linear embedding. Science ，290 （5500）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "201690bc-7ffa-49d6-94b4-a27c44cf312a", "label": "摘要883", "info": "Roweis，S.，Saul，L.，and  Hinton，G.（2002）.  Global  coordination  of；local  linear  models.  In  T.  Dietterich，S.  Becker，and  Z.  Ghahramani，；editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2251ff64-b2e9-43dd-947e-985c45dfada4", "label": "摘要884", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "37e347da-4a6a-43e6-802a-bd61515a83f2", "label": "摘要885", "info": "Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c34db9f-a8bc-47bc-893c-d5a02cabe5e7", "label": "摘要886", "info": "Processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "54e80577-2184-4037-bf92-5ba734b3af94", "label": "摘要887", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Rubin，D. B. et al. （1984）. Bayesianly justifiable and relevant frequency；calculations  for  the  applied  statistician.  The  Annals  of  Statistics  ，12", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f015e1fe-cec4-42d9-9d4c-2caa1596d85b", "label": "摘要888", "info": "Rumelhart，D.，Hinton，G.，and  Williams，R.（1986a）.  Learning；representations by back-propagating errors. Nature ，323 ，533–536.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "09f4dc00-d5a1-4c79-be05-406777dad609", "label": "摘要889", "info": "Rumelhart，D.  E.，Hinton，G.  E.，and  Williams，R.  J.（1986b）.；Learning  internal  representations  by  error  propagation.  In  D.  E.  Rumelhart；and  J.  L.  McClelland，editors，Parallel  Distributed  Processing  ，volume", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbc3bd4f-64cc-4b28-98ed-0fa43f6df8e3", "label": "摘要890", "info": "Rumelhart，D.  E.，Hinton，G.  E.，and  Williams，R.；J.（1986c）.；Learning  representations  by  back-propagating  errors.  Nature ，323  ，533–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc22eb9e-b96a-4c67-a5ab-8366db512bb2", "label": "摘要891", "info": "Rumelhart，D.  E.，McClelland，J.  L.，and；the  PDP  Research；Group（1986d）.  Parallel  Distributed  Processing:  Explorations  in  the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa624b4e-0a0f-4981-b2f0-02e28225dec1", "label": "摘要892", "info": "Russakovsky，O.，Deng，J.，Su，H.，Krause，J.，Satheesh，S.，；Ma，S.，Huang，Z.，Karpathy，A.，Khosla，A.，Bernstein，M.，；Berg，A.  C.，and  Fei-Fei，L.（2014a）.  ImageNet  Large  Scale  Visual", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b2686e20-1db5-4af9-aa2f-c22e61c8dbe6", "label": "摘要893", "info": "Russakovsky，O.，Deng，J.，Su，H.，Krause，J.，Satheesh，S.，；Ma，S.，Huang，Z.，Karpathy，A.，Khosla，A.，Bernstein，M.，et al.；（2014b）. Imagenet large scale visual recognition challenge. arXiv preprint", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d1cfbc1-67b7-485c-a094-416d4162acb4", "label": "摘要894", "info": "Russel，S.  J.  and  Norvig，P.（2003）.  Artificial  Intelligence:a  Modern；Approach . Prentice Hall.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7bdffaf7-22e8-438d-a33d-3fc2e762d855", "label": "摘要895", "info": "Rust，N.，Schwartz，O.，Movshon，J.；Simoncelli，E.；（2005）.  Spatiotemporal  elements  of  macaque  V1  receptivefields.  Neuron", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc301605-2ddb-4b8e-aa0e-77712d603b4e", "label": "摘要896", "info": "A.，and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cee4c2ae-d899-4967-adf3-5eceb4222eec", "label": "摘要897", "info": "Ramabhadran，B.；Sainath，T.，Mohamed，A.，Kingsbury，B.，and；（2013）. Deep convolutional neural networks for LVCSR. In ICASSP 2013", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "054eba31-2066-4685-a72d-f9737cae6876", "label": "摘要898", "info": "Salakhutdinov，R.（2010）.  Learning；in  Markov  randomfields  using；tempered  transitions.  In  Y.  Bengio，D.  Schuurmans，C.  Williams，J.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66ce97c7-c8b7-4dc5-bc80-10e078f82cc3", "label": "摘要899", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "71e33967-b136-4fe9-a6f7-9f53981231ef", "label": "摘要900", "info": "Salakhutdinov，R.  and  Hinton，G.（2009a）.  Deep  Boltzmann  machines.；In Proceedings of the International Conference on Artificial Intelligence and；Statistics ，volume 5，pages 448–455.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4343f298-cb28-46a4-8170-50d91be6b0c2", "label": "摘要901", "info": "Salakhutdinov，R.  and  Hinton，G.（2009b）.  Semantic  hashing.；International Journal of Approximate Reasoning .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "07cd08e2-027f-45f2-8626-cc6610861c86", "label": "摘要902", "info": "In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f68beb63-61f8-4110-a0b0-75ec1de7b3f4", "label": "摘要903", "info": "Salakhutdinov，R.  and  Hinton，G.  E.（2007a）.  Learning  a  nonlinear；embedding  by  preserving  class  neighbourhood  structure.  In  Proceedings  of；AISTATS-2007 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "45e6eb00-c649-47e5-b8a0-6737ab0c3cb3", "label": "摘要904", "info": "Salakhutdinov，R.  and  Hinton，G.  E.（2007b）.  Semantic  hashing.  In；SIGIR'2007 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d97d5aa0-d1d1-4c42-ac78-19d31bf9f0c5", "label": "摘要905", "info": "Salakhutdinov，R.  and  Hinton，G.  E.（2008）.  Using  deep  belief  nets  to；learn  covariance  kernels  for  Gaussian  processes.  In  J.  Platt，D.  Koller，Y.；Singer，and  S.  Roweis，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "68c1b29f-c92c-47f6-851c-f868cbecb05d", "label": "摘要906", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15be360e-de13-43fe-a647-af2756b4faf4", "label": "摘要907", "info": "Salakhutdinov，R. and Larochelle，H.（2010）. Efficient learning of deep；Boltzmann  machines.  In  Proceedings  of  the  Thirteenth  International；Conference  on  Artificial  Intelligence  and  Statistics（AISTATS  2010），", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef86d9fe-c898-4a05-9372-5b65c15357b6", "label": "摘要908", "info": "Salakhutdinov，R.；factorization. In NIPS'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b262a827-d343-4319-ae1b-e44173e229ea", "label": "摘要909", "info": "and  Mnih，A.（2008）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "45808e73-38f2-4a95-b41d-5c469339abbb", "label": "摘要910", "info": "Probabilistic  matrix", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d8b1d7e-c078-4a4f-83a1-71a4e426e06f", "label": "摘要911", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Salakhutdinov，R. and Murray，I.（2008）. On the quantitative analysis of；deep belief networks. In W. W. Cohen，A. McCallum，and S. T. Roweis，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9b581f47-c863-4825-b5cd-18a880be2f6c", "label": "摘要912", "info": "Salakhutdinov，R.，Mnih，A.，and  Hinton，G.（2007）.  Restricted；Boltzmann machines for collab-orativefiltering. In ICML .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa2afec3-492f-4b34-8b89-1e15024a4f10", "label": "摘要913", "info": "Sanger，T.  D.（1994）.  Neural  network；learning  control  of  robot；manipulators  using  gradually  increasing  task  difficulty.  IEEE  Transactions", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4f2fa30-5bf6-40ba-86b5-a3926ef28368", "label": "摘要914", "info": "Saul，L.  K.  and  Jordan，M.  I.（1996）.  Exploiting  tractable  substructures；in  intractable  networks.  In  D.  Touretzky，M.  Mozer，and  M.  Hasselmo，；editors，Advances in Neural Information Processing Systems 8（NIPS'95）", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ad42c08-823f-4f8a-a8d2-a45e0cc697e2", "label": "摘要915", "info": "Saul，L. K.，Jaakkola，T.，and Jordan，M. I.（1996）. Meanfield theory；for sigmoid  belief  networks. Journal of Artificial Intelligence Research ，4；，61–76.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8d1c8d25-e10e-496c-8ad4-c13a83d0941f", "label": "摘要916", "info": "Savich，A.  W.，Moussa，M.，and  Areibi，S.（2007）.  The  impact  of；arithmetic representation on implementing mlp-bp on fpgas: A study. Neural；Networks，IEEE Transactions on ，18 （1），240–252.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cafbc88e-b168-4da9-9c16-973b7de5e36d", "label": "摘要917", "info": "Saxe，A.  M.，Koh，P.  W.，Chen，Z.，Bhand，M.，Suresh，B.，and；Ng，A.（2011）. On random weights and unsupervised feature learning. In；Proc. ICML'2011 . ACM.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "56b971ab-6f55-4ad6-b0d9-8c0f308002c5", "label": "摘要918", "info": "Saxe，A.  M.，McClelland，J.  L.，and  Ganguli，S.（2013）.  Exact；solutions  to  the  nonlinear  dynamics  of  learning  in  deep  linear  neural；networks. In ICLR .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f7172105-3a5a-428b-8ad1-edf7c575c8af", "label": "摘要919", "info": "Schaul，T.，Antonoglou，I.，and  Silver，D.（2014）.  Unit；stochastic  optimization.；Representations .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0cc1ce5d-f29f-42bf-963e-efb1cdd9016a", "label": "摘要920", "info": "tests  for；International  Conference  on  Learning", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ddb8db1b-7a34-4543-a9ab-acc049c26880", "label": "摘要921", "info": "In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "964251a1-ec8d-47b8-9555-0c4e38da63be", "label": "摘要922", "info": "Schmidhuber，J.（1992）.  Learning  complex，extended  sequences  using；the principle of history compression. Neural Computation ，4 （2），234–；242.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f9f3770-d5af-44db-b99b-d932fbbe1b49", "label": "摘要923", "info": "Schmidhuber，J.（1996）.  Sequential  neural；Transactions on Neural Networks ，7 （1），142–146.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a04edbed-4e4d-455f-90e9-f69089a3ec5d", "label": "摘要924", "info": "text  compression.  IEEE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c3ad9d3-3159-4a04-a641-3adc84d8ac28", "label": "摘要925", "info": "Schmidhuber，J.（2012）.  Self-delimiting  neural  networks.  arXiv  preprint；arXiv:1210.0118 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e6fc8384-1c1a-4d7c-b77d-7c3c48023107", "label": "摘要926", "info": "Schölkopf，B.  and  Smola，A.  J.（2002）.  Learning with kernels: Support；vector machines，regular-ization，optimization，and beyond . MIT press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "468e0402-d281-412e-a756-904b5a80260f", "label": "摘要927", "info": "Schölkopf，B.，Burges，C. J. C.，and Smola，A. J.（1998a）. Advances；in kernel methods: support vector learning . MIT Press，Cambridge，MA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1413d267-ab5b-4dd1-8059-e31ee6acd8a1", "label": "摘要928", "info": "Schölkopf，B.，Smola，A.，and  Müller，K.-R.（1998b）.  Nonlinear；component  analysis  as  a  kernel  eigenvalue  problem.  Neural  Computation；，10 ，1299–1319.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2f323a6f-69ea-4074-a233-6ed101d0dc3a", "label": "摘要929", "info": "Schölkopf，B.，Burges，C.  J.  C.，and  Smola，A.  J.（1999）.  Advances；in  Kernel  Methods—Support  Vector  Learning  .  MIT  Press，Cambridge，；MA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "05e3ffae-4ab5-4694-8070-3a0555e87ffb", "label": "摘要930", "info": "Schölkopf，B.，Janzing，D.，Peters，J.，Sgouritsa，E.，Zhang，K.，；and Mooij，J.（2012）. On causal and anticausal learning. In ICML'2012 ，；pages 1255–1262.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "93f78308-cd89-4847-8956-dddda9e72aa7", "label": "摘要931", "info": "Schuster，M.（1999）.  On  supervised  learning  from  sequential  data  with；applications for speech recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49dd8e05-8732-4e4a-b58a-e17a034ed959", "label": "摘要932", "info": "Schuster，M.  and  Paliwal，K.（1997）.  Bidirectional  recurrent  neural；networks.  IEEE  Transactions  on  Signal  Processing  ，45  （11），2673–；2681.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9b40ba4e-146a-45d2-a632-c05e044044d2", "label": "摘要933", "info": "Schwenk，H.（2007）.  Continuous  space  language  models.  Computer；speech and language ，21 ，492–518.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c81b74a5-3bda-4fc6-80e2-164baaf5d002", "label": "摘要934", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Schwenk，H.（2010）.  Continuous  space  language  models  for  statistical；machine  translation.  The  Prague  Bulletin  of  Mathematical  Linguistics  ，93", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e25207d0-9549-457f-be2f-8d5bcb79a467", "label": "摘要935", "info": "Schwenk，H.（2014）. Cleaned subset of WMT '14 dataset.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5884cfd9-f2cd-44f8-b0d9-13c8e68d8bb6", "label": "摘要936", "info": "Schwenk，H.  and  Bengio，Y.（1998）.  Training  methods  for  adaptive；boosting  of  neural  networks.  In  M.  Jordan，M.  Kearns，and  S.  Solla，；editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0cbd0bd6-88d3-49e9-9fdb-cd7b7a620c67", "label": "摘要937", "info": "in  Neural", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0245d0ad-42ae-4248-a09f-0ce704d940cf", "label": "摘要938", "info": "Information", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "68733f79-35c0-4627-be26-e0ec75b9e4e8", "label": "摘要939", "info": "Processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "914e36d5-5519-465f-8b02-846d10d3d2c1", "label": "摘要940", "info": "Schwenk，H.  and  Gauvain，J.-L.（2002）.  Connectionist；modeling；International", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0bc13cab-447d-4082-99dc-7bf72423de14", "label": "摘要941", "info": "large  vocabulary  continuous  speech；Acoustics，Speech；Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6179c9d7-d22d-45f5-a2ac-3a5172f38a1a", "label": "摘要942", "info": "for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3df4ab8a-7846-467a-abb0-06d6a6a98507", "label": "摘要943", "info": "on", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aca07dc9-4d35-452d-9d3b-d2a94a64504c", "label": "摘要944", "info": "and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "10654fcb-afd4-4cbc-be99-fc1499b4b083", "label": "摘要945", "info": "recognition.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c082d68-a92d-496d-bee1-b33f4422d540", "label": "摘要946", "info": "language；In；Signal", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2794bf3f-218d-417f-8429-aae1fe5e1466", "label": "摘要947", "info": "Schwenk，H.，Costa-jussà，M.  R.，and  Fonollosa，J.  A.  R.（2006）.；task.  In；Continuous  space", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c9c2559-b828-4765-9468-65fbe422a1c5", "label": "摘要948", "info": "language  models  for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8aaf794a-99ad-459b-b273-1dcdc497a44d", "label": "摘要949", "info": "the  IWSLT  2006", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "73faa22d-0332-42b6-b7ae-5818af13a250", "label": "摘要950", "info": "Seide，F.，Li，G.，and  Yu，D.（2011）.  Conversational；speech；transcription  using  context-dependent  deep  neural  networks.  In  Interspeech", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96f9b325-3ccd-4f51-b437-6aa6af719353", "label": "摘要951", "info": "Sejnowski，T.（1987）.  Higher-order  Boltzmann  machines.；In  AIP；Conference  Proceedings  151  on  Neural  Networks  for  Computing  ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d8fda89-d3da-46c4-a23f-2bd24c6c1b16", "label": "摘要952", "info": "Series，P.，Reichert，D.  P.，and  Storkey，A.  J.（2010）.  Hallucinations；in  Charles  Bonnet  syndrome  induced  by  homeostasis:  a  deep  Boltzmann；machine  model.  In  Advances  in  Neural  Information  Processing  Systems  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c5275af3-356f-474a-b040-9a894a8659c0", "label": "摘要953", "info": "Sermanet，P.，Chintala，S.，and  LeCun，Y.（2012）.  Convolutional；In；neural  networks  applied", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8de1fa7-5421-4e49-9151-59174890c1d6", "label": "摘要954", "info": "to  house  numbers  digit  classification.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92d013ad-4ed0-43e2-9543-ac0bcdf5ebc3", "label": "摘要955", "info": "LeCun，Y.；Sermanet，P.，Kavukcuoglu，K.，Chintala，S.，and；（2013）.  Pedestrian  detection  with  unsupervised  multi-stage  feature", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9ad6bf7a-9d66-43ac-8ece-5e7e0b5bad46", "label": "摘要956", "info": "Shilov，G.（1977）. Linear Algebra. Dover Books on Mathematics Series.；Dover Publications.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef1ee924-135b-4e82-b303-da7c26cb80ea", "label": "摘要957", "info": "Siegelmann，H.（1995）.  Computation  beyond  the  Turing  limit.  Science；，268 （5210），545–548.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5516346a-652c-4c7a-bcf4-08d81332a1ba", "label": "摘要958", "info": "Siegelmann，H. and Sontag，E.（1991）. Turing computability with neural；nets. Applied Mathe-matics Letters ，4 （6），77–80.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "114e0534-314f-49dc-9bb5-c8eeb7af3a66", "label": "摘要959", "info": "Siegelmann，H.  T.  and  Sontag，E.  D.（1995）.  On  the  computational；power  of  neural  nets.  Journal  of  Computer  and  Systems  Sciences  ，50；（1），132–150.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "95f4cc4f-578c-4b3b-a0e6-a707316c2f09", "label": "摘要960", "info": "Sietsma，J. and Dow，R.（1991）. Creating artificial neural networks that；generalize. Neural Networks ，4 （1），67–79.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3016eaa-32e0-4b66-8ea1-d9e6ea6a2781", "label": "摘要961", "info": "Simard，D.，Steinkraus，P.  Y.，and  Platt，J.  C.（2003）.  Best  practices；for convolutional neural networks. In ICDAR'2003 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b89764c-a176-4fdb-a156-c498761dd660", "label": "摘要962", "info": "Simard，P.；and  Graf，H.  P.（1994）.  Backpropagation  without；multiplication.  In  Advances  in  Neural  Information  Processing  Systems  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f62edbc4-a0aa-46e5-ba3e-a32cccf884c4", "label": "摘要963", "info": "Simard，P.，Victorri，B.，LeCun，Y.，and；Denker，J.（1992）.；Tangent prop-A formalism for specifying selected invariances in an adaptive", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb0b180a-6179-4ee5-98e6-df44ac076750", "label": "摘要964", "info": "Simard，P.  Y.，LeCun，Y.，and  Denker，J.（1993）.  Efficient  pattern；recognition using a new transformation distance. In NIPS'92 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1473f91f-dfa5-409d-aeae-de9c8c1d95b9", "label": "摘要965", "info": "Simard，P.  Y.，LeCun，Y.  A.，Denker，J.  S.，and  Victorri，B.；（1998）.  Transformation；in  pattern  recognition—tangent", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "22174dac-949e-49c4-83a0-5b4e1d597670", "label": "摘要966", "info": "invariance", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2aebcb2b-b673-4613-bd95-46841fe41d3b", "label": "摘要967", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；distance and tangent propagation. Lecture Notes in Computer Science ，1524；.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf1e1f95-4d78-4d65-bdab-d8d8666b2255", "label": "摘要968", "info": "Simons，D.  J.  and  Levin，D.  T.（1998）.  Failure  to  detect  changes  to；people during a real-world interaction. Psychonomic Bulletin & Review ，5；（4），644–649.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "674c39f2-8289-4074-bef1-5c507a953458", "label": "摘要969", "info": "Simonyan，K.  and  Zisserman，A.（2015）.  Very  deep  convolutional；networks for large-scale image recognition. In ICLR .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b3781dee-a561-41b9-a7fe-de5a3b885574", "label": "摘要970", "info": "Sjöberg，J.  and  Ljung，L.（1995）.  Overtraining，regularization  and；searching for a minimum，with application to neural networks. International；Journal of Control ，62 （6），1391–1407.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f66779e-4de5-4de9-89e0-e5992b2388a8", "label": "摘要971", "info": "Skinner，B. F.（1958）. Reinforcement today. American Psychologist ，13；，94–99.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c23daa8d-515d-4149-935a-1da4825b8f72", "label": "摘要972", "info": "Smolensky，P.（1986）.  Information  processing  in  dynamical  systems:；Foundations of harmony theory. In D. E. Rumelhart and J. L. McClelland，；editors，Parallel  Distributed  Processing  ，volume  1，chapter  6，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4092aeb9-1c1d-42d2-9156-e5ac008ecada", "label": "摘要973", "info": "Snoek，J.，Larochelle，H.，and  Adams，R.  P.（2012）.  Practical；Bayesian optimization of machine learning algorithms. In NIPS'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a8860813-3a12-41eb-817e-284b9eed34e7", "label": "摘要974", "info": "Socher，R.，Huang，E.；Y.，and；Manning，C.  D.（2011a）.  Dynamic  pooling  and  unfolding  recursive", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4cedd6f1-2f17-4d51-89c3-a53707dd4f37", "label": "摘要975", "info": "H.，Pennington，J.，Ng，A.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fce6091a-b061-4182-8588-253d681e5ed5", "label": "摘要976", "info": "Socher，R.，Manning，C.，and  Ng，A.  Y.（2011b）.  Parsing  natural；scenes and natural language with recursive neural networks. In Proceedings；of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa7f5456-9c1c-43b3-b5f6-536937a29c34", "label": "摘要977", "info": "International  Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "80ccdfda-a25f-42b5-a109-874c41f21b81", "label": "摘要978", "info": "the", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c10fb1c0-e5fe-4b99-abcf-57bf8df964fa", "label": "摘要979", "info": "Y.，and；Socher，R.，Pennington，J.，Huang，E.；Manning，C.  D.（2011c）.  Semi-supervised  recursive  autoencoders  for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c3be173-a6e1-42f0-8dae-a7d56f543eac", "label": "摘要980", "info": "H.，Ng，A.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cea4841c-5389-4f29-89c5-e78caf28f593", "label": "摘要981", "info": "Y.，Chuang，J.，Manning，C.；Socher，R.，Perelygin，A.，Wu，J.；D.，Ng，A.  Y.，and  Potts，C.（2013a）.  Recursive  deep  models  for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b47f5276-63c9-4744-9c5e-273ade75ad2c", "label": "摘要982", "info": "Socher，R.，Ganjoo，M.，Manning，C.  D.，and  Ng，A.  Y.（2013b）.；Zero-shot learning through cross-modal transfer. In 27th Annual Conference；on Neural Information Processing Systems（NIPS 2013） .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "32ce6cad-0648-43e8-ac5c-463154bb1313", "label": "摘要983", "info": "A.，Maheswaranathan，N.，and；Sohl-Dickstein，J.，Weiss，E.；Ganguli，S.（2015）.  Deep  unsuper-vised  learning  using  nonequilibrium", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e478cdbf-f92c-4a3a-a44b-1b534eceb9e4", "label": "摘要984", "info": "Sohn，K.，Zhou，G.，and  Lee，H.（2013）.  Learning  and  selecting；features jointly with point-wise gated Boltzmann machines. In ICML'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "049b435d-7b7e-4ac2-8ef2-f7eb77177851", "label": "摘要985", "info": "Solomonoff，R.  J.（1989）.  A  system  for  incremental  learning  based  on；algorithmic probability.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e2020e5-700b-48c7-8ec2-f1df3fb3d296", "label": "摘要986", "info": "Sontag，E.  D.（1998）.  VC  dimension  of  neural  networks.  NATO  ASI；Series F Computer and Systems Sciences ，168 ，69–96.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "deaf49ab-eda5-4fe8-9365-cdde9cc3ee7c", "label": "摘要987", "info": "Sontag，E. D. and Sussman，H. J.（1989）. Backpropagation can give rise；to spurious local minima even for networks without hidden layers. Complex；Systems ，3 ，91–106.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccdf832b-9d5c-4325-aa45-b2ba2554f948", "label": "摘要988", "info": "Sparkes，B.（1996）.  The  Red  and  the  Black:  Studies  in  Greek  Pottery  .；Routledge.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc049e35-4650-4f6f-9e9e-6dd13d487e0c", "label": "摘要989", "info": "Spitkovsky，V.  I.，Alshawi，H.，and  Jurafsky，D.（2010）.  From  baby；steps to leapfrog: how“less is more”in unsupervised dependency parsing. In；HLT'10 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9596472-ad3f-4352-a319-cf65025d39a4", "label": "摘要990", "info": "Squire，W.  and  Trapp，G.（1998）.  Using  complex  variables  to  estimate；derivatives of real functions. SIAM Rev. ，40 （1），110–112.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b12708be-1a03-4a4f-9f1a-75731017c60a", "label": "摘要991", "info": "Srebro，N.  and  Shraibman，A.（2005）.  Rank，trace-norm  and  max-；norm. In Proceedings of the 18th Annual Conference on Learning Theory ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "329ddac2-e6bb-43d0-89a1-936ea2094373", "label": "摘要992", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；pages 545–560. Springer-Verlag.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e6a74237-6d6a-47aa-8192-776329763d9d", "label": "摘要993", "info": "Srivastava，N.（2013）.  Improving  Neural  Networks  With  Dropout；Master's thesis，U. Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0518f960-d1bb-4d9f-88b9-1f62439d43cb", "label": "摘要994", "info": ".", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9cbad110-0a2f-4974-a9dc-141b780d004d", "label": "摘要995", "info": "Srivastava，N.  and  Salakhutdinov，R.（2012）.  Multimodal  learning  with；deep Boltzmann machines. In NIPS'2012 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "31fcea58-ebe4-46c4-b35d-9a96c1ab577f", "label": "摘要996", "info": "Srivastava，N.，Salakhutdinov，R.  R.，and  Hinton，G.  E.（2013）.；Modeling  documents  with  deep  Boltzmann  machines.  arXiv  preprint；arXiv:1309.6865 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fdd549c4-cfcf-4f37-83a0-7fefa9fb1c73", "label": "摘要997", "info": "Srivastava，N.，Hinton，G.，Krizhevsky，A.，Sutskever，I.，and；Salakhutdinov，R.（2014）.  Dropout:  A  simple  way  to  prevent  neural；networks  from  overfitting.  Journal  of  Machine  Learning  Research ，15  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5febecf3-8391-4d71-8378-49ba6d52701c", "label": "摘要998", "info": "Srivastava，R.  K.，Greff，K.，and  Schmidhuber，J.（2015）.  Highway；networks. arXiv:1505.00387 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ed26b9d-3bb4-431f-8c62-8e3cf93ba50c", "label": "摘要999", "info": "Steinkrau，D.，Simard，P.  Y.，and  Buck，I.（2005）.  Using  GPUs  for；machine  learning  algorithms.  2013  12th  International  Conference  on；Document Analysis and Recognition ，0 ，1115–1119.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ec460907-0cb3-464e-8c51-dcb6b68d3bba", "label": "摘要1000", "info": "Stoyanov，V.，Ropson，A.，and  Eisner，J.（2011）.  Empirical；risk；minimization  of  graphical  model  parameters  given  approximate  inference，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a624ec40-6f35-4b39-8acc-6f9e51cfc583", "label": "摘要1001", "info": "Sukhbaatar，S.，Szlam，A.，Weston，J.，and；Weakly supervised memory networks. arXiv preprint arXiv:1503.08895 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59d61704-4250-40de-8374-19575e8a98f5", "label": "摘要1002", "info": "Fergus，R.（2015）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "86332ad4-4934-4293-a77c-0dfaf2e7c445", "label": "摘要1003", "info": "Supancic，J. and Ramanan，D.（2013）. Self-paced learning for long-term；tracking. In CVPR'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15ae4fe5-952d-43c7-8f2f-6285c0198cd0", "label": "摘要1004", "info": "Sussillo，D.（2014）.  Random  walks:Training  very  deep  nonlinear  feed-；forward networks with smart initialization. CoRR ，abs/1412.6558 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f1e12765-4bb2-4605-940b-d344b2149fce", "label": "摘要1005", "info": "Sutskever，I.（2012）.  Training  Recurrent  Neural  Networks；thesis，Department of computer science，University of Toronto.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1bf6af41-6eae-4c97-96ed-b8057d9a325b", "label": "摘要1006", "info": ".  Ph.D.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ad21ce3e-224a-4700-a8f7-2d8e75c88e42", "label": "摘要1007", "info": "Sutskever，I.  and  Hinton，G.  E.（2008）.  Deep  narrow  sigmoid  belief；networks  are  universal  approximators.  Neural  Computation ，20  （11），；2629–2636.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66a78bc7-c472-4bbd-bcdd-47e8cd4091e5", "label": "摘要1008", "info": "Sutskever，I.  and  Tieleman，T.（2010）.  On  the  Convergence  Properties；of Contrastive Divergence. In AISTATS'2010 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b5b1fbc-b7dc-4962-9e26-3e73d0daddc4", "label": "摘要1009", "info": "Sutskever，I.，Hinton，G.，and  Taylor，G.（2009）.  The；temporal restricted Boltzmann machine. In NIPS'2008 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d51e6fca-efd3-4add-b580-32c314f78713", "label": "摘要1010", "info": "recurrent", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "018edb96-f311-4afb-9502-689b94c55a91", "label": "摘要1011", "info": "Sutskever，I.，Martens，J.，and  Hinton，G.  E.（2011）.  Generating  text；with recurrent neural networks. In ICML'2011 ，pages 1017–1024.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15b6f31e-a3b3-494b-98b6-f1b48c51afa1", "label": "摘要1012", "info": "Sutskever，I.，Martens，J.，Dahl，G.，and Hinton，G.（2013）. On the；importance of initialization and momentum in deep learning. In ICML .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "50814cea-8721-451e-ab9e-b8839bd27234", "label": "摘要1013", "info": "Sutskever，I.，Vinyals，O.，and  Le，Q.  V.（2014）.  Sequence；sequence learning with neural networks. In NIPS'2014，arXiv:1409.3215 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f9dcd043-0bfc-4efb-98ec-b85b7c44d33f", "label": "摘要1014", "info": "to", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97340a65-a431-483b-8db7-2e8c6a3c8198", "label": "摘要1015", "info": "Sutton，R.；Introduction . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b262168c-4b7f-4d82-9788-3a09f3265daf", "label": "摘要1016", "info": "and  Barto，A.（1998）.  Reinforcement  Learning:  An", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa6674fc-af42-4a3c-9727-20d642196c1a", "label": "摘要1017", "info": "Sutton，R.  S.，Mcallester，D.，Singh，S.，and  Mansour，Y.（2000）.；function；for", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "decbc8c2-9a85-4abd-a1a3-15bf3978e0fd", "label": "摘要1018", "info": "learning  with", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a4f0707-e334-49f0-bbf2-0b1ac69c2c0b", "label": "摘要1019", "info": "reinforcement", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4837a07a-ec9a-4801-833a-4d3da02f99af", "label": "摘要1020", "info": "Swersky，K.，Ranzato，M.，Buchman，D.，Marlin，B.，and；de；Freitas，N.（2011）. On autoencoders and score matching for energy based", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fdb53456-ad96-4228-a206-1ac4529f2d19", "label": "摘要1021", "info": "Swersky，K.，Snoek，J.，and  Adams，R.  P.（2014）.  Freeze-thaw", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5034d585-3662-4b60-81d4-43e1280d77c7", "label": "摘要1022", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Bayesian optimization. arXiv preprint arXiv:1406.3896 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "df849a5f-0365-4286-b228-23a33115931a", "label": "摘要1023", "info": "Szegedy，C.，Liu，W.，Jia，Y.，Sermanet，P.，Reed，S.，；Anguelov，D.，Erhan，D.，Vanhoucke，V.，and；（2014a）.  Going  deeper  with  convolutions.  Technical", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ca4cf4f-3cf5-4895-a28d-32e9f00bd005", "label": "摘要1024", "info": "Rabinovich，A.；report，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "614600c5-dc79-46b9-b49c-5106e651d508", "label": "摘要1025", "info": "Szegedy，C.，Zaremba，W.，Sutskever，I.，Bruna，J.，Erhan，D.，；Goodfellow，I.  J.，and  Fergus，R.（2014b）.  Intriguing  properties  of；neural networks. ICLR ，abs/1312.6199 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aee8f965-1167-4328-b813-bff899a83fdd", "label": "摘要1026", "info": "Szegedy，C.，Vanhoucke，V.，Ioffe，S.，Shlens，J.，and  Wojna，Z.；（2015）. Rethinking the Inception Architecture for Computer Vision. ArXiv；e-prints .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af368f73-5565-45d9-a0ce-404392bf94f6", "label": "摘要1027", "info": "Taigman，Y.，Yang，M.，Ranzato，M.，and；Wolf，L.（2014）.；DeepFace: Closing the gap to human-level performance in face verification.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff2065b9-3157-4f73-a541-225bc39d0764", "label": "摘要1028", "info": "Tandy，D.  W.（1997）.  Works  and  Days:  A  Translation  and  Commentary；for the Social Sciences. University of California Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70f9898e-29d2-4593-9d14-998c0d64649e", "label": "摘要1029", "info": "Tang，Y.  and  Eliasmith，C.（2010）.  Deep  networks  for  robust  visual；recognition. In Proceedings of the 27th International Conference on Machine；Learning，June 21-24，2010，Haifa，Israel .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7bcc8d55-eebd-436f-8c0e-af963a00f5ce", "label": "摘要1030", "info": "Tang，Y.，Salakhutdinov，R.，and  Hinton，G.（2012）.  Deep  mixtures；of factor analysers. arXiv preprint arXiv:1206.4635 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ebd36837-d407-473a-95e9-240e72d38532", "label": "摘要1031", "info": "Taylor，G.  and  Hinton，G.（2009）.  Factored  conditional  restricted；Boltzmann  machines  for  modeling  motion  style.  In  L.  Bottou  and  M.；Littman，editors，Proceedings of the Twenty-sixth International Conference", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1dec00e9-3fe9-4080-919a-b8e7af56c293", "label": "摘要1032", "info": "Taylor，G.，Hinton，G.  E.，and  Roweis，S.（2007）.  Modeling  human；motion  using  binary  latent  variables.  In  B.  Schölkopf，J.  Platt，and  T.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "053f4375-ca33-4227-9ba4-bfca1f92745f", "label": "摘要1033", "info": "Hoffman，editors，Advances  in  Neural  Information  Processing  Systems；19（NIPS'06） ，pages 1345–1352. MIT Press，Cambridge，MA.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ad38d04c-b1c4-4957-b841-f696dcd07280", "label": "摘要1034", "info": "Teh，Y.，Welling，M.，Osindero，S.，and  Hinton，G.  E.（2003）.；Energy-based  models  for  sparse  overcomplete  representations.  Journal  of；Machine Learning Research ，4 ，1235–1260.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b388383-10fd-4a06-aab2-f36b806b975c", "label": "摘要1035", "info": "Tenenbaum，J.，de  Silva，V.，and  Langford，J.  C.（2000）.  A  global；geometric framework for nonlinear dimensionality reduction. Science ，290；（5500），2319–2323.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "576eae01-7cdf-43c4-9c88-3a586485d224", "label": "摘要1036", "info": "Theis，L.，van  den  Oord，A.，and  Bethge，M.（2015）.  A  note  on  the；evaluation of generative models. arXiv:1511.01844.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9ca70ce-eac4-49e8-9d6b-a38813fe35e5", "label": "摘要1037", "info": "Thompson，J.，Jain，A.，LeCun，Y.，and  Bregler，C.（2014）.  Joint；training  of  a  convolutional  network  and  a  graphical  model  for  human  pose；estimation. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26aabe82-019c-4888-8693-2bbd60d6a450", "label": "摘要1038", "info": "Thrun，S.（1995）. Learning to play the game of chess. In NIPS'1994 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b66be9f2-9104-424a-9429-1b06f0c7cb8e", "label": "摘要1039", "info": "Tibshirani，R. J.（1995）. Regression shrinkage and selection via the lasso.；Journal of the Royal Statistical Society B ，58 ，267–288.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c14ebc16-4ffb-4e32-bd71-5cb8f933a693", "label": "摘要1040", "info": "Tieleman，T.（2008）.  Training  restricted  Boltzmann  machines  using；approximations  to  the  like-lihood  gradient.  In  ICML'2008  ，pages  1064–；1071.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8af9a4bd-d989-45d8-8ec1-83190c01bcd8", "label": "摘要1041", "info": "Tieleman，T.  and  Hinton，G.（2009）.  Using  fast  weights  to  improve；persistent contrastive diver-gence. In ICML'2009 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "891f5d59-0f2b-4e93-b97e-f9696347c1c6", "label": "摘要1042", "info": "Tipping，M.  E.  and  Bishop，C.  M.（1999）.  Probabilistic  principal；components  analysis.  Journal  of  the  Royal  Statistical  Society  B  ，61；（3），611–622.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a929edec-d05e-436e-b8b9-e4b865399f77", "label": "摘要1043", "info": "Torralba，A.，Fergus，R.，and  Weiss，Y.（2008）.  Small  codes  and；large  databases for recognition. In Proceedings of the Computer Vision and；Pattern Recognition Conference（CVPR'08） ，pages 1–8.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5abbe1d3-8139-4d7f-bcdc-81a2a8dd8ae9", "label": "摘要1044", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Touretzky，D.  S.  and  Minton，G.  E.（1985）.  Symbols  among  the；neurons: Details of a con-nectionist inference architecture. In Proceedings of", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e379e5f0-75ef-48ff-b1b4-4ddec2e0432d", "label": "摘要1045", "info": "Tu，K.  and  Honavar，V.（2011）.  On；unsupervised learning of probabilistic grammars. In IJCAI'2011 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7f3143f0-0e4a-4e6e-ade4-268bb2576283", "label": "摘要1046", "info": "the  utility  of  curricula", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "478c85df-bd95-4edc-88cf-c0d85de0e97b", "label": "摘要1047", "info": "in", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4895bfb2-f3a1-4b91-8bea-45f906f6e948", "label": "摘要1048", "info": "Turaga，S.  C.，Murray，J.  F.，Jain，V.，Roth，F.，Helmstaedter，；M.，Briggman，K.，Denk，W.，and；S.（2010）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f1ab7116-b7bb-42d7-b91b-3403c9c55142", "label": "摘要1049", "info": "Seung，H.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e8c93b1-cea4-4f64-a001-6e215793f51b", "label": "摘要1050", "info": "Turian，J.，Ratinov，L.，and；Word；representations:  A  simple  and  general  method  for  semi-supervised  learning.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7564ba2c-f791-46f6-8c93-dac9b5fb1fd9", "label": "摘要1051", "info": "Bengio，Y.（2010）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ce85def-d156-4b10-9087-d90e39442846", "label": "摘要1052", "info": "Töscher，A.，Jahrer，M.，and  Bell，R.  M.（2009）.  The  BigChaos；solution to the Netflix grand prize.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "de720ca0-f681-4106-9bc5-f62896a007f0", "label": "摘要1053", "info": "Uria，B.，Murray，I.，and  Larochelle，H.（2013）.  Rnade:  The  real-；valued neural autoregressive density-estimator. In NIPS'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e6ec5b06-e577-414d-9c45-c9f4b7835dd9", "label": "摘要1054", "info": "van  den  Oörd，A.，Dieleman，S.，and  Schrauwen，B.（2013）.  Deep；content-based music recom-mendation. In NIPS'2013 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a46f4b80-cb2e-443c-9e8c-c263d883b887", "label": "摘要1055", "info": "van  der  Maaten，L.  and  Hinton，G.  E.（2008）.  Visualizing  data  using  t-；SNE. J. Machine Learning Res. ，9 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b3f2d95e-dd12-4676-85bc-cb6916f76aa8", "label": "摘要1056", "info": "Vanhoucke，V.，Senior，A.，and  Mao，M.  Z.（2011）.  Improving  the；speed  of  neural  networks  on  CPUs.  In  Proc.  Deep  Learning  and；Unsupervised Feature Learning NIPS Workshop .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "414164cc-8d0e-42c6-9f42-84ab3dcab792", "label": "摘要1057", "info": "Vapnik，V.  N.（1982）.  Estimation  of  Dependences  Based  on  Empirical；Data . Springer-Verlag，Berlin.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "457de901-d6d8-45b2-bcee-205b07c971aa", "label": "摘要1058", "info": "Vapnik，V.  N.（1995）.  The  Nature  of  Statistical  Learning  Theory  .；Springer，New York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d896e5c3-ee99-4dad-b680-3fc02f38016b", "label": "摘要1059", "info": "Vapnik，V.  N.  and  Chervonenkis，A.  Y.（1971）.  On  the  uniform；convergence of relative frequencies of events to their probabilities. Theory of；Probability and Its Applications ，16 ，264–280.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5abc2a73-f727-4e04-8bfe-3a5aac4ca806", "label": "摘要1060", "info": "Vincent，P.（2011）. A connection between score matching and denoising；autoencoders. Neural Computation ，23 （7）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b1c25a06-d8be-48b6-9369-486356676700", "label": "摘要1061", "info": "Vincent，P.  and  Bengio，Y.（2003）.  Manifold  Parzen  windows.  In；NIPS'2002 . MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d797041-3731-4fe7-a06c-e9f5fa82b889", "label": "摘要1062", "info": "Vincent，P.，Larochelle，H.，Bengio，Y.，and；Manzagol，P.-A.；（2008a）.  Extracting  and  composing  robust  features  with  denoising", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8394f490-b0a4-4fc9-a3d0-3b10bcc187f2", "label": "摘要1063", "info": "Manzagol，P.-A.；Vincent，P.，Larochelle，H.，Bengio，Y.，and；（2008b）.  Extracting  and  composing  robust  features  with  denoising", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbbd115d-2776-4a63-aa76-15e0eed40df9", "label": "摘要1064", "info": "Vincent，P.，Larochelle，H.，Lajoie，I.，Bengio，Y.，and  Manzagol，；P.-A.（2010）.  Stacked  denoising；autoencoders:  Learning  useful", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "196229c0-0b2d-4cf8-9211-5c9108b97bcf", "label": "摘要1065", "info": "Vincent，P.，de  Brébisson，A.，and  Bouthillier，X.（2015）.  Efficient；exact  gradient  update  for  training  deep  networks  with  very  large  sparse；targets. In C. Cortes，N. D. Lawrence，D. D. Lee，M. Sugiyama，and R.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14d526fb-bac5-40fd-9fab-8f288fe64675", "label": "摘要1066", "info": "Vinyals，O.，Kaiser，L.，Koo，T.，Petrov，S.，Sutskever，I.，and；Hinton，G.（2014a）.  Grammar  as  a  foreign  language.  arXiv  preprint；arXiv:1412.7449 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "861777e1-6f92-406a-9cb8-6694535adc30", "label": "摘要1067", "info": "Vinyals，O.，Toshev，A.，Bengio，S.，and Erhan，D.（2014b）. Show", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9480e79e-0e8d-49d3-a275-93a46203129f", "label": "摘要1068", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；and tell:a neural image caption generator. arXiv 1411.4555.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dd01b488-a0ab-4888-bb14-48467057fa2b", "label": "摘要1069", "info": "Vinyals，O.，Fortunato，M.，and Jaitly，N.（2015a）. Pointer networks.；arXiv preprint arXiv:1506.03134 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e5eff35-de36-4508-9383-f6a81e601ed2", "label": "摘要1070", "info": "Vinyals，O.，Toshev，A.，Bengio，S.，and Erhan，D.（2015b）. Show；and tell:a neural image caption generator. In CVPR'2015 . arXiv:1411.4555.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "296ef32c-d2ac-445d-b8f7-8f277ec6eefb", "label": "摘要1071", "info": "Viola，P.  and  Jones，M.（2001）.  Robust  real-time  object  detection.  In；International Journal of Computer Vision .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "29fd7bc0-2134-4f17-96d2-6e401d3a391e", "label": "摘要1072", "info": "Visin，F.，Kastner，K.，Cho，K.，Matteucci，M.，Courville，A.，and；Bengio，Y.（2015）.  ReNet:  A  recurrent  neural  network  based  alternative；to convolutional networks. arXiv preprint arXiv:1505.00393 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97f7aa3d-0179-4ff8-bbc4-550815db87a1", "label": "摘要1073", "info": "Von  Melchner，L.，Pallas，S.  L.，and  Sur，M.（2000）.  Visual；behaviour  mediated  by  retinal  projections  directed  to  the  auditory  pathway.；Nature ，404 （6780），871–876.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab4978a1-bc9b-4a45-b8c7-c49996fa7988", "label": "摘要1074", "info": "Wager，S.，Wang，S.，and  Liang，P.（2013）.  Dropout；training  as；adaptive  regularization.  In  Advances  in  Neural  Information  Processing", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "86102360-b560-46ff-9465-eda8caefc07f", "label": "摘要1075", "info": "Waibel，A.，Hanazawa，T.，Hinton，G.  E.，Shikano，K.，and  Lang，；K.（1989）.  Phoneme  recognition  using  time-delay  neural  networks.  IEEE；Transactions  on  Acoustics，Speech，and  Signal  Processing  ，37  ，328–", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9d7de1a4-0165-4651-b161-fe4fad796c90", "label": "摘要1076", "info": "Wan，L.，Zeiler，M.，Zhang，S.，LeCun，Y.，and；Fergus，R.；（2013）.  Regularization  of  neural  networks  using  dropconnect.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe450c1d-00ce-45b4-8670-672e772213d4", "label": "摘要1077", "info": "Wang，S. and Manning，C.（2013）. Fast dropout training. In ICML'2013；.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "775c122e-e1ef-4eb9-8174-15a1d467d300", "label": "摘要1078", "info": "Wang，Z.，Zhang，J.，Feng，J.，and  Chen，Z.（2014a）.  Knowledge；graph and text jointly embedding. In Proc. EMNLP'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8dd2ccee-9cd1-4c57-834b-39cff9413171", "label": "摘要1079", "info": "Wang，Z.，Zhang，J.，Feng，J.，and  Chen，Z.（2014b）.  Knowledge；graph embedding by translating on hyperplanes. In Proc. AAAI'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f21d608e-8f31-4794-b3c1-fdb1c87fafb3", "label": "摘要1080", "info": "Warde-Farley，D.，Goodfellow，I.  J.，Courville，A.，and  Bengio，Y.；（2014）. An empirical analysis of dropout in piecewise linear networks. In；ICL（1）.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "898b9b2b-dc7e-46de-9918-34270619aa6f", "label": "摘要1081", "info": "Wawrzynek，J.，Asanovic，K.，Kingsbury，B.，Johnson，D.，Beck，；J.，and  Morgan，N.（1996）.  Spert-II:  A  vector  microprocessor  system.；Computer ，29 （3），79–86.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1207a04d-2e0e-4cf4-991c-a24999a89d53", "label": "摘要1082", "info": "Weaver，L.  and  Tao，N.（2001）.  The  optimal  reward  baseline  for；gradient-based reinforcement learning. In Proc. UAI'2001 ，pages 538–545.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dbe7a91b-c1d8-48a6-8a45-8c5d6c04d5d1", "label": "摘要1083", "info": "Weinberger，K.  Q.  and  Saul，L.  K.（2004a）.  Unsupervised  learning  of；image  manifolds  by  semidefi-nite  programming.  In  Proceedings  of  the；Computer  Vision  and  Pattern  Recognition  Conference（CVPR'04）  ，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f730a274-5dd2-4a7d-a2d2-9f63a73a55c5", "label": "摘要1084", "info": "Weinberger，K.  Q.  and  Saul，L.  K.（2004b）.  Unsupervised  learning  of；image manifolds by semidefinite programming. In CVPR'2004 ，pages 988–；995.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "156bf1a8-457a-4029-b1be-b63d55ecf913", "label": "摘要1085", "info": "Weiss，Y.，Torralba，A.，and  Fergus，R.（2008）.  Spectral  hashing.  In；NIPS ，pages 1753–1760.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f74678ca-5499-499c-bfd9-02e5262f0e42", "label": "摘要1086", "info": "Welling，M.，Zemel，R. S.，and Hinton，G. E.（2002）. Self supervised；boosting.  In  Advances  in  Neural  Information  Processing  Systems  ，pages；665–672.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1381b32-35f4-4b50-873d-04bd70ea0249", "label": "摘要1087", "info": "Welling，M.，Hinton，G.  E.，and  Osindero，S.（2003a）.  Learning；sparse  topographic  representa-tions  with  products  of  Student-t  distributions.；In NIPS'2002 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "275776fc-53a1-49a4-8967-9028a0214f4d", "label": "摘要1088", "info": "Welling，M.，Zemel，R.，and  Hinton，G.  E.（2003b）.  Self-supervised；boosting.  In  S.  Becker，S.  Thrun，and  K.  Obermayer，editors，Advances；in Neural Information Processing Systems 15（NIPS'02） ，pages 665–672.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20712598-8eff-4cb4-af08-10fe5cce66c3", "label": "摘要1089", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；MIT Press.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d482a70-d99a-47e1-bb83-f132fb6ece68", "label": "摘要1090", "info": "Welling，M.，Rosen-Zvi，M.，and  Hinton，G.  E.（2005）.  Exponential；family harmoniums with an application to information retrieval. In L. Saul，；Y.  Weiss，and  L.  Bottou，editors，Advances", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccbb6a74-df09-4c61-bcf1-8b33045fbd72", "label": "摘要1091", "info": "Werbos，P.  J.（1981）.  Applications  of  advances  in  nonlinear  sensitivity；analysis.  In  Proceedings  of  the  10th  IFIP  Conference，31.8-4.9，NYC  ，；pages 762–770.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1a132ae4-431b-4728-9192-9722ed882ba0", "label": "摘要1092", "info": "Weston，J.，Bengio，S.，and  Usunier，N.（2010）.  Large  scale  image；annotation:  learning  to  rank  with  joint  word-image  embeddings.  Machine；Learning ，81 （1），21–35.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "33d9929e-4c17-4e5c-ad03-ac8a91eec7ac", "label": "摘要1093", "info": "Weston，J.，Chopra，S.，and  Bordes，A.（2014）.  Memory  networks.；arXiv preprint arXiv:1410.3916 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb71f547-c55c-4d22-9fff-10172bcc1cdf", "label": "摘要1094", "info": "Widrow，B.  and  Hoff，M.  E.（1960）.  Adaptive  switching  circuits.  In；1960 IRE WESCON Convention Record ，volume 4，pages 96–104. IRE，；New York.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a26a75d5-c24f-43f8-84a2-7bd290b0d77a", "label": "摘要1095", "info": "Wikipedia（2015）. List of animals by number of neurons—Wikipedia，the；free encyclopedia. ［Online；accessed 4-March-2015］.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8532a7f5-48d7-4185-8249-b9315bddb7e4", "label": "摘要1096", "info": "Williams，C. K. I. and Agakov，F. V.（2002）. Products of Gaussians and；Probabilistic  Minor  Component  Analysis.  Neural  Computation  ，14（5）；，1169–1182.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6468535-265c-401b-a3ca-94c4fcd4d79c", "label": "摘要1097", "info": "Williams，C. K. I. and Rasmussen，C. E.（1996）. Gaussian processes for；regression.  In  D.  Touretzky，M.  Mozer，and  M.  Hasselmo，editors，；Advances in Neural Information Processing Systems 8（NIPS'95） ，pages", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9d9b8ea1-6356-4df9-963e-b271ac3094c1", "label": "摘要1098", "info": "Williams，R.  J.（1992）.  Simple  statistical  gradient-following  algorithms；connectionist reinforcement learning. Machine Learning ，8 ，229–256.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2bfb912f-ffda-4116-a25b-32a4e43de36c", "label": "摘要1099", "info": "Williams，R.  J.  and  Zipser，D.（1989）.  A；learning  algorithm  for；continually running fully recurrent neural networks. Neural Computation ，1", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "75001a21-78e3-4beb-90a9-42105d8e0383", "label": "摘要1100", "info": "Wilson，D.  R.  and  Martinez，T.  R.（2003）.  The  general  inefficiency  of；batch training for gradient descent learning. Neural Networks ，16 （10），；1429–1451.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dfa48661-0c76-4e18-8052-69eaa4da0338", "label": "摘要1101", "info": "Wilson，J.  R.（1984）.  Variance；for  digital；simulation.  American  Journal  of  Mathematical  and  Management  Sciences", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "726ca841-ce78-41d3-9d7f-d6a98a8cfd24", "label": "摘要1102", "info": "techniques", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd5a48be-9f0e-4ac4-aa1c-8bcaeb7f8051", "label": "摘要1103", "info": "reduction", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "64237624-8b2a-41ca-a838-26a60b8d256b", "label": "摘要1104", "info": "Wiskott，L.  and  Sejnowski，T.  J.（2002）.  Slow  feature  analysis:；Unsupervised  learning  of  invari-ances.  Neural  Computation  ，14  （4），；715–770.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12f723cd-50b5-4dde-8bd5-e77030b046ff", "label": "摘要1105", "info": "Wolpert，D.  and  MacReady，W.（1997）.  No  free  lunch  theorems  for；optimization. IEEE Transactions on Evolutionary Computation ，1 ，67–82.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "183431b5-8035-4fea-ad58-98536ecf79c5", "label": "摘要1106", "info": "Wolpert，D. H.（1996）. The lack of a priori distinction between learning；algorithms. Neural Computation ，8 （7），1341–1390.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "76ca9a81-1f33-4dad-b209-a9dc7a4b88de", "label": "摘要1107", "info": "Wu，R.，Yan，S.，Shan，Y.，Dang，Q.，and  Sun，G.（2015）.  Deep；image: Scaling up image recognition. arXiv:1501.02876.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "37e1066b-b5ef-4219-ba2d-652aa9e967f8", "label": "摘要1108", "info": "Wu，Z.（1997）.  Global  continuation  for  distance  geometry  problems.；SIAM Journal of Optimization ，7 ，814–836.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d9ebd06-5cef-4059-bb80-ca3a7ac6b3b4", "label": "摘要1109", "info": "Xiong，H.  Y.，Barash，Y.，and  Frey，B.；J.（2011）.  Bayesian；prediction  of  tissue-regulated  splicing  using  RNA  sequence  and  cellular", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9616fb7c-eff6-4665-89ed-f2206617c612", "label": "摘要1110", "info": "L.，Kiros，R.，Cho，K.，Courville，A.，；Xu，K.，Ba，J.；Salakhutdinov，R.，Zemel，R.  S.，and  Bengio，Y.（2015）.  Show，", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e67608ab-dc55-4b3c-8a35-b2ff225b2693", "label": "摘要1111", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Yildiz，I.  B.，Jaeger，H.，and  Kiebel，S.  J.（2012）.  Re-visiting  the；echo state property. Neural networks ，35 ，1–9.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5743ea5-273e-4fd8-9622-504a3f2ac767", "label": "摘要1112", "info": "Yosinski，J.，Clune，J.，Bengio，Y.，and  Lipson，H.（2014）.  How；transferable are features in deep neural networks? In NIPS 27 ，pages 3320–；3328. Curran Associates，Inc.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "beaffc82-a022-49b9-99fb-e60497064165", "label": "摘要1113", "info": "Younes，L.（1998）.  On；the  convergence  of  Markovian  stochastic；algorithms  with  rapidly  decreasing  ergodicity  rates.  In  Stochastics  and", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b0058ca4-4f7e-4416-849d-19cc1cac57b0", "label": "摘要1114", "info": "Yu，D.，Wang，S.，and  Deng，L.（2010）.  Sequential  labeling  using；deep-structured conditional randomfields. IEEE Journal of Selected Topics in；Signal Processing .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dd2e606b-b05d-4b7e-bce7-b398a181d517", "label": "摘要1115", "info": "Zaremba，W.  and  Sutskever，I.（2014）.  Learning  to  execute.  arXiv；1410.4615.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e577d306-5927-4bf9-8590-07aa23159133", "label": "摘要1116", "info": "Zaremba，W.  and  Sutskever，I.（2015）.  Reinforcement  learning  neural；Turing machines. arXiv:1505.00521 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "15067f89-baa3-448d-9b20-6eb6c4c4a2a0", "label": "摘要1117", "info": "Zaslavsky，T.（1975）. Facing Up to Arrangements: Face-Count Formulas；for Partitions of Space by Hyperplanes . Number no. 154 in Memoirs of the；American Mathematical Society. American Mathematical Society.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a755eae-cc50-4e02-b019-3002e2f7ca40", "label": "摘要1118", "info": "Zeiler，M.  D.  and  Fergus，R.（2014）.  Visualizing  and  understanding；convolutional networks. In ECCV'14 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88500607-fc48-4ff6-bb86-e3df81184fdc", "label": "摘要1119", "info": "Zeiler，M. D.，Ranzato，M.，Monga，R.，Mao，M.，Yang，K.，Le，；Q.，Nguyen，P.，Senior，A.，Vanhoucke，V.，Dean，J.，and；Hinton，G.  E.（2013）.  On  rectified  linear  units  for  speech  processing.  In", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20c4efff-0ed7-4109-910c-69af340a07fa", "label": "摘要1120", "info": "Zhou，B.，Khosla，A.，Lapedriza，A.，Oliva，A.，and  Torralba，A.；（2015）.  Object  detectors  emerge  in  deep  scene  CNNs.  ICLR'2015，；arXiv:1412.6856.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66fb4be7-c7d1-4266-a9b6-67aec23bf61d", "label": "摘要1121", "info": "Zhou，J.  and  Troyanskaya，O.  G.（2014）.  Deep  supervised  and；convolutional  generative  stochastic  network  for  protein  secondary  structure；prediction. In ICML'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "164c0cc6-21dc-4cdb-bfb4-0939456b3551", "label": "摘要1122", "info": "Zhou，Y. and Chellappa，R.（1988）. Computation of opticalflow using a；International；neural  network.", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d809d30-76df-4993-8ad5-e2c25ee8b300", "label": "摘要1123", "info": "In  Neural  Networks，1988.，IEEE", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe18604e-04fd-4921-b85e-92fcf28bee98", "label": "摘要1124", "info": "Zöhrer，M.  and  Pernkopf，F.（2014）.  General  stochastic  networks  for；classification. In NIPS'2014 .", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edc5e95e-e95c-4cd0-a6c9-4d559bee5b6d", "label": "摘要1125", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；索引", "keywords": "索引", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d322aa7-6d6b-4de3-bef1-e4f92e832365", "label": "摘要1126", "info": "绝对值整流absolute value rectification", "keywords": "绝对值整流", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e42680d6-1535-48db-b0b0-dee70b7a8508", "label": "摘要1127", "info": "准确率accuracy", "keywords": "准确率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "128158c9-87a8-4422-bcf7-125f352a290e", "label": "摘要1128", "info": "声学acoustic", "keywords": "声学", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9db4d1d8-7a44-4873-8833-bde1815f0414", "label": "摘要1129", "info": "激活函数activation function", "keywords": "激活函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "451becc8-7b87-4c83-9bde-bccee35b65e3", "label": "摘要1130", "info": "AdaGrad AdaGrad", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f79f93bf-b19d-43d4-89c7-923010863a7e", "label": "摘要1131", "info": "对抗adversarial", "keywords": "对抗", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "59b97997-e889-4dd5-b94f-90170b953863", "label": "摘要1132", "info": "对抗样本adversarial example", "keywords": "对抗样本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d195153a-6f4a-49cf-a28e-aeb760cb40a7", "label": "摘要1133", "info": "对抗训练adversarial training", "keywords": "对抗训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e333382-c00a-4c96-887b-8f4e8eb1438a", "label": "摘要1134", "info": "几乎处处almost everywhere", "keywords": "几乎处处", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2552156-0d6e-4755-9305-6944d0bfa4c2", "label": "摘要1135", "info": "几乎必然almost sure", "keywords": "几乎必然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3fcc1c57-e04e-4cd6-bbda-750f5c0c086f", "label": "摘要1136", "info": "几乎必然收敛almost sure convergence", "keywords": "几乎必然收敛", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7a26165b-3389-4978-a6d3-0f1a2692943a", "label": "摘要1137", "info": "选择性剪接数据集alternative splicing dataset", "keywords": "选择性剪接数据集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5149ed10-e49f-4adc-ab92-3f0db7c3ae07", "label": "摘要1138", "info": "原始采样ancestral sampling", "keywords": "原始采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57490bff-14fe-4047-8b06-99b480dedd4d", "label": "摘要1139", "info": "退火重要采样annealed importance sampling", "keywords": "退火重要采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85f08b44-7666-4fd7-ac9b-4c36f5fb1e85", "label": "摘要1140", "info": "专用集成电路application-specific integrated circuit", "keywords": "专用集成电路", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "807ee459-9725-423e-8e81-cf54ba829ccb", "label": "摘要1141", "info": "近似贝叶斯计算approximate Bayesian computa-tion", "keywords": "近似贝叶斯计算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5e1dff5e-e3de-4e54-bbaa-ed7178ef6dfa", "label": "摘要1142", "info": "近似推断approximate inference", "keywords": "近似推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d6eb2243-fbe2-4efc-90e4-c1270d751966", "label": "摘要1143", "info": "架构architecture", "keywords": "架构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28df0e24-a26e-41d9-9a60-95f0732355fc", "label": "摘要1144", "info": "人工智能artificial intelligence", "keywords": "人工智能", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "82f4dea2-723c-4c9e-88dc-e7e5dcf9cde9", "label": "摘要1145", "info": "人工神经网络artificial neural network", "keywords": "人工神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "058c1c81-6aa1-46f2-8a89-5b54249bea7f", "label": "摘要1146", "info": "渐近无偏asymptotically unbiased", "keywords": "渐近无偏", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f54b6d6-0b49-44ec-ae5b-eff2a10145f0", "label": "摘要1147", "info": "异步随机梯度下降Asynchoronous Stochastic Gradient Descent", "keywords": "异步随机梯度下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e76c21b0-2eab-4ac2-90e7-37cf9c40704c", "label": "摘要1148", "info": "异步asynchronous", "keywords": "异步", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4ff280c-1b87-417c-afad-7711be087106", "label": "摘要1149", "info": "注意力机制attention mechanism", "keywords": "注意力机制", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca15bcf6-529e-4ff0-8f4f-ace3374bd8e7", "label": "摘要1150", "info": "属性attribute", "keywords": "属性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e705a7d5-9ed8-418f-a9dd-e67becf2bae6", "label": "摘要1151", "info": "自编码器autoencoder", "keywords": "自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b598962-40c3-4310-8c00-828d9ec8ca33", "label": "摘要1152", "info": "自动微分automatic differentiation", "keywords": "自动微分", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "016a74f2-ee4f-480f-aefd-660283351ec7", "label": "摘要1153", "info": "自动语音识别Automatic Speech Recognition", "keywords": "自动语音识别", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e557f109-7bb8-4c75-bd56-acaef2966248", "label": "摘要1154", "info": "自回归网络auto-regressive network", "keywords": "自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a88ec194-de86-4af4-beb4-bcee6da7c955", "label": "摘要1155", "info": "反向传播back propagation", "keywords": "反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2e6a7ed-7674-4f73-a549-5684a000bc85", "label": "摘要1156", "info": "回退back-off", "keywords": "回退", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c8314026-60ce-4a26-8cc7-480a47b51a43", "label": "摘要1157", "info": "反向传播backprop", "keywords": "反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff7f5256-dd82-4210-812f-2cc7a61e1931", "label": "摘要1158", "info": "通过时间反向传播back-propagation through time", "keywords": "通过时间反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "705c7fa5-314a-4ea2-a016-8d2342fa458e", "label": "摘要1159", "info": "词袋bag of words", "keywords": "词袋", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d86861d-0f3c-4c3e-b3c5-4ac97b901cfd", "label": "摘要1160", "info": "Bagging bootstrap aggregating", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11c8d981-91ca-4e82-8af2-52be20487c85", "label": "摘要1161", "info": "bandit bandit", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0431e440-7bfa-44e0-8c5d-18e4ec57954a", "label": "摘要1162", "info": "批量batch", "keywords": "批量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9098ac84-7ffe-4a43-b3b9-ebe5d14616c2", "label": "摘要1163", "info": "批标准化batch normalization", "keywords": "批标准化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92c37f1a-3465-4194-b6d3-c4cbcb254922", "label": "摘要1164", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；贝叶斯误差Bayes error", "keywords": "贝叶斯误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2cecc4a-3eca-420b-b437-6e815309eb22", "label": "摘要1165", "info": "贝叶斯规则Bayes' rule", "keywords": "贝叶斯规则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "72791cc5-3d20-43ba-aa49-2729722778ac", "label": "摘要1166", "info": "贝叶斯推断Bayesian inference", "keywords": "贝叶斯推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c6b199c-6ad5-4cdb-a2e1-b695aa7c917c", "label": "摘要1167", "info": "贝叶斯网络Bayesian network", "keywords": "贝叶斯网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6dbc039-d7e9-43af-9aeb-55fd6dc1cc1d", "label": "摘要1168", "info": "贝叶斯概率Bayesian probability", "keywords": "贝叶斯概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "17045df8-74cb-447b-8790-4f9943b886c6", "label": "摘要1169", "info": "贝叶斯统计Bayesian statistics", "keywords": "贝叶斯统计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "58809010-5e0d-4e4a-89a3-4ccd859f15fd", "label": "摘要1170", "info": "基准bechmark", "keywords": "基准", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0f31e5b4-2951-41ca-9ba1-0f83d8ac02cf", "label": "摘要1171", "info": "信念网络belief network", "keywords": "信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "385a4898-03d8-4ba8-93ec-0899c562e13a", "label": "摘要1172", "info": "Bernoulli分布Bernoulli distribution", "keywords": "分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc9b1e82-e880-43ff-bec6-063fc83d77f1", "label": "摘要1173", "info": "基准baseline", "keywords": "基准", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e26d4cd7-824b-41f6-93b0-1b886949c0d7", "label": "摘要1174", "info": "BFGS BFGS", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "359db781-64fa-4447-9a9b-537d79f20c9c", "label": "摘要1175", "info": "偏置bias in affine function", "keywords": "偏置", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed7d0b8a-bd7d-4e67-85c0-ac9b04b9daa6", "label": "摘要1176", "info": "偏差bias in statistics", "keywords": "偏差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "38cfb725-5132-4dd4-9846-8a95464354a2", "label": "摘要1177", "info": "有偏biased", "keywords": "有偏", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eba3d43f-3660-49eb-867c-25b5274544bb", "label": "摘要1178", "info": "有偏重要采样biased importance sampling", "keywords": "有偏重要采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9f0b961-6a43-46be-aaf8-d356061ad515", "label": "摘要1179", "info": "偏差biass", "keywords": "偏差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e710af3-ee28-49cd-9d24-f3e0483f37d6", "label": "摘要1180", "info": "二元语法bigram", "keywords": "二元语法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f4c96648-1a76-4f16-8771-9f19bc7cd500", "label": "摘要1181", "info": "二元关系binary relation", "keywords": "二元关系", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5c623f4e-db47-489f-a1f3-9e0328ba98df", "label": "摘要1182", "info": "二值稀疏编码binary sparse coding", "keywords": "二值稀疏编码", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "95e4c996-16bf-48cf-90cb-37954b3fa405", "label": "摘要1183", "info": "比特bit", "keywords": "比特", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "52286b28-d084-4f58-af78-73182186df30", "label": "摘要1184", "info": "块坐标下降block coordinate descent", "keywords": "块坐标下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a8e98371-4493-46c7-961b-f6f742586fe1", "label": "摘要1185", "info": "块吉布斯采样block Gibbs Sampling", "keywords": "块吉布斯采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1c40a9b-098d-4d24-80ee-ad93f68d09f3", "label": "摘要1186", "info": "玻尔兹曼分布Boltzmann distribution", "keywords": "玻尔兹曼分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb8b156e-ec6f-4895-b799-7e4209bd606b", "label": "摘要1187", "info": "玻尔兹曼机Boltzmann Machine", "keywords": "玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14153b41-771c-4348-abd9-05e7fc04ecfb", "label": "摘要1188", "info": "Boosting Boosting", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d86488ab-841c-4bab-a508-6209071c47ed", "label": "摘要1189", "info": "桥式采样bridge sampling", "keywords": "桥式采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c906d63-4917-4fa3-8135-67a7cfd29011", "label": "摘要1190", "info": "广播broadcasting", "keywords": "广播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6141f4a2-9224-48ab-b10d-06ea7c2841e6", "label": "摘要1191", "info": "磨合Burning-in", "keywords": "磨合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3a046cf-89f1-4d59-8c23-73a7dc4a025c", "label": "摘要1192", "info": "变分法calculus of variations", "keywords": "变分法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edd4b322-5595-4f1c-92d4-09cbe40213b8", "label": "摘要1193", "info": "容量capacity", "keywords": "容量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7f88d26-3fde-4929-9ebc-ce30e2de80ea", "label": "摘要1194", "info": "级联cascade", "keywords": "级联", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e572ad0b-d46f-4afa-8c95-41870aa49bce", "label": "摘要1195", "info": "灾难遗忘catastrophic forgetting", "keywords": "灾难遗忘", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "81168c6f-8381-41e4-bb0d-1123e85cf7e9", "label": "摘要1196", "info": "范畴分布categorical distribution", "keywords": "范畴分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd6074c9-73bd-4128-a027-f5de65f61ae1", "label": "摘要1197", "info": "因果因子causal factor", "keywords": "因果因子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d4a9da7b-69b0-41c3-bf84-f4a7bf854cfa", "label": "摘要1198", "info": "因果模型causal modeling", "keywords": "因果模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "644c4f4c-6796-4ddd-a1b9-1250cebd6b55", "label": "摘要1199", "info": "中心差分centered difference", "keywords": "中心差分", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2f34d07e-3939-42e6-a4f4-ecb770a924a2", "label": "摘要1200", "info": "中心极限定理central limit theorem", "keywords": "中心极限定理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d922e45-75b2-4f50-9ff4-5eea3f359414", "label": "摘要1201", "info": "链式法则chain rule", "keywords": "链式法则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed38fa4e-cb1a-4e15-9566-92c093c3d8ec", "label": "摘要1202", "info": "混沌chaos", "keywords": "混沌", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "665d4aae-9063-427b-b627-507788714f29", "label": "摘要1203", "info": "弦chord", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "65bdfd96-5953-447a-8b67-40a6ab3b95db", "label": "摘要1204", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；弦图chordal graph", "keywords": "弦图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c48e94e1-89ed-411b-92fb-44800cc6dcde", "label": "摘要1205", "info": "梯度截断clip gradient", "keywords": "梯度截断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6c63fd2d-c195-40f8-9443-d3f6cc1e788d", "label": "摘要1206", "info": "截断梯度clipping the gradient", "keywords": "截断梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a2f2662-16db-4c26-a6c6-339fe3a6d663", "label": "摘要1207", "info": "团clique", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "74fb2fe8-1f3f-44e1-8943-9211c516245b", "label": "摘要1208", "info": "团势能clique potential", "keywords": "团势能", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "919c3b7b-b234-48f4-90e9-907fbb7dcd1d", "label": "摘要1209", "info": "闭式解closed form solution", "keywords": "闭式解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc1eecfb-e787-4a42-a37e-840061e49772", "label": "摘要1210", "info": "级联coalesced", "keywords": "级联", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "73ba2ed9-f34e-4312-be95-35cafa1416fb", "label": "摘要1211", "info": "编码code", "keywords": "编码", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce94c54b-626c-4b6a-9111-a57cd921e533", "label": "摘要1212", "info": "协同过滤collaborativefiltering", "keywords": "协同过滤", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0c9a69f4-0c35-457b-bc8e-b789a1cc9329", "label": "摘要1213", "info": "列column", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e916494-6c71-4a3f-97cd-1bfe8ae57322", "label": "摘要1214", "info": "列空间column space", "keywords": "列空间", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92bdf2d3-8a4c-4e33-9f68-b5f023c504cb", "label": "摘要1215", "info": "共因common cause", "keywords": "共因", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57a9af35-0926-41c5-b6ef-e463c8c07645", "label": "摘要1216", "info": "完全图complete graph", "keywords": "完全图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d7a657c-ce9f-460f-98c3-19daf79989b7", "label": "摘要1217", "info": "复杂细胞complex cell", "keywords": "复杂细胞", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "603513fc-d87e-4ef3-afca-75dfb0ffaae5", "label": "摘要1218", "info": "计算图computational graph", "keywords": "计算图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ecf01cbd-1943-4199-9941-6e2d104425be", "label": "摘要1219", "info": "计算机视觉Computer Vision", "keywords": "计算机视觉", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "afc54294-1f8c-4c35-aa9d-c4578c661547", "label": "摘要1220", "info": "概念漂移concept drift", "keywords": "概念漂移", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbd0800b-7875-4b7e-b23f-4bfcd93aae4d", "label": "摘要1221", "info": "条件计算conditional computation", "keywords": "条件计算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "73c6bd4f-fd01-4ed3-8af7-c7287181fbba", "label": "摘要1222", "info": "条件概率conditional probability", "keywords": "条件概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11c0b39a-fb4f-430f-8e57-59f66153875e", "label": "摘要1223", "info": "条件独立的conditionally independent", "keywords": "条件独立的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97fea450-b370-41c6-b433-6534b6313b9e", "label": "摘要1224", "info": "共轭conjugate", "keywords": "共轭", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc9a7019-8fe8-4792-bdad-9bbe2e5c6928", "label": "摘要1225", "info": "共轭方向conjugate directions", "keywords": "共轭方向", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e7a2477-35e5-4a77-bed4-3f135eb9b4c9", "label": "摘要1226", "info": "共轭梯度conjugate gradient", "keywords": "共轭梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc08d2f2-2b6f-44cc-b071-47fa7ab094ab", "label": "摘要1227", "info": "联结主义connectionism", "keywords": "联结主义", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f4acc707-4b73-460b-9d9f-ffa54b7e6b93", "label": "摘要1228", "info": "一致性consistency", "keywords": "一致性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8f805c1d-3ead-48d2-96f3-4835658b6f95", "label": "摘要1229", "info": "约束优化constrained optimization", "keywords": "约束优化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc400681-df15-4541-991d-707e654a686a", "label": "摘要1230", "info": "特定环境下的独立context-specific independences", "keywords": "特定环境下的独立", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f23f9f62-9c34-4978-b5f2-ba0e055164d4", "label": "摘要1231", "info": "contextual bandit contextual bandit", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c280c8a8-935e-490b-8371-c41dbeade1e2", "label": "摘要1232", "info": "延拓法continuation method", "keywords": "延拓法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d940dd4-d77c-42e9-a921-605deb3ef6c2", "label": "摘要1233", "info": "收缩contractive", "keywords": "收缩", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e778fccf-75fb-49d2-9ef4-aba00a9042fd", "label": "摘要1234", "info": "收缩自编码器contractive autoencoder", "keywords": "收缩自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e5d805c-5bd3-4477-8660-4bd04daf050c", "label": "摘要1235", "info": "对比散度contrastive divergence", "keywords": "对比散度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a0aefb97-0675-4753-96c6-f67c1081dfa3", "label": "摘要1236", "info": "凸优化Convex optimization", "keywords": "凸优化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7d2a5e43-af9a-48ca-84a6-a4e0d00a7a69", "label": "摘要1237", "info": "卷积convolution", "keywords": "卷积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a8c11b0-f38a-4812-a0c1-dc5523f3bf70", "label": "摘要1238", "info": "卷积玻尔兹曼机Convolutional Boltzmann Machine", "keywords": "卷积玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b3c15777-378d-4c51-a6e7-6380087ca7a8", "label": "摘要1239", "info": "卷积网络convolutional net", "keywords": "卷积网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1fe7fd0b-5204-4dda-b9c3-67e885312c73", "label": "摘要1240", "info": "卷积神经网络convolutional neural network", "keywords": "卷积神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28a6f59b-0dab-45a6-b152-d63d49aef12b", "label": "摘要1241", "info": "坐标上升coordinate ascent", "keywords": "坐标上升", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "418555de-f51e-4508-957c-4a0abecdbc9b", "label": "摘要1242", "info": "坐标下降coordinate descent", "keywords": "坐标下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "03a0ad20-80fc-43b6-a72d-430884bde136", "label": "摘要1243", "info": "共父coparent", "keywords": "共父", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1dcf31fb-d5a7-4716-ba3b-d8a5c274275d", "label": "摘要1244", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；相关系数correlation", "keywords": "相关系数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3622099a-62e2-4965-9d89-389de822f9a3", "label": "摘要1245", "info": "代价cost", "keywords": "代价", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1a2b87e2-5628-42b5-aca1-a69fc606f1bc", "label": "摘要1246", "info": "代价函数cost function", "keywords": "代价函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "adf764a6-6cdc-47e3-a365-697de451f16b", "label": "摘要1247", "info": "协方差covariance", "keywords": "协方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "84a34988-e049-4b54-b831-74ec26700155", "label": "摘要1248", "info": "协方差矩阵covariance matrix", "keywords": "协方差矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e00e31f2-fbde-4ae5-b69c-f0efc53173b5", "label": "摘要1249", "info": "协方差RBM covariance RBM", "keywords": "协方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1401286-bf32-49ee-8ea3-33acbacca9bd", "label": "摘要1250", "info": "覆盖coverage", "keywords": "覆盖", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "576532b0-f96e-4d3c-8032-98c52485ffd9", "label": "摘要1251", "info": "准则criterion", "keywords": "准则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a67192b6-feb3-4c1e-afc4-ed7f2d1683c9", "label": "摘要1252", "info": "临界点critical point", "keywords": "临界点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d044677-9602-4fc9-bff2-4d836a770cbe", "label": "摘要1253", "info": "临界温度critical temperatures", "keywords": "临界温度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "86f1de81-a325-41b6-9e4f-93f72556b4be", "label": "摘要1254", "info": "互相关函数cross-correlation", "keywords": "互相关函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab13b952-9390-41ee-b16a-85270ce57c59", "label": "摘要1255", "info": "交叉熵cross-entropy", "keywords": "交叉熵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dffde187-a7d5-48d8-beee-ebe8589fbdf7", "label": "摘要1256", "info": "累积函数cumulative function", "keywords": "累积函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "19acc018-94a7-4d1f-9255-538d5d2566a4", "label": "摘要1257", "info": "课程学习curriculum learning", "keywords": "课程学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85982f77-43c2-4db4-a6f5-882065fa9cb0", "label": "摘要1258", "info": "维数灾难curse of dimensionality", "keywords": "维数灾难", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "13166cb8-94a4-4d30-b366-ad44979356c1", "label": "摘要1259", "info": "曲率curvature", "keywords": "曲率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bd1aaf40-a58e-40d4-8576-2fdb368749f7", "label": "摘要1260", "info": "控制论cybernetics", "keywords": "控制论", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20aedc7d-e174-474d-95c0-b297dfcdd7af", "label": "摘要1261", "info": "衰减damping", "keywords": "衰减", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5e72519c-ab27-481b-83dc-4e5024527c17", "label": "摘要1262", "info": "数据生成分布data generating distribution", "keywords": "数据生成分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e35a8901-a137-488e-a261-7f493ae653df", "label": "摘要1263", "info": "数据生成过程data generating process", "keywords": "数据生成过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a2c806b2-aed7-438a-a553-db25c4a5d36a", "label": "摘要1264", "info": "数据并行data parallelism", "keywords": "数据并行", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "159f5b03-2ae7-4181-b903-b1bce7793f38", "label": "摘要1265", "info": "数据点data point", "keywords": "数据点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "457944e8-2f0b-4e49-8247-0f002ffdf118", "label": "摘要1266", "info": "数据集dataset", "keywords": "数据集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9d95a4e1-b858-424c-a23e-f46ef4a049c9", "label": "摘要1267", "info": "数据集增强dataset augmentation", "keywords": "数据集增强", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0cd8fe1b-b740-4d25-b402-81a871b48b53", "label": "摘要1268", "info": "决策树decision tree", "keywords": "决策树", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "080c3a1d-12d0-47cd-ab61-b8bcabae9a48", "label": "摘要1269", "info": "解码器decoder", "keywords": "解码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c535ab6-b1f9-4f21-8e2b-ad2da112d9f3", "label": "摘要1270", "info": "分解decompose", "keywords": "分解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "de6c58f1-83a7-4bd2-a4ef-cb581324aa32", "label": "摘要1271", "info": "深度信念网络deep belief network", "keywords": "深度信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e9c99ef-fcb0-4418-a62c-13945e0f5e4c", "label": "摘要1272", "info": "深度玻尔兹曼机Deep Boltzmann Machine", "keywords": "深度玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cd150082-59bb-47ac-93ba-02181cb73bb8", "label": "摘要1273", "info": "深度回路deep circuit", "keywords": "深度回路", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c81e2af0-b83b-4d26-aede-76e0fbc28fa0", "label": "摘要1274", "info": "深度前馈网络deep feedforward network", "keywords": "深度前馈网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4f581a0c-87fb-45d6-8cf9-5f9bdf1888bd", "label": "摘要1275", "info": "深度生成模型deep generative model", "keywords": "深度生成模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "385b05c6-112e-4cd6-a77f-a5db04e0de0d", "label": "摘要1276", "info": "深度学习deep learning", "keywords": "深度学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ed4b385-eaf8-4c17-a701-15d0c7362974", "label": "摘要1277", "info": "深度模型deep model", "keywords": "深度模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "84c77f16-9f94-4112-a96a-e70ca8c364c2", "label": "摘要1278", "info": "深度网络deep network", "keywords": "深度网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf3350bb-c973-408e-b720-0010295958b6", "label": "摘要1279", "info": "点积dot product", "keywords": "点积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b4b2e6cf-b9b9-467c-9924-32aaebe1d184", "label": "摘要1280", "info": "双反向传播double backprop", "keywords": "双反向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e84fe2b-2376-4246-aea4-c440bd164764", "label": "摘要1281", "info": "双重分块循环矩阵doubly block circulant matrix", "keywords": "双重分块循环矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4eb4b1d9-d5af-49e6-b86d-accb01445ebf", "label": "摘要1282", "info": "降采样downsampling", "keywords": "降采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9dae7507-6d0d-492e-83dc-e508c4fa6b78", "label": "摘要1283", "info": "Dropout Dropout", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a1fa1364-f45b-4312-bddc-cf1ad36c3883", "label": "摘要1284", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Dropout Boosting Dropout Boosting", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a6f97d8-e14b-4923-b2b7-c4ab8d19649a", "label": "摘要1285", "info": "d-分离d-separation", "keywords": "分离", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0adbe0e8-34ef-4079-be16-24124cb934fe", "label": "摘要1286", "info": "动态规划dynamic programming", "keywords": "动态规划", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96853a33-564f-4d33-80ce-7ed3444b6c55", "label": "摘要1287", "info": "动态结构dynamic structure", "keywords": "动态结构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c099f31b-f2ee-4bdb-aabd-e0ff5d406e40", "label": "摘要1288", "info": "提前终止early stopping", "keywords": "提前终止", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "704bc8ed-3b93-45da-96a8-60a737f28512", "label": "摘要1289", "info": "回声状态网络echo state network", "keywords": "回声状态网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b51abb3-ad24-4f3b-9a21-e44ac977e4b6", "label": "摘要1290", "info": "有效容量effective capacity", "keywords": "有效容量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "56dd625c-d8ec-4572-9438-77220cf48e11", "label": "摘要1291", "info": "特征分解eigendecomposition", "keywords": "特征分解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f23c0aad-1f56-4dac-b10b-3f7088c4e366", "label": "摘要1292", "info": "特征值eigenvalue", "keywords": "特征值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39a68e24-a11e-4bfd-8ad4-fd306e4cffd2", "label": "摘要1293", "info": "特征向量eigenvector", "keywords": "特征向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4adc9ee9-68c2-408f-81ca-555e6c3871a9", "label": "摘要1294", "info": "基本单位向量elementary basis vectors", "keywords": "基本单位向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef080756-e911-4fc9-a238-b80ca85dc70c", "label": "摘要1295", "info": "元素对应乘积element-wise product", "keywords": "元素对应乘积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97643dbc-ef38-4b45-a507-c669f5e4460d", "label": "摘要1296", "info": "嵌入embedding", "keywords": "嵌入", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dad612e9-df4e-4063-8fea-7fcb2ceb945f", "label": "摘要1297", "info": "经验分布empirical distribution", "keywords": "经验分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "effb674d-e60c-47a4-8849-c02d1857c1ab", "label": "摘要1298", "info": "经验频率empirical frequency", "keywords": "经验频率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "83f329d7-94eb-44cd-995d-c0def461be43", "label": "摘要1299", "info": "经验风险empirical risk", "keywords": "经验风险", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e51d789-0907-4e0c-8316-7493f9626541", "label": "摘要1300", "info": "经验风险最小化empirical risk minimization", "keywords": "经验风险最小化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9313fad9-2dd6-4cbc-b26a-ce78052067ec", "label": "摘要1301", "info": "编码器encoder", "keywords": "编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d78c5c3c-d2f4-4236-bdee-a7df80563b37", "label": "摘要1302", "info": "端到端的end-to-end", "keywords": "端到端的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "33b288f3-0964-4d1f-b675-7c68e756910f", "label": "摘要1303", "info": "能量函数energy function", "keywords": "能量函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af352c58-09bc-4595-9528-4fba7cd0dc8d", "label": "摘要1304", "info": "基于能量的模型Energy-based model", "keywords": "基于能量的模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c0de949-9bcf-4d90-b16c-546a2787928c", "label": "摘要1305", "info": "集成ensemble", "keywords": "集成", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7ee9847-e999-48bc-b83e-da739ad9a045", "label": "摘要1306", "info": "集成学习ensemble learning", "keywords": "集成学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8f2f554-2dc1-46a9-bd55-94b093e702ea", "label": "摘要1307", "info": "轮epoch", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7f00c12-d54d-4c7c-8f59-2631fb81b818", "label": "摘要1308", "info": "轮数epochs", "keywords": "轮数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ffcabb1-bdad-4393-bbc6-43320f5d17be", "label": "摘要1309", "info": "等式约束equality constraint", "keywords": "等式约束", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc09b5f9-96de-4a40-8560-f48fa11b68aa", "label": "摘要1310", "info": "均衡分布Equilibrium Distribution", "keywords": "均衡分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1ab82a5-221b-41c3-9027-9aa32efbc406", "label": "摘要1311", "info": "等变equivariance", "keywords": "等变", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0da676e6-b739-4665-9bdf-6cd7dfa13bc3", "label": "摘要1312", "info": "等变表示equivariant representations", "keywords": "等变表示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21278d35-49b2-4c99-b2e4-1af552fcdb94", "label": "摘要1313", "info": "误差条error bar", "keywords": "误差条", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c7b624ec-ff72-464a-9d51-d397c12f288c", "label": "摘要1314", "info": "误差函数error function", "keywords": "误差函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ee7b898-022f-44d7-9969-dc93d7e314f8", "label": "摘要1315", "info": "误差度量error metric", "keywords": "误差度量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee3dca71-a951-406d-83ea-ccac095bda86", "label": "摘要1316", "info": "错误率error rate", "keywords": "错误率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cbcd238f-51bd-4665-8836-28b7f817427e", "label": "摘要1317", "info": "估计量estimator", "keywords": "估计量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e710d30-0429-418a-a9af-c0aed5e57990", "label": "摘要1318", "info": "欧几里得范数Euclidean norm", "keywords": "欧几里得范数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ffca7e3c-fcdd-45c9-89dd-b875080ea876", "label": "摘要1319", "info": "欧拉-拉格朗日方程Euler-Lagrange Equation", "keywords": "欧拉, 拉格朗日方程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "522d8dae-1df0-4403-be29-24542c914d25", "label": "摘要1320", "info": "证据下界evidence lower bound", "keywords": "证据下界", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8c157dd-2930-40b6-88b8-2cf47ba3c309", "label": "摘要1321", "info": "样本example", "keywords": "样本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e129053-1ac1-4ead-97a6-8fe7e46dbda9", "label": "摘要1322", "info": "额外误差excess error", "keywords": "额外误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5b7fa4fb-89b0-4959-83d5-2ad223410260", "label": "摘要1323", "info": "期望expectation", "keywords": "期望", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8acb3700-2385-4d07-acfc-ca7795f94792", "label": "摘要1324", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；期望最大化expectation maximization", "keywords": "期望最大化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce9d6107-8b55-4b52-8646-00fdb78767ff", "label": "摘要1325", "info": "E步expectation step", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6a77b45-9b0e-4334-9ce3-5cf8f91ae029", "label": "摘要1326", "info": "期望值expected value", "keywords": "期望值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c9fac61-e848-4370-875f-80855eb1c75a", "label": "摘要1327", "info": "经验experience，E", "keywords": "经验", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a0f8840-0d45-4c10-aa9d-41147a9c0486", "label": "摘要1328", "info": "专家网络expert network", "keywords": "专家网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "762873fc-aa76-444f-9472-b667cd2d1f8b", "label": "摘要1329", "info": "相消解释explaining away", "keywords": "相消解释", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff5ef79a-c2c6-482b-a318-e87ecde6b7c4", "label": "摘要1330", "info": "相消解释作用explaining away effect", "keywords": "相消解释作用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "825a1e0f-7fd6-4374-8795-f1b86dfa0342", "label": "摘要1331", "info": "解释因子explanatory factort", "keywords": "解释因子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "355f6b52-16a7-4874-a99a-f2266efc883d", "label": "摘要1332", "info": "梯度爆炸exploding gradient", "keywords": "梯度爆炸", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9cd56ef-3e45-4937-b745-baf80c8931d2", "label": "摘要1333", "info": "开发exploitation", "keywords": "开发", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55944ce0-d331-4903-afce-79fc89682be0", "label": "摘要1334", "info": "探索exploration", "keywords": "探索", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc315579-2032-474a-b8ec-7e8dcfdc696c", "label": "摘要1335", "info": "指数分布exponential distribution", "keywords": "指数分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "22c9ba36-3dfe-4fea-8633-8342f83ee9cb", "label": "摘要1336", "info": "因子factor", "keywords": "因子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "80e06a0d-e8fb-4701-8e76-ec254715eaec", "label": "摘要1337", "info": "因子分析factor analysis", "keywords": "因子分析", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b64f6179-02de-474d-b00f-369789cf1dac", "label": "摘要1338", "info": "因子图factor graph", "keywords": "因子图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc45dc65-536b-4038-b584-5cef9972f07c", "label": "摘要1339", "info": "因子factorial", "keywords": "因子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "522d31a4-97fe-49f0-a788-041c47454456", "label": "摘要1340", "info": "分解factorization", "keywords": "分解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8681e4b1-e1c4-4bfd-874c-fa5b804f8ca5", "label": "摘要1341", "info": "分解的factorized", "keywords": "分解的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8bc1e7a6-b2c6-4ce9-a780-55127d522fcd", "label": "摘要1342", "info": "变差因素factors of variation", "keywords": "变差因素", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab40dffe-c632-477b-bcd6-fd6a130c3a33", "label": "摘要1343", "info": "快速Dropout fast dropout", "keywords": "快速", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ca24d8a-7902-4452-b3b5-a9654e632c5b", "label": "摘要1344", "info": "快速持续性对比散度fast persistent contrastive di-vergence", "keywords": "快速持续性对比散度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7d1897e4-f327-4c75-ade1-8938507f87d9", "label": "摘要1345", "info": "可行feasible", "keywords": "可行", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c33f804-b7b3-4bd3-9ed1-db3057006121", "label": "摘要1346", "info": "特征feature", "keywords": "特征", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "466ce51a-18b1-4daa-83c0-06c1ba95c889", "label": "摘要1347", "info": "特征提取器feature extractor", "keywords": "特征提取器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2753c4b7-0e4a-4f61-9145-a7848f9af8a6", "label": "摘要1348", "info": "特征映射feature map", "keywords": "特征映射", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8f37d76-3bfa-4ae6-b09c-cc3bc690b772", "label": "摘要1349", "info": "特征选择feature selection", "keywords": "特征选择", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3bcab797-86d9-464a-be93-f69918967501", "label": "摘要1350", "info": "反馈feedback", "keywords": "反馈", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9641a442-95ad-43e3-8152-93e8be60ae7a", "label": "摘要1351", "info": "前向feedforward", "keywords": "前向", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2825f87-c670-42c2-b67a-b340be5119b3", "label": "摘要1352", "info": "前馈分类器feedforward classifier", "keywords": "前馈分类器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d24c8951-3b48-4eff-96fc-4bfb0824c34a", "label": "摘要1353", "info": "前馈网络feedforward network", "keywords": "前馈网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6dea9868-1934-448d-8e9a-c508591b8520", "label": "摘要1354", "info": "前馈神经网络feedforward neural network", "keywords": "前馈神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "314e103d-c0d6-44d1-9063-faee68ef4339", "label": "摘要1355", "info": "现场可编程门阵列field programmable gated array", "keywords": "现场可编程门阵列", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d2e02b17-6ce4-46a5-b1ea-8f7b61e0b735", "label": "摘要1356", "info": "精调fine-tune", "keywords": "精调", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5fde5693-3de4-487c-8ab7-b8ca970fd01f", "label": "摘要1357", "info": "精调fine-tuning", "keywords": "精调", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "653181f4-ac20-4ad1-8fe5-2b8f04568c78", "label": "摘要1358", "info": "有限差分finite difference", "keywords": "有限差分", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "606041fa-b4b1-49eb-9813-23b7f8da54dd", "label": "摘要1359", "info": "第一层first layer", "keywords": "第一层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "974422b4-647d-4d38-a2f3-f8829f419c2b", "label": "摘要1360", "info": "不动点方程fixed point equation", "keywords": "不动点方程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d9426ab-27fa-4855-b944-64e9dd42ab7d", "label": "摘要1361", "info": "定点运算fixed-point arithmetic", "keywords": "定点运算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5432390d-acf1-49fe-8118-37f46297ae1e", "label": "摘要1362", "info": "翻转flip", "keywords": "翻转", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9a0aba99-7dba-49dd-87e8-f10c9736f37e", "label": "摘要1363", "info": "浮点运算float-point arithmetic", "keywords": "浮点运算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c63820eb-95ef-4354-8243-2598a1a1af00", "label": "摘要1364", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；遗忘门forget gate", "keywords": "遗忘门", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e9b38d8-d765-4b30-aa65-7a751f356729", "label": "摘要1365", "info": "前向传播forward propagation", "keywords": "前向传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b23ec7f7-b55b-4786-92d6-d0be665711a7", "label": "摘要1366", "info": "傅里叶变换Fourier transform", "keywords": "傅里叶变换", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d47973ab-2f57-497b-9210-8037efa58a78", "label": "摘要1367", "info": "中央凹fovea", "keywords": "中央凹", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9d9d2a35-c446-4b96-b361-473fc410d0ec", "label": "摘要1368", "info": "自由能free energy", "keywords": "自由能", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "256a0320-0825-4a30-9c1b-6b9bda7c04af", "label": "摘要1369", "info": "频率派概率frequentist probability", "keywords": "频率派概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c447e33-cb95-4eb0-a03c-e280a2384c0d", "label": "摘要1370", "info": "频率派统计frequentist statistics", "keywords": "频率派统计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7daa4a7-ac27-4642-bc30-6f553e206afd", "label": "摘要1371", "info": "Frobenius范数Frobenius norm", "keywords": "范数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b1fe75c9-1417-43d3-b726-b0765917886e", "label": "摘要1372", "info": "F分数F-score", "keywords": "分数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2b3621d6-3ff7-44eb-9142-d2b31812beb4", "label": "摘要1373", "info": "全full", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c29b533c-b737-4c63-b5ba-31dd253469e6", "label": "摘要1374", "info": "泛函functional", "keywords": "泛函", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "899d6599-95a8-4a6e-b9b9-f5497cc7012d", "label": "摘要1375", "info": "泛函导数functional derivative", "keywords": "泛函导数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a47a457e-7bf9-4b6b-add1-128a5765ff59", "label": "摘要1376", "info": "Gabor函数Gabor function", "keywords": "函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e9441824-e9dd-4723-8df9-4a1f0344aa0b", "label": "摘要1377", "info": "Gamma分布Gamma distribution", "keywords": "分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a924ea2-2364-4a44-9721-73905a77bfa6", "label": "摘要1378", "info": "门控gated", "keywords": "门控", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccb05c79-417c-4763-afab-15a7f48bd94c", "label": "摘要1379", "info": "门控循环网络gated recurrent net", "keywords": "门控循环网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e426e107-8328-49fc-8c78-08e120615407", "label": "摘要1380", "info": "门控循环单元gated recurrent unit", "keywords": "门控循环单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcb43928-98fb-42c0-96a4-ea05d0d5aea5", "label": "摘要1381", "info": "门控RNN gated RNN", "keywords": "门控", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd8c4efd-737a-467c-95f9-dc95b94d2222", "label": "摘要1382", "info": "选通器gater", "keywords": "选通器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "efb26c0f-36b0-42d9-ae06-6d21a92e2caa", "label": "摘要1383", "info": "高斯分布Gaussian distribution", "keywords": "高斯分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1cc5393b-3ea4-47c1-80e1-3b118496c014", "label": "摘要1384", "info": "高斯核Gaussian kernel", "keywords": "高斯核", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2fc88d5c-0e73-433d-886e-88d522af1f25", "label": "摘要1385", "info": "高斯混合模型Gaussian Mixture Model", "keywords": "高斯混合模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f427fa8a-9f93-4b22-bafc-b374abafb935", "label": "摘要1386", "info": "高斯混合体Gaussian mixtures", "keywords": "高斯混合体", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d89ea583-4809-4c6e-a4f0-c518dac8374e", "label": "摘要1387", "info": "高斯输出分布Gaussian output distribution", "keywords": "高斯输出分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "36bf5f3d-af0d-4eab-b242-33dde4495c48", "label": "摘要1388", "info": "高斯RBM Gaussian RBM", "keywords": "高斯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "00f3a121-7ec0-4165-bdf5-5bf901962b5b", "label": "摘要1389", "info": "Gaussian-Bernoulli RBM Gaussian-Bernoulli RBM", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70a0e7d8-61f7-4fa5-be48-bab3600db531", "label": "摘要1390", "info": "通用GPU general purpose GPU", "keywords": "通用", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "05fe5470-0eb6-475e-bf19-503ca91f0f99", "label": "摘要1391", "info": "泛化generalization", "keywords": "泛化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e90e1a6-7251-44d4-a9ea-d9416dcf2465", "label": "摘要1392", "info": "泛化误差generalization error", "keywords": "泛化误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ad40cca-b865-41db-ba8c-808c7da41b6c", "label": "摘要1393", "info": "广义函数generalized function", "keywords": "广义函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "604a5da1-0530-42b9-9dda-19ec8d47d36f", "label": "摘要1394", "info": "广义Lagrange函数generalized Lagrange function", "keywords": "函数, 广义", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "568f7ffd-b49b-4c7b-a26b-9214e96af551", "label": "摘要1395", "info": "广义Lagrangian generalized Lagrangian", "keywords": "广义", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c5321565-9078-4bc7-8059-56ce67fe3ef0", "label": "摘要1396", "info": "广义伪似然generalized pseudolikelihood", "keywords": "广义伪似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d5574986-2710-4c65-9a44-1097462160b7", "label": "摘要1397", "info": "广义伪似然估计generalized pseudolikelihood esti-mator", "keywords": "广义伪似然估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ab0698b4-5805-453b-9770-4c228b2c6f27", "label": "摘要1398", "info": "广义得分匹配generalized score matching", "keywords": "广义得分匹配", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a6e74db-7bc3-40e4-8570-d984de726ac1", "label": "摘要1399", "info": "生成式对抗框架generative adversarial framework", "keywords": "生成式对抗框架", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b916287-b888-4f7d-8734-f6c65f8b3629", "label": "摘要1400", "info": "生成式对抗网络generative adversarial network", "keywords": "生成式对抗网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0fc28ad9-84f6-4f09-80a1-3262a0322304", "label": "摘要1401", "info": "生成模型generative model", "keywords": "生成模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ebe27db1-e1fa-4a87-bcb4-530eebfeff8d", "label": "摘要1402", "info": "生成式建模generative modeling", "keywords": "生成式建模", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2f95512d-8f34-4c26-938c-9a745ff56e2b", "label": "摘要1403", "info": "生成矩匹配网络generative moment matching net-work", "keywords": "生成矩匹配网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "222e48fa-582a-47ec-8ce5-08f9008f06d0", "label": "摘要1404", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；生成随机网络generative stochastic network", "keywords": "生成随机网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d09574b6-b3a8-4233-9351-882de99475e2", "label": "摘要1405", "info": "生成器网络generator network", "keywords": "生成器网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bcee3082-c06b-4b10-acbf-42d4bec8f28c", "label": "摘要1406", "info": "吉布斯分布Gibbs distribution", "keywords": "吉布斯分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b16996d1-0b70-4ae0-8b37-d1cc3f0b0ec8", "label": "摘要1407", "info": "Gibbs采样Gibbs Sampling", "keywords": "采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6dab18a1-06cd-471a-9bdc-af224f9081c2", "label": "摘要1408", "info": "吉布斯步数Gibbs steps", "keywords": "吉布斯步数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "75e4cec8-30d8-4c96-80a3-368060b3f418", "label": "摘要1409", "info": "全局对比度归一化Global contrast normalization", "keywords": "全局对比度归一化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "41d3a71c-c7de-470c-a15a-5b730b4370c9", "label": "摘要1410", "info": "全局极小值global minima", "keywords": "全局极小值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cd7abd56-f8c1-4e76-a3e4-2571db048096", "label": "摘要1411", "info": "全局最小点global minimum", "keywords": "全局最小点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ae4f58c-0ff0-480e-9fde-29930fb4241c", "label": "摘要1412", "info": "梯度gradient", "keywords": "梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "952d785e-1d83-43a9-9983-e88d04b51811", "label": "摘要1413", "info": "梯度上升gradient ascent", "keywords": "梯度上升", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff613971-e812-43e9-8d2c-a071c83bb4ab", "label": "摘要1414", "info": "梯度截断gradient clipping", "keywords": "梯度截断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1a657b95-4284-4336-8861-6d4bec7733ac", "label": "摘要1415", "info": "梯度下降gradient descent", "keywords": "梯度下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e86f6a6-4ada-42e5-86ba-838840f4a128", "label": "摘要1416", "info": "图模型graphical model", "keywords": "图模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9da0e8e2-4f52-42dd-b1cc-b87fb56b5846", "label": "摘要1417", "info": "图形处理器Graphics Processing Unit", "keywords": "图形处理器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "004a3492-6952-4a20-961f-04223b29d627", "label": "摘要1418", "info": "贪心greedy", "keywords": "贪心", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8bef7bf1-df33-42bf-a567-cc5a2ff5cc24", "label": "摘要1419", "info": "贪心算法greedy algorithm", "keywords": "贪心算法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9110e6c9-4e5e-4da8-bc9b-c4a8133da1f2", "label": "摘要1420", "info": "贪心逐层预训练greedy layer-wise pretraining", "keywords": "贪心逐层预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e64b3077-ea0d-48e0-ba6c-9b3c71e8ff04", "label": "摘要1421", "info": "贪心逐层训练greedy layer-wise training", "keywords": "贪心逐层训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f72659cc-bc6d-4ae7-bbc6-dd90675aa874", "label": "摘要1422", "info": "贪心逐层无监督预训练greedy layer-wise unsuper-vised pretraining", "keywords": "贪心逐层无监督预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a107161-ba65-427e-813f-9cf9a0a64ceb", "label": "摘要1423", "info": "贪心监督预训练greedy supervised pretraining", "keywords": "贪心监督预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af0f2238-c84c-42ab-8c5e-0660b1c04c3f", "label": "摘要1424", "info": "贪心无监督预训练greedy unsupervised pretraining", "keywords": "贪心无监督预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ae1a26c0-12b9-4184-b4c7-aee21d8a04a6", "label": "摘要1425", "info": "网格搜索grid search", "keywords": "网格搜索", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f42e5619-5c46-450a-b13f-56ac42cb779e", "label": "摘要1426", "info": "Hadamard乘积Hadamard product", "keywords": "乘积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "409341c1-3e0d-4b20-99a6-010a98bd0cb7", "label": "摘要1427", "info": "汉明距离Hamming distance", "keywords": "汉明距离", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f2995770-9253-4f01-84a9-841fcd9c949c", "label": "摘要1428", "info": "硬专家混合体hard mixture of experts", "keywords": "硬专家混合体", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fd297bf3-627e-407c-836e-f2305f8115ad", "label": "摘要1429", "info": "硬双曲正切函数hard tanh", "keywords": "硬双曲正切函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0179d15-acf6-411f-be4e-16860404187a", "label": "摘要1430", "info": "簧风琴harmonium", "keywords": "簧风琴", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6301b00-f856-4ad9-8247-5251590c297c", "label": "摘要1431", "info": "哈里斯链Harris Chain", "keywords": "哈里斯链", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9778a8a4-d52a-4b3c-9fae-3e67f3a46603", "label": "摘要1432", "info": "Helmholtz机Helmholtz machine", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ef1f3f5b-d91d-4d96-b380-a924190c8035", "label": "摘要1433", "info": "Hessian Hessian", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dcc45564-730b-49dd-9b57-3503c75389a5", "label": "摘要1434", "info": "异方差heteroscedastic", "keywords": "异方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c3b97151-46b9-4642-bc44-6436ff54ff40", "label": "摘要1435", "info": "隐藏层hidden layer", "keywords": "隐藏层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "06230ca4-1da2-4691-8cf4-d6431bfe5a6e", "label": "摘要1436", "info": "隐马尔可夫模型Hidden Markov Model", "keywords": "隐马尔可夫模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "20d203f7-cd60-4352-9805-db03b5616250", "label": "摘要1437", "info": "隐藏单元hidden unit", "keywords": "隐藏单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e545701-423a-4be2-a3e8-4ecc69e731a2", "label": "摘要1438", "info": "隐藏变量hidden variable", "keywords": "隐藏变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47fb45a2-46c4-451c-83f0-a08aee12b9fe", "label": "摘要1439", "info": "爬山hill climbing", "keywords": "爬山", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "06bbc378-41f6-40f7-ad99-eb59fa9534c1", "label": "摘要1440", "info": "超参数hyperparameter", "keywords": "超参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a488336-7a39-4cb8-a97c-c8ca2b2a20b0", "label": "摘要1441", "info": "超参数优化hyperparameter optimization", "keywords": "超参数优化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "78acb2f7-7b13-475f-8b63-c1b5f94d4f93", "label": "摘要1442", "info": "假设空间hypothesis space", "keywords": "假设空间", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e46e5ac-bdf9-4702-9fe8-7689d70c9a6b", "label": "摘要1443", "info": "同分布的identically distributed", "keywords": "同分布的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f8813c33-893a-4ea1-bd34-0c89610550f7", "label": "摘要1444", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；可辨认的identifiable", "keywords": "可辨认的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "565a0966-f90d-4c97-abba-27bb99237113", "label": "摘要1445", "info": "单位矩阵identity matrix", "keywords": "单位矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8858476-5f5b-48ab-bfce-bc45b128f897", "label": "摘要1446", "info": "独立同分布假设i.i.d. assumption", "keywords": "独立同分布假设", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66242d89-4da2-455c-8ee7-8104beb0a80d", "label": "摘要1447", "info": "病态ill conditioning", "keywords": "病态", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47a2caf2-9016-43ae-95fb-f4ea898ce8c4", "label": "摘要1448", "info": "不道德immorality", "keywords": "不道德", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc51bc1c-f092-4ddf-9d1b-b49d8fe2abdc", "label": "摘要1449", "info": "重要采样Importance Sampling", "keywords": "重要采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47267d48-4b7d-4361-b551-b54d27581a3f", "label": "摘要1450", "info": "相互独立的independent", "keywords": "相互独立的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14b43c9c-6530-40a7-b933-6b24a1cfa5d9", "label": "摘要1451", "info": "独立成分分析independent component analysis", "keywords": "独立成分分析", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bbc45329-148e-4180-8dc8-ff6aa86029df", "label": "摘要1452", "info": "独立同分布independent identically distributed", "keywords": "独立同分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "40c04833-159b-4a7a-81a9-2a9619a48ad3", "label": "摘要1453", "info": "独立子空间分析independent subspace analysis", "keywords": "独立子空间分析", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b43c6ff0-a16e-43f4-8203-91bd47a6b9c9", "label": "摘要1454", "info": "索引index of matrix", "keywords": "索引", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d63d2461-329b-4e97-9234-7c172b45eed9", "label": "摘要1455", "info": "不等式约束inequality constraint", "keywords": "不等式约束", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35c17a7e-9443-4dda-9f31-ffe90aeab733", "label": "摘要1456", "info": "推断inference", "keywords": "推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85e4264f-0842-420a-b66e-274c8478feb1", "label": "摘要1457", "info": "无限infinite", "keywords": "无限", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "624b0311-8d75-4c5e-a53c-52c397e4c99b", "label": "摘要1458", "info": "信息检索information retrieval", "keywords": "信息检索", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d1de8f4d-1d69-4444-af82-1b47fe5b2e9e", "label": "摘要1459", "info": "内积inner product", "keywords": "内积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a036b05-44f8-444a-933c-c32e8fa5e154", "label": "摘要1460", "info": "输入input", "keywords": "输入", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "67d0aeb9-84d2-404d-86fd-309bed264dac", "label": "摘要1461", "info": "输入分布input distribution", "keywords": "输入分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b304f81-3083-4aaf-a218-ccee4cb42d05", "label": "摘要1462", "info": "干预查询intervention query", "keywords": "干预查询", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f88c7e9d-0ef3-49d7-9471-41f709888833", "label": "摘要1463", "info": "不变invariant", "keywords": "不变", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "44d0c01c-194c-41ac-bc7e-3af691acbe9c", "label": "摘要1464", "info": "求逆invert", "keywords": "求逆", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "55009a27-d911-489c-8d24-9a0762b3253e", "label": "摘要1465", "info": "Isomap Isomap", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d9da2e0-2346-4c66-8287-edfad241bd40", "label": "摘要1466", "info": "各向同性isotropic", "keywords": "各向同性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "862d8eb3-d611-4b6e-b3f8-9f8e9d150c22", "label": "摘要1467", "info": "Jacobian Jacobian", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce5b0a7d-6554-47e7-87c0-4ac7599c62bb", "label": "摘要1468", "info": "Jacobian矩阵Jacobian matrix", "keywords": "矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f48da88e-a140-43de-a3d9-46b7beaf0140", "label": "摘要1469", "info": "联合概率分布joint probability distribution", "keywords": "联合概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "769efea4-d989-4c8f-9471-5fd84579d7e5", "label": "摘要1470", "info": "Karush-Kuhn-Tucker Karush-Kuhn-Tucker", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "69256b30-985b-4871-8414-41cac2707993", "label": "摘要1471", "info": "核函数kernel function", "keywords": "核函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6c00181-0f45-4b87-8eb1-acc91e968ce5", "label": "摘要1472", "info": "核机器kernel machine", "keywords": "核机器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5316de9-b894-403f-916b-18c58bb830d1", "label": "摘要1473", "info": "核方法kernel method", "keywords": "核方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7bff1dad-144c-4b3a-ad44-05fb8af1e3da", "label": "摘要1474", "info": "核技巧kernel trick", "keywords": "核技巧", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "319c36ab-d83f-414f-9526-6887cf7895ca", "label": "摘要1475", "info": "KL散度KL divergence", "keywords": "散度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8de2ca9a-8bce-480d-b152-e3b7afc2a89d", "label": "摘要1476", "info": "知识库knowledge base", "keywords": "知识库", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff72e8f6-d7ad-4bd6-bce7-ddcd846950f7", "label": "摘要1477", "info": "知识图谱knowledge graph", "keywords": "知识图谱", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "98a3ba25-3105-43b0-9045-5a81c3fe1f28", "label": "摘要1478", "info": "Krylov方法Krylov method", "keywords": "方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cf8a06d4-cbd4-4f82-98b6-e5b3b86c2282", "label": "摘要1479", "info": "KL散度Kullback-Leibler（KL） divergence", "keywords": "散度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce750b6c-1dd5-4301-9471-053f92de8950", "label": "摘要1480", "info": "标签label", "keywords": "标签", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bbda788a-35e4-460d-9ec8-3901311af43e", "label": "摘要1481", "info": "标注labeled", "keywords": "标注", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "605038bf-d0fb-4eab-b82c-8bd16add272f", "label": "摘要1482", "info": "拉格朗日乘子Lagrange multiplier", "keywords": "拉格朗日乘子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4558acd-63a9-41f7-8354-8768c942305d", "label": "摘要1483", "info": "语言模型language model", "keywords": "语言模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d38412a-b162-4993-8086-fa0bdc959b58", "label": "摘要1484", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Laplace分布Laplace distribution", "keywords": "分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "17214413-75f2-4a65-83a3-162c6c95ca7b", "label": "摘要1485", "info": "大学习步骤large learning step", "keywords": "大学习步骤", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8debcba4-b3c4-47c5-9603-df37c73c4a91", "label": "摘要1486", "info": "潜在latent", "keywords": "潜在", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "23f65169-9104-4a26-b381-d26b09697615", "label": "摘要1487", "info": "潜层latent layer", "keywords": "潜层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0ab4a2d2-2d03-4dbc-bd6f-8c8a405f09d1", "label": "摘要1488", "info": "潜变量latent variable", "keywords": "潜变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0ce80ba-c073-47b9-9b90-36da7b614a1f", "label": "摘要1489", "info": "大数定理Law of large number", "keywords": "大数定理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bbb88257-e88c-47f0-8173-8df97e14346f", "label": "摘要1490", "info": "逐层的layer-wise", "keywords": "逐层的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bae0deec-873c-44fa-a54f-a38322491ce5", "label": "摘要1491", "info": "L-BFGS L-BFGS", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d0568af9-feb5-4f84-b442-b261194b5510", "label": "摘要1492", "info": "渗漏整流线性单元Leaky ReLU", "keywords": "渗漏整流线性单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e6aa4ff-e7c8-458e-b47f-19a5b4c7feaa", "label": "摘要1493", "info": "渗漏单元leaky unit", "keywords": "渗漏单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3378ad1b-4ea5-4692-9ffd-f82a30e0ca8a", "label": "摘要1494", "info": "学成learned", "keywords": "学成", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "72df93a6-8cd9-4d41-8c33-d675dac1888d", "label": "摘要1495", "info": "学习近似推断learned approximate inference", "keywords": "学习近似推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0e66ca06-3568-4f76-9bd6-9891c84c7482", "label": "摘要1496", "info": "学习器learner", "keywords": "学习器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "241df6d4-9405-433e-ba29-445d29c5e220", "label": "摘要1497", "info": "学习率learning rate", "keywords": "学习率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4894a382-3a85-4ac8-9ace-d9c59029c79e", "label": "摘要1498", "info": "勒贝格可积Lebesgue-integrable", "keywords": "勒贝格可积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee9477a8-ee81-4f0f-a976-d1a38f89f6ea", "label": "摘要1499", "info": "左特征向量left eigenvector", "keywords": "左特征向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7be530b2-4f85-4a85-b332-9985caf252d4", "label": "摘要1500", "info": "左奇异向量left singular vector", "keywords": "左奇异向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "567e8c91-9be0-4b38-a525-2f4dd905229a", "label": "摘要1501", "info": "莱布尼兹法则Leibniz's rule", "keywords": "莱布尼兹法则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2758ff5e-98e4-408b-ba0b-81264e6eeae2", "label": "摘要1502", "info": "似然likelihood", "keywords": "似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc37ce4a-3590-418d-8721-ab1d1ef874a7", "label": "摘要1503", "info": "线搜索line search", "keywords": "线搜索", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2e533ab2-f9a5-40e5-b132-7f4b212ee086", "label": "摘要1504", "info": "线性自回归网络linear auto-regressive network", "keywords": "线性自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c9d7e90-0be9-47b8-b68e-bfdb8cb3ab19", "label": "摘要1505", "info": "线性分类器linear classifier", "keywords": "线性分类器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "faefc658-12c9-438b-9610-e4247e9e5aae", "label": "摘要1506", "info": "线性组合linear combination", "keywords": "线性组合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e5772138-52d7-4265-952c-9d81ab69cef9", "label": "摘要1507", "info": "线性相关linear dependence", "keywords": "线性相关", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9baa3057-0802-40d8-8b6f-c66561cb1e02", "label": "摘要1508", "info": "线性因子模型linear factor model", "keywords": "线性因子模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e268b32e-f90b-4418-a1b4-beba030b119d", "label": "摘要1509", "info": "线性模型linear model", "keywords": "线性模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "335a6acb-29dc-43a1-b3e1-d03e9183d1f0", "label": "摘要1510", "info": "线性回归linear regression", "keywords": "线性回归", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a6748eea-6421-436d-a63e-419318bbee26", "label": "摘要1511", "info": "线性阈值单元linear threshold units", "keywords": "线性阈值单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ea1c08e-d75a-425b-bd84-d6b760b04770", "label": "摘要1512", "info": "线性无关linearly independent", "keywords": "线性无关", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21b42025-b195-4758-b480-45fb4e6f6998", "label": "摘要1513", "info": "链接预测link prediction", "keywords": "链接预测", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66d6ce0b-76fe-4112-af8c-7cfdda2e640b", "label": "摘要1514", "info": "链接重要采样linked importance sampling", "keywords": "链接重要采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d9d3c12-5730-4962-8889-33986e1c49b8", "label": "摘要1515", "info": "Lipschitz Lipschitz", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb76f7f7-61e2-4a13-8a81-52938beef5fe", "label": "摘要1516", "info": "Lipschitz常数Lipschitz constant", "keywords": "常数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6066a442-8ad1-4dc0-bfcb-0d2363defef1", "label": "摘要1517", "info": "Lipschitz连续Lipschitz continuous", "keywords": "连续", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "21559909-c5ae-421d-915b-b62719ba4365", "label": "摘要1518", "info": "流体状态机liquid state machine", "keywords": "流体状态机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9f0cc0ce-0e40-4765-acbe-6025f7917531", "label": "摘要1519", "info": "局部条件概率分布local conditional probability dis-tribution", "keywords": "局部条件概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea94157f-e843-463a-8eb7-0cd5103fbbbf", "label": "摘要1520", "info": "局部不变性先验local constancy prior", "keywords": "局部不变性先验", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b0e0cfe2-e5d0-49c7-a514-8b8c5be5f0c7", "label": "摘要1521", "info": "局部对比度归一化local contrast normalization", "keywords": "局部对比度归一化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ed0117a1-b837-4848-ab1c-e168809248d2", "label": "摘要1522", "info": "局部下降local descent", "keywords": "局部下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "25e07d20-680c-4deb-98df-4c2a0830ef70", "label": "摘要1523", "info": "局部核local kernel", "keywords": "局部核", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "775a764b-19ff-454c-b7ad-22378d649432", "label": "摘要1524", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；局部极大值local maxima", "keywords": "局部极大值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3fde322-b066-4ee6-9c52-62975745e777", "label": "摘要1525", "info": "局部极大点local maximum", "keywords": "局部极大点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c59861e-5ea9-4ce2-9fd5-b524ff9c1772", "label": "摘要1526", "info": "局部极小值local minima", "keywords": "局部极小值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fa30dff0-d616-40b5-b43b-cde3c38a05ef", "label": "摘要1527", "info": "局部极小点local minimum", "keywords": "局部极小点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9a553420-1b51-4595-8888-b82e9cae5977", "label": "摘要1528", "info": "对数尺度logarithmic scale", "keywords": "对数尺度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a9680564-f5a7-49cd-812d-d7b469c571d6", "label": "摘要1529", "info": "逻辑回归logistic regression", "keywords": "逻辑回归", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "91aaeca0-19e1-46df-8339-6ddf90479943", "label": "摘要1530", "info": "logistic sigmoid logistic sigmoid", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "76ea4f77-ada9-4710-b1ed-971698b3f353", "label": "摘要1531", "info": "分对数logit", "keywords": "分对数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8e6d8b78-fd2c-44f4-b5de-99a171643fc3", "label": "摘要1532", "info": "对数线性模型log-linear model", "keywords": "对数线性模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6155dc6-e709-4bdf-831a-b105a8199eae", "label": "摘要1533", "info": "长短期记忆long short-term memory", "keywords": "长短期记忆", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "105e0fad-ec76-4d3a-b3d7-12637f5ab6cf", "label": "摘要1534", "info": "长期依赖long-term dependency", "keywords": "长期依赖", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "128a21d3-8b0a-44b4-94d7-51b82686e2db", "label": "摘要1535", "info": "环loop", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4092d535-e00a-4035-94ff-6ed12a0d3337", "label": "摘要1536", "info": "环状信念传播loopy belief propagation", "keywords": "环状信念传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "47525475-a23d-401e-b91d-2c323c2ef40e", "label": "摘要1537", "info": "损失loss", "keywords": "损失", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5ffca0d-c6e7-4676-912f-a98a6cdd9cc7", "label": "摘要1538", "info": "损失函数loss function", "keywords": "损失函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "19721281-36e3-41e9-9de4-fa3387dfeead", "label": "摘要1539", "info": "机器学习machine learning", "keywords": "机器学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3a092b7a-33e0-4f73-ad0f-27c21b04cf8a", "label": "摘要1540", "info": "机器学习模型machine learning model", "keywords": "机器学习模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2fd0e46-da3d-454d-8df9-c48c5f14a4d4", "label": "摘要1541", "info": "机器翻译machine translation", "keywords": "机器翻译", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d6e24181-ce8d-4ec6-ba7f-dcab842db894", "label": "摘要1542", "info": "主对角线main diagonal", "keywords": "主对角线", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac5e6c3a-1ff9-499b-993c-2f771bc72418", "label": "摘要1543", "info": "流形manifold", "keywords": "流形", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "63daa044-060a-4da2-8a0c-dcbc48f47378", "label": "摘要1544", "info": "流形假设manifold hypothesis", "keywords": "流形假设", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2967f092-bc2c-4f45-b738-a211ce1fb56f", "label": "摘要1545", "info": "流形学习manifold learning", "keywords": "流形学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e81e2b3-c3fe-4ef6-b3c9-d0abf7a832b6", "label": "摘要1546", "info": "边缘概率分布marginal probability distribution", "keywords": "边缘概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d64ec4bb-ac48-4aa8-a6ed-26c83e19c628", "label": "摘要1547", "info": "马尔可夫链Markov Chain", "keywords": "马尔可夫链", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a56c5e14-632a-49df-9f47-ac0ecfd18f7d", "label": "摘要1548", "info": "马尔可夫链蒙特卡罗Markov Chain Monte Carlo", "keywords": "马尔可夫链蒙特卡罗", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b97ca494-a664-48f5-9533-8b7b5baa9ca8", "label": "摘要1549", "info": "马尔可夫网络Markov network", "keywords": "马尔可夫网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6f5348f9-2882-4445-be86-8fd6b3d2d687", "label": "摘要1550", "info": "马尔可夫随机场Markov randomfield", "keywords": "马尔可夫随机场", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "16f16947-5a57-4c13-a182-add81e6e91c7", "label": "摘要1551", "info": "掩码mask", "keywords": "掩码", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a5338acd-8b68-439b-8d83-f3cd38eb9247", "label": "摘要1552", "info": "矩阵matrix", "keywords": "矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca3500e7-7d1b-48d5-8941-fecbc73be5e6", "label": "摘要1553", "info": "矩阵逆matrix inversion", "keywords": "矩阵逆", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "205ebbbc-e115-4093-88e2-55c5e9cd3e18", "label": "摘要1554", "info": "矩阵乘积matrix product", "keywords": "矩阵乘积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c04b3a70-4f96-4fcb-a90f-356f427577ca", "label": "摘要1555", "info": "最大范数max norm", "keywords": "最大范数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c282d0fe-9952-4c15-be67-74e338fbd30f", "label": "摘要1556", "info": "池pool", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ce548fc-24a9-46fc-bb5e-376631d4c9b0", "label": "摘要1557", "info": "最大池化max pooling", "keywords": "最大池化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "feb57ed2-71b3-465f-ada5-894e5c5f1d76", "label": "摘要1558", "info": "极大值maxima", "keywords": "极大值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "80f465b8-490b-434a-b7d1-5bb5378d9348", "label": "摘要1559", "info": "M步maximization step", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "88a84a02-aef4-4041-b642-6cbbada04da8", "label": "摘要1560", "info": "最大后验Maximum A Posteriori", "keywords": "最大后验", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7366b26-1315-4b76-af6b-30048a35062e", "label": "摘要1561", "info": "最大似然maximum likelihood", "keywords": "最大似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "258169be-e5cd-4a51-a3cd-d71b4c4b2217", "label": "摘要1562", "info": "最大似然估计maximum likelihood estimation", "keywords": "最大似然估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eef4c550-e929-4ca4-8ce9-776c2886a191", "label": "摘要1563", "info": "最大平均偏差maximum mean discrepancy", "keywords": "最大平均偏差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a9a7d17-03fe-4ea3-abb8-4280be134639", "label": "摘要1564", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；maxout maxout", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d92f8434-2100-400b-91b2-a1b09a079e7e", "label": "摘要1565", "info": "maxout单元maxout unit", "keywords": "单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce5a9e14-06ad-4761-be11-a429c91cc204", "label": "摘要1566", "info": "平均绝对误差mean absolute error", "keywords": "平均绝对误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "516f1984-8827-4e44-a6a2-36c3b2009b51", "label": "摘要1567", "info": "均值和协方差RBM mean and covariance RBM", "keywords": "均值和协方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fc15a1eb-171f-4c56-98af-a53cbb2aee0b", "label": "摘要1568", "info": "学生t 分布均值乘积mean product of Student t-distribution", "keywords": "分布均值乘积, 学生", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "65e69479-1de8-4ad7-8d3c-2d94b5c2de41", "label": "摘要1569", "info": "均方误差mean squared error", "keywords": "均方误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66af8373-81d8-42c0-938f-e0db6bbcb936", "label": "摘要1570", "info": "均值-协方差RBM mean-covariance restricted Boltzmann machine", "keywords": "协方差, 均值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35380496-eec9-4cf6-b17e-e601d61c87f8", "label": "摘要1571", "info": "均匀场meanfield", "keywords": "均匀场", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "938db7f6-b142-442d-8eec-49e8a98c6f9f", "label": "摘要1572", "info": "均值场mean-field", "keywords": "均值场", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6435011-8ed8-403d-8e0e-e2bbb44ebb09", "label": "摘要1573", "info": "测度论measure theory", "keywords": "测度论", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e204fe6-306f-45aa-a711-56239cae04e6", "label": "摘要1574", "info": "零测度measure zero", "keywords": "零测度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eeabfe2c-3f87-437c-b7e4-cd027580794f", "label": "摘要1575", "info": "记忆网络memory network", "keywords": "记忆网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac497737-f7ae-4923-8ff7-e72857f18f75", "label": "摘要1576", "info": "信息传输message passing", "keywords": "信息传输", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb0eb814-4abe-4bcf-a147-476341618a8a", "label": "摘要1577", "info": "小批量minibatch", "keywords": "小批量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3714a163-582a-4073-ae4d-7de03bfd1070", "label": "摘要1578", "info": "小批量随机minibatch stochastic", "keywords": "小批量随机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "743e1a98-4cd2-4f67-b2e4-32c50fcd3b56", "label": "摘要1579", "info": "极小值minima", "keywords": "极小值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d15a0a0-6def-4106-85b2-8c652320091d", "label": "摘要1580", "info": "极小点minimum", "keywords": "极小点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "26c04c4c-0c91-4730-94b5-a2ddedbc5fda", "label": "摘要1581", "info": "混合Mixing", "keywords": "混合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "97baf3f3-1527-4152-b9ff-9d3694fb35fa", "label": "摘要1582", "info": "混合时间Mixing Time", "keywords": "混合时间", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7b46a51d-3a3b-4295-8ff5-cb31af259d03", "label": "摘要1583", "info": "混合密度网络mixture density network", "keywords": "混合密度网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1fa629e-98d2-4482-9682-fed92bc0a28d", "label": "摘要1584", "info": "混合分布mixture distribution", "keywords": "混合分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0912ab4e-7e1b-40ab-8cb6-354e62c30acf", "label": "摘要1585", "info": "专家混合体mixture of experts", "keywords": "专家混合体", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "39dff148-90c8-4cd0-a84f-922ac9f316cc", "label": "摘要1586", "info": "模态modality", "keywords": "模态", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e20e30f3-926d-40dd-bfeb-bd97258d3a5a", "label": "摘要1587", "info": "峰值mode", "keywords": "峰值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f51895e1-9ce1-420e-a4bf-3e0aff38c5a2", "label": "摘要1588", "info": "模型model", "keywords": "模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "27feb271-c8d6-4a0a-bba6-b2ae08185f86", "label": "摘要1589", "info": "模型平均model averaging", "keywords": "模型平均", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c840ce4-a100-4f52-8e50-baa326457938", "label": "摘要1590", "info": "模型压缩model compression", "keywords": "模型压缩", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "529fbfe3-615c-476f-8094-c9cf66bbcc5c", "label": "摘要1591", "info": "模型可辨识性model identifiability", "keywords": "模型可辨识性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a509cb84-7e1c-49ba-9998-58e16a65eb96", "label": "摘要1592", "info": "模型并行model parallelism", "keywords": "模型并行", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57bdb80a-dae9-4bbc-b4eb-888811674821", "label": "摘要1593", "info": "矩moment", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0662df5-7532-496e-ad50-0725aec70aa8", "label": "摘要1594", "info": "矩匹配moment matching", "keywords": "矩匹配", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe7f0dc9-342d-4f21-876d-7f12934e8301", "label": "摘要1595", "info": "动量momentum", "keywords": "动量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96c35b43-790f-4ddf-9ddc-7127393641a4", "label": "摘要1596", "info": "蒙特卡罗Monte Carlo", "keywords": "蒙特卡罗", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b2cf249d-4ad3-4439-a2d5-d55651e494e0", "label": "摘要1597", "info": "Moore-Penrose伪逆Moore-Penrose pseudoinverse", "keywords": "伪逆", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b7121c0b-6c7d-4e62-b7eb-35e06bfc867d", "label": "摘要1598", "info": "道德化moralization", "keywords": "道德化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d82c075-3198-4327-88e1-443e048a1bcf", "label": "摘要1599", "info": "道德图moralized graph", "keywords": "道德图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bc07046a-27ff-49d2-8eaf-4a8537faa19d", "label": "摘要1600", "info": "多层感知机multilayer perceptron", "keywords": "多层感知机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6b8d1df-883c-4d4d-ad15-74555106d167", "label": "摘要1601", "info": "多峰值multimodal", "keywords": "多峰值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3ad1d48b-e46f-4518-9602-6e65ad3243e4", "label": "摘要1602", "info": "多模态学习multimodal learning", "keywords": "多模态学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e5903ed-599e-442c-8b3d-ac686d8f6324", "label": "摘要1603", "info": "多项式分布multinomial distribution", "keywords": "多项式分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57ca71c3-edad-4a7b-9a5c-72f25617407e", "label": "摘要1604", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；Multinoulli分布multinoulli distribution", "keywords": "分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "471f4214-49a1-4ca1-b538-031c384ffe31", "label": "摘要1605", "info": "多预测深度玻尔兹曼机multi-prediction deep Boltzmann machine", "keywords": "多预测深度玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5caf4c26-d894-454e-9315-dedeefdbd233", "label": "摘要1606", "info": "多任务学习multitask learning", "keywords": "多任务学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0b3f182-4ff2-46c2-9177-309d00afabb6", "label": "摘要1607", "info": "多维正态分布multivariate normal distribution", "keywords": "多维正态分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7c85e29-ec03-44a1-ba5b-0f41304e811b", "label": "摘要1608", "info": "朴素贝叶斯naive Bayes", "keywords": "朴素贝叶斯", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ded5b7f1-92b4-4542-bf1b-d0650bc0205b", "label": "摘要1609", "info": "奈特nats", "keywords": "奈特", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "683723d0-d7e5-4623-b195-ce71a41398aa", "label": "摘要1610", "info": "自然语言处理Natural Language Processing", "keywords": "自然语言处理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a5121dd4-5d93-432c-9ec5-1cfcc57c7455", "label": "摘要1611", "info": "最近邻nearest neighbor", "keywords": "最近邻", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5242c2df-e48b-4e17-b1d5-38b8102fbc98", "label": "摘要1612", "info": "最近邻图nearest neighbor graph", "keywords": "最近邻图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f6fbbb58-5086-49ea-bd98-1eaa0e4263e4", "label": "摘要1613", "info": "最近邻回归nearest neighbor regression", "keywords": "最近邻回归", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b3114a9-7014-40af-b7af-77e9f299535d", "label": "摘要1614", "info": "负定negative definite", "keywords": "负定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b89b411a-d16d-4158-9ee3-f050075e8e2c", "label": "摘要1615", "info": "负部函数negative part function", "keywords": "负部函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fb39a21d-1cad-46e6-b3df-caccf77acdd2", "label": "摘要1616", "info": "负相negative phase", "keywords": "负相", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "11b8fe08-ba4d-43a0-88ba-badd98ffc5e8", "label": "摘要1617", "info": "半负定negative semidefinite", "keywords": "半负定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b2354b3-3cd4-4154-9198-cc0ace6d14f8", "label": "摘要1618", "info": "Nesterov动量Nesterov momentum", "keywords": "动量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "67ccac61-2221-4477-aa31-3558e2054a8d", "label": "摘要1619", "info": "网络network", "keywords": "网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9bffa16d-cda6-4931-a650-85b5bab393cb", "label": "摘要1620", "info": "神经自回归密度估计器neural auto-regressive den-sity estimator", "keywords": "神经自回归密度估计器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1cf169a8-f892-4454-9751-6c91c71d9d15", "label": "摘要1621", "info": "神经自回归网络neural auto-regressive network", "keywords": "神经自回归网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5ea5561e-8689-4989-a2d8-43dbd396b194", "label": "摘要1622", "info": "神经语言模型Neural Language Model", "keywords": "神经语言模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a735b09-78aa-40a3-b1d6-0d6b8c813d99", "label": "摘要1623", "info": "神经机器翻译Neural Machine Translation", "keywords": "神经机器翻译", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eb87b5f2-3ec4-4e47-8578-3e9163b0655d", "label": "摘要1624", "info": "神经网络neural network", "keywords": "神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7e83a51b-769e-407b-97ba-299a51990aa4", "label": "摘要1625", "info": "神经网络图灵机neural Turing machine", "keywords": "神经网络图灵机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b08ed6ca-14e9-4620-9e01-3d5254b15550", "label": "摘要1626", "info": "牛顿法Newton's method", "keywords": "牛顿法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a6caad88-aad8-4ffd-8bd1-be9ddd37515c", "label": "摘要1627", "info": "n -gram n-gram", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "647937b4-866a-4029-9b2d-ead3f42b712a", "label": "摘要1628", "info": "没有免费午餐定理no free lunch theorem", "keywords": "没有免费午餐定理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aec3cdea-59a9-4bbb-9fb4-9299d79041d6", "label": "摘要1629", "info": "噪声noise", "keywords": "噪声", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b746bfa-b218-475e-9108-ec9fe559b19c", "label": "摘要1630", "info": "噪声分布noise distribution", "keywords": "噪声分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b77b272c-7bfe-4546-8b7b-70d1846af913", "label": "摘要1631", "info": "噪声对比估计noise-contrastive estimation", "keywords": "噪声对比估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92dea853-e313-4270-b343-cd5d06f9ddee", "label": "摘要1632", "info": "非凸nonconvex", "keywords": "非凸", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c216be8e-226d-422f-9323-50c6af3f9a72", "label": "摘要1633", "info": "非分布式nondistributed", "keywords": "非分布式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8628fc0b-4fac-4b7f-b48c-2953f499cbf6", "label": "摘要1634", "info": "非分布式表示nondistributed representation", "keywords": "非分布式表示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e87acf29-a458-4bf8-ad83-29ce92ee92bd", "label": "摘要1635", "info": "非线性共轭梯度nonlinear conjugate gradients", "keywords": "非线性共轭梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "865522ab-7801-4c92-a2eb-ead7b314430b", "label": "摘要1636", "info": "非线性独立成分估计nonlinear independent com-ponents estimation", "keywords": "非线性独立成分估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "49a2cc76-36c0-4fe1-921e-70f60f69efb9", "label": "摘要1637", "info": "非参数non-parametric", "keywords": "非参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6f906b8-60b8-4d52-a831-658a1d8021fb", "label": "摘要1638", "info": "范数norm", "keywords": "范数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "564ae929-485f-4baf-ae4f-de7a41c591ca", "label": "摘要1639", "info": "正态分布normal distribution", "keywords": "正态分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4dd16764-87ed-42af-ae56-b45271b119be", "label": "摘要1640", "info": "正规方程normal equation", "keywords": "正规方程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f51eef40-f5cd-4d02-b3f3-23b3a19e9ea3", "label": "摘要1641", "info": "归一化的normalized", "keywords": "归一化的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "db11534a-40d2-4444-82c0-2e4e2b6607a7", "label": "摘要1642", "info": "标准初始化normalized initialization", "keywords": "标准初始化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a94530c5-66f6-443d-8bb0-2a99f2690e29", "label": "摘要1643", "info": "数值numeric value", "keywords": "数值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e77fe044-84ba-444c-8644-1526553050f4", "label": "摘要1644", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；数值优化numerical optimization", "keywords": "数值优化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "edf997a9-2ce6-4e38-9a80-2305a7861122", "label": "摘要1645", "info": "对象识别object recognition", "keywords": "对象识别", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6ca691ca-b35b-4698-96a1-6d9b7de2cc3d", "label": "摘要1646", "info": "目标objective", "keywords": "目标", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90adb395-a161-4fd7-b265-33dd07c54cf4", "label": "摘要1647", "info": "目标函数objective function", "keywords": "目标函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "85182979-3c63-442d-abac-95293e9ebcd2", "label": "摘要1648", "info": "奥卡姆剃刀Occam's razor", "keywords": "奥卡姆剃刀", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac5b4fe6-1502-49fe-937b-25078143fb07", "label": "摘要1649", "info": "one-hot one-hot", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e1a5e39c-7441-47da-b37a-741f4decd945", "label": "摘要1650", "info": "一次学习one-shot learning", "keywords": "一次学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb0294c5-9b5d-4d20-859c-ccb82d4a4efb", "label": "摘要1651", "info": "在线online", "keywords": "在线", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46f78876-4c0e-40f9-9e5e-3841b8da6373", "label": "摘要1652", "info": "在线学习online learning", "keywords": "在线学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1df0f1f3-327d-4607-8227-e55db3c005de", "label": "摘要1653", "info": "操作operation", "keywords": "操作", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1563b5c6-7506-4399-9fdc-35a2ea7730c3", "label": "摘要1654", "info": "最佳容量optimal capacity", "keywords": "最佳容量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c83259e-9dff-44a9-bf40-8cbfc2e6b7ae", "label": "摘要1655", "info": "原点origin", "keywords": "原点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2443185e-41c6-4411-8622-1d348f730ddf", "label": "摘要1656", "info": "正交orthogonal", "keywords": "正交", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1bdcfc52-63be-404c-9dce-4b627a44226f", "label": "摘要1657", "info": "正交矩阵orthogonal matrix", "keywords": "正交矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7eb36de6-a3b4-444a-96c7-797a2de26b4f", "label": "摘要1658", "info": "标准正交orthonormal", "keywords": "标准正交", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "216e45d6-9d8f-47e0-99f8-ff2d024ae104", "label": "摘要1659", "info": "输出output", "keywords": "输出", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c279ba7e-c90d-4069-9e62-cc98e7094499", "label": "摘要1660", "info": "输出层output layer", "keywords": "输出层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8c32cfdd-b2da-46f0-9d5c-b96279bf32ae", "label": "摘要1661", "info": "过完备overcomplete", "keywords": "过完备", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b23dfdec-ddea-44ae-afde-0f9d5b876cd4", "label": "摘要1662", "info": "过估计overestimation", "keywords": "过估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc94e85e-2558-43c4-bd96-a0ef9256f47e", "label": "摘要1663", "info": "过拟合overfitting", "keywords": "过拟合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0756cf3-6ccf-402f-8021-48f9db71cdf6", "label": "摘要1664", "info": "过拟合机制overfitting regime", "keywords": "过拟合机制", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "42582dac-b8e9-49fa-a6ce-508ef8480bc9", "label": "摘要1665", "info": "上溢overflow", "keywords": "上溢", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8f36d6f-d9b3-4e1a-ba25-9509251822f7", "label": "摘要1666", "info": "并行分布式处理Parallel Distributed Processing", "keywords": "并行分布式处理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f8234042-24c9-4910-85a8-00f143290c7d", "label": "摘要1667", "info": "并行回火parallel tempering", "keywords": "并行回火", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66ec3bbb-1e43-49cc-a7df-da2a3af6ca76", "label": "摘要1668", "info": "参数parameter", "keywords": "参数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "48d605df-4956-48b0-a657-dee3f9f7579b", "label": "摘要1669", "info": "参数服务器parameter server", "keywords": "参数服务器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "779fbca0-d2ee-41bb-9e34-a878aa78f0f0", "label": "摘要1670", "info": "参数共享parameter sharing", "keywords": "参数共享", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6440b38f-0417-49af-8998-555918a3eaa4", "label": "摘要1671", "info": "有参情况parametric case", "keywords": "有参情况", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aa82f65a-d3ea-4653-951f-cbb8d7edaf06", "label": "摘要1672", "info": "参数化整流线性单元parametric ReLU", "keywords": "参数化整流线性单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9aa26e47-8833-416b-8de2-58a777a348d1", "label": "摘要1673", "info": "偏导数partial derivative", "keywords": "偏导数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dea87fe7-fde5-4cd0-acc4-d3de571d230c", "label": "摘要1674", "info": "配分函数Partition Function", "keywords": "配分函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3c08d9ed-b140-4c67-836a-7b064e6e1db4", "label": "摘要1675", "info": "性能度量performance measures", "keywords": "性能度量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "561a642f-f05a-4efb-b582-6f0e6b4f5190", "label": "摘要1676", "info": "性能度量performance metrics", "keywords": "性能度量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "111e7df6-0cb7-4cc0-a3c5-a04da3563b97", "label": "摘要1677", "info": "置换不变性permutation invariant", "keywords": "置换不变性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc4c765d-ee55-4724-b4ba-9930d5c76c3f", "label": "摘要1678", "info": "持续性对比散度persistent contrastive divergence", "keywords": "持续性对比散度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "93bb42bc-ab4b-4469-a58c-4f6c2e5184e4", "label": "摘要1679", "info": "音素phoneme", "keywords": "音素", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "09594cc6-0416-43cf-809e-fc736218f75c", "label": "摘要1680", "info": "语音phonetic", "keywords": "语音", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "92834c23-46f5-4d84-85cf-d8496d6b8934", "label": "摘要1681", "info": "分段piecewise", "keywords": "分段", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4ef8dcf6-73e5-4435-a7df-97815f7fa313", "label": "摘要1682", "info": "点估计point estimator", "keywords": "点估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3c4c627-2447-490e-9a61-c2d28d3f3760", "label": "摘要1683", "info": "策略policy", "keywords": "策略", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "44ea46b8-6990-4b38-a04c-4e02933da907", "label": "摘要1684", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；策略梯度policy gradient", "keywords": "策略梯度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6a8d1274-6a40-4292-ad0c-00d1aa9bbaa2", "label": "摘要1685", "info": "池化pooling", "keywords": "池化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3546a734-d74a-41df-926a-83267363221c", "label": "摘要1686", "info": "池化函数pooling function", "keywords": "池化函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "10b34cd5-544f-4a8b-8744-bd8cd6380961", "label": "摘要1687", "info": "病态条件poor conditioning", "keywords": "病态条件", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9927186a-a982-4082-9f19-5b04397ea193", "label": "摘要1688", "info": "正定positive definite", "keywords": "正定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cb932ab9-a18c-45bf-b3ab-27d66b0f3050", "label": "摘要1689", "info": "正部函数positive part function", "keywords": "正部函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57d8bb0b-41ae-4c27-be53-ca63d88b947e", "label": "摘要1690", "info": "正相positive phase", "keywords": "正相", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a1660b82-66ec-45ab-a8b9-c9fcc581ced8", "label": "摘要1691", "info": "半正定positive semidefinite", "keywords": "半正定", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d8a28e12-4fe1-4574-958c-c04b90ee514f", "label": "摘要1692", "info": "后验概率posterior probability", "keywords": "后验概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8de075ac-22e1-4e6c-939d-94c02c3df341", "label": "摘要1693", "info": "幂方法power method", "keywords": "幂方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "66bee100-e823-45ef-9162-076ddde5536b", "label": "摘要1694", "info": "PR曲线PR curve", "keywords": "曲线", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c90cc9af-acc2-461f-9eab-23804ec6bf28", "label": "摘要1695", "info": "精度precision", "keywords": "精度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee0472c0-029e-40e5-ae17-cff3aa493fc2", "label": "摘要1696", "info": "精度矩阵precision matrix", "keywords": "精度矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8230bc7f-0e6b-424a-84a6-42973bde2856", "label": "摘要1697", "info": "预测稀疏分解predictive sparse decomposition", "keywords": "预测稀疏分解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6bd4b27c-f149-4803-ae06-93073b558f87", "label": "摘要1698", "info": "预训练pretraining", "keywords": "预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c5a33346-5681-452e-b524-820bdf1b4de4", "label": "摘要1699", "info": "初级视觉皮层primary visual cortex", "keywords": "初级视觉皮层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2d16f90d-c6ab-46e6-8e2f-e9a99a381c20", "label": "摘要1700", "info": "主成分分析principal components analysis", "keywords": "主成分分析", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9d071ff5-403d-487f-b2ad-6fdfac2ccb57", "label": "摘要1701", "info": "先验概率prior probability", "keywords": "先验概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "60b28248-593e-42f5-854b-0deff724fe91", "label": "摘要1702", "info": "先验概率分布prior probability distribution", "keywords": "先验概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "954cc9ee-9029-4835-9137-89681132f727", "label": "摘要1703", "info": "概率PCA probabilistic PCA", "keywords": "概率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ff7ad482-c8be-44cc-ac0d-681711e7f34a", "label": "摘要1704", "info": "概率密度函数probability density function", "keywords": "概率密度函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c11095e6-6a91-4ad7-a2ff-459ca6869fb2", "label": "摘要1705", "info": "概率分布probability distribution", "keywords": "概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ba94bdd-fea6-49d4-8f1d-07d2d464f275", "label": "摘要1706", "info": "概率质量函数probability mass function", "keywords": "概率质量函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "705ae952-7fd8-431c-93bd-6bf05f12d25c", "label": "摘要1707", "info": "专家之积product of expert", "keywords": "专家之积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "35801e61-089a-4659-b105-cabec030adba", "label": "摘要1708", "info": "乘法法则product rule", "keywords": "乘法法则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ece4946d-28ce-45a1-a34c-fb484c3ea761", "label": "摘要1709", "info": "成比例proportional", "keywords": "成比例", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1f323c9b-a7d7-4877-b19d-623b92bda1ac", "label": "摘要1710", "info": "提议分布proposal distribution", "keywords": "提议分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "60d110fe-0e1e-4e8b-9591-0c99fb7d41b9", "label": "摘要1711", "info": "伪似然pseudolikelihood", "keywords": "伪似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1edd24cd-1abc-49c0-9ab0-c5839b9fe2bc", "label": "摘要1712", "info": "象限对quadrature pair", "keywords": "象限对", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b2087224-92f8-4297-9659-608188932a4e", "label": "摘要1713", "info": "量子力学quantum mechanics", "keywords": "量子力学", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4d6e925-2a6e-4932-926b-271e649013c5", "label": "摘要1714", "info": "径向基函数radial basis function", "keywords": "径向基函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5115a19-245d-41e3-a803-6b70c22cdb42", "label": "摘要1715", "info": "随机搜索random search", "keywords": "随机搜索", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0d16f24c-39ed-48e3-98c6-6982f19a6f9c", "label": "摘要1716", "info": "随机变量random variable", "keywords": "随机变量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d6d9845-cd72-474c-9313-c9c038397622", "label": "摘要1717", "info": "值域range", "keywords": "值域", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8d92c13f-221e-4856-b58f-bd5f6ac2886b", "label": "摘要1718", "info": "比率匹配ratio matching", "keywords": "比率匹配", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f021d450-2fce-4be8-9a28-2c67f4a04a69", "label": "摘要1719", "info": "召回率recall", "keywords": "召回率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1691221b-c6a7-4ac5-a29b-2c058bf6a252", "label": "摘要1720", "info": "接受域receptivefield", "keywords": "接受域", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4069e384-ebc9-42f5-b04e-7dd1d8516708", "label": "摘要1721", "info": "再循环recirculation", "keywords": "再循环", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee6f40b8-5fab-4361-89fb-1c033c09569a", "label": "摘要1722", "info": "推荐系统recommender system", "keywords": "推荐系统", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b2693436-ec63-41bc-a4e1-9951ed3687c3", "label": "摘要1723", "info": "重构reconstruction", "keywords": "重构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ce00d523-a56e-430a-bd7c-7091c4fe4d3b", "label": "摘要1724", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；重构误差reconstruction error", "keywords": "重构误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8b0cdf3-570c-460f-b9d0-8eddaf2a48f9", "label": "摘要1725", "info": "整流线性rectified linear", "keywords": "整流线性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "27bcca9b-3371-4e87-bc34-eee6dca1ea94", "label": "摘要1726", "info": "整流线性变换rectified linear transformation", "keywords": "整流线性变换", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3afeb0f0-936c-4030-8a0c-6d5ecf820d99", "label": "摘要1727", "info": "整流线性单元rectified linear unit", "keywords": "整流线性单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "aaae78aa-e119-483e-ab04-9423a0459d84", "label": "摘要1728", "info": "整流网络rectifier network", "keywords": "整流网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d681b87-ef14-4a93-b49c-6f20cff27ca4", "label": "摘要1729", "info": "循环recurrence", "keywords": "循环", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cb93d4ca-87d9-4cab-b759-6d8355dcf228", "label": "摘要1730", "info": "循环卷积网络recurrent convolutional network", "keywords": "循环卷积网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "478d02b4-a412-4654-bcff-67ff4713c644", "label": "摘要1731", "info": "循环网络recurrent network", "keywords": "循环网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0bdf353d-666c-43bb-9b1e-bee2f6780133", "label": "摘要1732", "info": "循环神经网络recurrent neural network", "keywords": "循环神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "616377b7-18f3-4c74-802a-ceeeeba35fba", "label": "摘要1733", "info": "回归regression", "keywords": "回归", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "82b613ef-c8ac-4c0c-b53a-ccd130cab192", "label": "摘要1734", "info": "正则化regularization", "keywords": "正则化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fda74d23-e9fe-42ce-be5f-1f09c748b8a7", "label": "摘要1735", "info": "正则化regularize", "keywords": "正则化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6fd90a16-2bc5-490e-b3cb-203261aa670f", "label": "摘要1736", "info": "正则化项regularizer", "keywords": "正则化项", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4174e688-8bf5-41e8-975c-bb7f237bb375", "label": "摘要1737", "info": "强化学习reinforcement learning", "keywords": "强化学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7c22e47d-96e4-49bc-beb5-1a8b9051b1bd", "label": "摘要1738", "info": "关系relation", "keywords": "关系", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "57bf6928-8a54-476b-a68a-8d72c8e885aa", "label": "摘要1739", "info": "关系型数据库relational database", "keywords": "关系型数据库", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "99c2166b-fdfc-4c60-abbb-51f969157bdf", "label": "摘要1740", "info": "重参数化reparametrization", "keywords": "重参数化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8068c3be-379f-46d6-8d6a-adc876a3ef27", "label": "摘要1741", "info": "重参数化技巧reparametrization trick", "keywords": "重参数化技巧", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7508eec6-0f0f-423c-a5f2-36dcb1aa7073", "label": "摘要1742", "info": "表示representation", "keywords": "表示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "22b6dbec-2184-47cd-b11d-14b439cc9b48", "label": "摘要1743", "info": "表示学习representation learning", "keywords": "表示学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2c7019c8-19d2-4d65-a644-97682bd0636e", "label": "摘要1744", "info": "表示容量representational capacity", "keywords": "表示容量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8d7b925-dff9-4806-8f94-602460876b0e", "label": "摘要1745", "info": "储层计算reservoir computing", "keywords": "储层计算", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "215e3d51-e4e8-4b91-a40a-50ba09321697", "label": "摘要1746", "info": "受限玻尔兹曼机Restricted Boltzmann Machine", "keywords": "受限玻尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5776c66e-1b01-4b4f-88ca-af27e395b2ed", "label": "摘要1747", "info": "反向相关reverse correlation", "keywords": "反向相关", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28e71c61-764e-4e71-ba4f-b7d51d5aeec3", "label": "摘要1748", "info": "反向模式累加reverse mode accumulation", "keywords": "反向模式累加", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6a096fb4-215d-44b5-88d2-f4487b9adfd8", "label": "摘要1749", "info": "岭回归ridge regression", "keywords": "岭回归", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4dee9fe9-4988-4608-93e1-a127044278e4", "label": "摘要1750", "info": "右特征向量right eigenvector", "keywords": "右特征向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1114ca15-7419-48eb-9042-d16911f9475b", "label": "摘要1751", "info": "右奇异向量right singular vector", "keywords": "右奇异向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "614ae4fc-8e67-48a4-957a-d73540e8a5c7", "label": "摘要1752", "info": "风险risk", "keywords": "风险", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c559127-6406-4be3-9ca4-c34bb3316ea0", "label": "摘要1753", "info": "行row", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e728acd-96a8-4761-8f0d-0802fb409433", "label": "摘要1754", "info": "扫视saccade", "keywords": "扫视", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "68e0deb3-b95d-4770-8eee-4cbb7d1a6195", "label": "摘要1755", "info": "鞍点saddle point", "keywords": "鞍点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f5a2062f-47ca-4a4c-956a-5fb5aed349b9", "label": "摘要1756", "info": "无鞍牛顿法saddle-free Newton method", "keywords": "无鞍牛顿法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1d00c209-2478-4e64-9bc0-189d42b59035", "label": "摘要1757", "info": "相同same", "keywords": "相同", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9e366282-dc7f-48fb-a824-c814dc4d48e2", "label": "摘要1758", "info": "样本均值sample mean", "keywords": "样本均值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f843cb55-8f8e-4958-b04c-51bb92ccb651", "label": "摘要1759", "info": "样本方差sample variance", "keywords": "样本方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "073613d3-51e6-4f55-8776-9cbdbcf17197", "label": "摘要1760", "info": "饱和saturate", "keywords": "饱和", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dee41ade-29ee-401b-b23d-ac0e520482d0", "label": "摘要1761", "info": "标量scalar", "keywords": "标量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9b2476f5-b5e8-40f5-87e1-54ef6ef6f47a", "label": "摘要1762", "info": "得分score", "keywords": "得分", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "da702c73-94ac-4c33-9120-6eb87333ca51", "label": "摘要1763", "info": "得分匹配score matching", "keywords": "得分匹配", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a30a0bb5-6733-4875-a3a3-7cc3921430e2", "label": "摘要1764", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；二阶导数second derivative", "keywords": "二阶导数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4a0c3a8e-972b-4122-acca-08a26cb8f0aa", "label": "摘要1765", "info": "二阶导数测试second derivative test", "keywords": "二阶导数测试", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ee972375-d537-483b-b1fd-82ea6835f925", "label": "摘要1766", "info": "第二层second layer", "keywords": "第二层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a7a92211-b40f-438b-a33a-00136d62f37e", "label": "摘要1767", "info": "二阶方法second-order method", "keywords": "二阶方法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e4ad38af-e2f9-4b20-a182-f3f398ea0380", "label": "摘要1768", "info": "自对比估计self-contrastive estimation", "keywords": "自对比估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "02076351-69a1-4803-956b-ed6adaffb6ef", "label": "摘要1769", "info": "自信息self-information", "keywords": "自信息", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7107825e-6dd8-4141-bea8-20e150b82747", "label": "摘要1770", "info": "语义哈希semantic hashing", "keywords": "语义哈希", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "34583e46-7917-40ca-abc4-d936f6c205b9", "label": "摘要1771", "info": "半受限波尔兹曼机semi-restricted Boltzmann Ma-chine", "keywords": "半受限波尔兹曼机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "788ac67a-69f4-4a40-a14e-efeea8d56ece", "label": "摘要1772", "info": "半监督semi-supervised", "keywords": "半监督", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d065316a-e9d2-45b4-873f-a26db5317a1c", "label": "摘要1773", "info": "半监督学习semi-supervised learning", "keywords": "半监督学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "195f6722-4b58-4263-b589-8b5d13a9d696", "label": "摘要1774", "info": "可分离的separable", "keywords": "可分离的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "75de913b-1422-45f9-92b9-9fb3a174d115", "label": "摘要1775", "info": "分离的separate", "keywords": "分离的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "09ba37e3-aa22-4f31-b587-326551fd5abc", "label": "摘要1776", "info": "分离separation", "keywords": "分离", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f58a5835-891a-4ea4-b0dc-0bdf2affc730", "label": "摘要1777", "info": "情景setting", "keywords": "情景", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b9e25ea0-8200-49b0-8295-8fd71152d3bf", "label": "摘要1778", "info": "浅度回路shadow circuit", "keywords": "浅度回路", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2a842783-f733-4e57-a6f2-c6354991351a", "label": "摘要1779", "info": "香农熵Shannon entropy", "keywords": "香农熵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1eac39d1-ac2e-42fd-8786-75d4949bf5e7", "label": "摘要1780", "info": "香农shannons", "keywords": "香农", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8118013c-2f24-47a1-acaa-f8220c05b719", "label": "摘要1781", "info": "塑造shaping", "keywords": "塑造", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5a2a5205-cb0d-4de1-9949-22371e2f70a2", "label": "摘要1782", "info": "短列表shortlist", "keywords": "短列表", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "550ea467-83d4-44fa-9358-dc3730d2c665", "label": "摘要1783", "info": "sigmoid sigmoid", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ece9e516-97d7-446f-8be0-266bd3ba02a2", "label": "摘要1784", "info": "sigmoid信念网络sigmoid Belief Network", "keywords": "信念网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cd8cfe85-42c1-4c11-a378-c97722b89e9a", "label": "摘要1785", "info": "简单细胞simple cell", "keywords": "简单细胞", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6fb3122a-a35c-4b31-bf48-a9b42edd0f79", "label": "摘要1786", "info": "奇异的singular", "keywords": "奇异的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ffbc3565-4a19-436f-9c87-2384cc2571a5", "label": "摘要1787", "info": "奇异值singular value", "keywords": "奇异值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc719dd8-af94-4fef-8c3d-b39c9a337cfe", "label": "摘要1788", "info": "奇异值分解singular value decomposition", "keywords": "奇异值分解", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d4734c1-b348-4701-8bca-41c9ea6f5855", "label": "摘要1789", "info": "奇异向量singular vector", "keywords": "奇异向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8b5a7702-4c66-40a9-8d45-b836fffc492e", "label": "摘要1790", "info": "跳跃连接skip connection", "keywords": "跳跃连接", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b5acf89a-d7e6-489b-9779-e688121fe3bb", "label": "摘要1791", "info": "慢特征分析slow feature analysis", "keywords": "慢特征分析", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7c09417-0e00-4cf6-9ed3-942982472cd6", "label": "摘要1792", "info": "慢性原则slowness principle", "keywords": "慢性原则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "939e4d90-689d-43ca-addf-dc315f15b34d", "label": "摘要1793", "info": "平滑smoothing", "keywords": "平滑", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e3fb9079-d3b0-45f8-94d3-40cccdf5fa48", "label": "摘要1794", "info": "平滑先验smoothness prior", "keywords": "平滑先验", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0b9c520b-70f0-42df-84b7-94427238b6d3", "label": "摘要1795", "info": "softmax softmax", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "63fb2575-c557-4d06-94f7-80735358fbe7", "label": "摘要1796", "info": "softmax函数softmax function", "keywords": "函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a1cbf0a-fe2b-48c9-be39-c7f2c3d590f3", "label": "摘要1797", "info": "softmax单元softmax unit", "keywords": "单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dc46548c-aa58-4c41-bb90-16809a7194cc", "label": "摘要1798", "info": "softplus softplus", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d6971fd9-60e5-43c4-a87a-c65820049d9c", "label": "摘要1799", "info": "softplus函数softplus function", "keywords": "函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1f41e069-92a3-42ae-90ed-d19ca1b04a65", "label": "摘要1800", "info": "生成子空间span", "keywords": "生成子空间", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ba3906a5-d8d1-4c05-b04f-34dc93fbfe1b", "label": "摘要1801", "info": "稀疏sparse", "keywords": "稀疏", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2f010c24-19f9-4592-9489-a5878e98b4eb", "label": "摘要1802", "info": "稀疏激活sparse activation", "keywords": "稀疏激活", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b100dc15-63da-4c1b-8f54-533aad66302a", "label": "摘要1803", "info": "稀疏编码sparse coding", "keywords": "稀疏编码", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e039d61-8245-435b-980a-86dae9dbf78b", "label": "摘要1804", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；稀疏连接sparse connectivity", "keywords": "稀疏连接", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "58a7d1e3-d055-4a22-aafb-57530cd18cd6", "label": "摘要1805", "info": "稀疏初始化sparse initialization", "keywords": "稀疏初始化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ccaa31fa-ade1-48fc-a1f7-8fbbd09bcc1d", "label": "摘要1806", "info": "稀疏交互sparse interactions", "keywords": "稀疏交互", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "688a0f6c-f617-445d-8729-bf7938c2c9be", "label": "摘要1807", "info": "稀疏权重sparse weights", "keywords": "稀疏权重", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4529cf65-2cbe-4c49-8149-c278dedd5b19", "label": "摘要1808", "info": "谱半径spectral radius", "keywords": "谱半径", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "637aa467-f8c6-4ed3-b3c0-f3b3e5957da2", "label": "摘要1809", "info": "语音识别Speech Recognition", "keywords": "语音识别", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4b1ed299-9ac4-40ac-8be3-c8e9915f904c", "label": "摘要1810", "info": "sphering sphering", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "65922510-4d0a-47ad-b528-0bffb5ca9379", "label": "摘要1811", "info": "尖峰和平板spike and slab", "keywords": "尖峰和平板", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e0d811f8-3345-40ae-9961-651e9093f120", "label": "摘要1812", "info": "尖峰和平板RBM spike and slab RBM", "keywords": "尖峰和平板", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dfc1228e-4c9e-4340-950e-1a7d45da856e", "label": "摘要1813", "info": "虚假模态spurious modes", "keywords": "虚假模态", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1667d82e-0d07-48da-a788-f89f48fa6d43", "label": "摘要1814", "info": "方阵square", "keywords": "方阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "df576119-77fa-4509-a094-ceed2cfdc7d7", "label": "摘要1815", "info": "标准差standard deviation", "keywords": "标准差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5126da3a-01be-4600-8c4c-ed2ec2893117", "label": "摘要1816", "info": "标准差standard error", "keywords": "标准差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "43170e57-57f6-4b14-b7a2-9a374db83cdb", "label": "摘要1817", "info": "标准正态分布standard normal distribution", "keywords": "标准正态分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2090ee82-3f06-4987-bf6e-f4d74aea9b14", "label": "摘要1818", "info": "声明statement", "keywords": "声明", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9107c8da-51b2-4107-8372-499dbc5dfe83", "label": "摘要1819", "info": "平稳的stationary", "keywords": "平稳的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "27e745dc-8fd5-46f2-90fb-284db44b4da0", "label": "摘要1820", "info": "平稳分布Stationary Distribution", "keywords": "平稳分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7c1f77f-6f54-4d2e-8119-d4871f63fb51", "label": "摘要1821", "info": "驻点stationary point", "keywords": "驻点", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "030bc5b8-0eda-4fc3-a959-910b9fc5207b", "label": "摘要1822", "info": "统计效率statistic efficiency", "keywords": "统计效率", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4d613057-480a-4420-9045-4338fe6985d0", "label": "摘要1823", "info": "统计学习理论statistical learning theory", "keywords": "统计学习理论", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7ac97cd9-6d9c-4317-9b83-2c97e9e35bcb", "label": "摘要1824", "info": "统计量statistics", "keywords": "统计量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6cf394a-a025-47c7-bdaf-90673df78d1a", "label": "摘要1825", "info": "最陡下降steepest descent", "keywords": "最陡下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f09cf473-8185-47de-a491-52c7598259b5", "label": "摘要1826", "info": "随机stochastic", "keywords": "随机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3ff2153-5bd7-4296-9c20-a7da4e865054", "label": "摘要1827", "info": "随机课程stochastic curriculum", "keywords": "随机课程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "29e8ce6c-83da-4efe-8999-15964b5b86b0", "label": "摘要1828", "info": "随机梯度上升Stochastic Gradient Ascent", "keywords": "随机梯度上升", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f4962cea-a80e-439d-aa89-f518864af0b8", "label": "摘要1829", "info": "随机梯度下降stochastic gradient descent", "keywords": "随机梯度下降", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b05d2a8d-65b0-4dec-844a-a42897b0d92f", "label": "摘要1830", "info": "随机矩阵Stochastic Matrix", "keywords": "随机矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "366fb53d-387a-4671-89bf-bfa1412dcdcb", "label": "摘要1831", "info": "随机最大似然stochastic maximum likelihood", "keywords": "随机最大似然", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5d0f50cd-29db-4f02-b726-deac6c3546f0", "label": "摘要1832", "info": "流stream", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ad1a1188-2acf-4d7a-bf56-9f049d26b125", "label": "摘要1833", "info": "步幅stride", "keywords": "步幅", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "793c76fa-455a-4f6f-b017-755f1b0bb389", "label": "摘要1834", "info": "结构学习structure learning", "keywords": "结构学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a3de9080-8fab-44ff-bccd-4098e0ed6867", "label": "摘要1835", "info": "结构化概率模型structured probabilistic model", "keywords": "结构化概率模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9c751079-eaf9-49c8-8b31-b77200057db3", "label": "摘要1836", "info": "结构化变分推断structured variational inference", "keywords": "结构化变分推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "118143c5-af4b-4c16-b7d3-a2d2d68e7f7c", "label": "摘要1837", "info": "亚原子subatomic", "keywords": "亚原子", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "19c367d9-bce7-423c-b574-c56f768db8f5", "label": "摘要1838", "info": "子采样subsample", "keywords": "子采样", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2fbcd40c-0001-434b-aa52-2f0aa332d449", "label": "摘要1839", "info": "求和法则sum rule", "keywords": "求和法则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "977a73b3-5808-4977-9f61-dd44381a69fb", "label": "摘要1840", "info": "和–积网络sum-product network", "keywords": "积网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0071167e-f273-4ddd-9177-9865a084718b", "label": "摘要1841", "info": "监督supervised", "keywords": "监督", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7d2ea136-10be-44cd-b883-74d13d9d8f0b", "label": "摘要1842", "info": "监督学习supervised learning", "keywords": "监督学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fe45499b-f826-4959-8012-4f18c8fe4490", "label": "摘要1843", "info": "监督学习算法supervised learning algorithm", "keywords": "监督学习算法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b6e2acf7-942b-4319-b456-8da9271d7e38", "label": "摘要1844", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；监督模型supervised model", "keywords": "监督模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "687016e1-d1dc-4c2e-91a2-935c143c20b7", "label": "摘要1845", "info": "监督预训练supervised pretraining", "keywords": "监督预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7dd3caff-ec96-4a8d-b781-569b7a4365a4", "label": "摘要1846", "info": "支持向量support vector", "keywords": "支持向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d67c01c8-05fd-4ab7-a349-305a7d0a2e86", "label": "摘要1847", "info": "代理损失函数surrogate loss function", "keywords": "代理损失函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "91905bd7-8121-4351-9034-2b7d19dd5f4f", "label": "摘要1848", "info": "符号symbol", "keywords": "符号", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d3073e86-b875-48cd-91bb-dfed9542df71", "label": "摘要1849", "info": "符号表示symbolic representation", "keywords": "符号表示", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ebd22193-dd4d-44a0-808b-95e48bd7e5dd", "label": "摘要1850", "info": "对称symmetric", "keywords": "对称", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1e0b5281-0abb-483b-8a36-e8c0647820f0", "label": "摘要1851", "info": "切面距离tangent distance", "keywords": "切面距离", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "83d0fa72-e623-479f-acb4-8a9a6b8c6d01", "label": "摘要1852", "info": "切平面tangent plane", "keywords": "切平面", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a912625c-6c80-45c0-8e23-c43e77bf1f33", "label": "摘要1853", "info": "正切传播tangent prop", "keywords": "正切传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ca1cc877-7782-4bec-8151-b7c0228bd262", "label": "摘要1854", "info": "泰勒taylor", "keywords": "泰勒", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc85cdcf-1bd1-41a5-a7ac-cebf4753f365", "label": "摘要1855", "info": "导师驱动过程teacher forcing", "keywords": "导师驱动过程", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f3e0a296-1d99-4cff-846d-c671aeb8bacb", "label": "摘要1856", "info": "温度temperature", "keywords": "温度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7fa94846-60cd-4f07-856b-6a2d17c88fcf", "label": "摘要1857", "info": "回火转移tempered transition", "keywords": "回火转移", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b145fa8a-18ac-47e5-b7e1-1b8549aacafd", "label": "摘要1858", "info": "回火tempering", "keywords": "回火", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5817fa11-57f1-48be-9aa3-cfa772b759dd", "label": "摘要1859", "info": "张量tensor", "keywords": "张量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b468e128-c430-4958-8239-c33d2d818daa", "label": "摘要1860", "info": "测试误差test error", "keywords": "测试误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d04a8b7d-b204-4412-8946-71cbcdf8074d", "label": "摘要1861", "info": "测试集test set", "keywords": "测试集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b022f9ae-2e88-45a5-b0e8-d74a3e358e97", "label": "摘要1862", "info": "碰撞情况the collider case", "keywords": "碰撞情况", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b714630c-8db4-4fa3-b210-e387d8fd0116", "label": "摘要1863", "info": "绑定的权重tied weights", "keywords": "绑定的权重", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0a1a7507-6dd1-44ee-80da-71cb7bd22e4a", "label": "摘要1864", "info": "Tikhonov正则Tikhonov regularization", "keywords": "正则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "96696bb4-93ba-4ee5-af7e-b7278e3c2903", "label": "摘要1865", "info": "平铺卷积tiled convolution", "keywords": "平铺卷积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e7801109-7402-4fc2-96ab-6a5ef9b48623", "label": "摘要1866", "info": "时延神经网络time delay neural network", "keywords": "时延神经网络", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f61d55c2-c28e-48d5-9cc2-f9f0f8f94dd7", "label": "摘要1867", "info": "时间步time step", "keywords": "时间步", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b8da8aa9-4e5f-42a1-a96c-3c31b4711a46", "label": "摘要1868", "info": "Toeplitz矩阵Toeplitz matrix", "keywords": "矩阵", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "bb5dea0f-98ef-485d-ab1b-f980e764ac76", "label": "摘要1869", "info": "标记token", "keywords": "标记", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c6f469c9-4348-4a19-a309-1d19e24bdee2", "label": "摘要1870", "info": "容差tolerance", "keywords": "容差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b23841bb-a853-48c3-a3ca-4233a59534f9", "label": "摘要1871", "info": "地质ICA topographic ICA", "keywords": "地质", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c0556e5b-6387-456b-9766-6960cf5ab23d", "label": "摘要1872", "info": "训练误差training error", "keywords": "训练误差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "9735dcef-7694-4c4a-b177-7a5bade63cde", "label": "摘要1873", "info": "训练集training set", "keywords": "训练集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2185df8-6ea5-436d-9560-ec02423f0dc1", "label": "摘要1874", "info": "转录transcribe", "keywords": "转录", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6e1d9f87-a816-40f7-b5bc-076c4a6f6fbf", "label": "摘要1875", "info": "转录系统transcription system", "keywords": "转录系统", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cb216a45-d047-44a2-8782-02cd52832e1a", "label": "摘要1876", "info": "迁移学习transfer learning", "keywords": "迁移学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "14b3daf4-e97e-4bb7-abf2-1ec02ce361ba", "label": "摘要1877", "info": "转移transition", "keywords": "转移", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "927d0c66-6771-408d-9093-ee4c518336b5", "label": "摘要1878", "info": "转置transpose", "keywords": "转置", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2abf625c-75df-4d56-9b8d-5b2226b56098", "label": "摘要1879", "info": "三角不等式triangle inequality", "keywords": "三角不等式", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b02c837a-741a-48cc-906b-81ab190a3819", "label": "摘要1880", "info": "三角形化triangulate", "keywords": "三角形化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d136b97c-8a83-43e4-b241-58e9272a3e6c", "label": "摘要1881", "info": "三角形化图triangulated graph", "keywords": "三角形化图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d7f119d7-d9a1-4ef1-abc6-b83336be7248", "label": "摘要1882", "info": "三元语法trigram", "keywords": "三元语法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3f90cf4e-fe5f-44ba-bb24-362f7c6e6852", "label": "摘要1883", "info": "无偏unbiased", "keywords": "无偏", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "968bc6e1-22a8-402d-8409-4ebb7fd5902d", "label": "摘要1884", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；无偏样本方差unbiased sample variance", "keywords": "无偏样本方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "dfbadb9a-4585-4d1c-b420-ef6ba5b82e89", "label": "摘要1885", "info": "欠完备undercomplete", "keywords": "欠完备", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a4691ed7-3e27-46b9-8ce7-cb912d88cf28", "label": "摘要1886", "info": "欠定的underdetermined", "keywords": "欠定的", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "971f8fa7-2f38-4ca2-bdd8-805b9ee8c731", "label": "摘要1887", "info": "欠估计underestimation", "keywords": "欠估计", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "609356df-3130-4ae3-8182-363671525dc0", "label": "摘要1888", "info": "欠拟合underfitting", "keywords": "欠拟合", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3d05c684-4b2e-4ad5-b5e9-b39e64e92c15", "label": "摘要1889", "info": "欠拟合机制underfitting regime", "keywords": "欠拟合机制", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "32c5f984-4572-4c1a-ab99-5234de90b460", "label": "摘要1890", "info": "下溢underflow", "keywords": "下溢", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b25adf29-8edb-4c82-947c-de2d1fbbdac8", "label": "摘要1891", "info": "潜在underlying", "keywords": "潜在", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "0103854a-dc27-4885-8e62-b4644d08a793", "label": "摘要1892", "info": "潜在成因underlying cause", "keywords": "潜在成因", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1ed1557d-88ae-46a2-9ee7-560461a088fc", "label": "摘要1893", "info": "无向undirected", "keywords": "无向", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "1abb7848-ee32-4d65-8ea6-e73ad3c98aa7", "label": "摘要1894", "info": "无向模型undirected model", "keywords": "无向模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "809c4c3f-3c56-4949-91aa-117cc173b702", "label": "摘要1895", "info": "展开图unfolded graph", "keywords": "展开图", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2b171a1-6c0f-4b9d-8283-7343e09b0d8a", "label": "摘要1896", "info": "展开unfolding", "keywords": "展开", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79a8ea1c-6bf2-482b-8ebc-455402d247d3", "label": "摘要1897", "info": "均匀分布uniform distribution", "keywords": "均匀分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4c78d87a-7f51-42bf-bc64-fe399c421f14", "label": "摘要1898", "info": "一元语法unigram", "keywords": "一元语法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "a1988b0b-97d3-44e3-ad91-d6e26ef991a6", "label": "摘要1899", "info": "单峰值unimodal", "keywords": "单峰值", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ac8e5ea2-5ec3-4f32-9c60-c076ed40940b", "label": "摘要1900", "info": "单元unit", "keywords": "单元", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af56b359-b61f-4936-b76d-837863e1d237", "label": "摘要1901", "info": "单位范数unit norm", "keywords": "单位范数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "61b661fa-0c97-4b43-a9f8-25b171d0e75a", "label": "摘要1902", "info": "单位向量unit vector", "keywords": "单位向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5c8c082d-7ead-4d61-bc20-f7d255b530b1", "label": "摘要1903", "info": "万能近似定理universal approximation theorem", "keywords": "万能近似定理", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "469c6520-0037-444d-9fdc-200a4906ba37", "label": "摘要1904", "info": "万能近似器universal approximator", "keywords": "万能近似器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6a5c9e69-decc-4c62-b614-be85c7a8df9a", "label": "摘要1905", "info": "万能函数近似器universal function approximator", "keywords": "万能函数近似器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c15c22a8-7a5d-44d6-bcd2-cca076a21a6a", "label": "摘要1906", "info": "未标注unlabeled", "keywords": "未标注", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "28967bdf-b1d6-4252-ac99-8d79313a3a27", "label": "摘要1907", "info": "未归一化概率函数unnormalized probability func-tion", "keywords": "未归一化概率函数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "fbbb84d0-bd92-4121-a404-d51787a9e8d9", "label": "摘要1908", "info": "非共享卷积unshared convolution", "keywords": "非共享卷积", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "82e0e8af-0681-4c16-a57c-35785b3b5bed", "label": "摘要1909", "info": "无监督unsupervised", "keywords": "无监督", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "10f2dc40-1ec9-4ae6-b6c4-60c08c5b08eb", "label": "摘要1910", "info": "无监督学习unsupervised learning", "keywords": "无监督学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "2042ae5a-109b-48e4-907b-b278bd699bdb", "label": "摘要1911", "info": "无监督学习算法unsupervised learning algorithm", "keywords": "无监督学习算法", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c2c447c8-dd93-4721-909d-0d6112e6b4fb", "label": "摘要1912", "info": "无监督预训练unsupervised pretraining", "keywords": "无监督预训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "af5ab1f1-4157-4bad-8402-0f73f16bd0fc", "label": "摘要1913", "info": "有效valid", "keywords": "有效", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "12126621-1480-4855-b06a-c0d1f7a3df3a", "label": "摘要1914", "info": "验证集validation set", "keywords": "验证集", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e95af88f-aad4-4f86-aee0-d47029f5a191", "label": "摘要1915", "info": "梯度消失与爆炸问题vanishing and exploding gra-dient problem", "keywords": "梯度消失与爆炸问题", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c4ca7a42-627d-4870-84d5-93455dd4bda6", "label": "摘要1916", "info": "梯度消失vanishing gradient", "keywords": "梯度消失", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "90c546a2-4f44-4f8c-bd42-ebfefbf39ac7", "label": "摘要1917", "info": "Vapnik-Chervonenkis维度Vapnik-Chervonenkis dimension", "keywords": "维度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "611284ed-d501-46ee-bf40-94545bae704c", "label": "摘要1918", "info": "变量消去variable elimination", "keywords": "变量消去", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "76449157-9d57-49e4-bd7f-6a8c19ed9d5a", "label": "摘要1919", "info": "方差variance", "keywords": "方差", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "79d2cc59-935b-4e8c-a2ef-ce7f2a831e23", "label": "摘要1920", "info": "方差减小variance reduction", "keywords": "方差减小", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "16e914fc-5545-4ca8-8ba6-ba6a5f3c6fde", "label": "摘要1921", "info": "变分自编码器variational auto-encoder", "keywords": "变分自编码器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "17c327dc-1396-4e2d-bb99-f686f464e71e", "label": "摘要1922", "info": "变分导数variational derivative", "keywords": "变分导数", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6f93f102-0108-4f00-960c-14ed895a3a6d", "label": "摘要1923", "info": "变分自由能variational free energy", "keywords": "变分自由能", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5077a948-afdd-4046-82d1-071df23b8e30", "label": "摘要1924", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)；变分推断variational inference", "keywords": "变分推断", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "72aac68b-35b2-440b-8c0b-34f90bbe51c7", "label": "摘要1925", "info": "向量vector", "keywords": "向量", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "baf7b521-d97f-4a47-adf0-13f18351562b", "label": "摘要1926", "info": "虚拟对抗样本virtual adversarial example", "keywords": "虚拟对抗样本", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3fea8eb3-5fc0-40db-a8ba-2207b53a1237", "label": "摘要1927", "info": "虚拟对抗训练virtual adversarial training", "keywords": "虚拟对抗训练", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6d913100-6043-4291-b39d-375a4e604a8b", "label": "摘要1928", "info": "可见层visible layer", "keywords": "可见层", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6071d270-a39b-4097-93de-d01733c48610", "label": "摘要1929", "info": "V-结构V-structure", "keywords": "结构", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "cc4e282a-6e59-482a-9d8e-85167509fced", "label": "摘要1930", "info": "醒眠wake sleep", "keywords": "醒眠", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d71c6cc4-f337-4549-a03a-500d26803152", "label": "摘要1931", "info": "warp warp", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "f990f881-b88c-4ed0-b7b1-b29f22fadf04", "label": "摘要1932", "info": "支持向量机support vector machine", "keywords": "支持向量机", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5357db9e-45e6-4e7b-9461-2fd5d71cd46e", "label": "摘要1933", "info": "无向图模型undirected graphical model", "keywords": "无向图模型", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "5f70f335-e40b-4515-98b7-6e3af808862e", "label": "摘要1934", "info": "权重weight", "keywords": "权重", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7f1c364a-ce75-401f-a763-9bcaf3242ceb", "label": "摘要1935", "info": "权重衰减weight decay", "keywords": "权重衰减", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "30367593-4e5c-4563-bd5f-3b4d0327120c", "label": "摘要1936", "info": "权重比例推断规则weight scaling inference rule", "keywords": "权重比例推断规则", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "7420e1bb-0d3c-4cc2-b5fd-ecf23ff968d6", "label": "摘要1937", "info": "权重空间对称性weight space symmetry", "keywords": "权重空间对称性", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e9a5a52e-0d1d-4ab9-b178-a3a67583ab00", "label": "摘要1938", "info": "条件概率分布conditional probability distribution", "keywords": "条件概率分布", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b375ed5b-6624-48bc-936b-073173844074", "label": "摘要1939", "info": "白化whitening", "keywords": "白化", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3e016015-3269-4054-a08d-046338178ad5", "label": "摘要1940", "info": "宽度width", "keywords": "宽度", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "46e75559-78d4-4427-93da-2d00e8217e47", "label": "摘要1941", "info": "赢者通吃winner-take-all", "keywords": "赢者通吃", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "b48302f0-5a71-40ad-8f46-61087d002ec4", "label": "摘要1942", "info": "正切传播tangent propagation", "keywords": "正切传播", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "d788b32f-cf6b-4e9a-98da-0d64c3099100", "label": "摘要1943", "info": "流形正切分类器manifold tangent classifier", "keywords": "流形正切分类器", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "019537a9-054b-41f8-9de9-035b2549838e", "label": "摘要1944", "info": "词嵌入word embedding", "keywords": "词嵌入", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "ea6845c4-91c0-4a3a-9b14-0838a314e3d0", "label": "摘要1945", "info": "词义消歧word-sense disambiguation", "keywords": "词义消歧", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8a034926-7b0f-4304-bf38-841759f3e9a5", "label": "摘要1946", "info": "零数据学习zero-data learning", "keywords": "零数据学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "70fe53a5-e8d7-46ec-9840-3e6b3cb93d02", "label": "摘要1947", "info": "零次学习zero-shot learning", "keywords": "零次学习", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3262d8a9-3d45-45de-ab56-182d152d6c42", "label": "摘要1948", "info": "Table of Contents", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "584f970e-136c-4680-86a7-f914ec0a7feb", "label": "摘要1949", "info": "书名页", "keywords": "书名页", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "e042daa8-982f-472e-8533-04a921aac828", "label": "摘要1950", "info": "版权页", "keywords": "版权页", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "98a67908-20ae-4fda-a5c2-96c1b63697f4", "label": "摘要1951", "info": "中文版推荐语（按姓氏拼音排序）", "keywords": "中文版推荐语, 按姓氏拼音排序", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "3dc482d1-8290-449f-b12f-c6eb28c9ddfa", "label": "摘要1952", "info": "译者序", "keywords": "译者序", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c9215dd6-f1bb-44b9-9f8a-c8ea08c778f5", "label": "摘要1953", "info": "中文版致谢", "keywords": "中文版致谢", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "eeecbfa2-a87b-4aad-88b0-57f580c6a2e5", "label": "摘要1954", "info": "英文原书致谢", "keywords": "英文原书致谢", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "6b3dffbc-fa89-41c4-93fb-48fdc663415a", "label": "摘要1955", "info": "数学符号", "keywords": "数学符号", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "8d5ce3bb-6d8f-4923-a2e8-af97ef59a1e6", "label": "摘要1956", "info": "目录", "keywords": "目录", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "83c454c0-d413-4620-8ba5-f6a959fa6744", "label": "摘要1957", "info": "参考文献", "keywords": "参考文献", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "4e382e9e-b949-4492-a47b-fa9affb5e511", "label": "摘要1958", "info": "索引", "keywords": "索引", "level": 3, "group": "chapter-20", "type": "段落"}, {"id": "c458dbc7-a4e5-42db-9eb3-73837708806a", "label": "摘要1959", "info": "(cid:1783)(cid:1567)(cid:1480)(cid:4656)(cid:3456)(cid:4647)(cid:2584)(cid:3176)(cid:3526)(cid:3564)(cid:119)(cid:4078)(cid:3456)(cid:120)(cid:287)(cid:73)(cid:85)(cid:85)(cid:81)(cid:27)(cid:16)(cid:16)(cid:88)(cid:88)(cid:88)(cid:15)(cid:90)(cid:66)(cid:67)(cid:80)(cid:80)(cid:76)(cid:15)(cid:80)(cid:83)(cid:72)", "keywords": "", "level": 3, "group": "chapter-20", "type": "段落"}], "links": [{"source": "b1e26336-7640-424a-9a12-24eca44b6c52", "target": "3cb33908-c3ee-49e6-b0b2-fce610d56d91"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "9f4b3115-654d-4379-8c96-20a4412b6321"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "e4a4d50c-1dca-418e-8f67-f4e7d0df6461"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "fd8d2abd-2512-4510-b761-a9cc391c9757"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "225f0983-5080-44f0-ba8f-47221fd90357"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "ceaf5214-10b5-4128-b0db-1f55f8f52cab"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "588ea5a9-feef-4cf7-bd60-70de292f30a1"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "4277579b-0d2e-4d01-b164-e1d92dbc58c9"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "791ba814-b889-493c-98a2-293d054c607c"}, {"source": "3cb33908-c3ee-49e6-b0b2-fce610d56d91", "target": "7147dd1b-ee39-46d0-b991-08d38ff04a11"}, {"source": "b1e26336-7640-424a-9a12-24eca44b6c52", "target": "e35185cf-8088-438d-9f20-75a96c68cf18"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "6387d188-e834-495d-abce-563f5977d55f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e36e49e0-1ca4-4295-9638-d64cce5b8d94"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e7b8ea8a-f5ca-4ccf-bca2-e56c3a992c98"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "fc2b1c9d-489a-4282-a629-d491f40b6a64"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "cdef7096-cef8-4427-9ccb-c425db65a5e1"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "cfd890be-e469-440c-a589-928b2577034e"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "0dbfa544-880b-496a-b612-3787e07139ae"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "f715dcdb-a501-457b-ade8-4c2b00a52702"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "d0fec474-8527-46d0-81b6-b155bc1a1997"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "1df51456-91a6-47fe-8963-68fc2c6d0231"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "0b58f591-2302-4cd5-9d8d-b4e0ee37c921"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "cd1d4d17-c8bd-4306-a5c2-602672cfcdd5"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "6e84b316-cd2a-4262-a021-3defbceb3d39"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "4d289b5a-6f42-4e72-8ca5-80e2491ef236"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "71369d75-3318-4198-8e75-53ed6b77c17b"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e8fb83f2-e13c-43c6-a7d7-c5ea79ac2b8c"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "b7598a81-e0c4-441f-93f8-247344387167"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "8fbedd07-d72b-414c-bf14-6af94ad541ae"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e2bc4e4f-6249-451f-b93d-356285ace02b"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "8f57a986-c5f4-445f-8cf0-fcded95ff494"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "c413759d-d8a2-4ffb-81c9-270ef6075e8d"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "06e0543b-37ea-4cb3-a221-5ab86ccc1811"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e4996a9f-a3d3-4031-b879-5312b19ce504"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "9e994e70-54da-4b08-b9c7-7cf45d7bc2f5"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "799ac7c1-6bb8-4d79-81ff-5d8bf46d6667"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "36508314-3b12-40c4-ba91-c008ffe798e4"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "65b23c5b-147f-4bc8-a233-afcfb9d7d7ea"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "4cde3f7b-d077-4a26-a6a3-b339a09f9dce"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "91f4899a-431b-4ee4-850e-9dfe227d352f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "c765b664-0578-4388-94d5-b3f2f7fa27bb"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "15141dcf-8b88-4b7d-a0cc-f61837a34e20"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "2cb153f6-d1b4-4cca-aa07-0a774e4a524e"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "581ddd1a-6d73-42c1-9e06-16dc0a1fc84b"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "1ac46acc-d780-4f78-8ae7-14530392db8b"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "3a607602-c493-4330-9871-5219ea3afc9f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "9592f74a-fb01-4654-abe8-7d5848162798"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "cd3f086f-1de7-4c46-b60b-7daceb43b3d9"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "1fa97d9f-4814-4cd9-8ed0-3b68a264f173"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "2ef420c4-b687-4fa8-b315-012f3af45637"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "0b9574c3-990c-4ab7-ba5c-e1ef2285648f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "59602c61-7554-4aed-8608-a934c25803b4"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "b7913c16-00d4-4260-b648-9b4d158b7f3f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "6192a0db-bc58-4be6-9ea9-45dacc0ad73a"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "93774bc4-b5c5-4b56-b5df-932c2852f57c"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "87e33993-6022-49b3-9e6e-998e417b0856"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "4380ff7e-b360-4096-965e-94b0e5565792"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "a8f3e005-0b13-411d-8d55-80eabdde9d7d"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "51364ad8-1950-4f50-a181-d8940cfd1b36"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "d664b6eb-25d6-4be9-ad51-cabebca280b1"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "dddac791-b25f-4f9a-b237-b9c3d05a1cf7"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "3910a54c-8fb1-4bd8-bbc0-d0bd0607ccc0"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "714a6eab-9c1a-4f1e-acc0-06ad00220851"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "7f290dca-874a-4a3a-bd10-7e0e4ac57247"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "978b7d12-f8d0-4475-8e32-24dd52273c04"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "c765fb4e-a08e-479d-8d7c-1600aa75c024"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "bb1d5316-200b-4cab-b007-4c3e5248805f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "34e8b362-72ba-421c-952f-de4f2a67c15a"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "9c13419f-9dc5-4352-95b4-422f83cac674"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "378f1b96-091e-482e-8714-62e9847b3f59"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "21441f7b-be7c-4d30-b9a0-a1592eb55836"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "adb885ca-1dc9-4d41-827e-cc90475f9b01"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "fbc980f3-450c-4333-bb75-2ea8ee8b9625"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "fb6c336b-59a4-4c49-b1cd-03e73c711be9"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "2af15641-ca1f-449f-86c0-bf070ee5b63d"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "ba5cc02f-9165-4a80-9d9e-65f6d3bbd78f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "ea225f54-d112-4328-8dfa-96d879443041"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "300de94c-3278-4ba8-a81d-ecd8b72b7747"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "a012060c-962f-4c06-85b8-8cfcfe37ae1b"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "e3176cc6-8ee2-45da-a200-10095ddd7e40"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "1b8e4d37-6322-4588-8fa3-4a1d1987ad17"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "148b35fa-d7ed-47c7-8eec-cb3460783add"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "dbc020fc-84cf-46a8-ae86-45ac6afb8d08"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "58399c68-8e89-4848-853b-808c4c66ebfa"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "883e3e5c-fe1b-4cd2-b6bd-f5554c1bbdf7"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "61e0d1cb-3a1d-4a16-b659-222053487599"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "64a4cf51-ffe3-4d8e-8698-0a0540633253"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "f3ee2db6-489a-4c17-8e65-76da521d8252"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "8fa08790-3267-4194-84d6-a8599bdef68f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "29c81824-b616-4500-8229-9abb600bc65f"}, {"source": "e35185cf-8088-438d-9f20-75a96c68cf18", "target": "3182f8c3-a382-4716-87cb-68d79d1a9103"}, {"source": "b1e26336-7640-424a-9a12-24eca44b6c52", "target": "6020d4d1-91f9-48a7-8b77-c0cf981e352b"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "5db66f2e-327f-4917-bce0-69d5b3cad422"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "add9305e-a66b-4ab9-a5c8-e971380d5150"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "e129b177-6f94-4e24-a6a3-ed382c6ed575"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "869a0c7b-277b-4bfe-aa9e-0b51422541bc"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "b2de711e-7fca-438e-9f10-96df0c15bc48"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "0f5f78a7-c17c-4126-8b0c-e756a10957a1"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "72272590-27bd-4206-a59c-96db000eaf6c"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "571ff02c-90a6-4297-9bd5-d6bae7c298cf"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "c2306458-1b99-4239-ad42-c6ff54963a18"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "db270d6b-2c9f-4820-b573-2b70c4eab152"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "ef2f97d1-85af-46f8-a140-30ef0255cbdd"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "0282dff3-325d-4b68-9378-dfd83c77b0ad"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "c482d277-723c-4bea-857c-d843acb47d5b"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "c36d5c5d-98a7-4042-a665-ad53af126631"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "fdb82484-65bd-4732-8010-c2682d277d25"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "d6717944-382c-4972-a60b-183ded3dddaf"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "7762a4e9-a4d8-415e-b56f-7c73982b9cd3"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "b8bb6233-5bc3-460d-a68c-444e3ee1d08b"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "7e68f96e-30cc-4692-b265-232e58a8b183"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "ae6d9ac6-1923-4b90-8f66-e3147da435b8"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "1929e293-de44-4522-bf2c-c80245eb2ecd"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "1fd60ac0-053a-4fec-b1a2-ff5a7e6eb434"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "4a233445-9e55-4d00-8963-73ad1b7db330"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "88326ec7-dfdb-442e-8197-e3cd5b031c03"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "ee2bab37-7e7c-44f9-8800-d2bbe5aa7400"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "f175e2b7-6a1e-4cc2-9744-b8295d8f8dc2"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "6290016f-8b41-4929-81a7-28dbbc53926e"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "e4e0c8c0-23a0-4f13-91ce-b1242494d50e"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "c5d8fff9-25bc-4125-a254-1509d626f61b"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "64724ae8-28d4-456d-8d36-dca59d3fdbec"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "e00d4de7-1455-4e52-aec4-fcc00ea5a6a5"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "7e5d547e-01aa-47da-a992-6da3fc17156a"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "c062870b-6f26-498f-ab44-b28a5c89cc92"}, {"source": "6020d4d1-91f9-48a7-8b77-c0cf981e352b", "target": "58728449-f736-4561-ab61-e7a169c520f9"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "3768fc32-968a-4054-95ef-af1754fb28f9"}, {"source": "3768fc32-968a-4054-95ef-af1754fb28f9", "target": "afb0d559-0408-4760-94a5-99cc9864f8f7"}, {"source": "3768fc32-968a-4054-95ef-af1754fb28f9", "target": "860131d0-b3d6-4b1a-b4c8-80d2a2bdd682"}, {"source": "3768fc32-968a-4054-95ef-af1754fb28f9", "target": "05980e0b-4950-4028-9ced-1788448f44c8"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "36500581-411f-4764-b4ab-f32ea5f7d2e5"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "cbb80b98-a398-44b7-a48e-f50baf501920"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "ff8430ed-a7cf-43f1-bbb3-519a7fd6d84a"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "a9e5914d-d893-465e-9f62-09673386f4d0"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "59aa8072-9b6c-4a78-9656-bf429d467787"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "0f0ec3cd-5027-458a-b786-234a1f6c58da"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "2da2b794-9a35-4841-acd8-36fd2baee14a"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "a8f39952-adec-46de-a883-7cc0d0f396ca"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "f57eb52b-0c1c-42ea-8c00-3ff2583c2f3b"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "1c7d5a77-6635-401e-8880-961621348709"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "9b5b300b-0e5c-47c3-a9d6-5fff15c01e30"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "7c842841-0e27-450a-af3d-7da4f0f43da6"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "04261eb7-43fc-4e26-92bb-5448f0d51c66"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "819f5bbd-2d31-4545-a654-2da3113305fb"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "401b69ed-1ba6-4fb5-95b6-7e92cc1249cf"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "0f5ddf74-df7f-4884-bea9-6e55c366e792"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "25226e66-94ae-4e6f-89c0-758e84f47ea2"}, {"source": "36500581-411f-4764-b4ab-f32ea5f7d2e5", "target": "49eec879-a035-4528-85f3-442a77eabdbd"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "c62f821d-9ec8-4688-a3df-8007e86927b4"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "ec736367-b1e4-4f6b-8c75-75a129ffca6e"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "06e1a7bc-a464-49e4-a9a0-556b514d57b9"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "bbaff4f6-0eb8-4b16-bd1c-519d25fceeeb"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "b34a1d7d-da54-4db2-bf5b-308620371b68"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "8128d062-c150-426e-bf33-ac1aa448320b"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "f697610e-7b73-459b-9f88-1a4b4c2a04dc"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "f11ba6fc-7e45-415b-8b68-3468d4428dfa"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "aef847a8-6f96-4830-8aae-8b3a62b8503d"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "c9abdc0f-3b4d-43ea-b5e3-72a1eb845220"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "76af5e92-cc83-4c38-a3d6-04864ea4a4f4"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "c7fd73a9-1da4-4e5d-8587-0d21c9ffaf81"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "43dfa9f3-7cf4-4a28-a9dd-d3f786c054c4"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "e34b7c02-c643-486a-ac9c-600f4b912b85"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "c5b81e65-eed8-4adc-ae67-75a396923c76"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "b77846b3-f11e-4c6e-8436-c908aa543197"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "e1da67e3-02cf-439b-9942-0f23d0635939"}, {"source": "c62f821d-9ec8-4688-a3df-8007e86927b4", "target": "d7437356-8b00-4de8-8193-6bcac71e7322"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "2dce0323-2a14-4ca1-bd47-e10a346f19c0"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "50ccd227-1e72-4327-b5e2-54f7f3418a00"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "5633bd6e-0d0c-482b-badc-62c30b871736"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "b9a229a4-07ca-4e4f-8319-5e463c1a02a7"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "7b8d3339-d519-4728-82ce-1e289b220151"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "f9ec413b-a64a-45ac-afbe-c75f02575418"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "dfa0191d-ea3b-4dad-ba32-79638a7784e2"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "3f0d3751-144a-4abd-a764-ab223083980a"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "6b4efab9-d1c3-4783-a4dc-d0b2ff3564b1"}, {"source": "2dce0323-2a14-4ca1-bd47-e10a346f19c0", "target": "e9067676-bf8d-471a-a41d-8417f0c55541"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "9a099d6a-445c-420a-8b03-777a3ccdfc27"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "61b36768-ede9-491b-9427-7f9b7fdb5ef1"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "6da10c2d-3353-4e83-8dad-43eb817907f2"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "292c0eff-f3aa-4202-94b1-5f6111ea9e9d"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "dda87f09-e906-4f41-933b-5ed5d740d11e"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "22372991-2a49-40a1-898f-f04412d1a587"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "06bf814b-2704-4f61-b111-a3cd9b3043d3"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "b09c4cb4-086f-4e1a-80d4-8b028954f55b"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "78c26023-3d9d-4007-82cb-25d21f2f9362"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "fd9b72a4-749d-4e49-b469-a36d73b2d024"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "435191b9-57fc-49ae-b903-699c0efe1353"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "f94900ec-e8ce-479d-8d8f-1e815402e97b"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "3fb4cbc7-e131-4745-8df9-70e75479958a"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "b5ddb78f-b811-4888-bebf-5db2b98774d4"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "71dad3df-c56a-449f-a5ed-1c1434733ea6"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "3ac19ced-34f4-4776-b809-9461e7ec5e25"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "064e5402-2932-46cd-af41-030f988a5b2d"}, {"source": "9a099d6a-445c-420a-8b03-777a3ccdfc27", "target": "99755dc8-4d85-433e-9014-9dadf9257ea5"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "1d80402a-57b6-470e-af65-ef10c01291bd"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "17532065-3a1b-4db4-bb52-eb51e164b444"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "32a42634-f3c9-4db5-b2eb-cbd65830f327"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "49f141a3-af02-4d7f-bde7-14ec9882aca1"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "d808c24b-8ead-44af-9fed-f7827c79b834"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "05a4a6e2-70a2-45a0-8cf6-17d31853a778"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "2d60e995-7c50-48bc-97b9-bd8e81e4c28b"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "6b05ae74-0ffc-4bad-b2fc-a720e279846d"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "f20df54c-d6cb-47c8-b3e4-00e4cad40ea7"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "3e567867-abd2-4542-a156-4136b221a7b6"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "5e4c468e-2966-4803-818f-2bc6d92639df"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "91336e01-89d8-42a2-ab99-d02951a75d76"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "fe684702-4726-4521-9bc6-29f1d04539df"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "1d4d8ba2-0bc6-4233-aefc-a7cad7e8e320"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "8987bf60-200a-4f13-bf12-cd98f865c33f"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "12063177-dbbb-458e-944c-d84493c9fe0f"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "c2793f25-53a7-4446-928c-53144d969de5"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "f01bb23c-e27a-4a1d-88e0-ba0c0a5756cb"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "d5024a53-6149-4983-ab9a-7cf0c21d2697"}, {"source": "1d80402a-57b6-470e-af65-ef10c01291bd", "target": "879b3bb3-dc20-426d-a732-33c346251340"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "043e5d74-b413-4c28-8400-edcb9675b6fa"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "dad39884-0005-4b45-aa7f-3cbc0d27b30a"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "6f5bac43-cbcc-422d-855f-91c3af08a4dd"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "5f7aacf6-77a2-435b-8942-bb17fa6adbd3"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "1135e29f-a2f6-4770-af44-dd71392e22c2"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "6d481c05-4a89-41e3-b64d-db4ae4cd6bad"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "5e9eea09-443d-4324-b033-5655f54f3e2d"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "0e04ea92-fe12-4a40-8f84-46c95b6d109c"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "c12393c2-b4d8-44f6-9c0b-60915cda139e"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "7c450eb6-2d75-4680-956b-6d9f55ee95ab"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "3ace4ea1-d222-4fe5-ba9e-99d2737b9cad"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "07ba42da-19b8-4c2f-9e1d-2ba97c24feee"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "99e3c86f-9dc9-4d1c-8d3e-d2cf0c229e9a"}, {"source": "043e5d74-b413-4c28-8400-edcb9675b6fa", "target": "ccbd4288-d915-46be-9c6d-abde4c8b79f7"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "dffff6b3-6177-45f9-a1a0-af862c221f07"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "eada462b-4f3e-495e-9e76-fec7a8581ce5"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "5e57f3e7-8f7f-4a15-b0b2-dc5f8a43dc92"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "9b852b7b-7c8a-4e50-8328-3f155584b791"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "55833416-6a67-492a-99f2-c80c3ddce94a"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "4d7f80b6-2406-4319-8288-44f0de4c306d"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "a0a507ff-c6dd-40a4-b419-b1b85e39e97f"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "3c943bff-8877-4997-bf1c-5a7c15b5de54"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "81a00f00-9798-42e9-8a58-b0e541d0f646"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "e583a43b-9e26-4fb5-9957-326d2c2acf01"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "324be544-b64f-4dc6-946d-33fb909ba5eb"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "4fd863e5-7bf0-4ed7-ad18-697e4be2b76f"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "61de76da-990b-4d13-b756-bf68fd4d06d4"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "52587fae-528f-49cb-8c82-f7611e200fca"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "972e3c32-12de-40ab-9d44-25476894437b"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "c299531d-cabe-4e87-8c27-016be3d5bf1e"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "d037669f-9eed-49fb-bc89-daab8a3d2d49"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "15a8ed99-b9ca-4ddb-9f04-7d0f534e5bdc"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "8632ff0e-d48a-4f3a-9ae7-5923f07a81c4"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "6df0251b-cb71-48b7-aa48-f52de4abed1b"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "3d88a67e-80e6-4e50-bb27-ed86487f233f"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "7daf6a3e-0e4f-4d39-a37f-061af1ea60da"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "f7798f5f-fe1b-429e-8177-ad85a81a81f3"}, {"source": "dffff6b3-6177-45f9-a1a0-af862c221f07", "target": "d7d0b6ab-c4d0-45ea-a7f0-47391cd8cef6"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "2dcf668d-e56a-471c-87af-36336987f879"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "be744a9a-70f2-4431-9987-3c52ba781446"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "11a66b6d-5fb6-449a-9e78-7502a348e1f4"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "13dca31a-f23a-4c95-b69e-1e7f77f0398a"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "c0cfffb7-a461-4a99-8e4a-479d8de8037f"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "a6f1925c-ed78-48ea-849f-f81804787667"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "e246d4e8-8555-4c15-be70-1949fdc95413"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "d4d1d308-f6c0-4438-8015-66e3deec70d9"}, {"source": "a9f84c7f-9d0f-4686-a3f1-02aa476131f9", "target": "f509a854-a16b-4ffd-90e5-d76692a4893c"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "afcf994e-fdc1-4914-a502-49776777256d"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "5d75b7cd-3ab9-4b5e-9206-80d3c02abb31"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "21c97d56-40a3-4c43-89cb-1177440781bf"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "6f97c8e3-44c0-4b05-834a-1116e6e7ec6a"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "fe1f9f35-ebeb-40af-a96b-5d9da0690636"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "bd293213-3b07-4baf-9152-e2e33d0e89f8"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "5c677835-4d6e-4dfc-9ea8-14d568c873ca"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "03dc3a27-3717-4f24-bff0-69a3760eda15"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "80c44071-1750-4135-ac4c-5c10d52537ee"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "6d02fbe5-a974-486b-b275-a2c94953bb5b"}, {"source": "3fe8f60c-9fa3-464a-ad56-3c3b4ff891a1", "target": "afdbb721-e9a7-4c32-8977-21722ca881d4"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "e918a3ed-983d-4ba3-80dd-db1904c0e564"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "9202652b-de45-42be-b6ff-db3ef19e31bb"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "41225b05-7722-4430-9eaa-04e1c11a19c6"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "2490a0ad-4f42-4f71-b75e-b8bf2a69d728"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "ece56822-c910-417f-b68c-462190937e02"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "329c9877-cc99-4ed2-8782-e489cce4dab7"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "43dab182-ad88-4ea2-b47e-40760426a1a1"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "dd5dd22e-1709-4b88-afba-c98a0b7d0294"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "cb1393a0-ca80-40bb-8a62-743e24019322"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "41dc3f55-3594-4a26-91d9-5166b058a8b7"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "e716fdb5-e0a5-45cf-a69a-fe88563149ec"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "6d4f6481-2d58-4511-8ed0-5391622a8807"}, {"source": "e918a3ed-983d-4ba3-80dd-db1904c0e564", "target": "047b7325-631b-4665-9abb-175d6d84ee99"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "2ebb834a-ba70-4caf-99f2-538a478af600"}, {"source": "2ebb834a-ba70-4caf-99f2-538a478af600", "target": "69cfa5fc-0824-4f45-a7ba-fa8fecb064fd"}, {"source": "2ebb834a-ba70-4caf-99f2-538a478af600", "target": "730c01f8-fcdc-43e4-8c8b-184572cf0c8e"}, {"source": "53dba2ae-8c6b-4045-ad69-f14962d1aa65", "target": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "4d06c647-3b84-4c2c-81b1-23cda1581fd9"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "fe8bded0-3716-4d7e-935e-0c3461899b33"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "35b13a67-b78f-4b97-bbf3-06887b8a2712"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "60d306b2-546e-4f7d-a6ba-c629595ad904"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "7bd9620a-afe2-4e35-8e70-5c36b81f8012"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "c216aa51-8c40-44d2-8c30-657cc07a20e9"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "b418c39b-df42-4e63-b24f-315ebb460b4b"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "a1e66262-26c7-4ee4-b96e-d2cbab29bd0f"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "bb4399b9-8773-48ba-8706-681227649279"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "e35fea74-8f72-4a43-b823-c5b8fe69b5b1"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "ba246938-0346-491f-9263-2e5197323cc9"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "c0c3b973-bbf0-40f6-94e9-e050545e3136"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "fb08780c-2e87-4215-a5cb-c50bf5637d32"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "7cff5273-5c41-4998-8f01-8d6c5fd1376c"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "22130431-ec91-420b-8833-151dc724cf37"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "38139c87-c345-4482-bb2b-8f95c40a8ca4"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "68e08954-70ce-41f6-969d-ab034ed925d2"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "12f63830-f83b-450a-8e2b-2374c797381f"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "342c16b6-262e-4d3c-9d1f-57f8852b6db5"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "8182e4d1-7f58-4ac1-8866-2c27654fafef"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "78dc5fd1-1774-46f4-9077-f1f46bb3793f"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "0f36df21-d663-406b-8c4d-e62e322f64d5"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "894f2d70-ff1e-41a5-99b6-cf1a109ba18f"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "89725635-0e4d-47c4-b18e-1f313a968452"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "c35002f0-ab96-43a4-90aa-ad0d2a4018f7"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "2e7f75e2-c21f-4d42-96ba-de6c06a291af"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "85cb58a1-8d6b-4a24-993c-1f5874e45932"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "634c67b5-6d98-4f40-8478-bfae78fec2dd"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "69a2de50-418f-4adf-af68-06960c718455"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "b6a75168-661b-4279-920b-7380fd2472db"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "4c940a40-5ead-4b20-a8d5-00bbd8dae544"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "5efc8ca7-057d-4c07-b7e1-831c4f0b250b"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "c729d245-91eb-43f1-a5e0-ebd8c42aaa5a"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "72f11dc9-52c0-4c12-9793-cae20f0e5076"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "701883d6-4d70-4dbb-be92-0144915de760"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "33628547-e5e4-47ff-8fae-321924672714"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "e0ab27b1-5822-435e-8a3d-2f5f48cf8b8b"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "aa231a64-833a-455f-9d0c-1d6e559b8892"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "79198185-13d2-431b-bdfb-3885fed1bc65"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "9d5eb376-252f-44dc-967b-13710e6019d1"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "bd5cd98d-e98f-41fd-b0ff-0194e79407ad"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "1b68fb30-8ec8-4fd6-84df-c64bbc5fdcac"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "a77a5d53-5a5d-42eb-8eef-2af8798c4db6"}, {"source": "aa13f887-7e48-4dec-a42d-7dbaa85bf50e", "target": "90b113cb-1b1d-4f14-941d-8d850de21594"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "075f9942-2a80-4543-ae8c-0cb14b4239ea"}, {"source": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "target": "a5dda387-9131-44a0-b592-1c901adb776f"}, {"source": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "target": "5dbb78ad-797a-4822-8d98-7791a87273e9"}, {"source": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "target": "874ad328-2517-451e-b2f5-70b3f640c1ae"}, {"source": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "target": "ed1bac3b-1217-4ad1-aa53-f268615b8045"}, {"source": "075f9942-2a80-4543-ae8c-0cb14b4239ea", "target": "24b0a1dd-6ef4-45b4-a0ec-7b7f0cd34485"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "b790a2c2-7a11-4ef2-b427-dd5125576f5c"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "55158685-0df9-4c25-ad0e-06f3e54dfa86"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "52d1f30e-bda9-4a13-9a52-ad45fa398eaf"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "6c5cd387-f3a1-4f30-a0b4-66f022e03fde"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "77e4d67c-1fdb-4962-8496-e00447ad6c98"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "e21c0e45-1c50-4e12-8e9e-e807c2f044b2"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "9ada1768-551b-421a-8884-2498af2d39bc"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "97f69696-8150-4af7-8088-fe673c33c457"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "9981d7b4-7b00-490f-86c0-a6ed17a45a25"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "f6a70b26-c1f3-4ebb-a00b-af99fdeca3dc"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "8d53c76c-9f98-41bb-b5c6-60d52d78362c"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "b0d23491-add4-4c75-a55a-133b0c884269"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "e41825cb-e358-46c2-9a59-23579f200e5e"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "1662a3cb-99df-4743-b083-9fb6dd8aa2e1"}, {"source": "b790a2c2-7a11-4ef2-b427-dd5125576f5c", "target": "b392fa61-624f-45cc-898a-5003c7f8afd2"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "53a44cbb-09ed-4f0c-9a10-640f1ea344a3"}, {"source": "53a44cbb-09ed-4f0c-9a10-640f1ea344a3", "target": "be155ce7-f6b3-4d72-a6db-1c99d6d581d2"}, {"source": "53a44cbb-09ed-4f0c-9a10-640f1ea344a3", "target": "93dfb729-ffb4-466d-a5fb-99bb4e8ca3da"}, {"source": "53a44cbb-09ed-4f0c-9a10-640f1ea344a3", "target": "3184c6f8-814d-4136-97d6-ceafa6330195"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "87a89f69-2fd6-4598-816d-d2fafc4281b3"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "01eaaf48-d477-4b0a-8829-c7ab44c8ca01"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "0ab68bc0-103b-4a0d-ba42-2fa603addb2a"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "cfadc1a2-3b88-48f1-8699-4e97a6f00c56"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "c6935ed5-439e-42ec-82a0-91d5c7f9bb3d"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "cda58efd-328e-4cd4-89f6-e88747453720"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "170b3368-2a9e-452b-b913-69c6b7d93292"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "3b1c2a60-d73e-4d07-9bb4-2c7318e62f69"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "5b59bbfa-0504-48fd-8229-4015331eed0f"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "b309f670-b9da-45f9-9312-604494aef47a"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "c418e165-81c8-4716-9c44-64bd73d3ab80"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "fb418ff4-854e-4f88-b226-37481110b327"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "34f2e78c-76c4-4adf-96db-db3d4bb502e0"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "a4c0d33f-39ea-4aec-8eb4-0974d8daa0f2"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "d28b18da-f90f-456f-8f86-85eef07efc93"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "79bf1fe5-0f6e-4790-8211-cdb71d3ff93b"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "276be3f5-f23c-4773-b43d-7585baf6259b"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "f2432701-be2e-4fbe-9e06-1cacac4b3b70"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "778026f7-ebce-4c8a-af9e-ef3f0dd759eb"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "b502f299-822b-40ff-a9b5-92379a8729a1"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "6fa1cf3f-b1ae-460f-98df-0111b58188e9"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "25ebe544-de97-4eb1-925f-60105c1a851e"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "b5f4a576-0a96-4f17-8231-a4354562e7c9"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "4bf974c2-a8cd-4f6e-b137-394e9e82a915"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "85cf4d1a-27cb-4c53-9056-fe0b1719f637"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "f929dd43-a191-4e6b-934b-c3fb26177373"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "860f4d01-6336-467d-a064-a3fea221c120"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "68be7291-cde1-42b6-867e-c092d0f09f5c"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "08fbc10e-3828-4780-af2f-4b489fdebb0f"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "8afe2901-4819-436f-8941-0d54f22923d7"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "ac7aaebd-c851-42d5-82de-97c3ea04a235"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "0563b6c1-95cb-4838-aba5-1d354b97b2b0"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "6a48ea37-a8ad-4d86-b8c2-0c51ebd2cc6b"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "ef700de7-294a-4c4e-b022-61e38e35c004"}, {"source": "87a89f69-2fd6-4598-816d-d2fafc4281b3", "target": "ed504886-18fc-45b2-9737-ef35761d4bc6"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "218712a1-80b8-467d-b2cf-4136a13efb36"}, {"source": "218712a1-80b8-467d-b2cf-4136a13efb36", "target": "bc5efd42-891b-4d07-9a57-f49af79aaed6"}, {"source": "218712a1-80b8-467d-b2cf-4136a13efb36", "target": "fb407bd7-e288-4261-9c38-2f802c26c261"}, {"source": "218712a1-80b8-467d-b2cf-4136a13efb36", "target": "c4f925d8-b97b-423b-9d17-777f1b0f926b"}, {"source": "218712a1-80b8-467d-b2cf-4136a13efb36", "target": "a48d8121-f3bb-4816-9e35-5124bcf26b5b"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "8e629ffe-3ff2-4f83-aa65-caf8ed9a0edb"}, {"source": "8e629ffe-3ff2-4f83-aa65-caf8ed9a0edb", "target": "6cf143ca-4045-4149-a38a-f0228f0454ac"}, {"source": "8e629ffe-3ff2-4f83-aa65-caf8ed9a0edb", "target": "c60fb3f4-d123-4cc2-8076-17ec217bf261"}, {"source": "8e629ffe-3ff2-4f83-aa65-caf8ed9a0edb", "target": "cae183da-5053-4ee1-b140-240852fe9ab4"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "48c39bc6-e735-4afe-8bbc-c6dd2f3c52c4"}, {"source": "48c39bc6-e735-4afe-8bbc-c6dd2f3c52c4", "target": "b817a606-8bef-41b5-a06e-e14e7d9e68bd"}, {"source": "48c39bc6-e735-4afe-8bbc-c6dd2f3c52c4", "target": "5aaa8135-a75c-4a78-aa76-2531bdbbf3d4"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "86b8602c-b84a-4813-bd1f-586f252114da"}, {"source": "86b8602c-b84a-4813-bd1f-586f252114da", "target": "c93461d0-ee7a-42ab-8d67-89d0a9685402"}, {"source": "86b8602c-b84a-4813-bd1f-586f252114da", "target": "9f3f9e8e-c714-4406-8cca-f55aeb3cde7c"}, {"source": "86b8602c-b84a-4813-bd1f-586f252114da", "target": "9b0eb60f-7458-4549-937a-1c220474ddd1"}, {"source": "86b8602c-b84a-4813-bd1f-586f252114da", "target": "0c6be5e5-4ee7-4667-9ca1-89be2f6758e3"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "46ea7816-2ce7-4942-b0b3-a5495b443992"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "060a54bb-ed7f-43fc-9cbf-f48f8175dd02"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "ab31991a-a7a0-4706-ae86-12f6a46fae72"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "80439a20-3673-486a-86e8-d3352997dfce"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "60a6cb34-54f6-4131-ae01-dceb01233f99"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "4ebe519c-7063-4b9d-b957-6c31f162c548"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "0b78a6ae-9ace-46b0-9a13-0042f10cf3c6"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "b1b2cf12-76fb-429c-b8da-5d1b4324b0d6"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "a081c8d8-c98f-45fd-8871-d3135bba02c9"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "4c3e480e-b603-4e30-a1b4-83f774934a92"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "6a30f54f-3f56-4b83-a796-eaac68f4c2e9"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "a3c54fc1-5f3f-43f7-b5fb-e0e4f5fbe787"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "78ace56f-9b9c-4d6a-b422-ddf4a9b35048"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "44d98696-2871-4f0e-9cdd-9147f5d5b9fb"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "84a9d0c0-9249-499d-a9df-c2e9c5186200"}, {"source": "b691d4ad-0ddb-49fa-8ba9-f312ae2e3fe9", "target": "a0e67463-366f-43b6-a453-f74271f24441"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "63770936-0a6f-452e-ae13-d0194f12f4cc"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "c9f859a0-a364-42d7-bb20-6e8ef6c7416c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "87cb0d1f-ac0e-438f-8177-8c01b82f419f"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "e729d44a-09ff-4f8f-8bca-45f49c5fc93f"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "c5399cff-249c-4fa5-959b-d86a6f369b56"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "52e4198a-34ef-4253-8825-ab993a4153cb"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "63a48710-9337-4d4f-bb03-e29133ba498d"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "84767f4d-9df4-401f-a900-ecb2e9e84390"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "a64b14a0-b0f2-4180-a667-2282c716919c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "9fc84c1a-6013-44da-bb7e-f62b878d5e80"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "1dde8a98-0140-4771-b54a-53f33f8c09fd"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "f85a6089-58f5-4d7d-8fb5-1d927ecd2e3e"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "3f4486cc-7ea0-4ec9-b2c3-fa056cfd8036"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "e2c7c9f0-9ecf-41eb-80ed-4a0f9baf87f3"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "9f677498-d32d-46da-980f-cde431166c87"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "c5efdca1-9f68-4c60-a6e2-460b24ebf3b0"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "54c05310-d3dc-40b3-9c9b-0552295c0257"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "8f1d95f8-fe02-42f4-851c-59d9b44c6b14"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "6dd53651-dc92-4a6f-922c-b5ba09ff8d4b"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "a3ade592-3611-45bd-ad7e-b1f9ef2c1983"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "a3dd6eeb-7a99-4e7b-90aa-9c8a82c82e36"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "8218945a-245c-420b-98e3-e734a3a89a8d"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "3daafca7-e85f-4a33-9ea3-739320d5b813"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "45b35c8c-be1c-4274-b360-f197772a393f"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "0571319b-e335-4d45-994b-09fe216c4e7c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "38df95cd-2b7c-4172-8968-b5ae12d5e37c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "491a9b9a-5f83-4281-a0b2-4d36fb5466d3"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "b34a4624-b240-4bcc-b8c3-aa1f84e6c569"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "206560ee-8eed-4940-b162-8b9a0ad39b86"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "77f91416-bb91-42d3-a84a-4bfc985b7f06"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "22512835-d2ba-4f3b-9ec7-3bc2eca7bf57"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "9f421fce-b105-426c-b180-5ccfd12cf3b5"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "4a6b9871-7d56-485a-b2ad-be8cb7412414"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "e7e8bf24-1a25-4eb9-aaca-eb29de598a48"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "6004ab67-a18b-4a18-96b7-856bf7da3982"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "74f084b8-6a83-4df6-ac7d-145ea23cf534"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "b074e0aa-a670-4f81-9311-d04ddc45169f"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "db1cefa2-182b-4f17-838f-64310b1a331c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "6aecf157-44cd-4d3e-82c0-4ebba06d804c"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "182a4ecc-a546-40c5-9a9a-b4ea6fce42ed"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "896613ad-e081-464d-85aa-30724bd600c2"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "fab7a6c6-2834-48ca-8339-422d5eb36992"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "d02181a8-e15e-4449-9b0d-e9502911c2c2"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "70abb7d3-ab83-4ef5-b809-6eb838e3dbc4"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "cd3b1ecc-8730-466c-8ff5-2f8a5f784475"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "657f10f5-ec84-4399-a225-fadf53ee75a8"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "84c16956-04fa-4d8f-88c6-053441c06a83"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "83ca5f37-c988-4078-bc6c-cf112c4ffe32"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "4601d909-d33f-440b-8c96-8425d751334d"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "8718948d-6a37-48ec-b676-895483e5fedd"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "5481889f-03fa-437f-954e-71ad2f6ee803"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "bbeae2a9-2661-438a-bf0c-ac663266171e"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "2ec2a0db-66c4-44a2-bd05-629c22c08d63"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "3e2fc096-3818-46d5-ab3d-7d3f6fbfb72e"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "9423e57e-0d60-4db5-8965-c4d4fe459848"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "a78406c0-8baa-4359-a500-9596ceb8a327"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "f5a3b93c-0ba3-4478-8f67-b363af51ccc7"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "a2419d86-83e6-4526-878c-bc4bdb83c106"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "716fefb9-9624-4de6-aebf-91abaa43747e"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "e8071a28-a1bf-4d7f-9efa-81d47c7da8a7"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "2adfbae2-2570-4a31-a303-00413a84d818"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "bbcdaedd-98db-4a28-aafd-7e529d3b53bc"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "7a2ab0f7-1ba0-4fdc-9b12-102c90acc658"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "01711602-2123-4030-864e-06425f800a3d"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "3ef892e7-f747-444f-871d-3c32c8f8e133"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "5ba5e718-6833-4047-a356-1df0accea2c7"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "35b03065-f095-4426-809c-95dc63df4960"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "ac80bb00-3a9c-4fb7-89b0-19b75a7908c3"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "9d676e77-af17-43aa-9ea4-c6073befca66"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "1c07e131-12b3-4637-a5e6-f3ed1d160921"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "f74b81ca-2eaf-43b0-8146-8162cc03bbe7"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "23dc956d-e09f-4ad5-b249-85bf351f1ef9"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "d717b6ae-11eb-4f00-83ee-3db9671cc53f"}, {"source": "63770936-0a6f-452e-ae13-d0194f12f4cc", "target": "332e7d16-0b4a-4815-b22d-8bb8c94aac21"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "c5be8054-2fb4-490c-a78c-e7966b7c87bd"}, {"source": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "target": "7ac6e88f-ecbc-4b2b-8e61-f2be39d3a316"}, {"source": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "target": "ffa3929e-98d0-4727-a3ce-8087ef93b907"}, {"source": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "target": "629ef581-932c-4516-add2-c753f9b5654e"}, {"source": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "target": "229ab6f4-a246-49cc-91fd-28ee3863e437"}, {"source": "c5be8054-2fb4-490c-a78c-e7966b7c87bd", "target": "5ccbab0b-83ad-4f41-8b56-25024dee4a3c"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "356926b4-c684-4884-86eb-a03b7cce74dc"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "add044ac-08d0-4672-ade3-5b7e2c0dab33"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "a8d9b458-f574-4280-9592-3966175d78a5"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "337979d0-1778-4d3a-af9d-6d5981a2a7de"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "c313d5aa-b12d-423b-b75e-1eb88cbefc00"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "4e5cb232-ffc3-4b37-bb29-edb746f1662d"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "1e5b4051-7eea-4a01-9bda-0df7c8ed4763"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "65a74f72-fda1-4957-93e6-b0c1c7d90254"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "69b72292-32bb-40b4-9716-03e3176c601d"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "c969c946-2860-4747-880b-113835d5e77a"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "2ed6e943-a4bc-418d-964d-a4d618e2e446"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "a77303f2-575e-4bef-8a64-905661dcd10b"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "19bf87c3-41b1-427c-90e5-d093158315b0"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "2eebbb24-373d-43aa-a7ba-6aea31b3c0d4"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "05e597f8-d79f-4e70-a131-e3cbb47d4183"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "e29e77bc-922f-4e16-b6e8-abe31341fcf4"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "4d26bf4a-615d-4cf6-bfa2-25e2dc0602ea"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "2ce96c33-d4ac-4e05-aab8-d44a1776a865"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "640906ca-70f1-4eda-b0d3-d5b04b60ed53"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "daaf8b8e-caa9-4042-ac53-8dceb55cb7ea"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "0974bdae-5d38-479c-821d-7f98862747f3"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "6c1a6eee-71a7-4753-bcbb-6de7175a2076"}, {"source": "356926b4-c684-4884-86eb-a03b7cce74dc", "target": "dab39d12-64bf-4f93-aea5-a46fb977913d"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "ac959196-2190-40e3-a722-e4722d929cd8"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "1c2392dc-babf-4b3e-8ece-4cdb0d047210"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "f7a84694-a99f-4fb6-aa0a-7ddd805be33f"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "f5385f9b-462a-4d3d-be57-f5fdd321335f"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "97104ea2-cf8b-4344-b3e0-96b1ea72e12a"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "36e6e657-79dc-45b9-81b3-5dfaa6943ccf"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "daf5dcdd-c09c-481a-aa69-a730344b5a04"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "cd92b3b2-caaa-41c3-a715-c09546598770"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "959b83a9-9d29-471e-8ae3-789988cadfa0"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "14c9f7bc-da77-41d7-8575-5c82652b6b3d"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "66b545c0-d808-47eb-80e3-f37cd619c181"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "27c5eca0-9670-488e-a17d-05b63863fbd7"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "07f26626-f2d1-44da-b128-839f7af19682"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "4f43140b-77a3-4c55-9a3a-e11d75e09128"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "8230cf26-e3f3-45db-b1f1-6db42661e79d"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "fc272bd1-9884-42cb-8bae-61086e549503"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "e8d0cd63-be81-4eea-b147-e1c0483afa75"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "c12c86d5-080b-4cb6-a867-7145269e4713"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "25182d73-5992-45c2-adac-bcd81bb28b68"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "23cab896-e012-4ea5-89d7-354fb0ad750e"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "3b04691c-3d50-4cf8-9d49-acd8a1d5ed8a"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "674ef669-4f87-404c-9af0-e01fc52eba1d"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "c92901d1-54ee-4c7e-9522-42b02e76369b"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "08d4a724-fe05-4d10-91b0-54c878ad2549"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "f65d619f-24f7-416c-9083-18dac8521973"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "8d76ff78-44e7-4fb7-8789-33dca54c80eb"}, {"source": "ac959196-2190-40e3-a722-e4722d929cd8", "target": "4a1117e2-88b8-4198-9797-28f8e1d072f0"}, {"source": "7045c527-0004-4c88-aeae-8b10e6134b82", "target": "0ac5f6e7-1add-4fb9-a113-fe10c4245936"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "485a9dc5-a515-4909-b09d-fa43054ac0e4"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "17b66602-1769-449b-9cfb-4ac080b4bac2"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "968a3cfa-e2c6-4871-95fa-fb1b7084e940"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "40273434-b037-4ae4-8587-8d384fc58028"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "0a0f3e94-3f16-4c7e-ac52-e50bbfeb11ee"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "791d3bcb-1ed7-47d9-b1fd-dca51ba06549"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "f1fb282e-a4d2-4dee-b77e-d93006e01393"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "0bb5fa90-3ea9-42e8-a17e-ddcbf4d9ae65"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "e42ab872-a834-4470-8ced-9b974389de10"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "396ff3b1-a60a-40c4-b411-92730bf7cc23"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "8e7a2e16-dd12-4343-a4fb-2b4886754007"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "16059016-fe09-430a-ae81-baf432918a64"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "079fd5a6-23a9-4d84-867b-0462392559c1"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "17c6b45f-f02e-4d1b-b203-0d3d16edef98"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "f5275367-e4f3-453d-9ff8-17a2f40e5678"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "ce7826a7-91b0-4336-821f-ae63afff0fe1"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "3001566c-7240-4a7e-a772-ddd92d44842b"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "c8d8b40d-d18f-47df-9934-84a52993545a"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "83dac0ba-591c-47d9-8fe7-4698a66dc3ce"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "b7f88cf5-54f0-42dc-b13d-d356f3997cc7"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "570ee7e2-6aba-4537-b2bd-e67e6d5c299e"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "c7b46a7f-5196-4aec-9372-f74402540d26"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "237bbcc0-d629-4af9-b7b9-3fdf95fc0c46"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "af1e1459-b3bb-4659-a0b8-de355d839859"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "f1220093-8a0c-4f17-9a11-b95c220cd990"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "932816f4-b62b-44e3-889d-29af2c3bbaf3"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "9d4c09fa-01b3-4345-91a4-0234cf6bd02d"}, {"source": "0ac5f6e7-1add-4fb9-a113-fe10c4245936", "target": "13688be7-9bc7-49f9-805f-bd3d11742c99"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "2f790937-6f45-4d08-9503-225f8640651c"}, {"source": "2f790937-6f45-4d08-9503-225f8640651c", "target": "9acfc2fe-fca5-432a-8e69-04c7847a8f33"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "615c0846-de67-43a1-9b80-0b104d15c105"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "c3a44142-43ee-4386-83cb-9d0de6589eec"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "08cb40d5-15e9-4de1-878b-af21e1efa58a"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "13861071-0749-4499-867f-f6b6539d10ba"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "620af10a-19f8-484d-8878-df37b22d75e3"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "8b83faca-b080-4847-8567-de09456fdd16"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "4efefb04-1b67-4e99-8970-3b2631b72b3c"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "af98b822-3e36-4534-a14d-d52eaa12a40f"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "a20c47ee-5fba-44d8-91bb-8475adef315a"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "9dbdfa5d-5e73-4a3f-ac4d-605d4f4acb7b"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "56dc860e-dce7-43be-b308-91fea7a0a8c7"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "f7c9b08b-1517-4dad-a97d-4357a7deff74"}, {"source": "615c0846-de67-43a1-9b80-0b104d15c105", "target": "f2b781c9-631f-4896-9099-ecc45384ee77"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "15148bc6-f768-494d-9ea6-359e60de35ba"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "5dc6f6be-f43f-41bf-a4fa-cbb21b4af3e2"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "baeb7777-6891-494e-b040-4d113a2a5307"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "deb2ed87-f10f-4b23-b866-b0349cddb864"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "d3ba9c2c-7960-4a1f-8e15-b8ddaf052e76"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "fc2ae307-85c5-4f26-a3ad-f63c7089feac"}, {"source": "15148bc6-f768-494d-9ea6-359e60de35ba", "target": "e7a561a5-3a36-4c4d-97e8-51d554d8953c"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "fdd043cd-d2b7-41c2-ac47-39e4cd525e7b"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "e453067f-b605-40fa-b687-f330811fcb06"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "64257ec1-6ea9-46a5-9ff6-1a96d18ca6d9"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "a417eedb-200a-4051-a043-522bc649bd1e"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "87773dce-19e3-4f43-8267-e99800bf5eab"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c280483a-1995-43ee-82ee-a5082e69ab41"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "669afdcb-4b6e-4285-b8cf-8b23d62daa08"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "5ff506e8-e6a4-4db6-b864-9c6f96bc3f4d"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "eca3c47b-9d08-4587-aa3b-ae39c178d239"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "a9531542-1b22-478a-b4db-8901ee5598bc"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "ae5affb9-66e3-48dd-b08f-2ab489f8d3b2"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "4ab25c62-f8cc-4589-a4a4-3568d87e8a26"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "0a59754c-6bbc-4222-809c-fe44032a7810"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "1350f8f8-e1a3-47cc-ac76-16bb2e9b4f83"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "74aabd27-3e37-4b65-88a6-b918531ab943"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "f4abbbc2-5d11-4492-be99-e099628defb0"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "f991c445-68a3-49b1-9a23-7394622354a6"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "5c464486-30c7-402b-b712-87476094f5d0"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "876c06cf-0935-41dd-a685-6322d8cc6fd5"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "bd3f6a90-61bf-4602-b94f-875265eaa32a"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "b1469aef-15d1-451d-a13f-fa9b2ba3650d"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c0b45df5-50f8-439d-947b-b2bbb317e769"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "37a02009-b9fd-4c73-9cba-8dd29975ca0d"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "2ab868c5-336d-4b2e-86fa-0b248a6b6e5c"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "6f5f9495-e8fe-4c05-a5ff-307515752ac4"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "09ca4e61-b286-464f-97dc-c3dff19b1668"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "cefc96d2-54cb-456e-88a9-8e424a173b5b"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "5fb7cc6d-7b7e-4382-9833-5fa39134c2e5"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "27d95f30-3c93-45e8-9686-84070240c500"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "805b60a1-8975-417b-80cc-e237bfe1d95e"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "f93febad-7c43-44a4-85cc-7448ae2d8f06"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "98712501-4d8c-4981-8956-b95f909de99a"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "18e440ef-d503-4490-9ad7-987defb0acef"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "cae30be1-718c-4b17-86ec-63a08efff18b"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "9f30ae50-d877-4743-8059-7ba873470c42"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "fecd02d5-4528-495f-9db8-c7a14f71c603"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "3070b318-a3e3-473a-a20f-f7f5c88e3907"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "d943f304-778b-47e3-9076-3ee8a7dbb2ce"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c9314075-abfd-4c28-b92a-65dda9580d24"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "9488e2b6-a48c-4d97-8487-18a58a876929"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "fa06002e-6ffe-4624-8cee-0a9810a60606"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "8779f531-9b4c-454e-981d-7723f306aae9"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c8923764-e53d-45c0-9d50-332a716ec11f"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "29c19681-a5ce-4465-8d53-58124ecb7e7e"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "9da6fb5d-6877-4786-aa65-40bbbff29305"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "cff349a5-48dc-47ad-96d4-7d36216d0f18"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "3917e1b2-6f3f-4671-90fc-9dbd89009276"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "eb124b99-095a-4b64-a488-7e1ce0675eea"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "80a4e1e2-150e-47dd-8c4f-827f2619c76c"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c705778f-d84d-45e6-8cd9-7b8ad4e7a1e5"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "0b83c62e-a827-41c0-b8cf-ef20edf43609"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "ae8361de-70cb-4233-a6e0-f2934f638c81"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "53d720e9-507a-49c9-b5d3-e4b9f9b25424"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "869bc397-1986-43a7-b79b-e9416aa4331f"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "b58abdc1-3271-4a4a-80b0-559833bc5d26"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "bd95eaaf-0b80-4f20-b860-22ec50e6436f"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "faba72bb-486f-4376-b068-25c59873f9ec"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "a980a3c4-4955-4a31-a3cf-96c3ea18f7d6"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "3e42208d-a7fa-4727-be92-d0cad4e1d678"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "86da56e5-db8e-41f7-ab46-c28024917bec"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "44199f0f-a9a3-46d4-af39-b2fadf64155a"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "1f91323b-a3ed-4672-bf1d-d409b521eb3f"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "bb145d70-24a9-43ed-8a9e-5f3312d2e383"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "f00d5522-2695-40b4-bdc8-a332841745b2"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "16b1e1ef-2c5a-4ef2-b1dc-2c155af390c0"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "09916e7c-6a1c-448e-8196-859ff370f148"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "937cdc5a-8dfa-4da5-b053-dca876bf8f42"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "7af5cd91-25cc-48d3-9fd7-e743aa71342b"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "5478e927-35eb-47fd-a0d1-b0a1ea46e4f6"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "c8701475-f24e-4ef0-a970-6064795f5a65"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "08ff49a7-1727-4f62-a1bd-919c182218d8"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "5073053f-6c64-4e3f-a9fe-f915d92a3846"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "e0a71a71-9561-4f3b-ac99-7486bbc8d5a3"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "e4d66724-8c5a-4152-82a9-ed0a5e068fbd"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "4f13b442-a14c-42ed-a8cf-863d72f2321e"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "fd707d3f-fc9b-4b3f-a36c-a76def73a1ea"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "8a1714ad-779f-4ca1-8475-0be308e51f79"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "b57c760c-6ebf-4dd4-aa27-7c9a0d91115a"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "425c2459-3d1a-4739-a09a-2deaa27a7413"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "161637f6-c237-4383-8206-69b3ba8f0913"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "265b2855-d6fa-48d7-97ae-5d9da3f6b88f"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "fbdf2186-9b6e-4f77-a90b-d896cb669bd7"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "f56c9b14-ab82-40c7-a98b-ebc97e1b73f6"}, {"source": "b72a2ec5-0a4e-40b5-9c2b-5889b3cc2c3e", "target": "a6a01c35-b7ec-4e2e-ac2b-bc6f74bd6de0"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "62ba0396-8f2f-4055-9e3d-eec1899a9572"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "40c515fa-8a35-404f-8a6d-9d7635e7aada"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "356ec497-bf93-4f22-97d9-b42e7e5837f8"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "602dffeb-ff1e-41cf-b8e7-488bba93594e"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "217a36b1-e5f1-49fd-8fcd-dec995ae8643"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "2e58764c-b1e2-4052-8da7-1be4a882b2d8"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "1867f03b-d5fc-425a-9785-99a92a3134de"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "449b9638-2466-41cc-87c0-9d96611c5cc4"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "c9333f27-8aab-4de0-88a6-141bd72127d0"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "bdd65124-4f2f-4e97-b75b-bb0de7886f63"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "759368ac-5ae4-4a5c-9b3d-64cc3d591cf0"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "ce75f645-52ed-4da8-92a8-281bcc32b2c7"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "89114c32-659b-4246-a135-a29158080cf5"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "515de9c0-e583-4d33-a9ce-5a41cc481236"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "d4cb0e1a-e48f-4b6a-9df9-3309544e2dd0"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "08aee597-847a-48ab-9e08-73488406c3c1"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "eb0ea772-12dd-4f6d-8a9b-e0733b1d7f8b"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "1d64314f-c893-45ec-8a50-6bb42a281522"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "5866f5a1-104d-438b-9fff-139efc127d8c"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "eeded39a-6db7-4382-9760-0b4e86aedba9"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "88d2b5c0-acfc-424e-a809-559c666078ba"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "1f64b106-e4d5-4796-a046-29e61fec4c75"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "5dbee0cc-9cb2-4450-afab-86da245ec78b"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "78ef57c4-a331-4fb6-847a-afa4329d9d0c"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "a57bc292-3ffe-47ae-89d5-75c95201bc55"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "27b442f8-969d-4a52-b6d6-806683a0bd11"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "37953da2-654a-4be8-8827-1ef1fcfc9db3"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "4da87067-c54c-44fa-8c84-d66041e8e21e"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "a73ef2c1-4a61-4295-a838-e382e10ed6ab"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "d858538c-8744-47d1-a02f-50a8769d785b"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "374fc1da-22bc-48fe-bdaa-e9aba9505402"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "425fcea2-8c27-4cb5-9508-cceff0739fb7"}, {"source": "62ba0396-8f2f-4055-9e3d-eec1899a9572", "target": "6f1d357e-df79-4b1d-945d-c9968690a8b1"}, {"source": "6f6a11cf-2ab7-40db-b2f6-9acae31b5e97", "target": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "582e162d-2c4c-4fcf-90ac-ca1ad4d69b0c"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "693b4d2b-4402-4414-aeee-a5acf335724c"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "a4e12cce-6d60-4521-9226-e3e63524c149"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "3f29d764-0473-474f-8fc1-1f2c5953ee98"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "32f566e1-a97a-4c83-b797-6c615ed41dba"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "b007c0d7-4cfb-460f-bf6e-0a5f5abdb606"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "cf7bd105-bc37-4941-a800-831969a63293"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "b5e6f254-7810-4e09-af43-46328c8541df"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "4ce4126d-2acd-4ab1-a1e6-c0f0b4ab199b"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "e34a19ac-a9a4-4da5-a387-473a181ec656"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "c813f934-c9fb-4db9-a1e4-58fa7a61ee57"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "8a43844c-67ab-4984-a90a-122a91b67ff2"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "2f97350a-bca1-4f9d-a338-a044fb386ce8"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "d29d0ada-4ad3-4c80-a3db-064d6ac5bae6"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "4feda145-4379-4f35-aee8-dc3a96123d5b"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "b405b6d2-9fd9-4035-bc2f-28424dccd390"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "6d0bf4cf-d756-4260-8134-433dddabc233"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "4a81a0d4-5670-42ec-a7c2-05c75b23ef65"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "71ef96b6-242b-46a9-bfb4-76be2eedf0cb"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "34d9b2cd-6c21-4722-ba61-4984d5393d53"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "8661101b-f304-48a2-80b1-030d9e5ab576"}, {"source": "f7fb451d-2b4c-451e-86e7-d6b2f97915b8", "target": "bc201f14-7365-4f95-82f1-711a668e8589"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "8a59087b-6c40-4544-a338-b8ff054ca094"}, {"source": "8a59087b-6c40-4544-a338-b8ff054ca094", "target": "1afc5dd0-7231-471f-898e-163b66994977"}, {"source": "8a59087b-6c40-4544-a338-b8ff054ca094", "target": "c3a3aa31-14f0-40eb-83a3-c2c95bad6358"}, {"source": "8a59087b-6c40-4544-a338-b8ff054ca094", "target": "3fa3bbee-7bb6-4e7e-ad0e-9bd48b2d41ac"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "f30eaa03-c9d1-45dd-97ff-24ca157e3804"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "1feea8c2-86c9-40e0-8238-512b9f838ac3"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "93b6049a-11ff-4324-83d6-677e1796fdd8"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "aea5fa9b-c0c3-496c-89c6-e49e60301e5f"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "3443ce02-2fbc-4bbc-ad9a-f1791975236e"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "788ed1da-9177-46bc-b235-2875a9416199"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "e7b62fab-bdd9-4bbc-822b-67276c539a04"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "f8ca9504-40a2-4069-808b-72fc72c8084b"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "cccf52d2-d168-419a-8ef1-23b770ea2023"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "8e062e79-0bf6-4f0b-ad18-43e9f9b5f605"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "1240be14-7d74-4b63-ab6d-8ed633635997"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "0a138425-8d4d-411c-8690-84472bd6c735"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "37231f52-4095-475e-924a-19955f6a3a8b"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "a1524643-8f93-4231-8691-ac7bd6a32076"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "77472101-4086-4ce9-baa9-672429479645"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "6c9aad24-efe9-48e1-a547-0d01c0e42572"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "6d5e16ab-21b3-4a5f-8140-67f4bed9b5fc"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "61ec6945-33af-4320-8cd4-f7a83250bae0"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "9760e559-c4f5-40e7-9e71-130bdd10c120"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "6a5e4110-137a-4bc0-b8c5-d036dea600b9"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "0da45cc6-d92f-4e25-ad0c-4efbd7bb96c5"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "0245a122-c396-495c-b048-fa2aaf09b73d"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "04d5866c-0cd0-4e15-bba7-0ae5755fe195"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "1ca0317f-ffda-4ca8-9fdd-75ce698ec5a3"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "978d12e3-f4ee-42c3-99b8-e60efb95e2e7"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "4ddcd579-1614-4fdb-8104-8bd1f91136fd"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "b991137f-be6c-4e0b-8d9a-287ef5b0a0cf"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "4bf774f4-ea2a-4bb9-a3ef-b080db921b95"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "60307d4d-ea40-4766-899e-80d17ee61123"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "b7a3718a-3cea-4fea-a522-4d439c31c0b8"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "a8a83afd-8d65-439b-8cbf-e6747627e842"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "8e3b20c2-fb8d-4ec6-ae9c-7fa4165fffb9"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "d8afde95-765f-44d5-8e38-3eea329eaf52"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "74043dc8-4707-40e7-b9d7-66a338c58002"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "4f72fb26-4253-4e22-8ac1-07ef61a6c8c5"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "e563bee3-7feb-48eb-9e05-b6dde06a256f"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "25434239-daef-46d1-94d0-da1a946319f3"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "d6db9e3d-12d2-4063-b9d0-4d584d8cc9bb"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "67f19f78-cb31-412d-ae87-8e457e135015"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "48033914-f004-4b53-b64a-7d4c2540f41f"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "aee31e0e-b18e-4997-b0f1-d2de9ba26bf0"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "b64cb134-ce48-46ee-877f-b9f0221726ca"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "a793171a-2048-4038-ad94-68bb27994cc8"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "9ad1bd48-5e02-42a7-b259-9a73cbe8fd7f"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "76330a8c-e37e-4f2f-ad19-f7b27d65c088"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "0ba42787-8a63-416f-8cc7-72d8bf4b8601"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "837132dc-98fb-4094-88be-0f4e0592a30e"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "86e4c5b1-c476-4d99-9294-d261119dce33"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "a858347c-2638-4654-896a-f68424440c76"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "89701bc7-1405-41f7-a9f1-af89c06edd00"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "e26be0d6-3228-4fef-8de0-c7c4a4987956"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "1da4db56-91e6-4190-9c28-cfd3677b1470"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "bf6bc0a5-02e0-4c2b-90a0-029e0c995f09"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "9fc19783-28f1-4012-8320-b9a248d1078d"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "eecec0c5-7df3-4c00-b391-375366a356e3"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "c8fa9d94-8a68-4bef-ab7c-5b640bda0540"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "45520a25-95cb-455b-945c-dc4a316bcfb6"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "507fe883-8b8d-4061-a1f1-dbf87f26091b"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "dba99d3e-420f-418f-8060-6ca6b20a9197"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "17b87aab-0206-45e0-a727-3b43e4809af2"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "378516e0-c839-4b7e-a0f7-b07b2610ab39"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "40fe57d0-3b4d-45f0-b31f-4758abd0d274"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "f01f99d3-bc4d-4bd9-8b2c-e2759c48d361"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "4cb2a37d-a709-457b-9cef-ca8a061d30ff"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "7e103ee8-fdcc-4ad3-9951-cfbb2c4ada75"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "c24ad2b2-17b1-438b-aad5-a0e4646c4024"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "7d7f6c8a-e3e7-4fdc-b62b-dca42a92e4ba"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "7669d313-5383-4d5a-a5a5-1d64c196ae24"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "6ed8613e-e1db-403b-8dab-08c37153741f"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "9d68abca-6838-4fe9-b31d-cf8adb9d10e2"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "2c297147-40b3-4fde-b2aa-78bfd39e5e9c"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "99e93cac-4df7-4c63-b187-f7b00d4d18a7"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "b15c80b2-bb25-4f2d-a886-61551ea2897e"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "b8e86b11-888f-4a3c-95f6-0b13e27645ee"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "62d1899b-5354-41d5-932a-a4ade215a393"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "12dd54d4-9ba5-44bb-9b40-89e7d91869cb"}, {"source": "f30eaa03-c9d1-45dd-97ff-24ca157e3804", "target": "ca1f70b0-925e-4d3f-9c76-d775d5a79109"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "c3f50562-6d2f-42e3-84b7-4ec18d880d52"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "7798d47d-aaa3-48cd-8d0c-6959ee7beefc"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "47e8bdac-d8fd-4501-b5f3-af6d9002719d"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "468664b3-d8f0-4692-a469-5c3e7ab65211"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "b4f2768d-de82-4f37-b07c-040ca6703535"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "08b06164-2233-423f-a803-23c3bb9cf203"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "1fc7d301-fa8f-431e-8499-e27bfed13d60"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "c1b4e672-f936-4637-a6b6-bb4aeb1e7f8c"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "ae00c426-6d67-4ddc-a737-1702e78c97ab"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "8026c164-06bd-4e7d-85cd-4cc53e91bd76"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d456c6c1-5691-4adb-a8b5-d96231882688"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "4bd06cbd-bfa8-4e91-9a31-1383592b19d3"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "f7cd467c-d54e-4f09-b0d4-da3a43db9b8b"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "47715a69-3f3a-4382-a16a-af2bbc7bf7ee"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "c22ee86a-db2b-4868-9e90-611bd52f7bb4"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "f33efad2-360e-4565-b57a-8f1d417bb91b"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "3ede5480-773f-43fd-9f4b-339b375f89ef"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "5848f47b-20cc-4fe3-b8c4-f20a70683010"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "7f93c8a9-bb5c-422f-af87-4befd885dfa6"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "81713b78-586a-4e5a-b2da-70302a00f837"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "79685f38-9c39-4514-b9d1-4398f3702184"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "0177ffda-342b-4dee-96d6-095a9ed8e5c6"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "ef6327b4-e728-4a5c-b1cf-b3cb811eb274"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "397d96e6-e8a5-4daf-8f56-29d609be3fad"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "6c805dd9-4814-44e8-b88f-4348a46bd187"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "99a7c393-36e9-466d-b26e-2a4217681ede"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d249caf9-a206-425f-9e8e-96e178242afc"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "1c57669e-6cf9-40f3-b06e-72050f048e9f"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "29e1b47c-aed7-4f33-b793-0cc009275328"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "744ab4df-7d6b-408f-a2c8-b64532a8b99d"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "79a93ccd-9f1c-499e-b661-ecc5c44d7da2"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d79b8e3a-4d21-42ee-be2a-0588a9bae9e6"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "8b857748-994a-46d9-b333-17bf004f7814"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "b5f2e9d1-fa0a-4b7c-b608-b8eb2890fe11"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "c42762f5-40f7-46a6-8f97-5e9d045d6001"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "b7290eeb-9999-4b57-91eb-26d89ee623d6"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "ea6052b2-309e-46bf-be77-16a257746b91"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "09543f48-2e54-48d4-afe3-dc72bd9c4480"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "9b7cb458-cb97-4e02-9c47-9c13f6709817"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "111c7461-8ffd-43ca-8085-8648acde5415"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "e5b02be6-2f77-4723-a4c2-a624551bc861"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d5bc7827-e827-42f0-9036-7e2e29980d22"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "0f143a28-eefb-4ab9-a071-400eb8dc4a52"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d29466a3-0e57-41ea-b446-e9b5bb5a3b54"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "e918ecb6-b230-41f6-aec7-3c53b3428c92"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "44bcb745-7e18-458b-9cdd-5a15bfef35a5"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "af30dac6-bea4-4885-89f3-5b4533f02d5d"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "b2af6275-814d-4ae2-aab1-ab7bc60b353e"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "5ab3dd5b-36bd-4bb6-9b4a-f579114bca19"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "b054d260-8f76-4439-8b59-6c9d2c8b905a"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "a1db578f-57a8-4398-ab6f-9cbc5aaef3bc"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "3df19a52-316f-477b-8674-c6b19a04de68"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "f38a7929-96b0-4285-b704-0cad731d7d35"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "00c31610-60bf-47ed-9bd3-e26fe6f617fe"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "cfad2660-d6aa-4e0a-9549-1c6d45e14fcf"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "1afef863-8343-49b9-901e-5a414d3d4602"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "d2a5ed11-9069-4e4f-887a-b251cbb9d836"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "62886cfa-bf90-47a9-8d4b-3a1bc2122fb5"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "a1227c3f-6ba9-487d-99e8-6c4294835842"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "cbe6d743-c055-41b5-b3b5-59cf91089600"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "7d317fc5-8820-42f2-8b3f-ad1f7231792f"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "6e04c4d1-fdd6-4a3f-88d1-faf73c2a57a7"}, {"source": "5d5a7295-a90d-4162-8c1d-6a9ff75922cb", "target": "c7c6cd32-0363-41fd-ae2a-8221cd621fd6"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "43ea4f26-2492-4eb8-8819-0d1dde15039f"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "9a3b4f2e-ffaa-484f-bbb5-c9c318574abe"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "17b85f71-2c3b-4800-aa0b-f602e73b19fa"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "76c76ae6-8bdf-424e-bcb2-06b85e0db3bc"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "f92104b0-9797-4dd9-be0e-1f74301eeabd"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "a6124eb4-7f73-4d75-8552-f0fc9041fe5d"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "ee967b76-2790-4152-89e1-a86fd5a53fc9"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "7cc0283a-5d10-4853-9cf3-8a05d4e0c74b"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "1ddca7a0-0bb0-4955-a7b5-76af9ae86b61"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "a3a419de-9afd-4a25-a7a0-be108a311cc7"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "51e12282-6afa-4c16-b555-e7dda8aee501"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "c12d7451-6618-49b6-98f3-6c17e23ef34a"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "e19dbb5e-eb99-4328-9b37-bdbcb92636bd"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "5d4f9523-9e94-4cf3-a5e3-8e0268006a73"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "12832579-5e23-4b08-b52d-c3c249f876da"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "6684f816-afff-449a-9344-95ee6907d20b"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "11e4e5fc-ecf1-4c6c-a0f5-c485993ad02d"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "07db2df9-71d1-40b5-9819-90ddb3c114f9"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "4b49678c-858e-4788-8140-9f1d5aca7e1f"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "f1b27146-b477-4a54-a75c-a9e0ddacb8d6"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "305f1dc4-fd86-484e-8bc8-9dbd8d558fc1"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "e1b9c998-fa78-479c-b1c6-04409b4d004f"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "b12c3097-fd75-4dba-916a-11dcd05a1635"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "32ed0b43-6ad7-4866-b89e-ec5910f58475"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "5b15ca3b-c5e7-4732-b342-199f59f112a9"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "b24e58e9-9c06-44ed-acb3-bead70a814b2"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "c2f75dee-887b-4357-99bf-7d87e568ad75"}, {"source": "43ea4f26-2492-4eb8-8819-0d1dde15039f", "target": "8961a51a-3d93-49e9-bfb4-6e285d9fe56a"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "8d08d757-0265-4364-8244-ee368e489de4"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5f655528-52e4-4d26-bbc8-ea2e7d7854a2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "a9a770d8-3bdd-45c3-962d-54625782db68"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "2d24c8b3-a96f-415c-86ed-ef88a8a8f349"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "c979434a-5dae-488b-9e69-9f5c4c97d4b4"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "d6adb17d-8146-4b10-aa38-c96baebff097"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "095feebc-4811-4f7e-9b7a-ceaa6212fc45"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "fc342d43-7dd3-45cc-8992-7a7d2a78c9b8"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "a09c04dd-e9d9-455d-ab38-30d3a1559e79"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "561ed393-cc3f-4ac7-a610-5f11145895d6"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "cd958be6-75e8-4f84-8841-f7e76eced64e"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "9fab7c7c-8900-4f11-b239-173fe7c3113a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "40246fd2-074d-4a7b-ae59-02244d58b58c"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "4901ae8e-9299-4d7f-ab36-999f04c49553"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "a00c328b-3c9a-4b73-8c40-5ca86933781d"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "82fa38f6-3c4a-49b4-bb78-4411099fe3b1"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "8299d2e3-c807-4d8b-837a-693740d9336a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "484591de-f717-448d-8702-51a8225517fd"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "d660c839-32b0-450a-8e42-2c804df1e97b"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "2e286e5f-b3d8-42c2-8d9d-6eb700318f21"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "9895656f-0cad-45e2-9f49-643ebc0db1a2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "1ed05ec7-4eaf-47fd-aef8-a78a2bb639e6"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "1810add9-154c-41e9-adc0-b24120a248df"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5b18eab9-15bc-4d2f-8dda-109d785946b4"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5cd19ab9-960f-476c-be52-42623a8ea7f4"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "4166e511-ef6d-40ad-b097-7f4d62de909e"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "f8e25844-f1da-4b96-879f-ee37bf43f76c"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5038228d-74ee-4ba7-8a72-9a209cfb24ed"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "4f845365-b9b9-4fb6-a256-3b072da46421"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "85c641d5-e36c-4a42-8219-c6c610d996c6"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "0f5367d7-5ae0-4744-b3d7-d3e563584778"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "062f76cd-d509-4c37-bb4c-816e2fc4fd03"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "0d02fa23-f61f-4b64-867c-eb2d0ae262b8"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5474d8e8-9c1f-43c2-98b4-d58a0e96122c"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "eae7c655-1da5-4354-8c8d-73d225580548"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "e81bea30-f10a-4b0e-b487-814b2e7361e6"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "ad77fde6-4cc2-4d5b-91df-b702a415d6d5"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "1ba6bec3-c3d6-4f73-b216-667498478c1b"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "7e8a72e9-acd6-48f9-b4d2-37fd962f009e"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "8bcdc83b-71ee-4f1d-b345-b0d7e174c46a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "bbd4e1b3-48ae-4768-b8d5-229ec1d49931"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "68fabf2a-b762-4c49-bf3e-29d1279e1278"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "63f7fd8e-37ee-4616-9f81-d30f1eea6254"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "6d39aea2-5600-4b7e-830c-d40a1263d864"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "51017097-9e6d-4d59-95ee-657c7f089085"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "79ec6287-a19a-40c3-b067-b82123c1b4d9"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "8e640147-3489-4d1a-bb58-87982c8ac563"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "d6e794ff-467a-4686-bcbd-567fa1ce92a2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "0373a355-9ea6-4d6c-91a7-bc214f7f1295"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "cb181de3-4dce-4c3c-8d8c-30068d070dd5"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "63b4731f-99ab-40fe-88a1-15067025fdd1"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "2c3ae533-f681-412e-8e75-b92e432e80ff"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "1033ab6d-37ad-4e01-9123-0a9cdc2d5d0a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "04b663f5-0d31-48e8-96ba-459cdc71328a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "f325e522-677d-4a1b-85ea-bf3cc9ee99ae"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "29cd7b55-dfec-4c67-a123-1ce1af78f651"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "9edb89c9-5636-471f-8d47-9de3eaf972d3"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "fa9f3c7e-b8d6-451a-af48-4d99e2d929d1"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "899a9f26-203e-43a5-9c24-775d64db06f8"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "437901b7-4488-4720-b976-fa40aa5d52ef"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "073825ac-fc93-4d67-8169-3b366ddc0631"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "90d9aea0-4db2-4c1e-974b-892da43b1b6e"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "d62cc73c-8a8e-46d2-883c-a94b8f136e3a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "477fc92e-18db-44c9-bff9-dd8193178560"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "ab2f1627-b809-4c56-b9e0-6fefb1c706e2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "972781dd-fb54-451d-91e4-3e4b7819c34f"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "a0904ef4-0d7f-4f8d-a5d4-28973677e2d2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "381917d2-a6cc-4158-87ac-ca96b8afd0ee"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "cc7f1605-52eb-446d-b564-84f8a450a49c"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "a74fb4b6-9988-4753-b7f4-3ac11dd75592"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "5c7dd41f-bb3e-4f32-8c4c-abab7fc1cd70"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "913f2da3-18ec-453d-9931-484c69c6f639"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "aa0c404a-fc95-4000-acb5-2029e1cf8b7a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "9469db13-dc02-4fa5-9c1d-6ba8dc98904e"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "61f39357-b0cb-4ab5-b201-81eb15029fc2"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "6c0675fa-6a65-4d30-8592-454219197546"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "d31cca04-694a-4d11-b00c-69e6ffaa68a4"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "14d33529-9c94-42e0-a7cc-3f2a0657351a"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "c71f8fe5-4158-4e4f-a175-1c1bfa4ddb08"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "f9897146-836f-4bfa-b2c6-fb1a9ebf6203"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "33429f72-c3ff-4b1e-b4de-f5f40b6d00ef"}, {"source": "8d08d757-0265-4364-8244-ee368e489de4", "target": "895dc9c0-d527-4e58-a89f-6fe33b6e686b"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "4640bd0f-17cd-4304-879b-a9e3d125f8ad"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "a7a46163-67b0-4fe3-b09b-f296fb2dcdeb"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "dd1bfa67-6961-4016-848f-dc7a4dee9401"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "7a00e2cc-f7ca-4a98-b33d-0e3594b01d75"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "5d405183-4a10-4e69-839a-8a5469fcdf6a"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "21d0b57c-6ece-44a2-a57d-ceb29b674d29"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "6b9b516b-c93c-4d9e-b56f-3fa613400034"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "f9db6a80-0963-4dbe-8b0d-2e1f460fc85a"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "200a7fd1-2399-426e-8379-ff1178263056"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "64e89a97-08ee-4eba-8379-89476892143f"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "a8c7f027-61c7-4b87-9cb8-8145c49e3826"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "c911d4a5-f8bc-49f1-9000-e5ba178ed3f7"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "81bd073c-4bf5-40c5-b117-b92c65e3e4ae"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "f6b5590c-ce8e-4e5c-b698-a5917e307dfd"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "680fcd7b-f145-4532-9caa-3f6648d3457b"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "cc8b0c53-e97d-4654-bed8-2e043558bdb3"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "eae6c89d-76dd-492f-93d0-0754a1684610"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "9ccc1652-3bb5-4f74-87b5-370fe1db0573"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "fe957801-a6fc-40b1-8822-5279616a3e15"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "60f779d1-6db2-4dc4-b2fa-404986694303"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "fb033b12-c97c-4c3d-acd0-019be3f410ea"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "d650084b-5988-4c82-8fd0-13d19782b74a"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "2f6a01df-4f2e-4c94-a7bd-63fa537cbf00"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "3d06037e-f389-46d2-a36e-220bdeef0faf"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "59214e42-ac36-49f8-b75d-efd40acb1ac2"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "48c449ab-a93b-47ec-9c14-d3493821d5f6"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "4a7033b2-dace-4ff9-bf7f-21ac09a82498"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "e85b34e4-c5c5-4993-88c8-0f1382504397"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "a3715061-2a90-46d1-8f0e-a2dac6a19608"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "b79036cb-9d00-4036-ac4f-0df911bf7428"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "a720895b-7282-48e2-be98-8c57343e94c3"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "034cd175-fddc-4fc2-9d70-2434a415f0bc"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "988f4a3a-1000-4fa6-af16-373c0c726efc"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "c3d26534-84b5-4342-8e7b-a432625ed418"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "617d108e-e175-42c0-957a-5993c4b8603c"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "97239ed9-c59b-429e-a20d-dd0ca6cf2be1"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "25660551-6ba3-49a6-a1a1-06da4a8d3794"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "6079c9f0-8760-47ba-a7dd-cd288f1ca930"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "90db7358-5f16-4dbd-a409-b0a10717b966"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "bc771ac9-53df-4df2-a11a-8efc8faa8621"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "478b191d-9735-469a-bba3-8c949e0b03fb"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "e77cfd67-1173-4a20-865f-4c56f365c83f"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "20480933-c6a3-49c5-9921-7edf33171e1c"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "00bee20e-0742-41ca-ad31-8cc20df494e7"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "9c7e8ff6-fbe5-4c2c-a458-422fcd6af8e6"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "6f1235cd-abe5-4889-802f-125d46c943d0"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "f8b8e8a4-0ece-4f2c-9d2d-4af903be34f3"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "3c15ab36-4e02-4dde-9753-45acd54e0f08"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "303989d1-381a-4ae0-8659-38cbbbbce82b"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "07a82008-78bb-40d7-94a0-78488d9e6167"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "5e54841b-3681-44b6-98eb-9a84245ebcdd"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "8928a5bb-ecbc-43c1-8c69-d1904365dc5a"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "7ced4303-7726-4d72-abe4-841d26a32dd1"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "98148375-888c-460b-b14d-8849f97efdee"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "8e536514-cfc8-443f-812f-8df20551edf1"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "c2f7c7e2-bc06-417f-a8ce-14ebc19475fc"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "abec4b5c-6dd7-4cc1-9d8e-e47827cebebb"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "ef852be7-e2a3-461f-9ac7-131b2d36d2ca"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "6e72f28a-926c-4971-a865-44098d53def2"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "434a4bc4-654a-4689-a07b-c14ba25b45ec"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "f8c2e453-35ea-4b48-9901-b76cfc9b448c"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "0d61a946-3338-4930-8bb1-c606e8463a32"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "0b810174-c821-40cf-b4c8-c6368f12fa65"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "0d6bd43e-bcfa-4c6f-a531-4a250d0fa1cf"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "a13b2ff5-f466-40d5-a246-c31d04b12cc2"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "0c4979d1-2495-4c21-8452-c417b71e63cf"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "48da7657-b641-4e32-8e6a-79b5b0cfb56e"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "8b767bd3-5592-4aff-837d-aa3dbc9ac896"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "b35bc84a-37ae-4711-9c5b-1a6e1ed626cf"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "7a08600a-a58e-44e4-81c4-b65bd7c871ec"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "92eb194c-7e8a-4be1-afb6-65f4dafd7e72"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "bdecf7bb-547c-4650-b20a-ba28681113f9"}, {"source": "8cd4ef28-9ca8-49bf-a9d7-addcd3615e14", "target": "330e5861-32c7-40b8-ac37-40b6bf4373b0"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "f2a34f8d-1535-4ce7-b56b-1f6f25a565af"}, {"source": "f2a34f8d-1535-4ce7-b56b-1f6f25a565af", "target": "261e01d0-8150-4280-af2c-9dac0148ceca"}, {"source": "f2a34f8d-1535-4ce7-b56b-1f6f25a565af", "target": "0801cb0e-7f94-44c1-97d6-73110b74c440"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "06c45e7f-2b0f-445a-9524-1a53f085f668"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "7aafad76-98d7-41f4-b02e-4403cd5d4d15"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "6f48b6a0-1ac9-40ff-b7f4-19181dcb0bf8"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "94d05379-8468-4827-a28e-2be64963daf8"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e104aaa0-f5e1-40ab-a37a-eb7dfb4c5a61"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "b15c6252-1ccd-457c-b57b-1280d40ae902"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e4ef17de-154e-4699-81e7-8ed3cb8188a1"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "8909cc3e-01ea-465d-af1b-505221ed9b48"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "c1fae477-3f33-43ee-9dbd-e2b0c1e97f7e"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "7c7622b8-5fe3-463b-a805-a5083d5174b4"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "53b91ced-5cde-449d-902f-e52dc3e13431"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "7ca16bc7-f3ef-4180-aea4-38e0099d0d60"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "169fded6-6867-4e04-8a4b-cc55b67fd2f9"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "a0ad7ef0-d10a-4134-88f3-05e7a2d92897"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "83c598b8-d887-4aef-887e-e8c5a150cfb3"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "7b069158-b80c-438c-856e-c19c9bf2d98f"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "6849077d-df61-46bd-b731-776f1a466808"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e1ba6aa6-3505-436e-adab-88f839b8c7b3"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "0f7d3c61-1a90-4bdf-99e0-d11426d82fe4"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "60af9883-7d6c-40df-84e5-d1a26cf75400"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "86c15d1e-0996-48bd-b9ac-ab0f31ddea5f"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "4865f250-14e9-4911-b807-d6d25ef05f5b"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "861228e7-42e2-481b-99a3-967502eb9c93"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "30a02490-8b7f-4e32-8296-ebb29d9f9945"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "70e9db68-23b3-4211-8eb0-6e71106ee7da"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "54cd6c4e-0578-419e-a384-3feda5f995ac"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "21ee9440-2f9a-42b5-b221-a8e14de29ca8"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e6f57719-9dd2-4a1c-b7eb-be4177f26296"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e9c73820-8388-4647-848d-8124f8275e26"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "c92f721d-5fef-4f7e-ab8f-cb327bc87912"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "b8741686-aab3-4736-b26a-3ce4f1fc4272"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "f5c19905-c654-4be9-8ba3-7e867a036f4c"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "274dff5d-1bf8-4e7e-817f-0e668b4308e5"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "e7b8f8d7-ea17-4106-911d-ef3ab3ab603b"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "47ed1138-62ff-4667-84e4-4ea3c7d44187"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "6261aac1-32d8-4c5f-9275-9c6b81c8663d"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "766d47c3-7700-44e8-a472-9a103893881f"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "d0662837-3bee-424a-9bf2-4831b865e1cd"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "2c872967-e2b3-49ab-9167-f56c3b54a029"}, {"source": "06c45e7f-2b0f-445a-9524-1a53f085f668", "target": "a83fe325-5eec-43e6-b1ef-26d1aae187f8"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "ad8f1e6d-9eda-4631-a5e7-a428823f0094"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "1cc5a203-9292-4012-8400-a9a6b920de73"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "da3c9d11-64ce-4185-82ba-222f8073a9f4"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "9294f3eb-d800-4cbd-b8ab-63c0943f5141"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "9919d91c-905b-4e8d-a0a7-f9de360a0704"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "af615571-1a16-4740-b358-30c7d9db4195"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "af0aa4fb-4d04-481d-9d30-5753f8e47602"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "2fcb4b82-ce1f-43bf-935e-cc738f144bcd"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "494b96ac-703f-4ce6-a392-6247f82d2de3"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "378b64de-c655-4761-8022-94b08df668b7"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "1e52114c-c6d7-4e2a-b7eb-b39c37a31264"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "60eb3261-fba2-4408-b7ad-48d04e1608ff"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "a950a5d0-5576-4b73-9383-dc1584058c0b"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "fbb8a9b1-b83f-4665-845f-8030ed4af3eb"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "b1ba8b0c-ccf9-45d0-b85a-c887f96ca8b8"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "a9217984-a988-48b3-9f3f-922071d23580"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "3bd28b98-0f3c-4f48-a621-fe4c75229369"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "9d16898a-cec8-443e-96cf-851e2c18a652"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "eea8acd9-bc66-4754-be70-cefac4167f7d"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "c13e138b-d61c-4b1c-8a1a-97ccebcce215"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "9b2fdc27-0554-465f-80a9-96c11b976b42"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "8af8914f-8a95-439f-8ec9-f307605bebf3"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "fae01717-2de0-4000-933d-f759bf29b09b"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "6cee61ff-5807-4262-a408-e228a3e45c98"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "38ad840c-98f6-4d9b-a4cd-ee340c2a872d"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "77efb4df-ce93-4c7a-abf0-13fefe443e7f"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "48dfac7a-9387-43c2-ad6f-70f2601e847d"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "7dcd21a7-59a6-4361-96a1-25aaf8b3df9b"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "d9df4b0d-95ea-4515-94b2-3a8a75b31097"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "f182bf51-4299-44b1-b75c-091193383d72"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "6fc36433-884e-4f3b-9697-afb499cd94a6"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "8845e81b-f12e-4956-a4df-3fc9180851ff"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "c739c0b8-a990-499a-9cd9-15ed2109acd9"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "e18b0ee2-a7b6-43b9-87cb-b400142d0eb2"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "ad285520-dd16-4c79-ac04-c43310520f83"}, {"source": "ad8f1e6d-9eda-4631-a5e7-a428823f0094", "target": "300a5041-0caf-4054-b124-9af09996d03d"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "9a00340a-9072-4c58-9a5f-98e204b02b37"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "53d417fd-4603-4e07-91ca-cf4c67099723"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "21e158d9-86b1-42ca-98cd-6e774cce8fbd"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "e43ead4f-67bc-44aa-9c3f-8d5bb90d3b4f"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "4bf886e9-e95a-4128-b8b1-6ddff59edfb1"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "f3aaeb4f-c0a5-4942-9922-11483c99c8e9"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "4671ea2d-ad53-4a36-821d-bb9b3ac70a2a"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "d54b6589-4f23-48e8-96c6-9392cb332864"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "40047a3c-9494-4e0b-94e8-03777d12a805"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "0eadad01-78e3-4558-8aa2-55cc4a04754d"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "5e03597a-736f-47f4-8880-e6c15a8def32"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "5e2205b2-be72-4a38-af29-0ad83ef36494"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "6eddfe8c-8c64-4c5a-8fb0-9ef699da9bad"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "3639eea0-dcad-40c6-a7fd-e174a21f9d8e"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "981ed653-fd98-4e7d-9c57-fc90578a3aef"}, {"source": "9a00340a-9072-4c58-9a5f-98e204b02b37", "target": "44e81305-3fe0-4964-b9a5-d6aeb6eca54c"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "6326c52f-5650-4bc7-b886-c745c8456402"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "78a9eb9e-4468-44ef-96d6-54ae4cb010e9"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "1d4b494f-1854-40c2-93de-70c8b1c1e34d"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "76b94898-479c-453f-ba4b-af6232f5ae94"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "20a09a30-c061-44bc-89eb-5c8a19d3ed2a"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "d336a35c-a34b-4fb9-a5d5-8809625eaf7d"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "3345b7e8-10d1-43e0-8421-b24e86118252"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "144d0fda-acf2-410f-a9ec-1f1b80961e33"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "b0f11199-1dc3-4d04-a2f0-944ba1e07a0b"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "7f066d66-0f2d-47c8-9f57-6d538dea1c2f"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "195fc0e3-0fdd-4c67-94d2-cc4cc533a51f"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "557d1f38-c890-4a5b-bb47-f629165616f7"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "94ccbf04-b7a3-4f17-922d-779f23994582"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "3d2203d8-7e9e-47ab-9f17-239fdeee6da5"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "f16ba6c1-1797-4486-a916-6c2ede6b4fc9"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "122ca4f9-ea3f-4d7f-9248-352b47fb83e5"}, {"source": "6326c52f-5650-4bc7-b886-c745c8456402", "target": "20700a5f-717e-4042-81ee-50701a67c98b"}, {"source": "1a35e510-76e4-4684-b8f6-255e6b58fb23", "target": "96695315-3329-4e73-ab3e-c060814a12f9"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "b91833c7-1a13-4b2c-bd50-b49a46080163"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "24ff0377-e01b-4308-b62e-9ef2fe36263c"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "9f2056e1-d0d7-451e-a4eb-3dd0e83dfee7"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "6fa88cb8-82b4-4341-83c3-9bfd6130e6bb"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "a0d2f88f-be01-4967-a84f-aaada7c08b02"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "97f5d25a-6808-4ab2-ad05-b9d32cffac04"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "6b127fa1-0ffc-41df-9596-e9558131338e"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "3674b618-e241-4578-aead-f45f4454a45d"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "ae8fd9bf-3dcb-40a7-8dea-5b0970e61f69"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "7a13d620-2b4b-4e85-96d8-abd0aa5d046c"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "0834a4de-e25b-4de7-b5b8-0ad6405b1e9c"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "bdcadbef-b98f-4ee6-b071-fb8e8f673eb2"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "4a4b4ab7-17a3-40fb-8f9d-0f20594a1144"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "095c90bd-726a-4361-a518-b50b06117dff"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "5bd52e85-d149-46b0-ac75-a62a566a50bf"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "70fdeb7f-3352-4f9e-a627-288c93031613"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "d298060a-9461-49ef-9fb7-9ce70791c387"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "3c2cc706-f576-4973-ab1a-5c30ac8c4188"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "122f9d78-31b9-46dd-9ae1-3a538b68b922"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "eed0d7d2-1723-4e52-821a-980492f2d13d"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "b1d30e90-e1cd-4797-9dc9-5923d58fa343"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "693be4d0-8cd5-4aec-b0b7-b9c742a4793f"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "60289330-3772-46eb-830f-6f471bb88235"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "45707e77-c270-4cdd-8475-21f54fe261a6"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "e25eead2-b731-449a-9046-c193c79e3fb3"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "c22e8e2e-947e-467d-b7a7-8849981c8256"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "29e10ba0-f19b-40d2-a161-c5e3a236ad5d"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "c3a95e55-c6ee-4d87-8210-cbffcd8c0d00"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "f3cb5284-2e1d-4fa9-874f-a356fee784d9"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "e3017152-fd41-416b-82cf-0f96c0607a2e"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "03b7d849-be74-44a6-a2e3-20066d45fd41"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "0799cf0a-381c-4b3d-b899-8c5f6c76a27c"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "bb1c4e5b-bd9c-48e9-85f5-4adc1e6fd5c5"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "b8c7eace-e5b5-4237-9963-fa7a8d189c71"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "57a47a45-5ee3-429e-a507-6894465996a0"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "941f58f1-fc06-45c8-8a61-c96064ca02a5"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "c5acc865-3af8-4ca8-b8ba-fe29ecb08898"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "853f984c-0caf-4a3f-ac23-ff46f9b52682"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "bdfb8335-5e7c-4516-9f26-e11f4d2e0cf0"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "095812c6-b13c-4188-b1d0-9c4356ccae36"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "6819fbef-e8dd-405b-9022-7c582127243c"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "8b8cdee7-c636-497d-bd87-1289ebccabbc"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "02260513-9ab1-4e76-8c6d-6fb2447d60d9"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "f7d41838-e141-4718-b8e2-6ecbeedd761f"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "c6570c38-adde-48eb-8d39-444bfa2387f8"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "05b09a6d-0c05-4436-8b4d-3edadec921a0"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "31e3d4c3-4294-40f3-8501-048db2a8f282"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "8590f3e8-102a-41e6-9a0a-379579686878"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "87fb041f-0f76-4dca-9bab-db3b413cd417"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "f5c5d21a-8375-4fbe-bb6a-a3520e922a74"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "1eabacd9-2f9a-494b-9969-20c9f12caf9f"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "03d14f59-3554-470a-b80e-c5dc518d1617"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "eef1ff56-65e1-4e78-bf1a-9af4b0ea20df"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "72a42edd-923d-4368-bae8-6a0c9d4653b9"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "4f3192d5-7926-4ff0-9996-abef6e4b3154"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "2c1229c8-9130-4a1c-9aa8-1eb585df1191"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "6b9f3e6c-dc93-457f-b42b-72b9a1940411"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "5136ed32-e782-487c-bcd0-5e6d00fbe3b2"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "174ac5c1-b3dd-4641-a1e0-be76e894905d"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "5ac914a5-acf1-4bed-a15c-e0e2e6f2e95b"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "05af3740-eabf-4c25-89d3-789ec64f4cd9"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "3797bcfd-1504-47f9-b769-a2d3bd0aac4a"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "f53385b4-1aa8-4f7a-9b33-92a4658f1680"}, {"source": "96695315-3329-4e73-ab3e-c060814a12f9", "target": "47b5fbdc-2a33-4d6c-8e4a-35b9b92d1e87"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "be1dd31f-9152-4934-a0c1-2658826c64c7"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "0cdb6494-5b68-4c04-8c31-e09d1eca4a82"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "74ab56e0-f43d-4b5d-af07-2be792d67564"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "55d32a00-5e4e-4a4c-9439-c05bb9f7d6aa"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "78d2f9de-b248-43fc-b144-d23f6fe55e74"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "fb350cd6-1d94-4d86-be62-368c2323e63e"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "c6303703-b0e1-45b3-967f-31bdc24d687c"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "d5aecbc2-b1cf-45c6-bd3b-ba8b52fc6e36"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "7fe00d37-78c5-431f-88e2-d5e28b31b973"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "94a09c93-58fa-43a0-8cde-40c09acf3ea5"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "4e9244fe-81fc-49a3-b4da-bbd5dfc8999c"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "50465555-f79c-47d1-a7a2-e10d0bbcb00b"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "21017dee-ace2-4131-b610-1b5fa6bb8557"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "2efdd158-223a-4315-bc84-ba0ab807933e"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "8ac6a260-a479-42c2-8cf2-a849a5aa096c"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "3fc78889-39bb-4fc1-a4c9-f197aa379a23"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "b1b9301a-058e-47d3-a536-3cf6937deb77"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "fe9407e4-52ed-4587-a565-a6f9001659a3"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "cd305d57-0b8a-423c-bde4-54a40c52d18b"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "3438ab78-67b2-484e-bdec-bcd37b101f2d"}, {"source": "be1dd31f-9152-4934-a0c1-2658826c64c7", "target": "60be9f52-f2de-4c29-be95-63850637e692"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "d85db99f-0b81-450a-8db6-7377238e491e"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "b820c62a-508e-47d9-bf34-7622ee14fe39"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "5d843b8a-2ae0-41e9-8116-4857241ecc63"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "e8a29565-89bc-40b1-8d7f-7c74af7ef4b6"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "374c0656-6dee-4cc1-a619-5d2ea9ac598a"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "efa81fd8-f1f1-4b17-b9fc-3afafdb35765"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a955c012-cb26-4fd6-a0e2-88a75a0cba04"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "760bbec5-0771-424f-8506-d275adf9e70c"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "4f3bbb78-a54a-4cdc-bbef-157d27148933"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "f8cb88dd-321e-445e-9617-ce240cd8ff9b"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "8ec7f48d-afaf-47ab-b529-34c049455778"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "ef6148d1-3ea5-4be1-b15f-08c78d725715"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "d7e07c07-4a3a-4a0e-b839-c04fd5254646"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "45acb4d5-c9d6-44e5-9859-942381d5abfa"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "de4f8a28-99b4-4c8f-a33c-18885db7484a"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "f9b4bdef-71ba-4ccf-8a41-dfb781f40583"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "3810a090-66be-47d7-9874-2cc290576781"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "ea2d2b88-572c-446b-a578-c84dbf69539e"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "11be5be3-16ed-4aa0-b381-094803f78b2e"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a0433b44-5125-4c31-920c-6ec62277cc8f"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "924c37d0-7a5a-44e6-bd36-efb0dec4e453"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a951affe-55c8-4c87-bc96-43d96bd1cdf2"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "b5df1d10-a6b9-43fd-b6a7-f7352d7469f3"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "4825aae4-200e-4214-98bf-23339a71503d"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "5616ac54-178f-4dd3-b665-a4ce8de1a0f8"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "38891b7d-8712-4ba6-9ed4-0ccaf7530d6a"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "fdf2b894-c8bc-4116-abbf-d73c0bce0627"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "47cddc49-3058-417f-ab51-829ad00891ea"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "ad52cc11-34ff-45d0-846a-009acb74c488"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "633a9db7-3c5f-48c2-a727-6f4059f38444"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a97aa2de-445e-4b7c-aad1-0d55f86a47e8"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "d66e052b-1b04-47ec-8c82-23bdd7ff6858"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a3eac910-8b20-450e-a33a-ddf2c6415e18"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "6db60cb9-cc59-4033-a408-726351cd4781"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "1e935c38-4ed6-4a4a-a4d7-1102fa17f9b2"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "a8d4f78e-69c0-448d-a271-906163eca1bf"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "d616c89b-c93b-477b-8193-f4bf7260cf88"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "b4d39445-fbdf-40b0-95ae-24efdbcc97d9"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "3aa41c40-a67a-45ff-968a-9c785bbed4f8"}, {"source": "d85db99f-0b81-450a-8db6-7377238e491e", "target": "d7b524c9-e735-4dbf-ba7d-8c50893f32bb"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "97ea4f5c-bc4b-4504-af45-6f40abbf539e"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e37eeb1e-ff0d-4d1f-9700-0c0749a83349"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "6655a207-352a-4a48-94cf-6935f01cd175"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "b4a4429c-74d7-406d-b37a-7d310e951632"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1f41573e-7575-4c80-a5bf-6975abf0780a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "86a01d56-ae6c-4755-a853-5158b202424d"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "9f960c9d-8a80-4425-98cd-d9637e1c1137"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "027f529d-70bb-4d5a-a39b-86ccb8368ee9"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "89b871e6-6a7b-4caa-80cd-d09abf2840a9"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "a9487bea-ae8b-4f37-ab0d-aea0d89c136c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "04b2660f-40c6-4758-936f-b2126f1804cb"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "79e6272c-09ed-4ad4-9649-10c81c9deb04"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "c1d0b874-bd47-47bf-bf03-5361b7b6ea10"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "a8fa2daf-7932-4e3e-a478-e5a949fac1a2"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "ecd6171a-850c-4ba4-be2d-c215dcaa7338"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "de7f0614-1632-4c62-9f31-53645aa263b7"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1a95f8c3-426b-4720-9c6c-166f695cbb2e"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "c235ec9e-0143-490e-b2d8-643f4b40d135"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1351ae64-8833-4749-a905-689027bbe788"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "75a53762-7106-4a16-ba2b-496eaf700d21"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "ded52856-aa9e-4123-aa87-937e7d8f9320"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "7a89d606-ec14-472c-9d31-b6303d387c21"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "09d010af-aa5e-43f8-9841-78576e7c5739"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "158999ab-0698-442b-8a3e-a005b53cde4c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "eb84cb12-8597-434a-aa08-c014d2f49b5c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "07f82526-a7eb-4b21-995e-f1549f5e201d"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "9625dd19-62fb-4565-ad6c-6d3bf0d35667"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "56efded3-b146-4119-8a3e-0cd10cb8efbb"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "df88d151-e034-431d-ba6f-ff044f641375"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4c17bc77-5cb4-42b8-8097-d7481f7f88b3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1d9f7c71-f7b6-4e8f-aace-eb2ec02ed856"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2e6b1da5-e8dc-4689-87c3-a00a9d2f2503"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "6abae6d8-f2da-4c59-9e15-44a6bf13a0f3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e707393d-d799-468d-9a24-273a4e38dc3f"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "c30b3f42-8231-423b-96ba-81a788cd3d73"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2bb75895-d0ba-4d58-80ac-e07e2c678033"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "073fe3ee-a397-4a5c-8460-5435c46268bb"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "684730ed-3632-48bc-8c40-ac7e0f5932e0"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "62bf17c6-9555-4491-a4f9-e6988b45984b"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8c1e792a-6887-4460-bf7f-7c30c7d32139"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "55c5e0a9-c724-41c0-89a5-9ec265fe2b88"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "58d297d4-9cdb-436d-808f-bc35a2774cf3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "c64f08c7-941d-48a6-9b03-68332c62011a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "769f989b-99b5-429a-ad98-d349c9025273"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "665c557e-aaa7-4d2e-8560-e26a50024a26"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "7bd51406-c488-48f5-b209-3e76e8eae097"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "774a14f7-4090-4527-88ca-f2fb34f27c4b"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8e468879-c6fb-48c1-8401-d8a94139852d"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "0e014b2d-53ab-4b53-a220-58df577216da"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1c070dfc-437a-484a-83dc-92d0412a192c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "949c11ef-bbae-407d-a13b-41fabdc1f12a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f63b1a68-667e-480b-af92-c99bc1e1aca9"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "c08d641f-331a-4750-a1b9-78c695f0bf85"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "87eabb2b-1db5-4da1-9083-7c60bd792396"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f0a10ddf-f89b-43ec-bfb9-8f93f0320211"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "afd68c7e-98db-434c-b945-b5311fb0d5bc"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "117346ec-fe79-4acc-8eab-c821ea4831a1"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4d2902d3-498b-4088-866b-5d8b84c864d2"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "d7bda35d-bbf2-4ace-acce-01f258f19ba5"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f4314e28-7718-4687-bc0f-d1997585f484"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "26e7ea3e-1f26-43b6-9e03-18bda5bc8245"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "3f45c7b3-410d-4fce-bc1d-bb0346a165e3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "80ee64c9-a61c-4ae6-945a-b79c51ac8bd8"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "90325a37-5b43-4f4d-b2b3-91b667c3be0c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e00078e4-5089-4885-bd03-d3988fc66488"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8b63e367-ceec-41ba-9365-9357ad7dbd9a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e4402da5-8df0-42c8-afbb-b6c860dfafb8"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "9a7cfd1e-26ec-44db-966e-f6b6d46638e3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "dc9f6f02-de34-4afe-bfed-2603b48a1235"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "5a7b46fe-edf0-46a7-9241-f7299a7222bb"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "d5425a4e-48ff-4b98-a133-294320957d9f"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "cf56faab-1b37-45fc-acb0-bd5d5fbd60b0"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "39c6826b-d878-4ed4-ad97-e86412b77906"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "27f8e852-eb3e-4de3-b4a2-f6503e526197"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2161108e-6de6-424d-b28b-14c4c30b8071"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "5213b9f8-6a07-4f92-b983-783969fd9da6"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "0f104b94-34ab-41f9-bcd7-0350019f9300"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "d7cbc92f-4364-4259-863e-6a13107c0b59"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "ae98afc8-43d4-488f-9496-54a9ce938523"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f98172f8-9e46-46e8-91e9-eb517c5a29ae"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4a56bb41-c72b-43fc-8e64-06beebd0ae20"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2dfca85a-09d8-4e52-82d7-0cbc0e5ece8e"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "6ab5dad7-ab9d-4db0-9209-4dba38749008"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "3cd43cfc-9a36-4586-a295-4926ac143512"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f2bf1fbb-d963-4710-bf76-5eeeb2b428b3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e4dfacd1-03c5-4de9-bd64-897bbb113b79"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f33f1de8-dbd1-43b1-8810-85bef2b0e9e8"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8e44dc01-c7a2-400e-8251-4bf4b3fed8ef"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "38b4ced9-956f-4777-9784-aa6064ee5c48"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "3cd3ac64-af73-4e25-81c8-97fd3bf95007"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "0257cd37-23d3-419e-aea8-7f33583e46b9"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4a94718d-03d7-4f28-9033-2f374fd399ab"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1f73d9c5-52cd-43bd-9d73-cb0ed200bf66"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "9838c181-752a-4d1d-85d0-4537214c2a0e"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f049d4b5-d556-43e8-afe3-0f7e10a7cb93"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "75db2e62-6a12-450f-9ae8-0a6931f5038a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "d9afda89-e0f2-46d9-8259-c837fe56ae8c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "ecd2cf87-a80c-4d0f-86e4-f4b4337f2f6c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "3fa077cf-8e6f-4bb3-92d2-728e1f359955"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2e4c200d-1644-4380-a3bb-ffd9ba466969"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8e8ea56c-203f-4c0c-8021-3e0179129344"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "aa082429-fbd5-45ad-884d-f0efcfbbf7f8"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "df116920-6fd2-485d-8688-928b142ad1bb"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "fd432fda-b853-464a-8621-ecd8b6a9fe4a"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2c25d6d9-d0dd-4888-8099-e0c48fc0df13"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "99027864-f726-45bf-bba5-f2ab8e2745a6"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "cc7d02c0-e509-4373-b8a8-ce76452a2f9f"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "924f5670-b2d5-47ed-aebb-b8cbbda88be2"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "7c526d63-3ac7-401f-89e0-db1d10337ccf"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "b6c84f11-f2f5-4c89-8514-5d3ebd8cd744"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4325493f-812b-434d-8313-ca3b2f037e53"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1b87f467-0e0e-40f0-9bff-287efc107510"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "94deca49-a349-4fa1-ad86-31a07531c408"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "5eb7a5c0-e3eb-43f4-a76e-0544551b1d63"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8952546d-8885-4b85-9444-9fc934d8f7e2"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "24c9f939-cad3-448e-9989-69e0003bd815"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f7a969b2-ce27-4102-941a-f2d0a1662f15"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "e0ab7b0a-e8af-4691-a0dc-c961109b73ed"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "010e602c-0ebd-4bbb-8188-38e657acaf74"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "a6803f01-fbd2-4ebe-99d8-38d9fbb41609"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "81e44237-87c5-4b7d-aa9e-0d9096a81eac"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "3e9da2e4-2c8d-472c-bf21-c70f1ad7c52d"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "f6e1aeab-b0ab-45c7-813a-fd950b9514ad"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "4573f3cb-56f8-4be7-a296-56bb09174370"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "720b57ba-0c25-48e1-8887-fb584c1e964c"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "2a2dc787-25d4-4dde-8065-40365770d6cd"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "8c301997-004d-47e0-8895-c90ba58b4c65"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "82044638-2bf0-40a2-bfad-4948482088a2"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "eb1348ef-54e5-4627-ada4-45f2a5197cb0"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1fd10ebc-bb1e-47b2-8093-c246301a4ee8"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "49eb84ce-fbdd-411a-9f87-78d1d29ceddc"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "d704004e-e7e9-4ca3-9a2d-5ba7e7a3dc33"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "1ffdd1c7-1548-4f2d-bb11-584af147caf3"}, {"source": "97ea4f5c-bc4b-4504-af45-6f40abbf539e", "target": "855465b3-5c7c-4df5-adf1-31a9f06cd1c8"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "227f4df3-22d8-4a6a-9c50-b8a8643a8d31"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "d5573836-74f9-427d-8925-5a56ec182edf"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "57cd53e5-5f08-437d-89b6-b58916aabfa1"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "3ca46ade-0c3a-43b6-98ad-3ca74004bf57"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "ec65ca04-6b55-407d-8bdb-85c64b26aa77"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "4296c515-8e8e-4ffa-a583-b77a35c88102"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "2d100f3c-08e4-4c92-a3d2-11c26873da10"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "0f193f3d-b37a-47d9-aff1-2f09ca26a827"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "c8c861b4-48da-464b-9542-68e260444cca"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "8e306ec5-28d9-437f-8cb5-35dc420aa10a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "7b2a5031-c595-4ae1-8630-341c5ceab8b2"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "19557b72-26e4-4eda-9dde-b8aa70797973"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "2e769d66-2f3b-4833-bb5c-b61ff8fbf03d"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "03a8108f-8e2c-4e45-8134-bfe91d809ae2"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "7a60e379-cd34-4f87-88d9-4816fb4b29a7"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "fa6cf602-59bd-4c5a-b9f4-e47c99dae92a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "58fe0d65-0472-4782-9a0f-029785bed2bc"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "23d73c28-6b12-4df3-9108-ff524017e10a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "97e99570-2bb8-408e-9f7b-122c81be794b"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "8e98e07b-4465-4a5b-9d2b-26665348a763"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "9ea40180-4943-472b-845a-b8db2926e2db"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "3450b179-dbb5-4337-a768-46c7938d826b"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "39eab5bb-2249-4edf-93c2-6c8de76779b0"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "ef01f2b1-12cf-459b-887d-9a40fc59bc8f"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "8665b1c9-0d7e-460b-8952-4b4327fd7c4c"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "e7052df8-e4ac-4c80-9de7-05467ed2c424"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "b804bd66-5d87-4898-aa2e-3fc9a935e13a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "eb886e9b-ea1f-46c7-9698-419bd362121a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "d1afcf5e-d8ea-4157-a482-eccc377a9788"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "00e07bcf-706c-4f91-b0bb-d59d71988386"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "0642e04a-5c17-4db6-9e44-7884366445ae"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "bdc67320-6763-4b20-954c-14bf44d3da81"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "48ebc3a3-994a-46b8-b66c-8ed90ec9f5af"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "58ac2ae2-5022-4154-86a3-3275a3b9550f"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "ab2505dc-ffb2-4fa8-bb4f-671226ee8540"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "882d8514-e4bc-4935-bb5a-540e95ea2afc"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "fe0d968e-2315-446d-bb21-53bedb5c9b43"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "5cf63b05-feb2-4aab-99f4-f43288c28673"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "4504b3e9-0b1a-49fa-b812-021003f62b02"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "3f17b579-574a-473e-951b-4fe452890bc6"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "04eb6c96-a518-41ff-b5c3-f9ec28611ca5"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "279f0491-9282-4305-acea-13f4c853d238"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "8da49990-ceff-4895-8c89-aec53cbf0bb1"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "a0932f82-df69-4be9-830b-9bdc540e3d3b"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "00bac383-4451-42ca-a078-c7e72489ed94"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "181e4290-01d3-4a59-b715-682e2ad7734a"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "32e5497a-26f4-44c2-890b-565d95e27418"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "32b3abb8-c9cf-4120-8c80-a765cfaecde7"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "c129d25f-e486-427a-8a23-d07155744890"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "9d6e3b4d-ac88-4cf4-977d-d56717a4bdf8"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "4d25e1a1-051a-4efa-84e9-dd8dd7a4cc87"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "78856499-b6f2-477a-9c4f-54ba0f684d36"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "290c1187-dad6-4e0a-b7e0-b03064dca0dc"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "78f7b57b-88d8-4a3c-ab1a-e50b50282e72"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "bc4951bf-599c-4eb1-a0c6-6ac191c93300"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "f614c305-2ea0-477b-a806-c88c13ddee3e"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "a1b4d10e-7b4f-4332-9425-fae4c2ae9dd9"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "d6ddf464-2d5a-4097-939f-d86593f8be2c"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "9fc9ce4e-9370-4a3a-ae85-ad1a683eaae2"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "5fc4c334-23e6-4508-b7b6-eb43f00220e7"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "ef6cb731-7892-480a-be16-52aab21cab8f"}, {"source": "fdab757d-c1fa-4e34-bb17-ef37aa9fbf52", "target": "239ea393-a64d-4061-82d8-0676baab4b68"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "72cd391b-50a1-4726-8349-587fab476f6b"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "c8c183ae-3591-41e2-bde0-97467fb20276"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "7792105b-3e0d-4138-afb5-81c75c51f459"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "1b1734ca-c874-4fa0-a6af-b1ca1391f8f8"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "041f0ddc-9110-4495-ac49-4fa2f9c11d5c"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "72493f76-fc35-4457-8ab5-fc1e79fe2fd5"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "b9256407-93a5-4cea-b175-66e1a82832a3"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "1274e955-7ac3-4a36-9dae-ce486f481d59"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "6195e592-418a-4371-8336-d8d5f9ef9533"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "4d3aa387-89d1-4db6-b778-7818855fd048"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "a0cbb9a0-3336-42d0-9f6a-16ea24306ac5"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "3370ee46-6533-4a26-ac7e-41c68ed4c96c"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "77b681d8-5b2b-4a5b-b171-4723ab08cbad"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "ebcaed38-e7e2-4b68-9859-0a74c2d052c0"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "5674814f-73c6-4a2a-83f4-1849a070ae9b"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "66e5efe5-c130-4409-85b9-edff552e3bcd"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "9d159d95-5f9d-449b-85fd-4978110d768f"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "c606c3fe-dfd8-4f28-a633-be531cfe72b9"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "5c210a2d-86b0-4127-875b-c3fe718de635"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "4951d11b-32e5-4903-a998-acb6a89300fe"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "5662a378-1801-440c-bb66-d652f6c71c0e"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "46968c08-28c4-4f16-b6c6-0573f347fa20"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "e17e0e45-b94f-4f86-b25c-17ab4ae92d21"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "8d409fbb-f49d-4223-9325-7764258ee8d8"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "688ddcde-aa47-40f6-9c31-5b1d41342ade"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "baa8d06b-b6ed-46a3-baf6-2688bbed26bb"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "da19caf8-b8bc-4267-853c-65ded043dece"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "16a9752f-ffe3-4f1c-8bc5-fa8321ab5fcc"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "aa934016-5c2c-4faf-8625-c756cb50a84e"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "e4d43bb3-50f1-4617-a055-4547f36cd4ec"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "7bea7ca0-7d29-4066-a477-be5f8a65b78c"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "7a1d6c88-8e54-4e3b-a182-c83646d7d0dd"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "05e21790-dc69-4aff-bc24-a2e901bf881f"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "ae4e4f65-c125-410d-990e-57360d9d4209"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "99e02803-90bb-436d-9fea-c724404a2293"}, {"source": "26a4d909-1885-41e3-bb90-de4cc0d4b6f2", "target": "bac42a92-81f4-4162-8dfe-aed8a0d5a49b"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "d0f18247-b17d-45f4-8311-cf2e26322ea5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7d31c368-4e11-45cd-bbc5-e18759527ccd"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "dd7124d3-3b76-44ea-a914-4ad4d910ffc6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2ad8b517-f5ad-464d-aa05-205827279be6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "448cb6e6-5a35-43bb-8125-09f86efb6a9b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2d15d851-989f-4bdc-8e72-8e7ace247a11"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "141e5f55-be45-4249-8204-2ebce6100bf0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "032ce2bc-b560-43ea-a924-220ed39753c6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "923e6090-9bb6-4055-bd06-c80bc9ec1eb0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "19518340-4121-45e4-ac1a-8a5c24477570"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "25693d43-81ca-44cd-af1a-bb48dd8f157a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6095dd79-e8c3-4b77-9309-c2b725ffe504"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "94268bae-3f84-4cf8-b88a-d8719dc305df"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "07bd5fd9-58bf-4ef0-a6b2-e57a50723478"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ff61dd75-272a-47ca-a7f4-76eca0eb3ef2"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ee1e2de2-098c-4465-ab84-09864ac3c76c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "10897e94-6834-48fa-8581-f251ad584a47"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4fb69909-ac15-4f0e-beb3-0b13109c3cd3"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "82d6e097-af9e-47b5-b4f6-d0a1e1abe575"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b85224a6-3d87-4dc9-a163-61209b5b10dc"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fb908e4b-9534-4722-b492-f03ff8e95ec8"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "8d41138f-d46b-4fcd-9235-13bdfba2baae"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4ca9dbbe-1921-4cf0-b12b-b47f74190018"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3eea701b-dd58-44d5-b9db-3402293260e9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c20c0882-320d-4265-8208-43b278d03e02"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ba6377e9-059e-44f0-b022-ec78e6cae08f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "932fb377-500e-4aab-9f98-b5b054d68706"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "02f8ea4f-4e67-49df-bf66-9a7b6b8280c0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c6179e2c-4aa6-4fcb-9f56-94d2ac0c437b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e759248d-63a4-4af9-8151-a38c254edc86"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a178d2fb-66ca-4cad-b985-fe4d61e799df"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "0d93667c-b579-4f04-b8ef-174a6146b4fd"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "bda59e7c-c323-4acb-8e08-a5f16cc08ad6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fb0072a9-6b03-44a5-bdeb-e15fd10ea14a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2bcecd41-e086-4a6d-9a1c-f42ff23053cf"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e895cee5-bf55-4d9a-9896-af9484657bfb"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d23d4187-efda-47cf-a570-e0197b4ea2fa"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6bf31b22-473b-49ce-9637-f40ba49cf2d0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7a967bcc-4abf-4019-b59f-eed87ae098c9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "cf265601-f3e4-4207-85d0-ba5a3286dacc"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a7bfde3a-6a4a-4a03-b668-c5ecc571fe84"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1f18c7d1-71cf-4485-afd5-983460c8a19a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "34a9bd13-3208-4942-bd58-d09620fe23d7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e40fdf15-81ef-4cf1-9fa6-e4d01f86438a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "55026534-ac35-4850-977c-0502ebb27692"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f02d4b9a-13da-46ac-a029-1f9068ac537a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f2c5271f-aad3-436d-8f1a-13717be1f864"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4fad72a5-782e-40b3-945b-9c50b866d9b4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1acae205-3685-43b9-abde-c74f233274f9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a110b7eb-8e2b-459c-bcba-6b4163fe99aa"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "02c3603b-067a-4b0a-915d-e96ed596bd41"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "8b39dfef-b2e9-4085-9532-a2bb4bace588"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fdd5d0d3-cc91-40e2-9898-30a5a25c165c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "15279ab2-9b38-49dd-a89e-b358de46bb7b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a6fbd085-ce21-48c6-abb6-1f5857a94c78"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "62da0d64-92b4-48de-b4db-6b1c25bac874"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b1a7ae99-83c7-4f01-bf66-6d6c20543c29"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f90ae7b3-799d-4d49-97e7-e29793235a29"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "0bf3c754-1597-4b32-9c36-4505c38329fa"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "02ab3d51-3095-4781-b042-194b3a71fbd1"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c084a3ea-923d-44de-856d-d295ca582af9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7eae9d0b-1c84-467c-87d7-0054e7006ec6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "02be2170-4710-42b4-b586-24495a879ef5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a7c43795-2651-4cba-9a4b-64bc7d15f151"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ce0d65c8-1d2d-473d-847f-bbea968eb9c4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fe31137b-c478-491b-a533-f86d6f0a0d28"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "492480ef-f6fe-4178-a3e5-732b5691b0e4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d4328153-722d-4ed3-8d77-e3dde9a1e16e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4561d0ae-4b21-4b66-be52-afd849b4a3e8"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ed51ff17-f61d-4cda-adc8-092209b9bc7e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "59e32a84-a21e-43dd-8f1c-735dcef43e8c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "468118bd-572d-447a-97ab-64763e68cbdc"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "0c288aa3-3097-4dd7-80d7-70499ac3990d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7a3b597a-7b58-4c8f-a99d-20627eea8a2f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e01a3905-986b-405c-8096-efbb51da9673"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9bdac309-9466-423c-8890-dbcf4501835d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "aab8a627-19bf-4337-81a7-97eff4d2cf4a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "615a458c-c5d7-4697-b75b-b483decf763b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e48fd6cb-6c61-4ff3-a2ae-4fe845946151"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fa7883b9-e2ef-473d-bbd2-616c4408e233"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "319b760e-3eae-4011-a62e-b619d692f5e3"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "edf622a4-d564-420a-bdf3-c07f1852bfa4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "090ebcc1-d7fd-44a7-b7b4-6d4ca55422e6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "569d93df-fdb0-4f3a-b8ca-34eeba227a90"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c4a02f86-92ba-459b-9a5c-2bb281bda513"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2a15c149-3bfc-4019-868e-b637256c675f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "df495002-5995-42bf-989a-ed6b4a4d99a0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ba29561c-a25d-4378-8965-864ba1e094dc"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "118e61b8-26eb-4c0f-b1a3-c2d1fdba09c4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2752922a-7e4c-49e3-a307-b2fb46aca47d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a72b6e22-2aed-4726-adb3-8a8507d29ec9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "70b14d55-73eb-47d5-94dd-f87000399519"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "15eab4ac-f9dd-4dbf-ab57-bac71bc0171b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "31548d05-e633-48af-b1dd-1087addef646"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ae93492c-6390-4420-9ac8-83f4556c2db7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6cc85755-c26e-4407-a96b-bf6e87a0468c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ba675173-adc2-4f52-8e89-366d2a7a2946"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "98049242-e4cb-4eb1-ae21-3c0e6d0ae436"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a73c34c9-fb74-48b1-808e-3666e9ba9e0f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "07fa70ff-99c8-4dfb-81a5-51e21469879b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d599677d-b816-4741-b3dd-354a79763384"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "42d826a9-d4bc-4454-aef1-dbbf2d5a9491"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a18324ab-84e0-4d3f-a6f7-5850c17a1a0b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "8be7d8a9-fb97-4975-941e-d9ac8f0c32ae"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9cce3c2b-62aa-49e1-822a-9707793e05f0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ac063121-b0d7-4690-bb8f-2652b8311f35"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "369a4390-7346-4050-abb7-04897afa3ba7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a42fb3d1-e4b9-453c-b13f-b0c234c820ce"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "900d2fe3-3782-4b70-9345-f04f97146aa6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "815df392-8da3-4368-ad96-4b19197ee51e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "23e0512f-8e9d-4571-a3c0-84a9ae4117c0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1314871b-862c-4631-910e-6785992418df"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7a278f26-3724-4e5e-bc90-ec9033474301"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c44f53da-65bc-45ea-8108-28862b70c50e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "cf67aa26-a199-4a34-82e8-34ac8b6328d3"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "43e57e7f-df54-4e2a-ab69-3ef1bd01605b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3fd60bd5-52be-486a-9973-00c60e092379"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e0679b35-223e-431a-adf2-7fdd66619d5c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e8024088-b479-4217-a1cd-52913d046c64"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fd3861ce-1e7d-4d2f-9000-e66e29c9da51"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7277a5d3-1fa8-4eaf-afed-9376c6bf9812"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "002852a2-20f5-4415-95bf-f0bcc9b8e3d5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c40d4934-298f-4bfb-919e-e23ee2c1d593"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "5a724698-b0e4-420e-aa6d-cba99335f25c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b831db3e-95d0-4383-bd9c-9ee3ca156424"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9c2d0812-1f67-44ef-8d27-d7dca35ca8c0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4cb68301-2af3-4673-a680-161066e63009"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "aef6a11f-038f-420e-9f5c-0f637d4e9463"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c181cdea-c0f6-43e8-88c9-7ec8bb46a840"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b6154a6b-5a3b-4baf-a49c-f1e93757f4c5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "717cc754-0405-42d4-83c2-314dcba8c0af"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9b0f72aa-ebeb-474b-9de6-8d5ab56b0522"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d1154209-6239-4911-8dba-ebdaf7640ec6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "7ecf44b4-4b91-4d57-b564-ea74a7fa2f29"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a249aa18-ae5c-484a-a277-7062e4da1c88"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6eca65a4-a6a1-40fa-9ab2-27a6fd841289"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3313aa7a-ab54-4725-ba90-5161a6cb7c54"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "749874a3-fe8a-4b4c-9124-3af236a0b77f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "92bdf2a0-a95c-4f61-a7c4-8ea1eb3ef728"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "8c9f6d3e-cc58-4749-8822-18414d8f905d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "467746b7-41af-4304-873d-f9844447bcd2"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fa6835eb-95f2-49f2-acc4-9b4ff4135a09"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "99ab9f49-2f50-4e33-8cfd-6996bdf00ce0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "344906cb-527b-4573-b1d5-050c1d2dcc77"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6815f957-2dfb-4cc6-9d05-f594855635f4"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9cb0fb37-3560-48e4-b073-af825cf7138d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d5a8f7d8-698b-47c8-b353-11f6e605a21d"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "846d12c7-14d4-44b6-8be5-52267e5ae281"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d6cd58a5-5edb-414f-84f9-a4a9b1d4ac8a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "53885280-056f-4a71-abef-77f6535f9288"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1cd5f44a-eb80-4489-9553-6b35102d6f3b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "02cf665d-ba8d-48e2-b587-0720ddb1aaf7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "45700180-7552-4e80-977d-f35da4c74228"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4ccb0302-d1c5-413c-92ae-6cb0b29efe48"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "5cc805ea-9656-4899-b754-e3c9d2fa4421"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "01108fe0-5303-4cac-a96f-63c1b7af5892"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3f998610-7b52-4f8c-a532-4fe4f1c27551"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d0b4ff81-63ac-4639-8341-1866ae7021a5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a4f5c988-5f06-4c78-92c6-5ecb3ef2b351"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b0f66103-3e4b-45d3-8324-b0e5656b7e6e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b1a761d0-8668-41fe-8450-f9e7a9bca8f1"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "c8f724c9-1663-48dc-8b6f-31e7d1245fcb"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "621cede5-ec07-4588-80f7-eba66a4ac08c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b6b22cfd-ba8f-4692-b5cf-309f6730a8d7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f9206cde-71fb-4660-812e-cd1284d2dcbf"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "857c3666-8f3a-4d28-8610-3ac4bdbe9108"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "eabee958-4560-48de-bfe7-3c94574e43f6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "817a5339-d7ea-471f-9961-741dafe1186b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "dabe4829-7aab-4854-9601-6fb2b8378b89"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "572f628b-a23c-4419-b313-b4c55d5137c6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d65bb45b-f3c2-48fa-98ed-493282922062"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4f2d0da7-5df7-4a0a-a7cb-d7ff5d283c8a"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b7561b8a-4638-4694-a60b-3b89146be8ed"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6f7075f4-bc46-414b-bd5a-c4a9f9c0d9ee"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f8c4a8fd-9649-4e4f-a4d7-7909e946dc86"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fa69557b-15d4-4f2a-9847-a32c1974f37c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "342ae529-e69e-4586-a378-11d0ad521dff"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "72c6e768-aa2f-4aef-ba15-915255284695"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "89f07747-d8aa-4553-899b-fb33930a0d41"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4569cca4-49fd-492e-ab74-961d1289bb35"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1bdf529e-78de-4eb4-9136-d28036045a1b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1af4cfc6-b7c6-4064-8d4f-a65f9ab4bcc8"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "aa8c410c-2953-4816-a8e6-c8f99b45d184"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4fc87ad2-0420-408f-b707-93be8c1675d1"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b7f16a71-0b38-4f3d-a3d2-3a1d2f5f4f23"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "ce51811e-8335-4750-8e57-76986039e418"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b501bc3f-41d3-4a90-85ca-cd558b81315b"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "5fe2856a-2a73-4707-bf67-eaa1445ae450"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a4588938-1435-419c-8e3e-b507ed05b0ff"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2c88952a-23c7-4baa-ac23-5c805897e5db"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2adec6de-24e4-4e57-8ad7-ee658f3990f6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e61cbdea-57af-4a8c-948e-54fe9e236fc7"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "af5ee38f-2076-467b-a0b2-1a0227523297"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "a7235edb-5a16-4f38-9a56-173fb4f410e2"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "42febe23-2feb-4901-a65e-31b4d244d59c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1c7fbc9d-87fe-4522-ac9e-3924ad44f985"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "aadcddde-9883-4311-a69a-c36d9c28ea4e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "0f543540-30d1-4ec2-8d92-5a24bca3fc30"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1c4e721e-1017-48e6-9df2-32d751895ce9"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "9371ecea-7875-4978-9d46-4c500fdf29b0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "2b8a24e1-c48b-493d-b793-e39c8f64320c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6e2ccd3b-310b-468f-9940-c6d7c14f020c"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "60ff71fb-80a4-4a13-8acc-4b0650eb7f54"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "473edc60-c829-44ac-b096-f5c27c44b1a5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "cc02cf39-a1e0-4452-a082-3e6b34eab4d0"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f028192d-8c29-4743-ab49-1f25856dab06"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "b687dc76-0a7f-43df-9abf-c200b126d3f5"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3ac88bc0-8301-4fc1-8456-db33a7ee67fb"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "03b646ac-ad36-4ab2-a640-706095762640"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "583327fa-45fe-4200-9585-ef85d09aa8fc"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "eaa849ee-63b1-44f2-86d7-711990a49cf1"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d7065d69-850b-443a-9efb-45c37e639149"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "112e804c-db0c-4244-83f2-c5b1e1755117"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "27dae5de-02a9-436d-bfcb-3e1991ea7dfe"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "f06faa14-3731-4007-ae4c-db518ac404ff"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "da2b4702-4026-42e0-86e3-7121cdc9e864"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "4ed02108-8e05-4f43-9c23-06a74566da95"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "cacb356a-78c7-4cb6-8ca1-d8b7fdf87fef"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "738351a5-63f1-4896-ad75-79a0cb7126a6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "367b0985-1be6-49eb-9410-a29b484424e1"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fb148968-f8df-44f5-901e-44a9886dc6a3"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "e21bfd53-d079-4c3d-b248-9b177fa14379"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "fcb59cb5-bd16-405d-8fef-9bbc73213d7f"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3fabd7c7-f7a0-46cc-804c-fc9feb38293e"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "83721be8-2806-4fc1-b345-8918b5d9ed74"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "aacc375b-a089-41ee-8a9d-f530157cc610"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "d2701c99-5f8a-400c-a645-bda976171ce6"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "6eaba12a-2972-48b1-bc0f-c5c35eb591c8"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "627dbe9d-7f08-4edd-be47-270c2b6f0607"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "1744abfb-5982-4270-8fe0-a23cadd5ad38"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "3685d30f-2787-48b7-9ea7-2a05f3243b54"}, {"source": "d0f18247-b17d-45f4-8311-cf2e26322ea5", "target": "65560cf8-2b48-47e2-954f-717b2c23fd0a"}, {"source": "ad95293b-2053-494b-b756-6b098a23365b", "target": "9199ddd6-1be9-4783-9da3-cd67a484335a"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "cd65d164-738b-4e0b-bd74-416fc8910325"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "43b415e3-cf8f-4493-953a-085edb17c704"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "c13dac42-7b76-42d1-a96d-5cb52ee9572f"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "4f715dfb-62e9-4a4e-b65a-aa13ca341007"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "6eb6eff6-44fb-47b5-95ff-e0154d5688d4"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "0d0333a8-1562-4514-bb50-dcd537ea496a"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "bd05669c-5e38-4437-b32d-576c7ee0528c"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "51a30a1d-4621-4601-a4c2-9b745ff9cd95"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "767f7e9e-4363-4b93-874a-d838cb69d97d"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "9c3dd3ea-bcd6-41ab-9e0b-cc27c4e7061a"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "aa74dd96-21ab-40da-b040-9d297b94621e"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "b1749f59-f012-4925-84e1-d8f90f86815f"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "9f7ea8b9-0232-4771-8431-efce175ede52"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "e5023635-9998-4012-8538-731981721d91"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "a22c257a-3827-42d4-8d3d-fa043ad97565"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "d24cabfb-eda0-414b-9fb2-5a821d327b33"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "9031d709-d5d4-4c76-9b66-8116c8b195fd"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "34277e1b-c251-4596-99e5-4ddea7f06519"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "4fff156e-b13c-4d1a-8fd9-21941da27953"}, {"source": "9199ddd6-1be9-4783-9da3-cd67a484335a", "target": "8bd14232-4131-4f9f-a06d-4d13dc4129a9"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "2def9aa4-91b4-4262-8b85-c92d7157faf5"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "7e443c4e-3b42-44a2-a72c-3634eb4a1a65"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "f6562582-6834-49cc-90b0-5ef5895ca41a"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "a60d7310-fc6a-4cda-a4f9-e0ed257f6d44"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "97321fd9-e763-4d42-926f-c95f07baa32b"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "b66ad34d-0ccf-42b7-8316-1dd3297dbe72"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "f62956d5-d416-438a-bd7c-1983068bab9d"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "f49a08e1-79fa-4ebe-a7a6-eb295648cdff"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "ac6d8d7a-f6a8-4039-a206-6c88b58a2b7d"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "22ee5f95-f2bd-4087-b326-e59eb0cf69b4"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "027a3ce6-4d46-4f42-baa5-088eca9fcf33"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "d5c79e44-3213-4a6a-87ac-0ee0194a55dc"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "0fb28f3e-fd1e-4e23-8126-46c32788caff"}, {"source": "2def9aa4-91b4-4262-8b85-c92d7157faf5", "target": "53d97857-ade1-4d00-a023-6dbd394766d8"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "12313b40-950b-412b-8af8-0fba3447b317"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "7d582850-aba1-40cc-8416-3d231376f499"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "16803577-087a-40c8-b206-eca55d90e990"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "c5d5ffd8-f246-46cb-bc36-15679a0df75c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d754813f-75b7-4f87-a108-4a01f5f2e3d1"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "e216b835-bb62-46a7-8f76-05e85ba713f9"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "4d95884e-efdf-4857-8996-f23de8ce20b1"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "52f519aa-0ea4-4f00-abdc-811455bdfae4"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d8b29c40-ab1a-4455-a3d9-1a535cbaa01d"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "6663802d-932f-444a-ace9-f1cc9ec31222"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "5326e002-a665-4923-8c9a-d935e4e3f90e"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "163fa939-b79a-48d6-9557-aa7d6a22cf6b"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "f2c4a9e5-54f4-48f3-8dc2-4516c2d1a323"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "439073e1-78e6-439e-aa5d-e70213932a25"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "b46435aa-55e4-4a50-9da9-4c9193be9f7b"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "c54c95af-c8e7-4bcc-b55e-53992de54d8e"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "01191360-a468-4c0f-95ad-ff9f533a91c7"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d17366fd-b91b-46b7-a3e7-ac7e0bd6ef43"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "2853f49b-45eb-48a6-a7ac-b72a4fe1dfe0"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "6917c3b3-f10c-4d68-a0da-276ec3f74318"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "ae2110f3-63a9-4298-a3b5-0c13d71920d8"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "276ae556-09d7-465e-8456-aa478ba93c65"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "e60197f5-04f8-4bfc-8ab9-d8cc61a5dd14"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0b76fe76-80c0-4572-8412-10e286a7fef5"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "ee196232-5d78-4137-bbd3-76bc14f17ae6"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "8a915624-73a0-4d80-87a7-5a0334d75e1d"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d79645df-3046-4239-8d5b-0553d30b37fb"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "02e7501e-6b39-4376-b5cb-d262069a7c61"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "f72df2e3-377d-4e8a-bc70-c3a632d224a1"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "e8b3077e-f55c-475b-98f6-6c8e579f0557"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "423a70e3-05db-4428-890c-bc895bfb74a0"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "7740c5bb-aa06-4fda-a06c-ca0ccf7497f6"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "2a79cde1-7754-4fc3-8259-d9b54f3a0087"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "5a1bf1d0-8dfc-4280-b0f0-cebb709fdf37"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "28c1bf3b-9e94-4e01-a4db-c5a8343177ad"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0fafd6f8-5a6c-4a10-99ca-fc4239691b40"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0df26a57-1ec0-4490-ad46-9ed1b9300f3c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "db15a3a7-c64d-44b3-b9aa-b5e890ce68b4"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "711def18-bac4-4bba-a4e6-9e9071d39bb9"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "47fff4ef-a7a5-4d59-988b-66c0da7ce9bd"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "3e87f925-d6d9-46f1-8f20-772c0f12c8ba"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "cfe6ad5c-c770-48b7-b705-a5d3655f2e92"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d3f041ea-099e-481f-bc2b-fce05b3ab87a"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "26154c6b-6135-498a-9b24-d6563807e8ac"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0ef1a013-1ada-46d2-bdb3-0cd63101e4db"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "19cd76de-e581-44bc-aba3-84923d8facff"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "eb63656b-67e0-4f98-89c0-a4fc465f3847"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "a127acd0-c6c9-4664-a6cf-58487094740c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d71e5e0b-8e72-4719-97fe-9e6fbb0ddc44"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "bac2a7b5-85c2-49a2-ac4d-6e7b434dc74b"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "da8e426a-13a3-4d42-8026-ce57d1e15b2d"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "7a94d28f-3eee-4343-9477-28126050d811"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "6a394924-400b-48e9-8831-d50b56f89312"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "97e111ca-99a8-4e05-b5ee-81c64a1a9f0c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "90fb022d-944f-4096-a89b-4bfc1d78f08a"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "003f418d-499d-44ff-bbc3-a13d71a344a3"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "37a0771f-fd3e-4b74-b432-783ae7bbdc1a"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "2f53fdae-d892-4a1b-952b-eb0a8adb4a35"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d6c27c23-12c1-4164-a9b3-9646b8bb3aba"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "8c1438db-8565-4ae1-98c9-c03bceaf3a44"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "65cb45ef-c78b-4292-ba2e-bbe0cf7ccaed"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "3f0d2514-a6f8-44a4-81c1-2f866544d12c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "52bca142-fae5-476d-88d9-88c22307fe74"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "a7ba3004-f2e6-4b70-8d44-eeefa6d6c590"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "5c4ad456-ba2f-40ae-8745-c92e00ef79b8"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0ee81a3f-e4b5-4887-ac9c-5d5fd9d656cd"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "f68fb71a-91f8-41b5-bb95-04b0728c7b42"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "1c48769f-fcb9-4c9a-a4c5-88fde03ab5ae"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "5975a77d-d306-4b0c-a60e-13bd95e5f9ad"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "828246f4-fcc9-4edf-ac43-41ae1e1a4a20"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "69421411-42cb-4ea3-b7f2-f67aab89c627"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "0f6731c5-9d29-4155-a799-8bcfaf01be3c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "9c7d1042-75bc-452d-b2d9-3cc30883d85a"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "8da43100-c2fe-49db-a188-b8f3e4a99f2c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "b590b42a-35cd-41a3-88be-c25628579784"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "da62a084-9463-484a-a478-5a3d0b654805"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "10da2b8a-356e-453b-84d3-d9546f94bdd3"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "64cc4848-5983-4ec7-a225-040e4a965686"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "fdd4025b-5df0-4827-b753-ffd2d3d5ef8d"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "b528df85-5805-4ef2-9429-106f3b667b23"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "077da3d8-f4e9-4347-9dde-8b8e5e8e8681"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "aacbebe9-e2e3-4adc-b215-ee9432836d28"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "6d14d04d-e3ff-46a9-9a33-89db29462341"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "e7d28435-40c2-4ff4-a40f-7d308fc7609c"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "118632c0-5324-4539-bd49-e48d61960e04"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "fb90ef35-9c76-43c6-99a5-8a015d81f660"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "966c20d1-959c-448c-9dec-de6835357f23"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "99e3b749-0225-4427-9f17-6db8bb0a303d"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d420a52c-e727-4ae2-b7c2-2e29f4c770fb"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "d2afbf51-1d08-4f57-91fb-232b52d4efb7"}, {"source": "12313b40-950b-412b-8af8-0fba3447b317", "target": "3a9af73a-5873-4f8a-b30c-ed8ed839d416"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "f9f2743e-0655-4ae0-a0f8-2e3e87055226"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "840da5ef-7011-44a7-9524-09062c9dfdb1"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "4d719fd6-30d1-465a-b07c-12f0d56e19ab"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "0ae7457b-bd42-4c2c-a6b2-a84a2564ac8a"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "1d8f741c-a3cc-4d2b-9828-fc4a383a587c"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "27af9262-54d2-4f27-b3ba-fcbc840c45b1"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "55bbe753-943d-491e-80d6-ebb33cd9dae9"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "9d421223-6976-4ea0-abac-f5f011547e10"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "31ce12ac-5cc8-48a2-8a57-b813986c832f"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "57626ea1-4fa0-473c-af06-b6c58252553b"}, {"source": "f9f2743e-0655-4ae0-a0f8-2e3e87055226", "target": "a9994d7b-88af-4502-aeb0-634958e213f5"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "7adaa4a9-f265-45df-bd8c-3f16203edac7"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "9150ce94-7f53-4b64-9dd2-16d8128d1813"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "4b47d111-1b31-45b1-ac65-412c651a9e16"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "671cd96d-a5cb-42be-82b0-5f5b680b197e"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "fe08eb71-1741-4c83-b899-3a69da496f64"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "7c642f7c-dd94-4ceb-b65e-dddcabe6d4e8"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "ee3ae3ab-df66-4c3b-a1de-f5f062751054"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "3f484a95-6faf-4616-b6ce-e79f333b8ea0"}, {"source": "7adaa4a9-f265-45df-bd8c-3f16203edac7", "target": "30a35798-baca-45a2-b89d-dc3aebbbbf00"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "c3aa290c-0413-4def-8b44-52c813a43d81"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "3f990e01-7695-4be3-974b-8b3050668f55"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "41602768-d404-473f-bc0e-7a32acd9bf18"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "e3bd0dfa-6e96-43bd-a454-e33c08f2e979"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "236a375e-4174-4738-9fb2-f2b75e814c7e"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "4ae62511-63f1-4c6f-b4b9-d7f7df517644"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "0c50d1e6-8951-487a-a312-dc7d12853c11"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "d4c4f0ff-c17a-47d6-8fea-a7572306c18e"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "8185b2a7-7ced-44bf-8c23-649d1372ef80"}, {"source": "c3aa290c-0413-4def-8b44-52c813a43d81", "target": "168b4f73-0dd4-4519-8079-b8b7a65b94d2"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "1ecf5166-2070-4795-9cc5-6b0c252799b0"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "cfc33171-977a-4656-88ab-788102b3c52d"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "607974ca-1645-4c03-8f2b-12a4e377f53f"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "91410fda-dbd3-4e0d-9416-be922be7c0b7"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "17046fd6-3601-4069-965b-7bd5ae67d237"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "2d57cd9d-a525-4263-9f93-f2e9f21cdbfa"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "14ac89af-7d0e-4dde-b2a0-559abdcffb78"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "fbd9b7d0-f721-437a-8543-5ebe4821cada"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "e3f7f3ee-a2f1-4602-8458-402c50c0d86c"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "b5b7a1f6-f4ad-45b6-b431-68014fa5115f"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "99b1dcf1-92d1-48cd-b527-33e636b97440"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "1b2044c4-70f2-4163-969e-27776917eb1f"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "a8aa3261-e373-4a2b-86c4-4bbedb9e574d"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "af27ebe2-f14f-41ac-89ab-80148883cd52"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "9faa7f3f-33d6-4a43-a779-1d85f0768b87"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "50bb7b20-f5be-43e8-a373-1ca20884ef2f"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "191af081-88b2-4910-81d6-8c453d5fa129"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "ab989a2d-b7c8-4189-9e7a-2c338e1b878c"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "b6f56709-b76e-4ff8-911d-d8fe16a56dee"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "d0626754-587f-480e-af3b-f3d5476ada36"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "fe805bc0-7e41-44d1-8fff-db749912686d"}, {"source": "1ecf5166-2070-4795-9cc5-6b0c252799b0", "target": "d0375ecf-d654-4fc9-9dfe-11bb97d137de"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3"}, {"source": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "target": "c1b13d3e-53f4-4b33-82b0-abef08314825"}, {"source": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "target": "8cac93ad-8a11-4782-ba02-674a4b5655e9"}, {"source": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "target": "230309ae-cc14-4162-898d-6019efb7c559"}, {"source": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "target": "dec47f56-a673-4547-b0f7-a0bc7c48f921"}, {"source": "a0834b23-5d89-4bab-b943-a8a7c5d3f7c3", "target": "c6503ae2-4dbb-42e3-b217-c8aefe4ec660"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "26fa5386-aa14-45ca-acaa-4ccc3dbb85aa"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "8ccd30c6-4e8e-42d5-8391-b782781fd42a"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "44515f02-1c5b-4d55-aa1d-886fa6e0621f"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "272e2e8d-1bc7-4bfa-9d19-eac72429806e"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "36e792c6-b8c0-44f3-a519-bdbd65021404"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "ddbe52fa-c85c-4574-877f-719281d88c60"}, {"source": "f65ab16e-4a4c-4ed7-ab19-1e3e90966a52", "target": "dd0ce933-445d-4174-8a02-fbf82bdde68f"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "5d1b5e54-8de4-42e9-99c6-fc5871fc1dd0"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "6fb7aa1e-18ba-460a-87a3-41a73eae0b9c"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "264ae62e-0968-4a48-923b-7081dc8d2e8e"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "29fab669-20e7-43ab-9291-866cb4058c94"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "929ce490-bb14-46f3-94a0-d35d5ef81dc1"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "738a086b-2545-4f78-b0f9-5952868b2b61"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "3d368aae-53f4-46a1-9f91-4a30db91c6f8"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "2b1af5c1-9275-4f1a-bf54-ee20fb43cc92"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "705c7385-287d-4058-a14b-41d703feddbc"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "c6e02c19-f73d-470a-b564-42e5b75b7b2c"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "bacd18ad-3e7a-4e8f-b1bf-130b08270650"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "74ecefb7-bbd4-43ed-ac9d-aed0151fd065"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "af6ee1bc-be8c-4dff-9754-57e35c1f8bb0"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "c1071ae0-ec9b-4737-a05c-f11ac8606e86"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "1200db73-c0e8-4144-8f7c-e1eff3e8f467"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "8d703831-4150-430a-bcfd-21d8655e10d5"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "05db4d95-df74-4e01-8e4e-8d513e0778ce"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "1b8dd287-2f51-4e20-9ca5-e6a83920b0e6"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "2550791d-8221-4d02-957e-89be5e437779"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "f44cf2da-e006-4d00-b426-c827710ec29d"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "acd1ed9f-6ded-45e0-b4d9-8fd967611e81"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "09387fad-13dd-4313-8732-8786f6e3226d"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "2d435a64-940b-429c-8cc1-a44f6afd17c8"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "ddbd38cc-cbfa-4f37-a8bd-7a292524234a"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "78c09362-43f6-4b83-94a2-b9f12671d703"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "90539333-56ce-409e-95bc-4c9fffec7126"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d03d410d-1fe7-495b-a830-cde86b947ea8"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "347caaa4-4170-40c0-801b-f58bae9798a9"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "5e6b85a4-a7ec-45f4-8ab4-4c9b9e972822"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "0fd878c0-d620-42f5-bedb-9c43247d1908"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "c8ecf46f-e2fa-43bc-8680-84a5d5551121"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "13fa1ec6-dd27-4a2a-adb9-38e22c982fb9"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "7abb0b08-ebb5-4eb2-849d-e05cfd3a3902"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "16a0e528-f758-4e22-9386-1607ce6224c8"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "135110df-4e27-4b73-8865-b8bc3ae460d0"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "b522e282-c9dd-46b6-bf4b-b7ed1c1b20fe"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d7b40ebe-2699-4c52-b61a-9b67e4be00c2"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "067a89b8-0bed-4199-a8e9-e9e34e7c97ee"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "c870de4f-e32b-47d6-8d6d-e7142a838c2b"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "3f1939d2-b75d-42d7-a5b2-725849ddf496"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "67fe940e-b423-4606-b938-10b492c9c3c6"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "bd50b36a-8df0-4dc1-b643-c65d9ed161fa"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "faeb128a-1054-41be-81af-bda5cfd0c2e0"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "f6e35320-c78e-4ad7-9627-fd10003b1442"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "3de8afb9-2987-40a6-98d9-bbbabaf377bf"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "43f808a5-06c4-4b14-b25f-1e604e62c8e1"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "5cc2818a-0772-46fb-bdff-4a9b5a65d152"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "f6712cfb-48a9-4f60-9e7d-e4043a77e2ef"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "e25b16d9-8d4c-4070-bbb6-cb4aa31ed6fd"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d55ff9cc-1209-436f-8734-eee1b56468a7"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "efc798ae-61a5-45b6-a20b-d893dc2b9a16"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "3442aee6-ada6-4e1f-9c08-8c3dfbead85a"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "89776f97-187a-4cf3-bab7-a58bd680b0c5"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "1ec13b24-85aa-452a-b0ac-977a28718b3d"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "57cecbc8-f001-446a-905b-aa722d669935"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d3d65e83-73c9-4892-80e4-bdd497975381"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "28e645e3-e8e1-408e-aa16-ab1c097e201c"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "561dcd60-567f-42ac-9f14-2240dcb96577"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "95b490b3-9415-447c-abe5-6e068b51998f"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "84494bff-5962-478d-9d96-9ce8c3abc54f"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d0d4d742-e2db-4d03-bc69-bfaa28438d11"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "fa813d5e-6dfd-4df4-baf8-4bd27e26da7e"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "f8fda9f9-226d-4da1-a958-afe873f4feda"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "dbf695a1-348b-46e8-9db5-052017ca1239"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "16e8d08a-bdaf-4e8f-8c6f-4122da688a81"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "d720e5a8-0ae0-45c6-8e7f-ff2552dfdb39"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "98d4eedf-9599-48ec-ac0a-5236705363a9"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "9a02e54d-19d8-4587-9229-1e1f5f675562"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "acaf9820-ce22-43c2-bc20-99efed901225"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "69136c89-e36f-4405-829e-82f7216e4ad9"}, {"source": "9e7859fe-17d2-4e7b-9990-cdd0a4bfa72e", "target": "0cc56e55-d940-4665-9c9d-732732ccfd86"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "7e75318b-5daa-49de-8d70-96de284ca966"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "d58f0f8e-210f-47f7-b43f-15ed596185f3"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "fc1a7ea5-90a4-4888-9b0e-39d1242cbdf2"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "efd2268e-33c3-470d-ac4c-32f465093f13"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "3210bce0-26d2-4af3-b83d-6321f89589c3"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "f8661310-79a9-4d9e-9b6b-ba4916c63aa8"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "2aa1fae9-9640-458d-a7ad-2c8f39421494"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "8a8a330c-044d-4828-ad1c-826ea5ee1bdd"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "2dc52559-3465-481d-b39c-aad0124a5ed9"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "4d335102-76ae-4945-acf5-706e34889f91"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "8999ba65-0817-43e1-9d92-06f601491b49"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "3b3c0a5b-8ac4-4e7d-86b6-afcc422014d0"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "014a7b3e-4b51-4cf2-b391-884119a15a79"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "6c665316-0664-4e1b-9ad5-d2304ab1e479"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "4e536734-4982-4c84-93c2-2ad4e5ce7cd2"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "721c72a9-9f67-452c-baee-3f4964614442"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "5aa45ddc-2196-49ab-b0f4-e2ac47f0dec7"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "c5ef8fcb-6d04-4a19-8400-14856a52e6f2"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "e7d2b99f-e34d-4833-933b-3035e309c26d"}, {"source": "7e75318b-5daa-49de-8d70-96de284ca966", "target": "528cc544-e8dd-477d-aa75-7577e4082d5a"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "bc032186-c788-4135-a392-30615b0f5582"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "ce2854a6-6970-428d-8d33-dea56cd7028e"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "60a8ecb4-8eab-44d1-9b76-4bd959ae5260"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "78e6afcd-7d45-4001-9453-0df5399e0bc1"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "4b0ee05e-57a3-4322-8579-8938796146e7"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "a0e43c83-0cb9-45b3-b091-8d1e8a72c5e9"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "9eba17d9-463a-4f80-b59e-8df1100cdeef"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "c8d690e5-52b4-49fa-998a-1be2280efe07"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "861212b1-9bed-496d-8e67-dc0fe09c4a9f"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "28fa15f6-1b73-4f9d-b030-e84c96a05f4b"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "1678adbc-d2b4-454e-b00b-4b8e60ddbdc2"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "0aa4c7d3-064a-4631-8249-ed8680521200"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "0377f431-1609-42e7-b0df-f61b8d2bb10d"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "845a087a-d783-4c77-a559-68d78701bbb0"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "dc2cae19-5e11-4195-8b4f-1415646ec106"}, {"source": "bc032186-c788-4135-a392-30615b0f5582", "target": "328147c5-a5b0-4c99-a443-46d599bc6a9e"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "cfb2b136-6b57-46b9-8c47-98c2f10d402a"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "4010e581-f144-4557-be49-5d64cee33be2"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "12088dff-16be-4a68-b800-717bbef5b0b5"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "4842e23c-2f5e-4900-9c03-dd31dddbf51b"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "2fb20c4d-c1d5-4b25-88be-e13bd23ba84c"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "5ae0a624-c4fa-4870-bef9-64d7af47f33a"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "ec55fa40-351b-4853-a215-7d56296bc291"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "2f8e498f-7f47-4c34-a3ec-af9712da9e95"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f66712b2-019e-4d30-9f16-125f56bb0eaa"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "e40016c7-bd4f-455e-9db6-d37b99a41ab9"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "bc7b0389-9d75-407c-a59b-998ff932f91d"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "359e0c24-090f-4678-a036-437c6756d2d7"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "ddb1ac32-c2cd-4641-94a4-79b3b5a54820"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "c85dc7a5-72b6-46f1-b12e-6ffb1ecc762f"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "09e59c78-2b33-435e-b6c5-48c4c741bcda"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "1787699f-c931-4b7e-8ec8-0f3161292375"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "8af43414-8ba5-4c4c-b958-e0f483d5aeff"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "acfefdf9-f953-4830-baad-63d084f04066"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "e8859f0a-7d59-4883-9332-cbcbe8f845d4"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "453c3afe-c160-423c-8813-2cca53025ee9"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "a502d92e-71c2-41a3-a2fc-b216c85a24b3"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "df8ea3a6-5f24-41a2-ba6c-64327f249454"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "418bccd9-8765-491c-aa20-440e04999c77"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "34f56e1b-eb53-4b38-b1cf-d218a3a6c574"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "0fa32c25-73f7-4069-b6b0-bdbdea0238b2"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f912fb63-f6b0-4064-b57f-3f2045bb8ff5"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "82d5535b-8dec-4e04-a2de-0427084085fb"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "d8ab4764-596f-4283-a593-02f6cebae7b3"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "d46a9691-e917-4d50-9bb8-7b4cfa9bc590"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "faaaa789-3741-48a2-810e-202adf82e242"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f5db7ef3-94ce-407f-aa6c-e1bbf30c56d1"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "1eb5d11e-b37e-4836-983d-2a410b7fddc5"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "56125b30-de30-482c-b22b-ea8546fcd416"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "9e2e1162-dd50-4619-b721-22ea8fa4c739"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "6a267310-5da7-4b8b-99e1-1de9a63325f3"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "dba71d6d-c2c9-47a0-a38d-b7976ed655f2"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "0e9664e0-255a-44a7-bd8e-f61be5a5802f"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "4b404369-44d5-4680-8731-a5712765633d"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "ed40b7b8-ca91-4f28-9ce4-372aec594cac"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "35661162-8246-412d-aaf1-e37baf8646af"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f7fd90cd-7b3f-43e5-bd63-a8d0ac0a017e"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "cf9c7bd2-ae03-4c1f-92fe-e8244f245285"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "28f8bca5-fe82-4e33-9814-0f42e36d8850"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "556e64b8-34df-45e7-8ff9-5766524dc86f"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "e616c255-4dac-4973-89e5-863e180cc7c0"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f84c5f7e-eb58-47f6-b3b9-9745c85dba51"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "00ea110c-4adf-4324-8c9f-893ce157c4af"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "d113f0c9-c3c8-4e5c-ac98-8534d50e664d"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "6f521af7-0741-4df3-8e4b-835bbce011e4"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "605c6612-53f1-4bc7-8ded-7169c75b1a25"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "c5b21875-29cf-48cd-9e5e-a7f0c024bf70"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "26bc271e-0d2c-42f1-8603-69d3c600b089"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "18bd6a9c-29a4-437c-be1f-49fa8504b370"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "a2efe8d7-c797-40fa-a349-7925589e5e5b"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "5dd3697b-3428-4839-ab8f-06afc838e2ad"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "6754cd71-607f-48f5-aaad-9006ab29ae69"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "e85e8c4e-fe17-4997-9cdc-5a040d033f07"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "d34c6969-cafb-4d1c-a078-ed53aadb1141"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "c85d7a42-15f7-4ca0-9710-f6d28826867b"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "4073b33a-2891-47ec-8802-1ae7e7fc84c1"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "f7dc67fc-17c9-4a3b-b0c8-026cdff8828b"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "094fdf78-861f-408b-98e3-5429ceff72c6"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "24a17ed3-258c-4860-85d4-277b095fbebe"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "dd882bb9-392c-4daa-9a3c-4ed8b1abdb57"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "ef01b4c0-57a6-4410-88dc-44d06afa36f8"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "7e668013-fff0-460c-82ff-408120184c94"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "999726e3-5ac0-4e2c-a015-198dc05abc82"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "38be9613-7154-4eb0-91b2-e493c2e9ab8f"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "99a02722-b2fb-4755-8800-337a68c872e4"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "5274ea74-8ed9-42fc-8374-70ac7f2c3ea2"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "8269631f-94c4-4f32-9ccf-abb35b3410e9"}, {"source": "cfb2b136-6b57-46b9-8c47-98c2f10d402a", "target": "7fb911b2-2391-42e8-b77b-18a3f6918a51"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "204d0357-586a-4366-bbb8-ce554617c42a"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "d82e258b-e40c-41f4-9ee0-825a6a4b6fd7"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "1bad68ce-4f0d-4433-bd24-7329c489d58b"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "333e1ba3-80b0-4ca5-978e-756e9735b51e"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "114698f8-1256-48b3-bab3-c718c4b5419d"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "2a4a4482-006e-435d-ac0a-ef152af40e87"}, {"source": "204d0357-586a-4366-bbb8-ce554617c42a", "target": "2b4e250e-93b6-48c3-8d49-9085a38ae1b6"}, {"source": "ec2fde5a-a05f-4958-b321-9249210671fd", "target": "d124111e-8fc5-444a-8be0-e909a1e41acd"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "3f520135-6a5e-4918-a208-5e48033af047"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "4a5b6fdd-0156-41e7-893c-d1c01bc0f7a9"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "f3e38609-29b3-4ef4-a7f7-5d2c2ba85374"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "8666aa77-3e7b-4477-98cb-129370d3a136"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "b5903855-961d-40f1-a295-017b928f08b3"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "7a088862-24c0-4e92-ac9c-ff7164388c7a"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "e15a6fce-ad42-4a05-bac7-0218d2cbaef5"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "0efe37bc-cff7-4cbe-8a18-2a08fb7bbdcd"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "6c7c35c4-54c5-45be-9ec6-55323089cdf9"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "b9ff8809-30a3-4f87-82af-d7c374d7e911"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "6952fe85-7142-4d83-a646-ac505c6446a5"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "9962c3ac-fb06-4fed-995a-6789a998d4ac"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "44a034a3-479c-4625-ad17-ef3bea8c9ab1"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "e552e34e-ef76-466f-9168-d4ea8a4b1b99"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "154469c4-319e-41e4-9b9c-dd4e3ef80851"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "4976a03b-aa38-422d-8f26-1cf22c166ee0"}, {"source": "d124111e-8fc5-444a-8be0-e909a1e41acd", "target": "2017b0d6-e98a-4761-a558-4d1e70d21672"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6"}, {"source": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6", "target": "8a0bcb2a-5383-4be2-979f-947225e32834"}, {"source": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6", "target": "c9d3680b-994f-47a4-a8e2-8ad9e9292916"}, {"source": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6", "target": "fd31deb5-270d-4722-8a83-132c2a791929"}, {"source": "2fbebe84-8d3c-4d44-ab9b-7d22bc18d7d6", "target": "aee90122-d451-4f31-a0bb-650fcd8fc6b9"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "bdee96bb-c9a6-4323-90a7-b684250dac33"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "9d2612f6-a590-4db0-b462-9b1da39913d0"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "80c59ec5-ce1d-4fe5-abc7-47add5ff515f"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "7193ba2b-7c19-4fbe-b8b3-e7af3089807e"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "cb468fba-0692-4833-8aab-2733b501e2e2"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "a49e6b9d-6082-4f32-b7f9-1c769c4d0547"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "c5c077fc-1fad-4c44-9af9-fe433f1cd8eb"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "e3011207-4833-4e6c-ab30-58ba17cfafeb"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "cc0d1ad0-a1e3-497d-8efc-143f1c924e98"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "f62ac043-b5aa-4bb3-920a-bb8505eef7fb"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "a9cf1850-e570-49b4-9ae2-4240b1b0cbda"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "bc7ec3fa-a78e-4023-9cc6-2ddf0056da66"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "c3b0302c-d6ef-4b05-8d8e-cd50d104cb6e"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "a068dc00-e996-4a74-a671-f5832c590672"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "4a4e4565-3945-4e37-a6dd-f40e3bb453cd"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "3e71427a-281c-4dbc-9e9a-22e609085464"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "57fb3785-29e1-46d6-a4d0-059d9d18bf5e"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "29fb5858-8eaa-4b91-8ea7-e0eb92f7ced1"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "be1d1758-162f-47c7-8917-20a42e017ab2"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "fc4ba4f4-720e-45e5-a710-2f2bdf8c17bc"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "4f41c90d-391a-4853-85f7-31410d26a170"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "e41f1425-88b7-4af2-8c62-da4b4888f676"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "5eddb272-0bde-4a59-9677-5cbda59d61e6"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "d3d00c33-a7b1-41d1-bde7-29ea529cee63"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "cd4df32d-d698-44ae-bcf4-b9b97f226637"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "f0b6ffe8-b1c6-4ff0-9335-89eca046138b"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "59997aa1-eb49-419d-955e-2f87664673d6"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "2fa9a702-d62b-40b4-92bd-6e49a4d1a2a3"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "08a5a657-d17a-4e57-bbc8-9f139f5ecf47"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "d1482079-31a1-443b-b6c3-d3b428333efe"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "69da2004-2eb9-46f4-820e-41811db4aee5"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "c941cf1c-62dd-4e37-b854-feaad1fcc00f"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "a4deda0a-2a9a-4952-a1f3-d81841ac4a67"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "bed08686-3dd9-45f1-a5e2-0dec8af94646"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "1e7d730e-4f99-499a-b754-582fc6d03e6a"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "bd61c1f2-4caa-494c-91e2-7c3c0a7917c5"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "03facb8b-4e0f-40a5-a6ec-7d2c9920bac9"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "dee92c2a-d5f8-47bc-8c5f-998f49524d4f"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "a247d713-db6a-482d-9967-494875a0f3b2"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "806a9a23-37af-4aef-a036-c1e453254ffe"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "50a67f82-68c7-40ba-bcb2-97aec8753596"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "3b4e0c0b-39b2-4a42-a95a-44f6eab7cde8"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "22fc5fd6-3ddd-4654-a201-bedb5e27e158"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "85bc6fa3-acab-48e3-bc03-318e3feeadb8"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "8ed852c1-e2a2-4254-8486-be191b9d4f9b"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "8bfdb0f4-9ab4-4a9a-8e81-24de295ada80"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "ba2e7fe5-9772-4ada-94a7-1a5f1b64906c"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "54d9b6f8-82a3-4dde-9642-0445318f045c"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "600d1ba8-f7ae-449d-88bb-44a71bc42e04"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "5de83757-7011-40d2-a69a-a00b99834d8f"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "0a2bc486-b97e-48b0-aa97-f478ca50c64d"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "036f3910-66e4-4c21-bf7d-976c0d00e3d5"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "21812f1f-a517-46c8-a9ba-31ec931e0d42"}, {"source": "ed8cf30f-0dd4-4a07-b496-a5a66f6be406", "target": "f1bd5468-25e2-47fa-a2e7-256b94d3b464"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "521ff321-fb01-47a6-9ed7-26eb2149ca3c"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "d4a7a7cd-a9b8-419f-8f2f-c775a3de7054"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8713d692-bba6-4e15-a4cf-6cf5043b400f"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "861e9891-9af3-4f72-bdb4-6aa94425bf7b"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "4de6fd18-0c70-488f-96f8-3a21950425f1"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "0e68d101-a5bc-4a56-bf54-7867b1ea9ff1"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "4fac2bf1-49d2-4091-ae56-908b691d11fa"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "cd7eea27-ad1d-44b4-bebd-44c225bb0955"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b3108fce-dbda-4554-9cb8-d331da1f7e54"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "f3cacd97-1405-403a-be6b-c5c13ea93f18"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "060fed1c-94c7-4a66-8083-daede47421fd"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b00dba53-09ea-4a13-a37b-666bafa029e0"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "7fe9f75d-6dd8-425e-88a5-51c019920434"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "7cb08905-ca5e-4eba-ae97-1ae444c93688"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "79e75bac-ef39-4298-8850-cdacb9b3a8d6"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "64639c60-7868-4ff3-8c81-f9db04cbf283"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8a281922-d8a1-45b0-9df8-95584dfc8f86"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b3f37760-8431-4527-8517-bc584860fab3"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "278d4aad-ba37-4dad-824d-cb022d0159b8"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "af5ec4ca-3fba-406f-92a0-31bb4c87eff8"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "0cb857ba-131e-4c8e-ac17-a22bc5e2b245"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "2c3c3c65-e20e-4998-b263-6ffde36dbe79"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "cb13125f-ef93-4afc-ac75-e1784fed236a"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "9ae42f2c-5254-4b21-bb21-0ca11daa5916"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "3d502acc-881c-4545-901b-651a82da9948"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "419de115-0f27-4c8c-a382-6aa4e8067c59"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b87048d3-9f78-4a33-bd2f-c43a23aaf4eb"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "ffda09ae-9762-42f5-ab12-37ae66a703f6"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "7e8c2e4b-a8f1-4207-89e5-0d478f7588e0"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "32bf76fa-62e2-4864-96a8-033af9b54472"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "e80eb9f1-7397-40d8-aa30-b2af725eaf46"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "850bff39-fa9a-4357-9fd9-70389c9b681c"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "695e63bf-61b0-4a7c-8d76-8ee3feced18e"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "d0af07c2-0157-44aa-b389-7f651487eadb"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "57ed80a0-d906-455d-ab34-2855684e266d"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "6aa7d850-f1e1-4532-ba5f-a83007bb3ad2"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "d96810b1-4cae-45c6-a79b-db67292184f9"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "c2902641-a5d9-47ee-a074-aab6f9833c70"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8e4eaefd-da4d-496b-81df-53f9153d06cb"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "5746af90-7035-491f-93d4-59d3feb98b41"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "400ded32-786a-44a8-95a8-a307c3530039"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8930f568-2a02-4785-9ff3-0cd6e7ce0d79"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "74f74ebc-0adb-4518-9809-16c58983175c"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "4afe1014-17fd-4357-94ce-92c00f266c80"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "dae95684-a9cc-4d65-b89b-093ed59b1e97"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "e959fb4b-5775-4a83-a5ab-9282fbb0b856"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "1ed0ebd3-00c0-4122-b471-09c7b6ab4da2"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "9e9c4e74-fcff-45e5-b04d-395e172c46bc"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "2aea8606-4dac-4295-9bbd-51d059a16403"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "a49061c5-e309-4144-81a7-a8fb9fea8827"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "c22f9375-17f5-4848-95c4-c8eb39a06b2f"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "320a82e7-02d5-45a9-8a14-c179a83bc9d9"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "4dc8bb7b-8931-461a-ae1a-86e258a192b5"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "682cd9cc-07ad-42b4-aa02-8a2f2f120e39"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "380bfeaa-af7c-470f-ba46-23be8286acdf"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b540011f-c677-4c90-bd6b-f0249df771ae"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "f4ab50dc-5645-4cdf-b1d8-a52c316bbabf"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b63db74d-a4de-4633-9c46-b248767d9e6c"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "e88429fe-167f-4352-8068-28efa9568ee8"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "3c6db0f1-2963-49c5-81b4-3b1cd5f73e02"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "1fe18d99-aa5c-485e-a5a6-cc181d4a9959"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "7129e019-5de8-458a-937e-7d02db93088e"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "3e36bcd6-b56d-40a2-bb5a-beef56c1d402"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8f10410d-45b4-4bf9-9dae-120dba06856a"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "0a70056f-9c83-418b-9b99-9f3a1359214e"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "03e1baee-f9d8-4359-972e-574debe4db61"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "af391ce4-aa93-4bc1-adfd-c91698b3efbb"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "6bebcebb-5038-407c-82c5-0dee21a1ca01"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "663845da-31f1-42aa-af34-d07091ca31e5"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "73dcb447-2790-431c-aa2a-e8f69308b82b"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "45c1657a-0eef-422b-863d-e0496c128588"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "2cdab351-08b6-4f3e-9c90-5a305c280ada"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "8e78481c-fcfe-4e12-bfb3-4ab9d3cd014c"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "3f138df3-80fa-4f13-9d9a-72765f7a0464"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "241e8a5f-969e-4a93-85e5-3f8bde2a4ed8"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "df745947-b8da-475f-a9e2-dc9aa4009506"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "ffde9527-dc88-4c4e-994b-b3baa0e1ebba"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "23ce8210-3cc3-4974-8f46-d907cc9b7d65"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "4ccec422-fee2-47b3-950d-49ed76f2e453"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "37cf1c6e-0415-4141-b66d-48e7f5ccbd2f"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "6cd47f75-8a2b-48a9-b388-237c46b57f54"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "83153732-7920-4fcf-aa2c-406f6fbdda1b"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "711a6bbe-7a29-4252-9294-1e39207aef36"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "3c0d5daa-6dc2-455c-98c4-d94064d1003f"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "bbad1140-d7f9-4a61-a41c-acd088dd9b01"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "2c76aa82-9dff-4395-997a-9cf649c9c8f1"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "57a46f50-57f1-4da9-818b-f8493aaa133a"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "bd41ce97-2c9a-4948-b3dd-bcd0b64528b9"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "c713132f-2d14-4054-ba73-62d78f13636b"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "b96d550d-8846-4ebc-8d30-fb88bc4ddc91"}, {"source": "521ff321-fb01-47a6-9ed7-26eb2149ca3c", "target": "d532e090-4ead-48d4-898f-0bd2b76696c7"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "ab211937-fe59-4303-9618-47518307adc4"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "450d3798-e1cc-4ec4-bfa2-53b985fb9a0f"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9939437d-9274-4744-994d-8b896db5597f"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "31177599-5c1c-4c21-bc1c-a49831311c7a"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "461ea639-9ae8-43a0-9303-0c01b7a9c827"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "676abb63-90aa-47cc-81bb-cf9d8db524e0"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "bf65bdd1-377c-4024-ad6d-71ffd62b1130"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "c7c6da35-6a9c-4599-9037-d5421eaf5e6a"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "d066d7f2-9c29-43e1-8405-d5cdeed61518"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "1dfd19f9-b3ce-4659-a454-ab25ec5a6012"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "85192e0b-1cc7-492f-9117-bf3a368903a7"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "18854aa5-ec12-40e8-9777-406c11455f7a"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "c6971fd7-fb0f-4645-a0c9-5cdefa6dcec2"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "63717420-3e0c-4083-b8e3-3517f4646d80"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "51b385e1-c025-4d84-880f-7c2447280e1d"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "4f574eba-291b-4dff-a3a7-943285bc68af"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "063a3eee-322b-4ad2-a06f-877f27d2dfab"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "397eb9ec-2576-45fd-9a24-0ab88a3188ba"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "c80604fc-d1ce-4396-8d00-9d69e3867c13"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7122c81c-469b-4a8b-adc5-74182ed3f4cd"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9f87a14b-e2e0-4223-9a5c-319a66238fa2"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7ab46e05-f664-4242-96a4-b325287700b8"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "e11f1167-67fe-45b2-a874-3caf2981cad7"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "270eb440-b326-4282-9ad6-1612e95318db"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "1ed13c81-e760-4ae9-ab45-9df070c77711"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "07300653-62ec-4c60-b4a8-fdd334d20716"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "56c3d036-19e0-4b93-b103-efb9298ad6e3"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "5f4fde0d-de1e-4988-9118-09a7b524a892"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7b29cc2f-ad14-4e9c-9a67-257c06ca89ad"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "3b89a015-d10a-4d19-a999-22b90aa42089"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "c7399a8e-91b6-4be5-8f0b-cae2e9e13944"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "0c52dac9-e19e-422a-bb0e-9beebe28a7e6"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "ccb04fd5-2dd1-4630-b7b8-a4cf57931942"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "3403f33a-aac2-4458-ab06-a49a41f13789"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "4e884de4-d64a-4601-9430-0af19bb9d82c"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "1f6dbf5b-26fd-4da1-8f3b-18a5ccd1e86c"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "1b5117f8-b74e-4b2a-b5b3-bc687803b5c3"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "47ff2651-3290-4ed0-a6ec-a4865950de02"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "588c255f-5526-481d-8b51-4370d0761fd4"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9b228f2c-707a-49d0-902c-88f67f801ed9"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "62bf0614-34ca-4d99-aa30-810c6cb04a90"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "ae425390-fbf1-4f10-b4e7-2be31437d4bd"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "a2b0ea2c-5c9c-4235-ba36-2e14a0cdf91e"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "30ccfe45-d2e0-40ac-b601-bd163a0db38b"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "5366694d-dcad-47ea-8e65-cddf0ea462df"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "2796efa0-6d14-4b34-97f9-3aaf6d1972a9"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7eadccab-15e1-4f6b-874b-e625cbb84cd2"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "5794fd1c-9202-4b02-8007-1154e35d0325"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "e0ab8185-24ce-4340-beb4-aade920c455e"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "10ba7069-954a-49b9-8718-33fc0cc946cd"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "68df0984-d5cb-4fb0-883e-a93a34521b03"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7488c6e1-a0ed-40fd-9572-0681d1450fef"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "ac48fd63-d358-446d-8e42-cf517c6365e9"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "cf4aacc9-a855-455c-9350-acd74499a6e8"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "300d38df-be01-4fb6-a973-c69a116ac1aa"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "911ef710-20cf-486f-87ae-616a6d7b563e"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "b1f80345-fc99-488d-a106-9e57eb9c52c5"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "488e24cf-d008-454a-97e8-651bef9333eb"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "dd9b200a-eb0f-4841-8b90-6467146ec657"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "a282979a-bb79-4b18-9ac3-2db2803fc938"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "483f3c22-a75b-4345-aa41-3c4133b87263"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9b8ee9ab-05ee-4b0d-84c3-fddad5b41db7"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "67e2f6fb-309c-45e9-bef6-2fc0685f1b47"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "ea9c0cd9-45de-4fbe-a464-2be36ad372de"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "ea0e8980-0856-4f23-9d84-f4f37ada3d17"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "d4f6e755-1249-49ed-8eb5-08fd9eeab793"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9f04ae0a-3cae-43fe-b1c7-5832702b6995"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "522159ba-0d4f-4c2f-b6f0-5cce47c18bec"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "7de42920-b893-471e-b401-f9653bc2bb00"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "6857fad3-8830-4cfc-9647-e874684fac30"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "bd78ea1e-913b-47b9-a5d8-a0d448fcba78"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "9bbc2c7b-0bda-44b3-9f96-3d52f1d080c7"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "2485f464-8582-456a-a3b0-9a57ed8442ae"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "5596b860-638c-4951-aa10-28f1ca2e663f"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "470a1bf2-cd06-4bd7-b7ed-ca83e3c18abe"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "8f08f04e-784f-4253-8699-166e62cf60e0"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "488ce9ab-46cc-405d-9a5a-23ff0785038a"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "c112f45d-113e-4b42-a0fc-fcb4ec198455"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "73f73648-567c-455c-9777-612be3e205a5"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "fbc1304e-3f13-4ef4-9597-8633da1b4f24"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "d7008fc3-bac1-4574-af7a-30d9de438876"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "62936849-19b4-4c56-9de1-2205deff9663"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "85fa1754-8dc4-4fcd-987c-e8e09607b082"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "89b27aed-d098-462d-8b77-426f2e1a8d14"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "83fdff29-481b-4f0b-9aa1-15b9d8c21c3e"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "56c4b12c-01b6-43d0-8a6e-717b23d1c0a7"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "1aae05d9-8bb5-4401-8ce7-67341194bd4f"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "f37c20fd-9ad0-4844-b76f-83aeeb71e707"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "309a4eda-e9ea-4d93-8026-0093c9fb82fc"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "8d4281bd-0e14-4303-a245-4b564c7f14c6"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "5c9f49d3-41cd-4682-99eb-d6744dc04c79"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "32fd12d2-d5a8-49bd-b029-019a2510984f"}, {"source": "ab211937-fe59-4303-9618-47518307adc4", "target": "98efa724-66cd-4c75-82f1-c59af22b3b8e"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "cfe34f3b-956f-4e55-9e4f-ead3f72c748c"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "70d45260-72b0-44fe-81f3-1e3183c39492"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "3bce00d9-16fc-41ef-841c-e2a88c681653"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "8a660a04-4176-4653-9c98-07d3f148b47e"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "6044b2e2-5795-40ef-a27f-645f57dcdc8c"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "50091255-14ca-4f0a-9cdc-9a94a473dca2"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "f73f20ff-cdf8-404a-b7cb-a05eb93180f1"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "3a138d8b-cc60-4e3a-8f18-899b8d9c2d91"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "96807cfd-ff41-419a-883c-9cfecb14ff29"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "5ca96d0e-0451-4878-9fe7-944058f3532f"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "0d69b18f-e165-46fd-82a0-276434b16fbf"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "0f248213-8a93-4522-a62f-f58713a4abc6"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "7d124d30-fa00-4cd9-aada-1a6833bed99f"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "b02a85c3-28d7-4d68-9fb9-88294e855ffa"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "b051a8c6-f88e-4cd3-ab93-8a77b576fd45"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "4264a9b4-a98d-4b3d-b0c7-43538a634bc6"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "958ae5c8-0cd6-4d13-8ce5-af04c072578c"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "f181449b-70fd-48a4-973c-24e1a8142e36"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "a3efc137-f9ce-4cf9-999a-811d4f3b352e"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "649f6a0f-0553-49ce-a3b0-c04121960db2"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "36d7e7aa-1fe1-4516-81b7-57c81947cf9f"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "a5078c7c-0a10-434f-bda7-d880c53122f3"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "70560447-2a2b-4311-a030-7423913270ae"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "d4941862-39a5-4665-a14b-c84cb11a08ed"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "1312020b-4f6d-407e-b840-ccfe36a62b00"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "a5cc4735-86bf-47c7-b820-7ba3a30a6823"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "1fa44104-bde1-4172-b13f-6e95ffcbecfd"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "ac6be952-2ec2-486c-a8f2-d8fd7fcd34e6"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "56080438-ef05-48f5-b482-6ada6eb75f6c"}, {"source": "8ea0c55f-dc0f-45d7-b13c-3e3847d01394", "target": "e5086b76-303e-4596-b468-e598e46b55e7"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "d60085f6-0f47-4106-9517-2fb59dfb5768"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9e60de25-bf17-4015-8f31-95a18e2c5b9b"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "804e282c-4683-4180-b742-ef92674405dd"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "ab4aea01-e433-4f4c-848a-63550e97fb16"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9e9caf30-b0c3-451c-82b2-29c32e09b846"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "8f6b8359-23e3-497f-a0b0-146783e949aa"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "f544a10b-b00a-4aeb-8fc3-9321545f34bd"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "193389da-4b06-443f-a8cb-4bd41d9d91c4"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "64052bb7-4c54-426b-95be-e61678b96c47"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "442b9ea6-cef3-4166-9109-d350c2c7bbf4"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "1966b85f-64a0-4453-9e5b-829543d0cbe5"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "07dfb2b6-b0e0-450c-ae77-2457e18917f6"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "089ca358-a8b0-46cb-9272-6d71753ab661"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "4fe9d504-2482-4123-8379-20c0ce836e52"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "3af39288-f923-4e8f-8915-0b6813d1d1f1"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "84267945-3e9f-4cae-b77b-dd3299e88e4b"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "063f0f88-379b-4744-bc58-533c158580bd"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "ae78eac2-b518-4fb7-ade1-062b6d9f9056"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "f5c13248-8eba-4b35-8733-1f462045cd18"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "fd189eae-dd75-42c0-a22a-be0bd6f285f4"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "7abe8e43-6145-4830-a356-c0cecbc0252d"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9f9ac61d-ffa3-4d5f-9af8-e6391082fe7b"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "218f736e-151b-44e5-8d93-cc60d4298cb7"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "fb298752-66ea-4f9d-8177-1a2a98ab8f56"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "de2931ce-5b8a-4585-84d3-5c0dbcb110d6"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "cb18b1cb-47a5-4457-b5d8-e0cc05aa0014"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "332a4954-760b-42f7-8751-e5355392d355"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "a0597476-986b-43ee-b538-bca9f56107ff"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "7580001f-a266-47b2-9a07-500d6f80686f"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "3741f63a-26b7-4b55-963e-4236d6ee3c4a"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "5d519d74-fe2f-4cd1-b657-c9761e9d434f"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "7fbcaf3b-1eff-4fe3-abed-8b55d4926b45"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "6d1670cf-2ce5-4057-985c-d68b0fbff67f"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "3c06b38a-8e02-4796-b284-ee0ebd7e1333"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "48bc2c38-f308-4d2c-bd14-4b2373b177d6"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "0cf8b121-31d9-41fd-9b83-3c87b1a346da"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "398fecae-80e5-476e-aa1b-283e75fc03bb"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "b84e0409-488f-47c1-84a2-18e5c4646030"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "aba449aa-cea1-47ea-8d48-c6a9ba4edc76"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9cfb92e0-e926-42f6-9822-cad263598f40"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "7c29d4a0-ee9f-4cb5-8dd2-126e8b039df6"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "c084001d-d454-4639-b8bc-b2b557baf30f"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "358fa50f-ba0e-4a38-97c6-525033e230e3"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "a9b2b914-9ab1-48fc-bc9b-64d4875b6065"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "6da8c7fd-55d2-40a2-b84d-8672c80c1cef"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "d3a78e1c-6fe2-48b5-be73-923bf5fbb5c2"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "2f3a3dc5-0774-4261-8efe-a9a83ecca3a5"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "81e8a5a5-8990-4c79-87c0-8462014c0c18"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "342adb72-8d97-4e78-a16a-557696765092"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "47258ae2-baac-4561-845f-933538eb6f69"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "77043b6d-0efc-4034-8301-3fd6b6bdaa08"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "255b8f0f-fc28-4084-a4b4-857f2c0142fd"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "282d0221-b27f-4e09-a61e-1fa3a165e0b6"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "b02592df-d255-4d4c-bfb8-486765b89ce5"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "fd7e8628-55ae-4d86-b916-75aa785e9ae0"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "191ac078-c5ae-49c2-a543-eaa4386842e5"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "6a395206-6887-4c15-a380-e2782429290a"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "23c95708-d4b1-4675-88d7-b2fb1e6085c8"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "6b9a6112-9588-4526-bd9e-64dddab95d80"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "122064c8-9292-426a-84ef-8b6e55deed45"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "577d0ae0-7a5f-4496-9b22-585a690c5fa4"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "7157c2ef-9b6a-4cd4-b73f-a8b9d95222ce"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "c40daf28-7ee2-40de-b15f-783266e16d36"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9879a39c-2b21-4689-a099-760b2ed2a73c"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "b8669e64-50e8-4fae-8f07-889b9e47dd0b"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "b13483f9-e448-4bf1-97e7-1f5a6857ed7f"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "792b71ff-cf23-4596-87bb-4de436735d97"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "0f2d6630-a1a5-46cb-8399-99d9f726e834"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "156cdffc-6fb0-4bd2-803a-d6a882eb549e"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "8127021f-aae2-4fee-94df-ca12ce1bf5a8"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "ce545bc8-e6ab-4d31-90f5-993ec2944afc"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "bddb0daa-43f0-481b-baa9-3c936e5a4fd0"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "889839b1-b89c-4da3-a28a-e4600e107c4b"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "93b5d6e1-673c-48f0-a7ea-96468e315b58"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "36b52f94-1957-4c2b-9bbf-3729068eb74d"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "39f6b0d3-3dbc-42cc-ad88-ef0b8bdcde4c"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "507b787b-ae5f-4045-8072-079b759d61f1"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "d56b712b-22a7-45be-8b6b-8d3e4140d725"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9f043dc3-75fd-48fc-bd8a-596b6a807e70"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "5c5a8033-befd-43e4-afbd-80aa006aeb51"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "cc482a6a-c0df-4a60-bcc4-aaaa5e9311be"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "1eeb12eb-b3dc-43ae-9d63-820f7fa15f99"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "ab4a1e8a-36ea-4315-94e9-500549461765"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "2619e1eb-893c-4843-bd15-659cc845f0e5"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "9f56fdee-7cd5-428e-b838-796714f8954d"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "24bc24ff-6cd5-4837-8429-0e1aaeb8d3b2"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "517bdae5-0a24-433c-9dfc-57c09ac34e24"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "bf1adf8e-f2bf-47e9-b821-b0e68b2b5941"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "54a4ae6c-8cbd-4e5a-a3b3-58243cb2943a"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "b7e1f801-8ac6-44bb-9a9c-35187daf1a47"}, {"source": "d60085f6-0f47-4106-9517-2fb59dfb5768", "target": "0a932af9-1f33-4a8a-b879-3839f6cb5e65"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "21852c36-e778-44be-b5d4-c3e0b5f8b61d"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "191c25f7-c9a9-42e0-8b25-e44e33642d35"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "739a83bf-a224-4c4e-aa7e-856f3d149fb1"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "64aec55e-77a3-4fc0-8468-098f3e909614"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "8602e2d7-ebdc-4699-b51b-8199eac558e6"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "d8d08228-75ba-44eb-88e2-6193fa2c3c1e"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "db124520-cde3-478b-9fee-e055bedfc437"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "69c8e743-7777-41c3-bda1-fb156be35aba"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "8d5a90a3-3204-4932-8b53-4e3c36a1c098"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "bb6475ee-ea1a-4b23-8f24-a23553c7f92d"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "5b7d4858-b31c-4bb6-9482-fcc6c197fe8e"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "167f1f88-31dd-436d-92e5-398fbcde193b"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "b292238a-f958-4ad5-a15b-2c5209d590f3"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "5f1ea752-0b6b-4ad1-9495-da51b98ab58b"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "4821e48b-8c92-4fc2-9859-f2bbd917ed09"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "56ed52cb-0f98-476b-ad2e-fe3e90b55858"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "a5d5bff2-1a3c-4e26-a79e-85992a1b9fb0"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "6a29bfd1-5e7b-4582-b4f0-9a5061fce081"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "e39a94e1-07ef-4026-be9a-ba5fb3d029cc"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "c1f859b5-3c33-4a99-a1bf-36f5d1105435"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "e24eaa59-17ef-4fbb-9f8d-a0ee568bca25"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "8264844b-59ae-4765-b118-bf6a2bfcacd1"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "40c73d4c-d2a8-4025-9241-9b39f19272aa"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "86b8a11e-85e8-415d-a6a6-15a335a81491"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "253b5960-095b-4519-a234-f64f5ca19cda"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "5daed29d-babd-4e33-bd16-6674fcc5d82d"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "00e5aaef-5f4b-4bd9-9e7f-1ee30411cea1"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "b02da623-3638-474f-9d35-cf1367287b2e"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "b8e302ed-3209-4c9a-9ac8-13e7fb965d1c"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "85edf61c-97cb-4d03-8b55-73b2f33c0fef"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "7d31d8cb-5f06-4a65-9115-a23262fe247f"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "3b5038cc-780d-4c80-b8fc-0f53bcd863d2"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "0c9c7810-6e2d-485b-aab5-4bff28a364d8"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "e0981c5f-19ef-4967-8f9b-7761073cd44d"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "f217af67-dfba-4523-9171-17316e3913e2"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "225bb416-aa03-4d61-ad81-90d7106221c4"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "37264da2-88f3-4efd-a106-14129c3244bb"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "8d20a82d-5500-44bf-8e5e-9457c58dbfff"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "4620a938-4b7d-4d84-ae7d-4542c74c8da7"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "cdbc38d1-f306-489f-9e51-3b679793c416"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "9ba5b0b7-d23a-4372-a415-7b1876182c68"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "3900cd58-14fb-446f-b686-91120b66ede5"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "3ed1d176-68b6-4d54-854a-04421fa44d55"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "0dc65fae-22cf-4546-9a70-cca5ba6cb3d5"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "66bd07e7-e9c0-4994-9d62-99b4cec59373"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "d6bff36f-3187-4c6b-a5a0-f1c87a2f3018"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "6538e200-927d-42f5-820c-9ed89ab0b623"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "6942ef44-6f1d-4b48-8949-333532c9d1c2"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "f9d5c9c9-19a4-4d29-9c95-27a0783687c4"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "51d9c436-2e7b-4368-b886-60e270a149f3"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "01ce8201-0b54-4004-8a3e-484872b8779d"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "c0ee11df-0993-488d-93b3-cb75414673b7"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "b41df16e-a9a2-43d0-a8b3-712fac1c3157"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "7b5283e8-02e6-47cf-9158-b9e0416b9fa5"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "226961f4-5015-4804-bc5c-aa6855ccf5cb"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "75eb7a7c-b9c0-4eb8-ad2a-ea0dadfe691c"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "31d9988e-32fc-4c3c-b75b-9a92337d2419"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "823484c9-21b3-436e-8d1f-00b554e91ea7"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "06555872-bba6-4a7c-a461-bd0507be2ca7"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "7a930c84-8f3e-495d-91e6-4e434001d09c"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "c8fe74f3-23ec-4ab1-b0cf-dbc8dcb60710"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "eef1ac03-537c-4c07-b63f-81e48d299dc9"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "09371340-ad71-48d6-ae0a-d124c02341ff"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "54f4abc9-67c3-4c4b-9c18-6f2771d24c96"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "729abd36-3e6c-4da8-9ac2-c3123fb64120"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "092aaba0-8675-42a2-a4ad-8e741f42870f"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "6fc7c502-a5a9-42ec-8dfc-8e0698800b20"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "df36945f-fa45-44ab-8856-1566fffcc8df"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "7d3dbd36-bcc5-4b1b-8c41-69f9a33c7b0b"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "a4984c17-3cd0-4004-b3b5-05549db6d010"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "077d7893-4991-45d4-804a-8ba8d1562404"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "c6d7b0c0-0ffd-468a-b956-e63ceffb9e71"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "91613096-4314-4221-8973-7b8c3375b603"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "2c756682-29c4-4fd7-9e62-ba68c07735b9"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "b4704ce2-2044-42d2-b6c1-ce52ceef7503"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "bcfe25d7-7d83-4cd3-9aae-95a35c763e38"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "e2c4ec39-1efd-47f3-b450-bf88fe81ebac"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "7bb2f54c-09fd-4665-9086-b32d5ec08225"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "9741d575-ccd6-4bc1-83bc-c4b700515668"}, {"source": "21852c36-e778-44be-b5d4-c3e0b5f8b61d", "target": "9fadce69-ef70-4b59-a023-327ef3bc3a3d"}, {"source": "4bd5aa2b-b935-4172-869b-94b4c52e9417", "target": "70c09e3f-d78d-41d2-8b60-85e5627c8e47"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "eca2bb4e-e8bc-49b1-a972-c1f376aba63c"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "f27404cd-fbb5-41ab-918a-03d87b75134c"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "743f6505-29b1-4f5c-a1a8-8982cdd93fce"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "e2842942-ce8c-414e-a078-47a7213bd15a"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "2e8a764c-d346-4297-98c8-3a10b6e046cd"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "cff0b030-b022-4c1a-b454-0881e9e97b83"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "8fbdd7cf-7eff-4b65-a5e7-40633ab52e90"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "baebe870-83d1-427f-83f2-11fce326641f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "1c746585-ce6d-4b25-8bbe-93d90a2832c5"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "33e03774-7df1-4054-bdce-2d6e6d310125"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "d8d9746c-ddac-48d4-8161-46622f4e6d73"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "b847978f-cfd0-42cc-8419-45bc285ece1f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "25f402fc-23ed-4613-b5f8-1bd0564158f1"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "85203381-7ed3-4f47-9b86-cc65102d0fa9"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "20f85bf2-1f34-47be-a8a6-640a03c6f06e"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "39ab6ece-0abb-4bf3-8ee9-f48320f9d658"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "0702d83c-440b-4719-9c57-d38235890795"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "31bf1c4b-ebdf-4769-b89a-eb2cdf47ce30"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "20cb3ec1-8ee9-4ef6-998d-e82322688216"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "a9bc96d1-d6e0-4fc7-a841-94d9f14fcaad"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "532716b3-d0f2-4bee-8791-04c7a795b3e6"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "e01d2d57-0120-4d4a-adcc-017b6091b9e2"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "ed4c72d0-c450-43fe-bf87-eb7858aa1670"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "baafb005-d47a-4f61-abcb-89447f56a6cb"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "376aaffa-a6b2-4d72-ba5e-de21712791ed"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "5dbdf199-690f-41b4-9ec1-02c74766d66f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "d510d492-6b3f-431d-bb9b-a0b8ab4a01eb"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "d610dec9-96ef-45d8-af3d-dbf555e4c8e3"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "7bf4c94b-a2d9-4001-b147-4ad452d6f7f3"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "5c5cc57e-abaf-4970-89e3-70cc1e28b68b"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "4f13c760-458b-4da8-8abf-03985082a9b6"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "9a10dca6-f93d-44b9-9ecf-1b62e37914a1"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "39db2bee-8f4d-4265-b2e2-0d2535e8ed51"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "06dc75de-ee32-4872-a81a-5937503960dc"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "ead0899a-9fb6-49ac-9a18-d07efdec2ab4"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "a2f1ee0e-353e-43e3-ae52-08e56c721821"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "b086e37d-4c54-4752-b894-1c3f6bb3f919"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "16d65c32-c844-43a1-b724-b34eb6e7019d"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "2febfd03-f605-4e86-94e1-247fd29a4fed"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "2498b696-451f-488c-bc4c-71cfedb9d893"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "90a45177-2f35-40b7-a8a3-1f5c1108bfc7"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "faeef798-221c-49a6-8994-0d10e8556a52"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "0766fb6a-d6e0-429c-8818-a0cfff42f6b8"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "2b294193-3c0d-4f42-b976-a9b271d44e97"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "cc76ada9-7511-4c2c-85eb-826f88ada00a"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "6718b2a3-c704-40d3-a542-f9ab0cd5208e"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "03703dd3-b9d1-4532-8104-4dd080ce1e52"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "67d7024a-97c6-4cc6-89b1-ab8f9ef0ef82"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "cbd7cac7-5be8-40a4-9bbb-2b7c63b13756"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "225f0a28-4337-4449-a85c-b86f57318029"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "462254fa-6088-4e6c-b343-9d00159c6b06"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "26f70d07-d099-421f-b71a-a27c81c6faa1"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "7c5e221b-20f9-4af1-a714-612112345f5d"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "f6485968-ade8-412f-8d9f-b343d5fa142e"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "839368db-0340-4d64-926d-4c22f7df05a0"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "c04d71bb-09d8-41bb-959d-3c6789f8916f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "872a5bdb-d092-4a2d-852f-76c271148313"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "04a3cbcd-c77d-4db9-92c5-9aa5ead8137c"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "dabc31ee-d784-4f3e-b63f-9d4bddc970e0"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "d12ce108-fbc9-4466-99c2-deaf193d614b"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "59cc3e37-618d-441b-8c24-fde53485a1f7"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "c3fba006-3a04-4163-b22e-c004d208154c"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "952e273d-9187-4a59-9c3b-3efaed69e0cf"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "7345a9e2-c099-4f06-a9a7-c85e5ca8bbea"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "b7c7622d-a8c1-499a-b929-de41802417c0"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "9c6efed6-7e7b-4c11-9ec0-347cf6273d3f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "ea33d028-9190-40df-aada-17b19c1b63d7"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "7ae94995-0965-4944-833d-69241d0c9c4d"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "a852fe38-fcb8-4a6c-89ac-cae03f56a3df"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "00e082f9-ed2f-4f3f-9d12-91f2099015cf"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "53179275-fea9-464c-86be-d8fb3dbf1f31"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "be056972-575e-4f34-84c5-efb5d775acc3"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "4ebcadab-f4e4-4df8-ae84-512221b73d14"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "c817b8b9-058b-420f-a3b6-db17907cf29f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "351eabe0-59f6-4797-9211-3f6b249161da"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "f0996c90-fe77-45be-9d3d-ee71e9623a59"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "77d65f4a-de6d-43db-93f8-268f608065f4"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "0c67d403-2a54-43e1-b367-1c82bda3e0d0"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "fffebb4b-e67b-4674-89d8-9911c22f689f"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "79a66e9a-4848-4a0a-9c2f-d85fb9aef929"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "130b59f3-769d-4276-aae0-560db9e00788"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "52305711-e4c3-4ea2-9fa3-589fc4c4c220"}, {"source": "70c09e3f-d78d-41d2-8b60-85e5627c8e47", "target": "f80483b5-aae7-4182-baff-8e28a482efd8"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "25d1522e-41b4-421e-ae7a-312858f67343"}, {"source": "25d1522e-41b4-421e-ae7a-312858f67343", "target": "7c18681b-a47e-45da-a064-b4bd6fed74f9"}, {"source": "25d1522e-41b4-421e-ae7a-312858f67343", "target": "192e2667-7cd6-4388-b22d-37310fde7e96"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "18b5bde4-602d-4acc-9927-aacb32c5de84"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "8a3ee38a-ff9c-4a7d-b46e-57e8175aff06"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "fe13cf23-dd80-4cbe-bd59-23ebcb2833c5"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "9bbf444b-8865-4e94-99cf-d9c7a6006cf5"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "7314c2af-6544-4637-a94c-ba6946ffb2e1"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "0ea605db-a016-4f4a-bf53-928a51b9fa8c"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "35a6271a-06d6-428e-94cf-21982b74d35c"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "ef53b742-b868-42c3-9e1e-2eeefc2d14eb"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "d5d1f4fa-35b6-4b50-86b6-68c75adae6fa"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "2537c9f7-ec2f-4aa1-b532-ab2f4d2b7f5c"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "a291bf5f-5a41-46f8-ba43-9071ecadd2f1"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "b5840cf1-9d4f-43dd-bd9a-85c0417317e6"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "601f7e50-e6fb-4db3-ba99-7a0816688135"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "0103fca9-4128-42b8-b386-1bd9555ed641"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "999bb344-e4aa-4ed9-9e31-337332d14cad"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "2a41d5a5-6a5f-4a4d-a94d-cd55683ea900"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "d68d2811-c0ea-42cd-a2fe-339d0a4064be"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "f10fe3c5-fdd3-4ad5-8bb1-5e141de3ef4f"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "45f31da9-77e6-414f-b805-54f4e2f70aed"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "54893447-92e9-43aa-bd43-960299ec7dcf"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "3de37db2-a106-45b8-a644-8b750f7c7aa0"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "f9b0a3e3-f7eb-4033-871b-16a524461867"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "bdfeca41-9d76-47c2-9b5b-1a4537123348"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "12d53ae2-1643-4357-b46b-a5ca647c89e2"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "52ab0a85-b073-4c62-af74-783f2f48c56c"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "f2170fe8-51d2-4ee7-8f8a-da1ce24354bc"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "bc434004-f138-4171-9ec6-23d1ec847c40"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "fd6c87b9-228f-41ef-b4f0-a2ea51c763d8"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "7d9d9636-cc23-41f3-a728-6329a8f29d29"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "d89f482d-1657-4b1e-89b2-ddf20e62a50b"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "d9b01406-6e74-4b20-b8f2-75038aad5fce"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "4b1440ea-dd26-406c-bdda-61695432587f"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "609632a3-8d58-45b6-b80e-24de793abf08"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "50703611-a613-463e-ae36-52eacab3858a"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "563a2094-b8b8-4346-8789-464b11727163"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "b807b365-21b6-4cf8-930a-0a68c0311b39"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "447f782f-2ca4-48d2-82cd-771fafc1da1b"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "a42e2df9-865f-4dc0-9ac7-ced9f68e96b1"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "161ad59b-7167-4276-b31e-26b31b3ccf5e"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "b54c0cab-8feb-48c2-840b-26bd6015f751"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "bb8ea4bc-b91c-458c-bb67-a244816b7ab6"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "7cb3194c-1f97-42c9-8b23-2fb6e6cd549a"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "5c24d9f2-57c0-4f32-86a4-083e4ff45c9a"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "b2237c3b-2a9f-47c7-8605-77cf6c8cc326"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "412c3097-d6cb-422d-9441-c950b15650da"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "8ea2300c-81af-42ed-bd2b-5f1bbcb2d6f3"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "58ebb6be-1e8a-40b7-88a5-cb710094d430"}, {"source": "6e87e378-607e-42d9-9a0b-8eec5a1eb03e", "target": "662a5cf2-1a2d-405a-bf16-f1a40e0c1b41"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "28443ed6-e339-45a4-937d-cc06e198441a"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "614543a4-6f71-4b91-96ac-7b95af5b633f"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "7b437f2b-99d5-421c-8720-41e75ef0eab1"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "d9eaefb2-9309-49c0-b19c-cd4ce2fc6ac0"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "d5f51f10-70ad-467a-8d45-2f1e29df46db"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "9cb58e6c-405f-44be-b10a-94413d183090"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "12f2f109-c247-4627-8f38-08f07beca82b"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "8ebbfb4a-92bd-499c-b2bd-29d674079fd1"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "105bfe32-a2b3-4d8a-bc9d-9a4cef51cd7e"}, {"source": "28443ed6-e339-45a4-937d-cc06e198441a", "target": "f370b400-a30b-4e7e-8f46-839b7047fd29"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "a86ee1ec-480d-478b-ba9c-698288a98b2a"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "33ed60f4-24da-42ef-979d-482d8b97b00d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "d533817f-a415-4d1d-9d5f-c0cecff8f300"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "9850829a-16a7-430d-8d23-b41844cb16e9"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "89364c03-bebc-4d8c-a422-fe348aa31bf1"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "add3ee5a-38d0-44d3-a8a6-c85771ea1d41"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "29c5e28b-a829-4376-9c9a-3b25e93264c6"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "1fc6d905-3ba0-4590-af26-cc0b68b699d2"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "6ae4a247-bc62-4cc8-ba8e-df406bfc2e61"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "9b434f04-4779-4631-96b3-0ffc93b656d9"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "c3f2b1db-a8e4-4df9-b35d-31cc91cab450"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "7d8edc6e-6efe-4406-b9f7-b26ddd26de2b"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "ec05419c-521d-44e8-9420-709330a4f06d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "e80e7cbe-f594-45e7-845a-726b209563c3"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "b2467ec7-cebf-4327-a4c4-60d29604b8ef"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "b1a6bf6e-0a5b-4c86-aa3c-41f81bd0c32f"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "b1ba9223-c432-47af-8650-b3f0ed638232"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "d22c7e23-fa66-417b-8e29-dc0aeba85cfb"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "f2d4322e-eaaf-481c-9184-84bedfe12ece"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "9abeb4d4-9b1e-4e33-9362-d61357815712"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "54af9ab8-4138-4118-bb7f-745d20b71c34"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "12c2b588-a8ba-43fe-b590-8c66bc0483bb"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "ebe36ec3-faf5-47a2-b06e-62a7e23858ef"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "ce90a964-ea36-433d-bb85-0881c41ed0c8"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "b7b7a0bb-7a66-45d7-8564-2373810bd70a"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "a25a6196-ae43-4ec4-b25f-622cde692d3c"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "1f601877-7b3f-449c-9e65-954cd07b4b1a"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "41ee0e21-8d88-4ca5-9e56-f244313a76a8"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "126b6ad9-1d74-4383-bffe-f1d9dce2d082"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "99f24d80-49b3-4a58-90ef-3c7dc679af7a"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "73af0c9c-a9e4-4b3d-ad28-c388bd7219f6"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "9d275c17-c97c-44cb-b823-d366d1b49616"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "0faa3384-8706-4f40-b905-7a21cffef89d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "0154fe71-b8e8-4fb1-9853-9d47c3520913"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "f35f9804-00df-4475-a99e-8c3af5c6fcdd"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "fa2e4162-d51e-4a9a-a88f-c3e87bb7394d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "3f0a009e-83e2-4580-96e3-ae42cb1f408d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "c0722288-0d70-42ba-8d8a-fefed39a0ccb"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "0025d13e-c825-4a8f-ac2c-05e80dfb882a"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "e3613415-1c53-48cd-8f07-f95df0a41a53"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "a46e506b-642b-49a9-b36e-271c28903f40"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "6f7f6f20-c28f-4fbb-860e-ea42309eca4d"}, {"source": "a86ee1ec-480d-478b-ba9c-698288a98b2a", "target": "561dc114-5a6d-4fe5-87d7-74670a0e4dc8"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "fbbfaf5c-82d8-461d-a784-c2479e56d491"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "35ca46c7-9aa6-42cd-a396-c1d9876d5b3a"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "b08507ff-f8ce-418e-963f-6dc47aeb5aad"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "a403deac-3134-4000-8418-ecef8dc2463c"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "abae668e-3b80-4a43-a2ae-d1a484713dcc"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "3266084e-369e-4dfc-97f4-251a4bba6451"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "e699a410-42ac-4353-8751-ccec2b78eb58"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "1e48cd0d-d13f-4b42-b69b-d3154c1ceb79"}, {"source": "fbbfaf5c-82d8-461d-a784-c2479e56d491", "target": "f96c85c2-9def-4fc1-ab41-f2559e5183f2"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "a77ccdf1-42d1-4abc-b17f-d716db522cf0"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "cce80d4a-2208-4488-8bff-4a7c710e50b8"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "c1bf8532-c298-4bdc-b6ed-e076636a8c51"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "9a8e1e66-ccc4-48cb-bfb6-e2d0690c4e14"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "e4c70af9-7976-4e3d-a4ec-7b4cc2940fe2"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "34a74bda-766a-472d-962e-9c8d1b4f2a6a"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "7f1a421f-3b90-4c63-a2ee-58bbf8cac1ae"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "ff71a1c0-e52c-4f00-b6b9-937260ac7f0c"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "b3f5b79e-041b-4317-aff1-1c1e2213d573"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "7d4d86fc-00d6-48ad-8217-2de769eff8ba"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "cebbd400-b726-4a9b-a2e5-7d068262c899"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "167f28ff-8536-4d94-8b9e-4687afedbab9"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "403d7e33-3f53-4acf-a75c-0e423d872992"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "001802bf-4e02-4b0e-a4b0-e20cdea6e941"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "acce5934-2d69-44f2-ba07-c6bc3484ecef"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "d51e95cc-9a3c-4151-9563-488cfab2e875"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "7b6127bc-e562-407f-a665-931bac3764b8"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "3d138843-4209-4583-9fb5-488aef444916"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "673fb7cf-0ac0-4e17-8f73-1f8df8ded864"}, {"source": "ca6b4a04-e39e-43a9-ae8c-27eff6ec59f0", "target": "c08d0f94-2139-4f68-914c-aeb39548c99f"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "51f62548-da2e-4f14-a365-86e9360952c1"}, {"source": "51f62548-da2e-4f14-a365-86e9360952c1", "target": "e6705c77-b93c-406b-8f13-fa85185d49f0"}, {"source": "51f62548-da2e-4f14-a365-86e9360952c1", "target": "8b37b8c8-09e0-4609-9416-fe1b7f114fd7"}, {"source": "51f62548-da2e-4f14-a365-86e9360952c1", "target": "bdb40a5b-524b-44e3-93a5-dcdd3b8acb5a"}, {"source": "51f62548-da2e-4f14-a365-86e9360952c1", "target": "c4c031e3-bdc2-43cd-b8d5-665d649d5a99"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "da236e4c-e325-4ac3-823c-7be324aa4a9b"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "a8841753-2004-4784-bc74-399d8b807610"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "b9f24062-82b0-4a70-8b82-23c031d5b239"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "034de583-1031-4522-bfa2-878d2063c1ae"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "604027ff-6ddc-44fa-af19-63b9cf4f3842"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "6a8660cf-f03a-4b19-837e-2661edfbc31f"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "c437f528-2381-4453-8c4d-df53a62d497d"}, {"source": "da236e4c-e325-4ac3-823c-7be324aa4a9b", "target": "d3074a10-d91a-47bf-bdee-b46402f48a42"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "ab5841ab-2d57-4258-973b-5f2b2b13658f"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "d3c316df-9967-4558-b0a5-46011880bbbd"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "fdf665b8-1996-4989-9e25-d522c03f98da"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "3aa6d283-b169-4534-a675-49cae7d765b7"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "2ab5213d-f182-4f13-929f-55e9c4482594"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "ad4f0287-22c0-40a1-a3ee-0bd7c4bfed84"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "102f11f7-ce02-405f-8e2d-6dd62dc48c1c"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "b3524a68-fca8-4c05-a310-c4bd59143927"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "db363827-841e-4eea-8879-668313e18692"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "8f356fa9-ecf8-4ad0-bae7-744fd83eb614"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "f660d9a3-0760-441e-beef-4321f1dfde85"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "4bc7b80a-2557-4e27-b108-fac83013e9e5"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "d8912bd1-7883-4dc2-9008-46ed2a823aa2"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "4ae2849b-ecbb-4f66-8e58-778123107b0f"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "aa00ac38-8891-4e3d-ba07-e360455334bb"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "fa5ba3e9-511f-4759-a4fd-860f0917fd7b"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "c3b33694-acb2-4cde-9390-2576f2c04898"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "3b4aad49-5b1b-439b-a1e3-7fcba878fbfc"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "bdfeb90d-e3a8-4a75-ba5a-38dd6e454fb5"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "15c56c38-e503-4e46-8093-b490dff044a2"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "b531b209-d463-4b76-80e1-26e741db4c1a"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "826905d3-7254-4e00-8bf1-17345b1d3892"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "7a405f60-43f9-489c-9ffd-c86a22201823"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "aa09e8c1-11b8-4382-b5e4-df5c594a8601"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "05714f45-d690-499e-a13e-00da2d2b36c4"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "a5068bf8-8354-43d5-aad7-ada6847e2c92"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "89da3557-5c44-428c-9dd2-c94826478799"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "95983ef5-d7e7-4a74-b8cf-d7660c796c13"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "2b62da72-8ec9-4011-b9fb-f5b0e6c812ec"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "3673e625-d651-4edd-8b8d-d68c42a662e6"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "2bb37786-8e54-4941-ad29-d773c71924e3"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "30d81765-ec79-4602-8a87-4c38d941d269"}, {"source": "2ca3056e-e1ca-4114-90b3-8bc6cf776f0e", "target": "18793ed8-de52-43da-932c-7a167ff06a6c"}, {"source": "4ad1935f-bbc3-4ab9-bacf-0732b9a532fd", "target": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "21dd5170-8006-4c93-9031-1c423edd4bee"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "f4671ee1-dfac-4c1d-9fbc-3faaabe1b977"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "7138764e-d3d4-4dcd-85f0-277bbadb1bb7"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "b9385d62-dd73-4438-9f09-98bdd8915a00"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "e0d7e4a0-9d57-4099-b1b9-d3aca14d5e8d"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "7effec9f-3623-48cf-a31d-a1eed9609bce"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "98574e89-2ffa-48f9-bc22-3b69ecea7d84"}, {"source": "c86e7921-8bc2-47e0-815a-adebb5bcaf5c", "target": "00673808-b921-433b-a7ec-460d80a0963b"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "10a3c6f9-fb84-4ad6-b100-73ea504799af"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "bd41ef74-46f3-4858-afa9-d4c05fe76d97"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "122dfbb3-4a5f-431d-b7aa-ec8f33853e40"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "f7d5a2e9-8151-4fb0-a537-9749e789681a"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "7f5104fd-0b93-4c60-a2e5-b9966a860b5e"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "8a0ab510-9d36-4eff-b5ae-4e0c53039b03"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "f4557b2a-2763-4d42-bd84-4d05155736b0"}, {"source": "10a3c6f9-fb84-4ad6-b100-73ea504799af", "target": "786df9ee-a760-45c2-9863-f0f942143b67"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "1432b101-a27b-466f-9874-a28f7c9ee7fa"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "ddd3e465-9568-4fa3-bf24-64a5620e3742"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "581fa6d9-3b35-4106-8df0-06bec530d321"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "3103a4cf-5f41-437a-ba03-8f96fdc04a14"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "e2a145c8-c336-49ea-a0b7-bf1034d477af"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "b9864278-eab8-415d-83df-2d90b14b2f43"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "b1a9efeb-606d-495d-8b3c-75b84ab7136b"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "efc6020c-8080-4624-915a-c6ff8eaf28b2"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "a99a2fc0-e3e6-440e-8ac0-9d70268e34c5"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "9882456a-7176-49e7-a7a3-9dffd42cfadc"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "80e92f3d-9599-40e1-97ca-1cdb49594928"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "5017280d-68ef-442a-bb65-3a7b7076c7c7"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "0d58dc08-59eb-40f5-810c-49d5cc5b00d1"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "622d75de-4346-4fc4-8929-07d510c75920"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "fe30e68c-b9f0-4860-878d-acd4aaa6cfa3"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "e6c118b5-b8bf-4038-ac70-d4b7899ebce3"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "1cb77ede-89d7-4ffa-a47e-56c07523bd2a"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "9dea42da-0c38-4a9e-93d4-4757459614bb"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "223232c8-843c-42f0-84cd-0850a9937b95"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "7aaa882a-3cdd-44e8-8bfe-3f09180d9340"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "05295715-263d-4da6-9322-baa5c4637ad5"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "9370267e-3d3a-49d1-bebb-b8beb09bf551"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "53ea5cd9-5ce7-4cb1-80d8-09d7ad1ea999"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "d9023208-cfb8-4311-ac0e-050e2b79b559"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "cd3d6f3f-c315-4871-8af6-1c8812bd90ef"}, {"source": "1432b101-a27b-466f-9874-a28f7c9ee7fa", "target": "a57acc55-03c3-4219-bea8-88677d60380f"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "dda6e8db-07e0-409b-8440-da725a2ab0d0"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "7d042eb4-8352-4aa4-bf4d-c5bbe9480d58"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "920b176b-4931-479e-a192-84b646b016bc"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "4f8045d1-862c-4485-baea-0fbc8ac04740"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "ae5dca6d-3d7a-4854-b49c-eacd89ef21db"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "41b8c722-ab20-4e5a-834e-59d2563ea4c6"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "eafff8c1-8ad9-4a57-b0c8-a30f773ad0c5"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "062d71bc-e8ce-4e7c-94d8-1031c42c7e4a"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "9aa6ee96-25f0-4d90-9a97-40618f1ffd2c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "92b4f19b-021e-4575-af38-690142701d75"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "769de0b9-1109-4257-a1be-5ade63b9a7d4"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "93d7291e-17d5-4b5b-8be3-f8e74acfdbd7"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "a2a9bd2e-bdf8-405c-89f3-1a2c670c955e"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "76025110-87e5-4756-a3ff-edd27a13b23e"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "4b1b3cb3-61d0-4e71-a9d2-0e5fb883ecbc"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "8c147073-b878-4201-8aa7-148a02bd94e9"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "b46aba95-3b83-49cf-8c30-1c2217c4e431"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "5c335d74-73e5-411f-85d7-dd0dbf6bc7f8"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "ab8672e1-80ff-4cc2-a67a-46184e21e42c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "0a558b67-e40c-4f42-9302-e9b969eded72"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "d9992062-3253-4213-abaf-30171d697695"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "4b644a0a-92ec-4af1-bcb2-895a6d8bef4c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "a6260b85-895e-4590-bd4e-1ace55e3b05a"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "966aea9e-7238-44bc-9d4d-d697bf9f6674"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "ce8ee095-c4a4-4925-8284-03baa906cfe0"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "0c426b8a-0e1a-4d46-a12a-9bfb790e97b1"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "de3ea796-f2ab-497a-b91f-ed8b57942c5c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "fed92cb8-0e74-415f-8b7c-0bdf71f4a096"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f1cd506e-2e1d-4283-b696-5c01c2f35d09"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "9bab2775-9657-4b80-8f78-7947f79b61f4"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "122f7c6a-4119-43c2-9a04-acbf69090466"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "a271a1d2-fd63-4d69-b772-a0bc7f64bb53"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f8a85ff6-80e9-4b1b-881e-59329a969775"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "cd8ea698-361b-420d-a7d8-463efe95b83b"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "a6634ba3-336e-4b4e-8fee-4de23347424f"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "fa2646be-41f2-4087-8777-8828ba753591"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f372df22-3487-41a3-a504-7f2af6a755aa"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "52dd415d-0dbf-425d-9515-4e007d1f501a"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "447896b7-57b7-422e-9db1-4c0440051c09"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "9911153f-7872-4570-9b74-52c1db6011c2"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "05a6091d-8d18-4db8-b37c-7ab2dc89a5ee"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "e9bf6d85-7c6d-4145-bc83-f9c9f5e483d4"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "b671dd49-56d4-4491-84b4-09fabffa7054"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "70074d7d-6aa2-4998-9ba9-81946c99de37"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "d4680de0-f5c9-4390-9a7b-3c1b1aca51ff"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "e7312ede-2f92-48b0-af9e-1c6c2cc79139"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "773e2861-1f4c-4829-9440-403e041d413f"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "d6d53e1b-9ef0-4247-b10b-87f859aa66d6"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f58e551d-44f1-4398-aed1-a1b434be064d"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "4330a38c-63a4-4bca-8feb-32e632971248"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "5824d3ec-bd69-4195-92aa-f84d56941e37"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "aaf18eeb-897d-432c-a4fd-e625d31bf7dc"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "afaa33dd-0f06-406a-9c44-af0bbce8b27c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "cc6daa10-a630-45c6-996c-9bda9db3c2f5"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "7acb7570-01bd-4250-a67b-aeac81f6d601"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "64e3289f-7841-4d82-87d2-5d9502a57821"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "b50a430c-bdd8-4fe2-a931-c6c14f157659"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "c25d979a-c79a-4d17-939c-f68f35a6fb0b"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "96998db1-db98-4ff9-a604-ad8fa9f89e40"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "773150d5-3fc3-4a66-9a83-7eb0b42e7b6c"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "480f5b43-1e33-493c-abb0-a3612442aaee"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f7d7b2c4-6b17-45a9-8da6-87326b0c4702"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "e455647d-6857-4e07-b05b-dbcc3c1ee28a"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "fa4142b0-6965-4de0-a564-6660de7bafe9"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "f3be88b5-0742-4610-a5ea-be1101b313c4"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "cb11916a-d093-41ed-998b-c1fdcdf272ee"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "d00ac444-dc28-484a-8854-ab8deec1ae8e"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "5cfa4154-238f-439d-9d39-f75026230ae0"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "a5cb063c-bc9f-4216-8e78-a2c54e5938c2"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "7125ac11-97eb-4e31-91cc-7166afe3efd0"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "53c049d2-6269-4164-93de-79268707ecee"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "42db0bee-b762-4d2e-a960-94615c05d8ca"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "da502558-58df-47ba-b810-d508962f0a76"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "19d19c9d-383a-4819-992e-2337fc1ca61d"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "7e66825e-9949-465c-b9be-aa1eafb125ae"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "9c3aabb1-601f-45ec-bf01-312552975c4a"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "3dc57ce9-8965-4d4f-a28e-4612a5cf3aa5"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "5f3caac9-da98-48e4-b7d4-ff99e5c8dadd"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "47dfc76a-f34a-4cba-ad6b-0ebffd1871c2"}, {"source": "dda6e8db-07e0-409b-8440-da725a2ab0d0", "target": "fce5e349-256c-4d2c-b978-977bd5ba3cc3"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "00a82921-a13e-44ed-98b8-3e215ab8f981"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "5d4ab3ae-3d27-4af1-9682-6d2b30054735"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "c0430a76-a743-4cd9-b8e2-4aa82fafcd6a"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "e99e174d-fb8d-436f-beed-dfac5a2f2965"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "b4923386-8c91-4517-ad9f-dff477f04435"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "b99ff8da-b9f3-4401-9ea4-92b45a11ad21"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "3b3651ff-c865-4888-9304-1b7d97939eae"}, {"source": "00a82921-a13e-44ed-98b8-3e215ab8f981", "target": "9fd7a3a3-9fb8-4a46-8983-544c4196de73"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "e7f352de-0275-4986-8780-d4e9e94c0c77"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "381201ac-7de2-47e3-a9a8-5b051d286ef9"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "b1a936e0-d228-4dff-a8fa-29e2e262edf8"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "0dcf16b3-ab7c-48d3-8072-b9b50c54f2f5"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "c1c9e437-67d7-4949-b4f7-317cfd1fb004"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "f0e51a2c-d6e2-42c7-989c-9e681301f025"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "5d6eac67-1fd2-485d-9bcd-f6d479eadb3a"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "d8bc66c4-371a-4a24-a52d-b896977af581"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "063ef1d7-7e1e-4aad-a9b0-37dde9f69800"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "b867b3f2-9624-4a56-b7c3-5e121ffec795"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "e5265d5a-20c6-4914-9fc2-8fb95725e26d"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "96cebccf-36ed-46a6-aeb6-396054af8315"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "979ad605-f2d7-4832-9814-61faaae380bd"}, {"source": "e7f352de-0275-4986-8780-d4e9e94c0c77", "target": "087642e6-7f32-4ec7-ba03-4bb1ebe06ae7"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "8a25b9df-ee33-4de9-9235-d3b98ff04544"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "fa6673dd-3391-4be5-b084-60653bc5caa1"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "ab05b32f-d8e7-48e8-9aaf-4ee9886b707e"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "f0e14aec-3acc-4a8e-9ed8-b2cb2caf6c6b"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "a06185c8-493c-4122-a45d-d5f8881a8efa"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "4dd9c960-adc3-4b72-9370-108737528313"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "54d56086-f7ef-4f0c-a06a-65150c912d12"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "bb595bc0-f228-467d-8f20-bc25dc3f877e"}, {"source": "9d9e4041-ee19-40c0-a63f-a6c2e0972bb9", "target": "93d74c45-ebe6-45d4-abfd-7cdfc378e274"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "9cd0ba57-91ee-4ddd-95c1-528e089aca98"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "fbbe8a4d-8963-443d-b03c-13acfd70e66c"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "0f6753ea-0783-4e9f-9398-802271e7be90"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "534ed38d-351b-4cb7-ae9e-e70b5d477671"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "abfaa454-cf61-4f3e-bbac-fe83a2770e15"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "eace84b0-4a37-43e0-9b1b-568607856056"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "8d445061-a650-49e8-83df-d4dfa5a2fb16"}, {"source": "9cd0ba57-91ee-4ddd-95c1-528e089aca98", "target": "d2365770-536b-438a-8375-9fdc10cdf263"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "46d770c1-035c-4b62-a702-5a1ea43c0e8c"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "5888c076-ea82-4411-80fc-5cd694f9933f"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "33428521-8250-46b9-b98c-48f8018235c4"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "b9dee598-50c3-48b8-a543-544c3f557c01"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "67d39096-44de-4332-8424-9f72bf7811cd"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "6faa38c0-3a12-4209-aa0c-d07541ecb24a"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "4ba8396a-acea-4b79-a349-ed56d82c69d5"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "ee3dd8f8-9171-4193-8819-04b4df1275c1"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "8600c9dd-0131-467b-b849-03fca48652fd"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "54292f43-3cd1-4245-82f4-eeca665f58b4"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "64f66af2-b12c-4803-8b34-eddf905f66c1"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "629c01fc-701f-4cf9-b7f9-6c296b78c8e7"}, {"source": "46d770c1-035c-4b62-a702-5a1ea43c0e8c", "target": "75d03d04-dc8b-4d98-8fd4-d892c599af4b"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "83ba9c35-75d7-4346-94dd-4667ca23cd8e"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "915ce7c5-74e2-43b2-80a4-d6ee3a0d76f4"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "8dfdebc4-d3d0-455c-841d-0f39f91599e3"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "b0f8778d-9347-4685-add2-d8a3c1870606"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "7c8d84d6-6de2-4b97-ae48-c3299837bdb8"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "09300c62-04ed-4dcf-a265-76fd66adcf26"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "15220e42-0946-47c5-8d4c-e5a7d7532b4c"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "79a3b016-c45b-458d-8a92-97e9ca479a04"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "6759c189-2b4c-42e2-bec7-0248cdb7bc1c"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "7d9ec8c6-acb1-4b99-ae13-3539df4e81ac"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "a929d99f-d62f-47e7-a2d9-031a5eb6e18f"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "6c59ddd0-693a-4715-942f-00d6159f851a"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "dcebb07b-cce2-48f6-8761-b5f691c1557e"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "91aa6f68-718d-44ff-9184-708e298d533f"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "61418106-8d86-4459-adca-f35ce7ef820b"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "42b34602-4626-4c10-9365-2c839ba0672f"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "d10d3933-bbba-47e6-b84f-b448a6657f4a"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "53224200-498d-4674-816f-975da5ae7184"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "c7068e5a-5926-48c7-9577-022c66338f95"}, {"source": "1c5e20dc-97d6-42d5-b26e-6f85a0f7cf56", "target": "c2bd26ea-4343-4d0e-a28e-e494fa6b86fd"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "9e796374-c705-4497-a523-5f16e388b374"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "f3a48789-0132-4dc9-997b-fbc2409b4548"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "5be72b70-5cbb-4c61-b8f4-9f694cfcdd47"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "930c0970-4f25-49a9-bc52-301e373693e4"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "5e8ddd26-863c-459a-8e23-caa54186d157"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "15047d56-d50e-4476-8849-1f68368196b3"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "88883b88-da99-4f00-8361-3ed09a1ce338"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "9428b702-fc46-4147-afcd-98ac31751598"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "6c82666e-fd4a-4e29-bed4-ec0ebf4ecdb6"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "0717d5d8-1646-4e3a-a4ed-4a37872fef05"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "1de54d3b-f32a-4b10-9b71-4e4dd3892808"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "ec49b187-87bf-4415-b528-ea77555eba83"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "04aed686-a948-43d9-b66b-5d18281fabc1"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "cb2d365a-cab5-4926-bc4a-00808d356878"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "76d827d9-6c7c-4d6a-9083-ed22c9092331"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "89198d3c-f373-4735-973c-e0ad3f55b09d"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "39fbeb9e-eca9-4c34-87a6-47ff98abf8a1"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "4fc12d92-9dbf-4e59-bbd5-f9f11ae18dda"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "89ef190e-f49e-4ffe-96dd-185f3ae5c823"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "5fff3b75-6456-440c-8ac6-3359481c8707"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "f7e2fc23-44c6-4c4c-b2bf-6c240b2c57ff"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "a5bc7ea6-27b0-47ed-8ee0-5f9cda1e821d"}, {"source": "cd88f5d2-29d0-4d49-86f6-ff0404bbc99a", "target": "ead33b56-1052-46fa-b613-3b765f05f0a1"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "8f269230-fe09-48e8-8d18-c64513858db0"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "d5c32f3b-7f38-4718-bb27-a2791f83c05a"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "233448fa-7ea5-4aef-8ee0-79e5ffba1b09"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "82dc351f-efea-4ab4-bc0c-5fcf04c46a12"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "f426ce1a-1d41-41c7-9685-5c04ab34181b"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "65c48901-fce8-4151-b2bf-5b7c676230bb"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "08f10adc-8b5a-4f0d-865b-02713413b083"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "dab1039b-9976-4d59-879c-044d06d4bc43"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "59c38535-16a4-474f-978e-fb674f87fc11"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "5538cc5a-cca2-4c57-b4c5-7b5bd0ff3f67"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "f88ec4bc-c152-4225-b73b-eca1afdfac65"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "b3311787-09fd-461f-b00b-0c0bcaf3b469"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "51ce0f99-92bd-4f1d-bed4-ce0b3648235d"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "15a1b708-6bc7-46d3-8d7b-43b5d0b1e199"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "193cc973-122d-4d04-9a2d-51a8a1c72a10"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "fd12598c-f6bc-4c49-b537-867c85014ca0"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "ed372949-08df-46fd-84bf-b87169b3c77b"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "33ea9ab2-4152-4c48-9711-60f3a0b1e721"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "0f93cbb0-4c3d-4405-ae59-942e17318e4f"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "15ce8687-f545-459e-8599-6bffeddc1139"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "abac8236-3013-459a-8d3f-87388ad36e34"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "b99c6e23-98de-47d8-a195-c4f9ca149f2b"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "ca3f48e9-84dc-4953-b0cf-a0a052dd70ba"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "ff721f71-cae0-4210-a1e2-ac1d1e3a804c"}, {"source": "8f269230-fe09-48e8-8d18-c64513858db0", "target": "074c2394-82d0-41f8-ab53-26d96cf1c970"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "35c7258f-ae4c-420c-b79b-dee779a6bb38"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "51fde2f0-69ba-4fc8-a577-66a34735b0b9"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "ffa77c64-525d-44bf-a1ba-91413281ec77"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "39001db7-65cd-4fa3-98bf-9dc8ad08a89d"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "6f3cdb2e-5ee1-4a54-ac3f-bdfe58a22940"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "f4df8d6d-d639-495e-b562-256aa62c809a"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "b2742078-0b83-4643-8d5f-760f6ea10202"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "7f5da94b-184e-449e-9fdc-fe397b427064"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "90c8e1fd-2a59-424b-a91e-769bf68aaac0"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "99c23c1b-4e31-403e-913b-d811090efc89"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "13bc2a9e-96ea-4ba1-ade0-5eefd4a61faf"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "b25ebd9e-684f-49a5-bb9f-4af4f745d7f1"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "be9d3979-69ee-4606-ac08-4b8e6c86c026"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "9fa8809f-fe27-4f8b-ba5c-f905513e21d5"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "9a4a5e5e-ea7c-43c9-affa-da834f16e930"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "7f0033ad-72d2-49ca-9a68-9519b10ca4c9"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "db2c219b-0f08-4a92-b8d9-2f44495806c3"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "da8960a0-bd00-49a0-9633-e0f672bddd20"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "5cacd1ab-8ed3-4196-ab7e-666f182263d4"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "10fbaa82-93a8-4d9c-a89e-fe99612722b2"}, {"source": "35c7258f-ae4c-420c-b79b-dee779a6bb38", "target": "33b8e447-0929-41ee-8ce7-0fd2a4d5cbbd"}, {"source": "38e6ce0c-ba18-4f77-8597-91f25c0ff9d3", "target": "583d53ce-6f87-481d-9d3a-b651f26edb0c"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "93e6472a-ca02-48ce-83db-f01b90363503"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "29f72e75-f76e-4cd1-9da0-a121e26ae014"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "b63dbe01-a180-4ce7-bc17-c8475677615a"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "a7232479-0a71-49c6-92c6-f69503c4a26b"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "ec737d70-a317-4f8a-8b69-3ce4cbb1725c"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "a032d43f-2366-4898-a567-17a50711e78d"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "0798fd94-e396-4cf6-8751-7d40a2b2d34b"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "cf6cb56c-2d9a-49e6-aa19-f604f8017918"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "ed26ca57-9217-46a4-b4ba-57e0242e1997"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "0fab2def-15b8-4a94-bc51-87e8dffb687d"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "182473fe-a2f7-4630-a216-d7a898d05a4f"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "99c7462c-83a2-42fb-a10e-2e89cae7a1fe"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "1cf75c6c-0143-4c5c-9f40-2bb63e36f049"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "9d553273-229e-40fe-97ba-6a7eab2cc013"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "8d79ca66-8a86-4f39-8fa6-fe599923ec43"}, {"source": "583d53ce-6f87-481d-9d3a-b651f26edb0c", "target": "c28ddcb5-d478-4038-aa2a-524f6b5ca46c"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "823e55f4-5cc1-4794-afc7-d45361131bff"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "d80b691b-7ed2-48a5-b1a0-75b809924d7c"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "d2b345aa-befe-4230-aa50-f8b22d1d364a"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "2e2b61f2-0b2f-4dd5-a581-02618b9e24a7"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "def3c4e5-26cb-4aa7-b526-6b2b1f1a39ca"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "41323104-8841-43db-b19d-13781e658b1b"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "c954b69d-692a-4f79-841d-395c8e7cdf05"}, {"source": "823e55f4-5cc1-4794-afc7-d45361131bff", "target": "0925d1ef-ebde-4146-955a-de9fdec48e6d"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "c64fb5f2-ade7-4d1d-b4d5-25330c47b3c0"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "0fd36442-e1f4-4719-bb1a-799777c25dbf"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "0a0ff11a-cec7-4788-a30d-2425368abb69"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "c2ba843d-ef3a-421d-af61-617fd8fe6280"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "263f0f7d-4b24-49d0-b472-f75db4dfd18a"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "9837a129-828c-4a08-bb49-eb002d27f415"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "3e15d852-7b50-45bc-8310-e6ef2969e20b"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "02d0f43d-f78f-4463-973f-075bf4944c48"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "57944078-5548-4e0c-8b48-9b2c96d150ff"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "2bde2acc-3fa1-472d-b7ca-d6952b3ad0cd"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "0884b1f5-a441-44d4-ba82-ba35f0eb7b21"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "aa2ad3ab-4e84-44b5-8d6a-ff3fa9a1132b"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "f34b031f-f409-4030-8b57-a7c6b3f85613"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "e4f77e5e-8cc5-4ae3-b1df-bef6c15045b9"}, {"source": "dbcdbb42-7c68-450e-a1e3-8970bdd465e6", "target": "00f9e75a-bafe-4536-bce1-ca881584ab00"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "f5899921-9bb9-43ae-9621-1782cc1c3c18"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "cf6202bc-c31f-4ce8-bbd3-ca5b8fd70ba7"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "14f9c7ce-be5b-4fd2-9913-ed7d9a7740bb"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "e7df469c-95dc-4f75-9735-aebc875dcd32"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "c332c0d3-5945-440a-b73c-3476ade786ca"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "5b0375fc-00b2-42f0-bf7b-482be19d5116"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "fb80b30e-2aef-47cd-b837-12d9b5fec5aa"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "e728e893-f7ba-4ce2-9e22-43bff4d8e114"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "10923666-5337-4060-ad08-59b052beacd6"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "a0bbe250-796d-4c20-9d50-cd5dd6396ebc"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "3903b2d9-e8f9-4006-98b7-a003105d73c7"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "4521f28a-adcb-410c-8ed1-b5e0aa86b252"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "6fe7786b-32bd-4a57-814e-3afdda7cbe64"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "d49cdd20-c9e5-4d3d-9fd0-b9767c7a31e6"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "e620c703-c57f-4d91-808b-6207ada8f9ec"}, {"source": "f5899921-9bb9-43ae-9621-1782cc1c3c18", "target": "3e70dde3-f062-4558-b974-1f04b745cd30"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "216d4817-797e-4f1b-a51a-6b2095fe32ca"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "e7382623-1e88-424f-8648-b5c1dbc31ec9"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "13e40ed1-917d-4f50-ab99-0e45474d76a9"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "c3f5812e-4c3a-4182-a9b7-2381330e73d2"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "861af66e-3b0c-4b77-94d0-e3b1f9049e2e"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "cb9367f0-3aee-4223-a009-e9e74cbb3672"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "fab6990b-0f3e-4238-99d5-31224c8472f7"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "19eacf3a-1971-47b7-8216-78fa2bce06f0"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "cb326093-9422-40b4-a621-4f88a79c70e7"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "28f7bb2b-213e-43f3-a7e7-8fc4e9f14da6"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "a631bed8-88c8-4550-987a-b66490923648"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "3330d8fe-027d-4855-8cbf-ab832bf6493e"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "1828b3ec-fdab-4b20-99ca-ff22bfe4e225"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "75d4b810-2ab1-4654-bebd-e73929f03b52"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "1681e834-b5fb-4551-880f-a7b179c361ad"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "482442ff-cb66-4767-94f0-0834763ac30b"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "bfcc885c-69c0-4bd3-b26a-8932be322ee3"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "3a6b7f94-1ac2-45e1-b558-fdef9fec4273"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "18739d63-e96c-47f2-9732-f9887b2559c9"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "0f60df97-3292-4c4e-806f-6345a951b96d"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "5d14298d-5d2b-4617-b9ea-6b07408c5989"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "3a6005d2-da44-4e9e-9d2a-741af3eb9ea2"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "6d1aef64-c3cb-4a52-925b-8e63d6db0b53"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "141b7c7c-b597-44ba-a7d0-9af5e5fafb66"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "ceb31084-c73b-46aa-a5fc-49002861fb81"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "dbb59bc5-059b-4f20-8862-08cee23f617c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "528b608b-288e-4838-81d5-045b6b66b9aa"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "42602539-5e05-4636-b921-4c51c151e6c4"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "ed33ecd2-5184-4890-958d-70c2b1dd033f"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "8fd946aa-9797-41cc-ad35-001ba1b26753"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "13987dd0-25bc-4ca7-8359-8071a14cf8e1"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "8a2e198a-c6be-4954-b726-85e9374c6f5c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "72ee88db-abd4-4660-bc77-e23f536ec03a"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "fa026691-0c0c-43ee-89e5-6ae48b4158a0"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "f5436098-8b87-41d3-8f2b-55aa7d0033db"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "eea4696d-135c-4b34-b387-06f83d9fa2c3"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "1091f5ff-d27d-4d9b-bc78-a052501735f8"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "35e5a490-545b-42df-9b02-5356536cfb6b"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "094433f4-1d61-4495-bff8-87ed32b3ff49"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "3b962399-429f-4598-b7f5-d3fd038d6356"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "5f373b2d-1917-4b7b-8ea8-f523534ec0aa"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "7d5420ad-0e3d-4859-9505-64c75b5f2383"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "a93213ef-197c-4ba2-a1f8-c71e7db9d24e"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "c120a75f-368d-469f-a186-8ddab7306e56"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "aeaa0e50-99cb-400d-baec-4667a823d2f5"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "98b6a530-7f54-4c67-b1ad-76ea73e39e1e"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "c13695c6-f3aa-4679-8005-b937ace7de09"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "cf7b285e-0b7a-45f8-b1ae-3b11ad4e1558"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "71afdd2f-9df6-49fd-9f7e-dfab431f0192"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "f26ddda1-53c9-468f-a1b3-23731121be4c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "57c16dcf-68a5-4b52-8370-0dc9d996a359"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "6b98a7a1-6d44-4f1e-b110-86f73f91df3f"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "33154fe0-7723-454e-8011-7c7d6cc811e7"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "03eca012-e51f-4e93-be48-40e46e47d15f"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "b17be1f1-51ab-4a7c-b31a-f1341a4bd555"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "55bc6fa9-c269-4ff1-b131-13facbb91a19"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "5d8edb63-91af-409f-85a2-aec8fd463cbf"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "541619cf-3288-47ba-bf29-21c768c6847c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "a2a4f9dd-99d1-4ba2-867c-79987dad2843"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "cf7524ba-8689-4102-85b2-2062230c91e5"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "156f62d1-2957-4e0e-8f88-06c473cc2292"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "9e81ab9e-5e51-42da-8bef-c950aba34956"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "0d3ba0ad-9a69-404a-9eb3-aad0ee55e9ba"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "658456ca-6cbc-4a3c-b10b-5c87b08643cc"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "81a8ab75-f358-4e93-ba39-c1736aa75b64"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "03d60dd9-6284-45d5-a453-4bd9b3ef8a0c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "d62529df-c917-45a3-ab4b-dbb876dcf635"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "289329b1-3a50-4f30-9bc4-88dca8907c96"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "38bb54cb-d3b0-4c1a-9b99-927fb4991979"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "23f8be6d-770f-4759-8e1a-591d8e9ca7ad"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "5dbd1ebb-50be-44ca-bb71-c4e0658e9686"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "c4440fe1-fc46-467c-93ac-6a4bf9111fe4"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "40d1ffe6-5d12-4fb6-9742-6093fca9e801"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "8d280c82-4c37-4286-a8a4-5e1fda9c197d"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "401233c4-3922-44bf-b1dc-4fe1fdd7f7ab"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "0cc17194-1584-4055-a934-84c02040cb82"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "49d8c4f0-4dea-4351-a770-c50d8f21213a"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "cbbe32ac-32a7-4cdd-b73b-8785a18ce17c"}, {"source": "216d4817-797e-4f1b-a51a-6b2095fe32ca", "target": "6d70d521-3bb5-4ad3-869a-5a31258c3a82"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "35d4c1cb-4615-4c12-89ba-3d17a8405573"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "f9fb85d3-523b-4b00-8609-1c98b4a5ed49"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "980c8b10-5235-497f-ace8-b6d406c4b2a0"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "284ce3ad-a338-49f5-a9c6-2e4646372ce8"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "3c7bdcad-6dcf-46e9-a0e3-3176a225664d"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "e64e4b00-a838-4dd1-9094-4ca87275ef96"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "0ac70b38-1f70-4d94-9d23-43065aa4be21"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "9bcbf268-e09c-4eda-bf58-0ef451f1558e"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "b732237e-717d-44bf-a2d2-2c3b1f8eb759"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "a83f1767-bd6a-4105-8095-0a0f4393490e"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "849b5f1a-5cc9-42f0-a534-d6a221c5dff8"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "d7bd1674-c968-4608-b8f8-fd74efdc87f6"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "9bce36f6-e00a-42db-9d14-318b314a33bc"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "c9683920-2510-43bf-a693-9e6b31bed485"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "00494658-b138-4dac-93ed-cbe86aa3bc9c"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "5c0fc8f1-9bba-40b4-8569-d03504324a94"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "4432bf75-55d4-4cce-9061-eaf9364a5c2a"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "0906ffa1-1ab0-44f6-b8c6-353f15db2d8d"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "25055bc8-4b8b-4596-94c7-f87c777105dc"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "ce4f07d5-c3e9-41a9-9d76-36e96ca2118d"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "628c2f23-31c7-4e4c-ba34-edddd66ae912"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "bc5c803a-6a4c-4043-867e-2c0a955cb4a9"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "e04be5cd-92a4-4361-8ada-bffe9c4c3a31"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "e65ed23f-027a-41c1-be31-440f516f58e0"}, {"source": "35d4c1cb-4615-4c12-89ba-3d17a8405573", "target": "63253922-1c52-4f24-a98f-ca39b737ef4d"}, {"source": "7d0f807b-d203-4b94-b42f-8b12602938ec", "target": "e87b12b6-96d3-4839-900a-0c89794a69c9"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "46110ac0-bf61-4ce9-a48a-87ae898af352"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "1fcf278e-e09d-407c-bbac-6a217c6a81d2"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "adb34331-8cd2-4a0c-8728-9f9cc40d1e39"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "de7a0075-9ff7-468b-8cbe-e6f560fc3e50"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "14e7eadf-d8c1-4d91-bec5-122edf82bde5"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "ffaec40a-55cc-4374-b567-4194fc3e17a9"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "f604f76b-588d-4db0-a88a-662a46aa4cbe"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "369a2b2b-42d5-43c4-81d3-d59f528b6f1b"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "1538443e-ead3-4cb3-bd9f-979980b59cfc"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "70b90957-8ed9-4ebb-994c-2a9050efa75e"}, {"source": "e87b12b6-96d3-4839-900a-0c89794a69c9", "target": "d32e11d9-7588-4265-b0aa-7650b6a75289"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "a9a3c265-aedd-469c-8bad-1184eac25c54"}, {"source": "a9a3c265-aedd-469c-8bad-1184eac25c54", "target": "3eb24b43-cecb-4ca7-a0e9-45e860df6daf"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "2501e958-dea4-49a2-8d92-e07c5ee3c3fb"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "6645cf43-f986-43d4-83f3-7e375f917804"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "b6d6cc5b-1dd7-4274-aa11-2472928966ad"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "8cae0b6a-cc2f-47f6-9cb7-76e651929bb7"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "b4199f77-beb2-441b-a356-6c00943af93c"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "46315e26-e8b8-4981-97cd-5a59f2f48708"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "2953b79c-b8c1-4430-bb14-62005a6e86c0"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "370f6838-f0dc-444c-9b86-5d498051f2e3"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "91fc3a21-5394-4877-8412-0d2e673f6db8"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "0134f9b7-6574-493d-8f04-6fea77723ecc"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "21598b3f-237d-40c4-a97d-0da6b37f2710"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "7b62c179-64d2-496b-a7be-a316cf5cc1bf"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "50c0ee26-aca2-45c8-8208-04d364021f01"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "27bfce55-ec4e-4274-bb61-3b9bcebe2e34"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "986260c4-6537-4686-a55e-0ebd1feb9975"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "d803b778-96e6-42a6-bc57-b475f8db57b4"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "36dfe828-c966-4072-b0db-8dc78d3d61d6"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "871653cd-7ca1-4ab3-a4a2-0317b2ec4517"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "ebceb7d9-3328-4e97-a497-1d8a73f5a22f"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "0ac36377-a9c1-486c-8e88-c906c7532023"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "dd7c6265-0ddd-4c12-bb50-83d65fa2371e"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "9cb4ab11-856e-4f2a-add0-888316829e46"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "1e939b1a-d818-41f1-9622-03f62f563ef8"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "6a7321ed-1235-4db9-8f0c-39fce9716472"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "2f26bcc5-8436-4b4e-a593-32d8f8dd8aae"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "f1db2a02-1d18-43f8-be4c-a4c80eda1959"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "ca8e096b-b157-44cd-976c-d22387ebce50"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "9771647b-62ca-4f8a-9069-0e9cd0ac01b2"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "92501ca1-6b8b-48cc-bf4f-7e5bce6a06ab"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "ac6bd262-1606-4623-a72e-cf0837d15717"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "48968f29-ae8f-409e-88c6-e24eba8716a0"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "0f433e34-2608-4b8f-867e-a19ff715feb7"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "8610a9ff-a92d-4a22-8762-042ae48c8b66"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "1e24eb92-4444-41c6-bc56-b0d847bd1d01"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "62a0385e-ed7f-453b-b49e-2f3afb233b94"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "2d3d4e25-b2cd-43de-a8ee-1fb921b4d100"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "f3cef828-57a8-49a2-98df-0269c03b3ef6"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "52cd8cb9-1950-448a-b4e9-e3ae9c4ca1d7"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "22d2d20e-b15f-4274-9151-2bd4452261b2"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "7ed8d4e6-724e-47b3-9744-573f81fd4d5e"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "7cafa3a0-c546-45d1-b260-40f5d7e6ad77"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "0f2900f2-b915-42a8-a778-739b41b4c9c9"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "b3fde2af-1ca8-480a-a926-04046007f5fe"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "80966402-84d7-43ea-aefa-7f9b86c47158"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "b046bc4a-5140-4946-805c-6fe70cea60e5"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "d8f9db9f-f157-4716-986b-03af31012683"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "3f3e114f-4be7-43eb-91ef-33bf683842bc"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "9bf48d45-46de-417b-b346-a5dabf66bc2b"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "757151d2-df3c-4d34-b3a9-2d68f5b2ff4d"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "abb1f435-dc49-4247-8262-f2f8fc657637"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "fd062895-759d-47b5-ac40-011d2e951209"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "de2e8ef5-8e1b-4443-b028-f3f3b3a26cdf"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "d27928b8-c26e-4a5f-810d-9931f1a4f756"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "0f331c70-af0f-4f86-9141-9e185f291eaf"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "34fca34d-9df9-417a-bbc7-9bf985f39428"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "331324af-632a-4248-bf1a-14d524ed3e56"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "aadd2e86-5525-4ff1-8335-9cdd9775c0bf"}, {"source": "d3e64ee4-cdd0-4214-9d12-ac523fe4a017", "target": "f89a48a3-45c2-4498-9c40-6edf86d2bddb"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "453f2dff-b180-4bb7-8b35-51957d5ca849"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "7e966893-2f3f-4df8-a417-7d67c89ae727"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "eb2de971-b819-4909-9ab9-1c1540936fe4"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "669df274-0737-4d76-b5f0-acbd781fd72d"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "0361f461-abde-4027-8f54-953ebc63e758"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "b530fbba-e6c4-445f-a94b-3fbd60df0032"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "db7b6c3f-05e7-4192-92f1-35edfc9918ca"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "b73a177d-c1bd-4f17-874a-34ac57dda078"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "4311cce0-3265-45fb-907f-495b89293050"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "86e9e588-d33f-46eb-b51a-b45b4bf897df"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "1f666764-cc06-4b93-8ea2-6da550249644"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "9480fb6d-18dc-4265-9979-ae5e84b7c899"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "508f0f69-9c17-4522-80fa-e40f84b0a848"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "180644d3-0ed4-415d-9448-b5485a5ac746"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "e70ff614-0cf9-4031-902b-f748c00d8823"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "2477d79b-13be-4ebd-8881-457d0cfbc80f"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "96e8db47-0df1-4031-a905-7efabc9593e2"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "91794426-0ba8-4373-8f0f-176cea9b0977"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "98b8c4d7-6ce6-4cc7-ad55-ccb97c5e28ab"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "52d2b874-5215-4a70-ad48-ebad295a6569"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "e1d56df9-5880-48d3-905b-d828718579d3"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "c8ddeedf-02b1-4535-b5f0-c19d789ef6df"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "6705feef-d534-4958-93ae-444fee2e207d"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "50c7c84e-97de-4c0b-a852-0d94aa40f705"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "eccc80a1-b43c-456a-8e45-8cb214c8892b"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "7fbe1c03-0ec9-49fa-8c1a-81580abaccd5"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "849fc0ac-e1b9-4add-887d-4eeecc303aa6"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "a1bb57d8-8199-4c2a-b7b2-41cd9b9e70fd"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "9c5a7389-3043-4bdd-be18-31c27bf2e217"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "0721539d-395a-47c5-abb5-cedbcf748caf"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "d81006bc-aa65-4d6a-9fae-ac08f074fe95"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "abea3476-2954-4eff-b189-3f2775c28d7d"}, {"source": "19d59543-e7b1-4fbd-a1be-8ec3242ac1c0", "target": "95a13075-ef52-4d89-bdaf-f464ba234312"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "f0301b62-1763-4765-9bac-b86eafc0191d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "84f282f1-b66c-476f-b3d4-42a3216d0853"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "3f607ac0-318c-40f7-9584-2679f0487844"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "643e6d31-1fa3-44a4-b046-21aedd035e64"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "dc7319c4-8e38-4fc4-af23-8845ad8b8114"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "0cbf0637-9cac-47f5-8cc7-cbc783b7bdc5"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e30a4081-ce07-4f24-8ed1-8ccf9d4f675d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "08876ad2-e02f-48b2-8790-ab7fcda03b6a"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "06c60be8-14e5-463c-82ba-8b7a61ecc21d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "9d691697-e5b7-4337-af20-40a10e3de1c9"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "548fde31-58f9-4fed-a53f-b9f7c09cf973"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "8adb2128-e935-4cee-82bf-0df3363e9ad9"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "9c708d73-6798-4404-8094-115ce579a2c9"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "1664c124-7853-48fd-b3cc-28c2483d09ed"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "1a35d2c5-e61b-4dd2-93e2-e1d4a539fd02"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "768c2170-7b59-489d-9f43-6389430c7ab5"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "495ceafe-4a02-45e2-b8bc-c0088a7b2e6c"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "87a80d84-6f1e-4a15-8109-b73874637be4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "ff66aaa1-631d-4983-af70-3b6533dc9c8b"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "8b66c8d1-9983-4e32-9096-d29fd9e7396a"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "3200c3b3-2e65-4c31-8578-60138c0d187e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "dcc466c5-7b6b-4652-b356-ac98b98f7772"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "c292d517-7497-4f21-9bd7-858ad3009876"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "f951627c-3d35-417e-b762-1f76123b6128"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "39686b63-d8c1-463b-979a-aa1e51de9f3d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d0922492-e3a6-43de-bb0f-d5774c577b1f"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "eac920e1-3b2b-4693-8713-93dd2bd33ced"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e850d737-5c9f-41a5-92ce-e3c155166da4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "027e4a1f-7dd5-44ff-94e2-2c6165791dee"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "7567685b-43b7-4dd4-921a-33575646d016"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "0ed6bbc7-607c-428f-ac0c-fde47894e706"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "fece62d5-2318-403d-9cca-f2f3c90c4d03"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "aaffbb17-761c-4b4c-b356-bc15fa24ca5b"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "c30629ff-ce0c-46d6-943b-91072c1ad9a3"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "0cd1d35f-c88d-430e-9439-07f6ad59faaf"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "6cb32279-4c31-42f8-a6f4-2bcc0feb942e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "7dc2f734-63f0-4a64-a747-9602587eeef2"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "a9076d16-1659-408f-b14d-6ce45eafc941"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e439d57c-e7ba-471d-bd22-f6c5f7a84c29"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e7a82ba6-0661-4de6-a623-3c3d39e4a5f1"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "902f4ed4-bb10-40c6-a4a1-fa7bf7bd2075"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "28b5f0e8-5cb8-4499-b93b-f2af5f3490a0"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "1d7942cb-6d6f-4156-87b4-e998dd82eab5"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d8396137-f0d3-4a33-9707-ac8f7b94ea4f"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "059a4928-aa0c-4cc9-90b8-531f81175794"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "ba58c9d7-b4a0-446a-9423-2c4566f84e19"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "7eacb75a-d264-4547-ab7b-410289b22eb5"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "9cf4131e-296a-46d3-9d4b-3eacf2b4a11e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "22dec105-c707-4d65-8076-4e9ae232107d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d46d400d-937a-47e5-9072-f7bb94b1d9cf"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e0cee287-d656-49e0-bf14-4e27ee7a0455"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "faa7dd00-0503-4e23-8aa3-5e98c6a444d9"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "59ed7c79-8d66-4559-8e0b-8d41198354f3"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "db121a84-5e79-4417-b0c9-7be7f412b289"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "80f39b90-0f63-4f58-a9a8-361bc7aea532"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "9de13580-6b44-4a5c-8496-1422d5fe785d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "166e22a8-6373-42c5-b25d-e2b7e6c5a1b7"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "ef967c9e-fa4d-43f0-aa16-615d397892f4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "2c4e8e26-1ca1-41d1-994c-d0d07e0789e0"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "1315ef38-4465-4cfd-bdca-d252ce73d2b8"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "92868e96-bdf8-4565-815a-2fddb4060704"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "42274555-8d8a-4ef9-ac9c-d4e03df6c293"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "cc30a13c-07b8-4cde-9e1b-dd7769c5d59e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "c1902fdc-cce3-448d-bd5d-5093ab1ed16d"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "da9462fe-fcc6-4b27-a9e2-0d6c290cffdd"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "79816a8f-7f8a-4931-a31f-b752b98ae5d4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "bf63c2ca-ec5a-476f-85bf-1c5b3b94613c"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "92589ae3-9cf0-44ec-aa32-d734dfecbd8b"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "71695424-1863-449e-94f5-2f3b4033be2a"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e2415ff5-51e4-42a8-b9fc-6b63809eb1cd"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "581602a1-52b9-432e-b0ac-cfe1c218c114"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "432b9f63-d434-4d96-a9df-e94007e2321b"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "5e11aa4e-ba83-4549-8bb9-0387058c03e7"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "89634f5c-4243-4bad-a73f-e817d09716b1"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "25eb8fdd-d977-4165-bfc2-41f0c59b3c85"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "a635b459-a100-4d1c-9e9f-b0d1d1f9a3c2"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "5c28a17e-01d1-476a-892b-c0a451a9c5aa"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "a8128647-becf-43e3-a1c4-2991538f152a"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "176c0c1e-e2e9-486a-854a-c47451fc8d92"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "206d3d56-7624-4463-86c4-b041dd69bd6b"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "2c907a23-1a11-45be-92fd-c839757efc1c"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "44c36d71-b761-4eda-8d19-2f088c75d4fc"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "75850b40-0e96-4e20-b17e-81167472d91e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "19774c11-5644-40c2-be61-46dab244ca27"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "dfb80145-423e-46cb-9bd2-9290c56ff844"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "7603f833-395a-467a-b756-7db8f38fdc09"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d5e08240-b7e3-4a93-af37-faf531c4cc09"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "14b4cd53-594d-488a-adb1-9818afbd8f40"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "1380094d-c78a-4e8b-b7c9-d7e8d1e28822"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "77287d48-56d1-46c8-8c83-5157bdc1a2e4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "015cbb03-b5a0-4553-85a7-438e42900b65"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "4ae50f99-38a3-4b5f-bfb1-737bb20daa43"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "a3a65f28-a529-4677-805e-5aa6ea2ddb84"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e7949ab4-1cdc-48ba-bd8e-ade72a78ece1"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "63050b7d-c4d6-4219-9ac2-9a333df9733e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "25257bba-f0dc-414a-ba6f-afaf0194fd08"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "460e0034-55a7-4495-86a4-71d2db838af7"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "334d6ec8-3e00-4da7-8060-5806a8c46d84"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "058e46c0-6644-49a1-a5ff-4d5fbed7ad97"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d2f920ee-96ed-4c50-9d2b-dbc9cf30f4e4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "4292c978-c77e-4318-bc92-2bc144470f2c"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "a6311c8b-1e83-43cc-a125-49a0d681a295"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "b9a0b28a-1515-4d65-b605-b7d427d2e403"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "47f81844-88c7-4069-a81d-fe034090bb18"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "0d6af05b-0ab8-4150-a93d-916637349911"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d3a2f85e-938b-4f7f-b199-a12d7681c7cf"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "28d1c936-d9e7-4e7f-b67a-a7f0d964756c"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "2ebc3dad-3e49-4863-a3c9-5a40c68fee19"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "8fded51a-1890-427c-82b3-47ced103e754"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "3c54038a-a1c4-4ec6-893d-7fdfee069261"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "02e0521c-8dda-46e0-85db-e0f16c6d3f65"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "4edc5ee5-79ac-455a-a404-c6e63602943e"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "0cf6a5a5-ee47-483f-86f6-4aff292a32f4"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "d0b14a0f-1bda-4954-b3a2-a3b22df8e558"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "ef9a61c8-ff21-4183-ad34-e168e82507dd"}, {"source": "f0301b62-1763-4765-9bac-b86eafc0191d", "target": "e159edbd-3a3f-409a-b44c-396fc52c4387"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "33401eff-a5fb-40ac-bbc4-701568bc2c45"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "8748b37c-f6c4-44b6-9556-6ea21db7b8a5"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "76b003d9-55db-47a1-b0d8-5ccd2e5d807a"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "93eb67c4-1a4f-4a58-bf75-fd3ed0fbfaa0"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "cf8700d9-2f4f-4778-b34f-7134b1d9f341"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "cddeac6e-4179-4216-b1b1-4231b9dc4541"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "04e5b763-d5f7-4c24-aee8-0a43f9f3332f"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "4f7c2ddc-340c-4b8b-a5f6-88d70788756a"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "4d0d993c-e6ef-428f-a792-a0c608c6b8bd"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "bdbae9d4-dec8-4c9a-bbc8-6a1cb256a762"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "a1f4402d-aaad-4fca-839b-5a3f7f3e03b6"}, {"source": "bd14ca7b-2b71-4a48-b9e7-0bf03b1f1388", "target": "559d40b5-1722-428e-945a-ed9cb0d59219"}, {"source": "3b17aede-7732-46af-9458-e5bb104b5d9f", "target": "3b8f05c8-e603-4084-997d-7ae63ae17688"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "2efa5da7-aa33-4b58-8b5a-53e2a74cc303"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "8804a62f-7be8-4919-9758-bb6feab00bca"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "4cdfb5e6-5e29-42e8-aa7f-7ad50cf784a9"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "52db2db4-e79a-4fed-b990-925a76ded5d8"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "1042c604-797b-4eb2-803c-b9fe894da2d8"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "343ef0fc-58a1-4b2f-90be-52a181a1cfc9"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "f5c2ff78-0cde-4626-b69d-912e8e323b9b"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "2c40367a-cdd3-4f53-a15a-9c314e787209"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "3c9f1c69-befb-460f-bf3e-0b17c2252110"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "b54b9426-e481-4325-9793-48fef15fc1ad"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "6afbad31-1c29-495a-9461-a3ca2bfb14ac"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "ecd0e9f4-9408-4258-ba6d-722d3f7a5ffd"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "018d6a23-b284-4e6b-8adb-f471331ed4a3"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "4745c971-3e54-474c-b8c7-8969ec160f44"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "6a8986b2-7fd1-4979-9d94-d4982c2133c1"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "f582d6e5-57c7-4b23-a545-0bab434079df"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "8eb0f5b5-c5c4-4370-ac30-d32fc24b95b2"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "2ed96f4a-4118-4373-8905-29afd4cec687"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "6a19baea-905e-4d1a-98b2-54e85cb90def"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "14546998-8441-404e-816a-10b46b2058b0"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "cb32538a-e98c-4b81-b704-de63e86756f7"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "65934208-3ad6-4bd6-8936-24718ea9e80c"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "5e6b4188-04d7-4394-a792-3f7c53cf56ff"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "f59c68f9-1b46-4439-8533-3169ea5fce7a"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "626548b3-8fcf-4952-8e67-f08b213d43d2"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "738be25a-d18f-4118-b5e0-82dd7bf498aa"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "55f66f9a-d103-40a4-80db-da00a02c6c83"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "c98c3c1c-2bca-4932-9d27-84c785e18869"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "a690d02e-5cfe-46a9-ba53-150dab2cf19b"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "7efe1db2-8dc1-4d06-92fa-edfcedd46e3e"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "38cff021-6079-477f-85fe-b1a80e163ccf"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "bdb679b8-88e6-4151-bace-131668411238"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "a2b78f79-732d-4a27-94c5-aa87e6976e77"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "99473665-3d6f-41a8-9847-b6765c52769f"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "b3e36db4-5a8b-4fc7-ac7e-08e425774f82"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "639719cc-4862-4f9f-8d50-ea3a93de3112"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "7b6826b9-79f2-4038-8493-3cb977262416"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "d53120c3-5719-4385-9b31-2266b6d2c6bc"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "31c42e93-f25d-4af2-8c76-4faa6eb28048"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "43546a1a-7f80-4749-8146-97c194f25755"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "fbc89323-53cf-4d03-9b3b-e6071066e03a"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "daaebf17-f5ff-472d-88d4-26c1bf60f511"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "c5ec68c7-eee4-452a-a7ad-6a5b1eb52aec"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "7989c7a0-1841-46a9-935b-44d2bd444271"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "9fa9d38e-50ef-4093-80c2-b953e1ce28fb"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "aef54462-1228-4484-85f4-337fc3c9c512"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "6dd082a0-51ed-41de-a7fe-396733699587"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "8fbe5265-d424-46a8-a522-847e8993d8b9"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "359cdbad-41ac-4a98-9224-22805c763915"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "ee016b75-03f6-4a22-b4ca-e7b01c56f70f"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "d8ad2987-aa20-4219-b993-f75f28bf4ae2"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "f7c8b249-8116-4adb-bf2d-5bbdd7df79ae"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "06a4006b-d9ee-4389-8352-0e1d7566486d"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "4b981c20-c159-4c0f-a379-ae6ecbd204f9"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "dfebeb35-ab81-4dc3-a5ad-03bfb4698059"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "115576c1-4c88-4643-bfb8-40d6f6a811c5"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "96748920-67fa-4381-bc97-c4146621af51"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "c2469ca1-7ffc-40c1-a5e7-187a937cd15c"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "c40b65cd-25ce-4299-b584-aaa3395f46ee"}, {"source": "3b8f05c8-e603-4084-997d-7ae63ae17688", "target": "18772017-100d-477b-8910-c45f0d64ca36"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "f4c1962e-7454-4516-b1a3-01508092cd07"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "62fab4b6-8f4c-4b0a-92ca-142fed841d89"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "52836780-2d57-46f1-9dd8-65f140111aaa"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "8f532643-8344-4bc0-b18e-3307c8b25c36"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "a136bc59-2233-4511-a8a5-92f4e7828d9f"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "36ca49e8-d56f-4e7d-872e-cb9b9ad14b81"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "f54e4bd7-c41d-4110-aad9-0ab85402d026"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "0f4bde4f-b6ab-4c73-9e3b-c3512ff4982a"}, {"source": "f4c1962e-7454-4516-b1a3-01508092cd07", "target": "ab4cd026-474c-4046-a4d2-c07410beda78"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "f9df9436-6520-4194-afd0-994590b1bacc"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "e949c1b4-54af-4d85-b840-8d7fd23a72b8"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "a2cae305-678a-48c5-b1ec-3d12f7847a2e"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "b97f23c3-3c57-404f-b3b9-2be0a1916968"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "3904e6fd-2fe0-436a-84c3-4e93f6338be5"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "44890840-35bb-4745-bc6a-00c8d257a04d"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "9498bd60-b97a-4b9a-9ef2-deb9c4c80486"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "496d56da-975a-4ed7-9ad8-0c6d5b262250"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "a807bd0d-08ce-4555-9366-06b9e1489ef2"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "85503dd2-af2c-42a3-abd5-bafb4bf54703"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "d60eff68-01c8-4f99-bf72-67bf31e88ad5"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "7b65ff29-72a9-4d7d-a204-5515e6fb439d"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "8a730a3e-ca48-4550-b303-f5f88805ea70"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "08106e4d-9042-43cb-b2f8-44b7b4f8e0a9"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "acf4dcb2-19fd-4642-b050-124f4d0bf33e"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "f6b48f5e-8268-4828-b574-673677de5b7f"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "b6095c0b-d255-460e-a3ec-79d4400b778d"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "641f025a-27f2-4e59-8e42-866bca99fc92"}, {"source": "f9df9436-6520-4194-afd0-994590b1bacc", "target": "cf04282e-2eb0-49b9-9cff-6aaff70f18dd"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "683c3de8-6bff-4ef2-a0e7-04dba882e915"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "1c721586-6bf8-4fcf-a49c-94c7ad86e4b3"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "3a0cf010-11a6-4083-81fd-cb3ed1d408ae"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "2c3cc3a0-8b95-4438-b920-a2fbb939ba52"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "b6c66144-64a8-4657-950f-2a7662696f69"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "cf2b6863-46fc-422c-88ad-09ef9a3f6635"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "70b00a5b-7ee2-4ba1-af87-b6fff462882b"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "60f056d3-85ee-4733-8715-81100c254775"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "f944e135-6461-4491-a09e-68aa9db68583"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "2a514b74-4902-46a6-88c0-eb523649aa20"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "bffb4279-7f99-4154-860d-af55426552c0"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "272ed851-21d0-4cf1-b129-3ac5cb908116"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "69c2d9b1-4818-49ca-b168-23c6b97f732d"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "ce4a2150-4ead-4577-be84-f1d52c6af321"}, {"source": "683c3de8-6bff-4ef2-a0e7-04dba882e915", "target": "1cefff4f-7f7b-4be5-8f44-6458ff2004a7"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "15def481-ef04-49b5-ad37-c8f095bc0c7b"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "f1104393-b44c-4fdf-94cb-2354eed805aa"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "c5bba5c9-b5e7-4eb1-8c8a-2911fecb0df9"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "e4813aff-fe6f-4c9a-a537-bfed42c58591"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "b071bc0d-b250-47af-90b2-7e743815e4ed"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "c8f8ebe7-dfe6-4ccd-9775-24b32855c4db"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "06b608dc-1583-4957-8c7d-91e63b6feeaa"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "dc5ff139-69a2-4648-8d0d-446e9425d92d"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "087252d1-707b-4281-ba32-20659b6e484a"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "b0e4e1bf-f632-4219-ab3d-f8d6c1a5d315"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "00460bc3-4ca8-41c8-b678-a358a06ca08d"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "4ca40986-6d2c-4c65-9655-ed0080b8d5d9"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "3a445fb4-ba12-4845-8c35-344bcfb7bb1b"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "95582872-e484-48ab-98cb-803b78bbf349"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "fdc4f251-321e-4168-b6d4-682a0353fcac"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "aecff16a-23ad-4920-b353-8acbc31c0ce9"}, {"source": "15def481-ef04-49b5-ad37-c8f095bc0c7b", "target": "f7824bb7-804d-4a1b-96d1-fc41a2014f97"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "1646ebab-effc-469c-8529-78a0cb48f5b4"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "a750373d-f1bc-4556-976f-6b1c02d133e8"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "72a1291c-5853-41e4-8077-852e79d795fa"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "ae486e37-7225-4401-aa05-f09233428ab4"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "34b626e7-772c-4158-996f-c9ac899445a8"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "f96a29d3-dccb-4d84-8ff8-ebfe1c782333"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "b0938d62-7202-4bfc-b467-960cef39af88"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "a79f34e9-aa57-4e60-9157-b21219c30222"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "db5b1a8a-b4a3-421e-9716-b64542fb0c9c"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "2e9591d9-0de8-4679-b04c-c876d8f5487d"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "18b6b7cc-450f-4249-998f-be870dc17ac2"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "c955df4e-53e8-40ac-accb-bf45866890e8"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "3cde6418-4264-4fbc-a606-35241432305e"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "da29fd87-6d4f-42ae-afe9-a4f1d8a17307"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "82e27ccf-de13-4d81-acf1-978277e11028"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "a2bf40ce-fcb7-44b1-aa08-2d880c675864"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "ef1d5ccc-fc75-498d-a2b5-2678b1797096"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "6756575c-f5ef-46b5-83cc-eaea15e0f9f5"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "14b80778-3b28-48d8-9bff-222d47cd9f6f"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "a2037e08-029a-4813-97e8-3e31228d4c30"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "cc47b75f-784f-4dfe-af07-efb091f4b4f4"}, {"source": "1646ebab-effc-469c-8529-78a0cb48f5b4", "target": "0184762e-742e-4efd-97cf-45b0efd46285"}, {"source": "59d043fe-ba87-441e-84c8-9d202ce3d334", "target": "dc08a83d-e819-4793-ad61-b34ec24f61d2"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "3d2a5672-9e75-42d3-b945-6641fc94336d"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "6cc8ee79-c2de-4dd9-853e-118bb626de60"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "c6672ae5-6e9a-4fc3-852b-6683e504f996"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "aa365c6a-fb13-41c2-8bc4-e6624acf19ec"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "0447b6d7-675f-4541-aedb-39733d71823b"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "f0326a75-ddf0-441a-90b6-15bd6b8484fd"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "8a850ad0-6bda-4c9b-b667-197e8bd93c12"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "bee8388f-2348-4bcd-8963-404c5fdba430"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "935c744e-929a-455c-9274-a9ab2d6d9547"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "e501cf46-cedb-4662-bd7b-fd6c32a465af"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "c54389a8-66d9-4c19-88d9-29f396d1df63"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "31abbdcd-3cba-4672-b695-f0477b9dc4d4"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "9c0a4be0-e3f3-47f8-9dab-9150a9cc7cd4"}, {"source": "dc08a83d-e819-4793-ad61-b34ec24f61d2", "target": "bd35d951-d381-49be-8da3-4bdbc5c4184d"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "0c2b8187-6061-486f-a82b-238e5b2b3686"}, {"source": "0c2b8187-6061-486f-a82b-238e5b2b3686", "target": "b6ce863a-fe7b-4677-8cd1-255e0279036b"}, {"source": "0c2b8187-6061-486f-a82b-238e5b2b3686", "target": "af58a5bb-0b71-42ec-a8dc-2cb46a908d54"}, {"source": "0c2b8187-6061-486f-a82b-238e5b2b3686", "target": "c6ca9e15-d14e-4aef-a909-802ab67b89fd"}, {"source": "0c2b8187-6061-486f-a82b-238e5b2b3686", "target": "d204da3b-6326-4145-85b4-517b1ac10911"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "05e55176-79cd-4fad-b443-ea6fdc07183f"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "feb3a81f-dc92-4d37-9eac-fad8687bf86c"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "056ef51a-310e-43f8-98ef-301d2bb1bbd3"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "078821a5-42b5-44b1-bb18-0e1a972715b1"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "390f1dea-056f-4288-bcdc-49c07da79aab"}, {"source": "f642a7b6-ca1d-4eba-bc75-ba901e38d88b", "target": "20352cdd-8f59-4e9a-8a87-c665441e5a10"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "e3fbe242-0b8c-477c-ae38-064968266a52"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "243a9832-c16d-4363-885f-702744591b5e"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "e3602308-e0c3-409c-8540-1945c678a6b9"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "5680fd15-29c8-41d4-b397-ee9b1adc5934"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "dbddcb73-d489-442e-a8a5-1a4f834e6da5"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "e69da00a-eb8a-4245-894d-e67f2c49f20d"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "defc1a72-91ab-497d-8f96-bcfa2ee4e11a"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "02b29c56-e274-4582-8a72-864103f1a313"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "cc330bac-58dd-4775-9d28-52a0759567c0"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "04ee0aa2-059f-460c-afaa-b68e79b35e05"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "519b173e-0a15-47b6-a43d-dcc92a84597c"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "88aaa073-aed5-4874-94e8-3e24f3d808fd"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "43161072-949a-4f5c-9705-20ecc3d092f9"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "557b1f25-6b95-46d9-9061-4f4ff3c7ef0e"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "9953dd93-913d-4bcd-88b9-ec9a89bc5399"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "d8dbea16-727b-4ca3-9f39-3de9a84faf1b"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "ea491dd6-79a7-41d1-a912-3097ad4f0d84"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "2a83c808-c918-4169-98d2-1f262a5636c7"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "62e75a77-028b-4518-aa08-27ef76dedf6b"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "73ef763a-3f78-459d-9065-0df7d86a3d10"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "39b81aae-3b78-4b7b-be5f-279a38e156ff"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "29d4b2c3-f558-41b8-ba22-482716644b5c"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "5d54fbd8-2628-446f-a205-5b056ee5f6e0"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "b8b9fb77-3ccc-45ea-8663-9a3d1cc5f5dc"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "d9cceeea-34f1-40a6-a03d-e057b199cd17"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "a3a2ee58-47af-465c-9ab5-c2fde836e144"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "5d2a6658-93be-46f7-abb1-1edcea9a4479"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "9b1870c3-40ed-4054-8a1c-ef38712958a1"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "4a6712b8-f14b-4072-8828-2eb48324be4c"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "08933edc-9210-4c61-98f8-728e729dc652"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "ab007bc3-823c-44c4-9760-6b8d1c6ba06c"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "28517301-00cb-4b97-9a51-d090cecf243f"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "37148dbd-1130-432d-8011-1cce94b9aaaa"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "5bea6493-9fdf-4f96-9f9d-17964598ec8b"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "09433c03-4316-4636-be79-6f5f0a7e257f"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "50871430-b261-4b5d-bf44-77ed6a299c10"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "39fc72e2-c29e-4084-abc6-3eb20aa64e85"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "d611f63c-0b73-4216-89b8-bf3f59d72456"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "6775d8d9-5693-4aeb-97c8-0a49ce3f838a"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "e154f0a0-0482-4d3d-9b33-e87e007b5dca"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "ba070847-0374-469c-82f1-3264acc1bdc8"}, {"source": "e3fbe242-0b8c-477c-ae38-064968266a52", "target": "9401a8c5-ba5c-4cd3-9c37-e766459b8697"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "3d1b1947-d95b-45e1-9613-31f19011ec9a"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "fd720561-c463-4c03-aca4-fd20ce41b184"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "cf843570-77eb-49f7-9129-a594e3e65c3f"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "788be409-ce89-4df8-88d3-97c3d50a9522"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "9124f913-f3f1-4e91-83c8-2245b63d6708"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "f156b2f4-3cc0-48d0-8501-98401188ce46"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "c5b807fe-15ff-45dd-bcd5-a992ea7b7c97"}, {"source": "3d1b1947-d95b-45e1-9613-31f19011ec9a", "target": "fee54833-d4c1-4887-b43b-99fa541de048"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "682f4267-f1cb-462f-928d-5b42d771ca10"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "fc0f7c7e-9027-4f36-b07d-945423887ca9"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "82962f90-b8b3-45f7-a961-a5a544b6ed47"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "44855884-d2fa-451a-bf6c-587afb9f1a74"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "e403350b-fadb-40db-a55a-1c64ec1358b2"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "ad273dc6-5303-4b90-ab26-fa0c7ddb198e"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "d9cf8690-28f2-45a2-bc8d-60ed88f9af86"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "28200dbc-d923-40f5-beb5-4aaad5e92c52"}, {"source": "682f4267-f1cb-462f-928d-5b42d771ca10", "target": "309d5ed3-fd3d-47bc-b7ba-f7cf35ff0cb2"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "e55414b2-46e7-4899-84fa-e8a9462cba10"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "1f734ebd-b275-4fb0-8e0e-d87dbee740ee"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "40d8b1f3-79f0-4442-aa88-986cb92d4fe6"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "26b1a9b8-c465-4a9b-9ba8-c4cfd3b765e1"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "10dbbc95-57ce-417a-9b7f-5d2c2dabe657"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "c4234698-2d43-45b4-a23d-a57023a0cab5"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "b9bc027e-5745-44dd-8aba-13067e001178"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "b8e3d45b-564b-4865-8bcc-a5f008399a36"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "c01f07d7-ed4f-4eaa-9d0c-71792e929e00"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "fef17546-cc50-4d3f-96e8-b7f11f004657"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "4938255f-c89e-4774-8c6b-671abced3d0c"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "8cdff998-5ff5-464b-8e24-9418446e83d2"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "c26f428f-d2e2-46a0-bf2a-5acee5a2d9b7"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "4c7f6f82-362f-476a-91ec-4016c3714758"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "3c24f3a4-e790-4a45-8e39-44346443fb95"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "c9770066-6b62-4a33-8774-a42b7eb3d381"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "f2d0c9e2-57aa-4df6-9086-cb402d9d4620"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "848e6560-fd2d-4dc8-ad7c-59914627ef68"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "70bf12c8-942f-44c3-b46c-72d5048364b9"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "a2f47b6c-c33a-4c85-9ca6-726cb4219bbd"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "36f8a7f1-6a6a-45c9-861d-2ff5746bbe85"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "921125fa-b44d-4836-ae5d-b05d33ed1ac1"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "fda294fa-1349-4a6d-af86-7079e7ba818a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "4c6b7deb-a768-47cd-9f80-df63482101ba"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "1a40208c-3959-4f8e-9b8f-f351c11000e0"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "f8bec5b9-fa36-41ce-8337-9bdcaf9c1b00"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "39ff90c9-d776-4b31-b861-8c0a138de07b"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "ae29ef57-adce-425f-8e95-b02190989c45"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "2ea98194-4916-4ef6-bf31-0cebacd446a8"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "b3a2bb01-c480-4a08-9cec-4efa32b31e52"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "9cbf9daa-ff80-4de2-b1cd-4085b3aeee4a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "4bf5ea6f-40da-48cf-b3ee-7e57ed71963a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "22637ee7-e262-49c2-a640-389513af996a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "675c348a-7e35-46e2-95fe-fcbe3a4721ec"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "0d45a59a-f895-4d4f-9232-7d88704dc601"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "1dabce8e-effa-4e4b-8d25-9e4f363b173a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "60ca24be-d278-4ee5-a342-807ee1b11cb7"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "8fd21a5e-6efb-4497-9643-7f575fb08d20"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "75cf1e5d-cf50-4109-9317-dc47f3e6fa04"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "550c1836-53f8-4b8d-a67c-e5a50f6b0f7c"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "6056a966-3d1e-4896-8b69-3b533931659a"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "39252fa8-49ad-48a3-b0af-fc85b25b01b3"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "7118620e-3b0e-44c7-b28b-ba97e5307e15"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "b1d5a205-fb6e-41b7-a27b-f9897e10d6c2"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "2fe67d1f-7349-4ed7-b5f6-70f6132978d7"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "bc738eee-ed2a-4a1a-9c1c-0ab5aade3653"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "bcb169be-1f06-46f0-b235-99661dae904d"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "8ca830e2-ff25-438c-891e-fa1af029e564"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "4b7ed0f2-4cac-400e-9ce6-fc29cff09391"}, {"source": "e55414b2-46e7-4899-84fa-e8a9462cba10", "target": "1c5ac0b9-de78-4075-b21b-fce6086b186a"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "1c86de8c-f3e2-43d3-8794-0422fada648f"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "08368a43-afb3-410c-86f6-eefcbfcc55d2"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "9281c124-891d-4731-b704-0b7c7a8b8470"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "930f1020-cabf-4c5b-b638-c6cd1f5483fe"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "36b7bfd0-1aa9-403c-9cda-3888c6e31b72"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "5f03aede-269c-47e0-959b-60b8310863dc"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "bcaafdbb-0d05-43e7-962c-e1d2542ee19f"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "440f1dec-1203-40e8-855e-7961e6f32be3"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "c702ab20-188d-4437-a1c8-854fc394bbbb"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "191f28fe-c438-446b-87c7-822fb392819b"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "301ec334-413e-45a3-90b7-3bcbfdf5f814"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "9730e9cc-a08e-4fc9-a27e-cc46eb4eac0a"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "a2d4b5aa-216d-4d53-a560-b7b178e95c4c"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "9ef206b9-bceb-4b49-8593-51875a4a8217"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "3d5891e4-41ee-4ea0-a3f9-7908e642a813"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "9e09992e-dee0-44dc-9e44-c5133d1726e6"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "97a4fc8e-7304-4398-9bf6-6cb37538e211"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "79988209-5c9c-4245-85e3-aafd7c1f6145"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "c22296a5-75de-4cb0-8448-18d69237ab55"}, {"source": "1c86de8c-f3e2-43d3-8794-0422fada648f", "target": "2a580fbe-c45b-4fbf-a443-8fae1d4a8b15"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "e78a68c0-fddf-4a65-92a4-bfba53903ee0"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "9fb916c5-fff7-432a-9970-5133ed568204"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "4bcbfd08-a38f-4663-8370-e4bc9080d3cc"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "0683fbca-4e0d-4da3-94fc-26c6ebcfe1d1"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "86146dde-1c1b-44c8-94f7-5d44e052381d"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "5e446d4f-7cd0-4f5a-a49b-e92d36f96d2a"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "1b829b6c-06a5-478d-bd93-db8c3185e6b5"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "e209d306-a4d4-4186-a5f7-e9bc2086c080"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "802f2a64-0698-49d6-99a3-a1b67c12e169"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "74cd3f53-80de-47c1-80f2-3020b62b136c"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "c9b84b0c-d055-4ec1-9a22-b407939197ab"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "afc355fa-946e-4864-9227-0205c438bc3b"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "5789db87-74a3-40a3-abd3-363cc5f4518c"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "faa51386-8d5e-4f3c-a3d3-0e2f0cdef29a"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "195dd2f6-a639-4ec4-871b-101dc76d43ae"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "0705e5d2-cc06-42bd-9f0a-61a5c1587d6e"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "5ef1f9d0-a2bf-4daa-a6a1-dde7dd71c685"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "4fe30ae5-4491-4771-ada4-06534e18eeb3"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "1f4fad65-77a4-41c0-a0c2-ed055cfe2802"}, {"source": "1c83cc82-d2ea-4a8e-9eae-6afb584fc658", "target": "84bcfdfb-7055-47d3-9762-3a301e69f41e"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "c4313204-9c3e-4156-85f2-2c3eedda6168"}, {"source": "c4313204-9c3e-4156-85f2-2c3eedda6168", "target": "4e139601-d947-49ea-a283-bbb3f488dfb4"}, {"source": "c4313204-9c3e-4156-85f2-2c3eedda6168", "target": "428f9cef-4200-463f-b01f-e077711f6b05"}, {"source": "c4313204-9c3e-4156-85f2-2c3eedda6168", "target": "9c90817c-d4b5-4cdd-a61b-ae274056f5fd"}, {"source": "c4313204-9c3e-4156-85f2-2c3eedda6168", "target": "4fc4698a-5525-4c0f-9956-fcbd260e7408"}, {"source": "c4313204-9c3e-4156-85f2-2c3eedda6168", "target": "8848a701-9d84-49b0-a5e6-d05f3db99d38"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "09cb9e96-0966-4ec9-80c7-e536e74a9983"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "b1bcfa5c-86d1-49e6-b2a1-f1e7b838679e"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "3f214f35-4784-4ffd-b46e-cfe0cba2bed5"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "714472eb-a006-4e4f-9eb5-ded52c7dcf7c"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "2990a9bc-7527-43f5-8fa5-5a74e30c4aad"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "84880f9b-05a2-4fec-a640-bcc8738e9003"}, {"source": "09cb9e96-0966-4ec9-80c7-e536e74a9983", "target": "e9b09991-a6cd-427c-b123-0c800ba404c1"}, {"source": "71fad15e-8c89-4c88-84e3-0bb1ed905c91", "target": "5aafed38-d568-4557-bb8d-6da1f1a265b5"}, {"source": "5aafed38-d568-4557-bb8d-6da1f1a265b5", "target": "de1ac076-0f57-4f49-9bb8-4045ce94d486"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "41ee94f6-100b-449b-aaa3-44ee30de1ab1"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "81aa421b-9b93-4517-aeb1-ccd5e737c7b2"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "05336a6c-68af-45b2-a0c0-c22206f3a980"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "59ec13de-e7bb-41eb-87c8-09b6e06cd017"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "9ce5507f-b792-4621-a277-f2c88a6e3f10"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "f2de9bda-3de3-440a-9137-47df481d7642"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "27c3195e-d782-4745-802d-65c820528cb0"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "10afcf46-c489-4313-8b56-44bce2b6a556"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "9cba6734-189a-41ad-b522-8b983dc6424a"}, {"source": "41ee94f6-100b-449b-aaa3-44ee30de1ab1", "target": "5214a9eb-30f0-4cd6-a9e6-965af67d3c40"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "561321bc-ee30-44ff-9f1a-cd267b46ea63"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "f031c0f2-470a-4440-81f3-79d8aa23d95f"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "1101b47b-e76d-47bc-b8f0-41ecff0155bf"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "e268c901-721d-4788-89e8-2d5d6db3e35b"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "2c20d956-c4d0-4ef0-a0bf-0327130eef70"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "7cf9bde8-8142-4dcf-9e41-cc3c1efcb6d9"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "7de044f4-eab3-48c2-859d-48164772c20a"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "e0b6969b-a08c-4640-a1a9-b90809b1323c"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "08ebf2e4-d3d7-45f0-b5b2-cc28709229b2"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "e30c88ba-905b-4abc-849b-2eb7c11cba36"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "892a8d6d-7e21-4b3d-880d-5c613addbaa3"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "186157bf-390c-4936-bbac-9bcc5222096e"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "23c3d888-b83a-4b2d-92bd-c2ee9c37b0ca"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "3c2140e8-e66d-44d4-9c2c-c67ae9a072cf"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "2346421d-95a1-42cc-8b72-9d1a562caa3e"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "571a5445-600b-4515-acd4-17a7a397bc9d"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "3d83c9a4-b219-4c3d-99ce-14ec8215f427"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "a5970173-a499-4114-8a28-c305129f6246"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "b42326bc-4f41-4952-8731-d44b80e15602"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "268a69f8-7c4e-447f-b45e-33ba2eff45a8"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "d7ea19da-4c5f-4be0-98bf-180681a53f7b"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "8c65ef4f-0d84-4297-a7ba-e017250c61cc"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "f4bdf908-61d0-4f0a-8521-a40a138f2204"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "7793d99a-b7e6-4f5c-8845-bdec9c5bc27f"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "6d6be1ff-77e2-4e89-9bf1-f2948d000c3b"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "98bf940c-2a31-434a-ad02-0b0d908f6323"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "e851fd59-4e29-4059-8ff2-67e0370c30c8"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "408c8d82-aeb5-43cf-abd6-047fc4e2de53"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "c3884d74-2587-4bef-aad4-107f63839287"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "5b466cd9-270b-4f20-9960-a783a13b267a"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "ca13ebf6-61b7-47b8-b237-495ad8a42d92"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "b8bdcca2-e7e8-4d9e-99ae-fd85bcd38303"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "2b7ff346-5a0b-4a71-80f5-51894c202d8b"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "02303756-1efa-4438-9cc3-ee61409a2ecd"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "f704c7ca-4415-4685-b577-ba151b3db1ff"}, {"source": "561321bc-ee30-44ff-9f1a-cd267b46ea63", "target": "a4aff58c-6542-4601-8210-5b4ec9558dc2"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "dd4feb9a-5163-4a12-99c3-5b80422c7517"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "bf86814d-f759-4714-85cd-3d1c503a89ca"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "04111f8f-c378-4906-b071-87221d27a57d"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "083b9508-b241-41fb-aabb-78d9d6695e6f"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "1d63e159-5c6c-4259-8aab-4855d06e0b69"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "9086675f-f28c-4ecf-9bde-d8ea1184c1de"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "1774acfc-38b0-42eb-b002-45f9934235b7"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "325d1bfe-07dd-4f9d-ba80-116d31ec31cb"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "c0287cfb-8df1-4cce-8322-6af7d2dbb361"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "82681adf-4c3b-4a7a-beb3-a7764d82a280"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "34607e8e-1eb5-44aa-93b2-1cb2a487e9fa"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "4e845515-5003-4a3a-9754-97af39df76a0"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "b248f3cb-ed02-45d5-ab46-4cb9d99753a9"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "1762cbea-1733-435a-b5d1-a64cc938719c"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "dc18c8b3-d69e-47c0-a444-f525e6edb19d"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "410ff9af-5cb9-42d2-abee-9a412bc654db"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "93590696-c0c3-4e7e-93b8-71b1ca5512c8"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "35324c24-b41e-42f6-8bcc-e9e682c1634c"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "b57d9ce9-007f-4b5e-a5e2-6db0195d094a"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "ae33e708-33d8-4426-b623-9a4f23e9d71e"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "df09ae1d-2128-415f-a1d8-1386acf5f86b"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "d8e38808-c520-4203-a5c9-814589390e60"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "8ab42e7a-3934-4db4-b3f6-0bb73c830497"}, {"source": "dd4feb9a-5163-4a12-99c3-5b80422c7517", "target": "8d696d44-eba1-4704-be26-2e94cfdb2a96"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "68da2b13-55a3-47ed-a92d-a49407fdb60c"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "a828fcf5-e7ef-46b4-bfc9-5b7bd7157cf4"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "2e341363-22a9-4a37-9e5c-b2d43c36f192"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "997367dd-e775-420b-a48f-b0838c489fac"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "2864268a-f15d-4eef-90b4-7a8569c85c48"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "48121686-093f-491f-b7ee-86e959295e3b"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "d998189e-ded6-40dd-824d-e0e2f306b034"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "833c446a-1c16-4c24-9f00-bcdf4d79ec5c"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "5598e4fe-5265-44b6-85b5-cd16bcaab779"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "0005250a-4311-4ab0-a3d6-0b38f822e2dc"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "bad39dd0-1ea5-4d15-a200-f06d592626f6"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "6cae8caa-161f-4ca4-8788-b7a4bf1b2e01"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "50266f9a-1b50-4c23-a1c5-ffe8d8347b13"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "27ce2723-83d4-4683-b603-abb22b22479b"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "4ecf86e2-26ee-4e73-8fdc-e845bb561c65"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "99061817-0ad7-4bf1-9612-53ee5d8a770e"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "b3e701ce-4cdb-4bf5-a083-f38748198ee3"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "6facb8e7-5609-4239-87aa-cffad64fadbe"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "7e4c4a04-f90b-499b-a640-908097dca060"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "33d23223-82bf-491d-99d4-0e6136c69ab5"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "5ffbfa53-62bc-4cbc-b556-06b8cb611874"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "8022ccd1-ed74-47e3-90ab-fb6d263a21f9"}, {"source": "68da2b13-55a3-47ed-a92d-a49407fdb60c", "target": "90742030-ad49-42f7-9f4a-dfbbf7a5b143"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "3ea228f6-40a2-4725-b530-8daec048cfda"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "9b997a12-6328-43ec-a2df-47211c30d3e5"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "37d52922-ead6-4bc1-b807-0a5c649900f1"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "56ccb4dc-c185-43cc-8cbd-ee5ad415a2fd"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "b2ac10d2-57d3-45ad-815f-0ecbec1bfe52"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "c6e082d1-176f-4727-affe-6dbf347adb10"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "8049a18b-58dc-4203-a6ad-2a10b3d3bc78"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "6977d0c1-0781-4d73-a83c-856cc417c974"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "e876e7a7-2dda-4c7d-aa48-b969b177ffc1"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "c6cf316f-c267-4f0e-93ab-7d9a7335cd04"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "e3831b2b-dd9e-47b7-a9ca-a4cc7a4abeb4"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "82b5c4d6-8bce-4927-871b-e7550125aa47"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "f3b22d84-2d6d-4f7a-99b8-b16bfa1f81df"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "3ef216ad-0864-4f3f-a1a2-be1948971045"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "42ba9669-67f0-488a-a9f9-d3cfaaabb8cd"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "024ccc17-0066-40f4-aa57-50dc9b601c26"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "eb775a8d-9386-4981-9304-2846d087f005"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "b334e28b-fe83-4330-8ef5-08add13ac0eb"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "8c5d119d-25b0-49d2-af46-c479e683ac81"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "1440f06f-0c66-4dfa-813e-b749405cb85f"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "f07437ed-df5b-4c74-bd57-b93546b74955"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "4767b609-3282-49da-a07a-0d193e7a2be1"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "e43e994b-2a60-4c6a-ab18-c500ee0e472f"}, {"source": "f1bfb7aa-c009-4cf6-ab53-4b7953d6b92b", "target": "45ec86f2-e290-4207-9c46-e720ee948811"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "5607b770-4812-463b-a08c-bf25a12d2b02"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "79bc278c-76db-48f3-a0f0-301ae01f9cd9"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "da9f4769-91e7-4953-b5b2-8878c8fc325f"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "b1670e92-3465-47be-87a3-98de3e51d1b3"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "7b63fbc1-bd72-4e6e-b638-2ba5085f8502"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "4cab08aa-88e6-423c-9e71-7e62b72e54b9"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "9fb4f0db-89d4-4e5a-8546-a4b3ca024c0d"}, {"source": "5607b770-4812-463b-a08c-bf25a12d2b02", "target": "615d71dd-9e3f-4689-9b7c-b36deb74b16b"}, {"source": "756da707-03b0-45a1-a6cc-d157ab898e19", "target": "2c7f603d-5e9c-489a-9150-10f6a031eafa"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "d08efac5-c1f2-40af-ac2c-4fbc08928f22"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "5d7973ee-2d0c-4662-8f2f-dffabdce44aa"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "9e359aea-bcf3-4f12-acbd-3c07612a0619"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "45013813-5d8c-419d-8fb7-ea3414113107"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "83055007-f57a-4b44-be60-eb6f3f3feb06"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "34bf3a46-8980-4a78-bd1a-8b711db6d0c7"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "779bdc5c-682d-4b83-9a9d-5359702170a1"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "eaa2dc73-6139-450d-a272-3f4b79cb12e1"}, {"source": "2c7f603d-5e9c-489a-9150-10f6a031eafa", "target": "a60b6b34-3dd5-46ae-98de-34aca3b9132a"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "dc63e22d-deff-4467-bfaf-f198f3226c18"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "f1467f78-216b-4030-b08a-d19e3f5d92b1"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "cb007f63-4305-44e3-9b97-b9b8ccaa6e3f"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "e1397c8b-295b-4950-8e16-be9dbf596bf3"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "c0efd449-264c-4474-aead-63a74c676e98"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "8e40c0cf-1cca-4d11-9efe-15c917c4eca3"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "10a8cadb-7a97-45c2-8a6b-6b2903d42ed7"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "3e7ed91c-c557-49c1-b743-b155a615beba"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "aaf79bae-232c-49a9-b1e9-f8eb4921cda7"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "611013dd-a0a8-499c-b3c6-a82d0e586a82"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "05dee522-e3fd-440c-bf6a-7ce29b7f4cd4"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "daa99f74-52ab-4f15-a657-28f9bcd32114"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "5eef27af-a9cc-4c1d-ba37-3fae54ae9b1f"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "8159614c-1831-420d-8e8b-6619ef83ecd8"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "5d781a29-ac1b-4555-936d-6322c5f6a429"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "3df905eb-82ab-4d26-b8e6-b9ffed845931"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "7ce04953-3109-4141-8c52-651f3e31da56"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "df5681fa-a0d7-4b03-9d91-9e9fe31c81dc"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "ba78de9f-0526-468b-9578-05df41938eb7"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "8f62d872-e93c-4e3c-996b-0854746159f4"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "024b4f96-7956-4d65-b89b-d44e459577c4"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "18290a37-497a-4f36-9cc8-d62f066b2c2c"}, {"source": "dc63e22d-deff-4467-bfaf-f198f3226c18", "target": "78364ccb-05b1-4ed5-9b4f-89f49a61baac"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "363bfb70-6d6b-40f4-b041-9d44510b61c0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "655a6626-7074-4675-8197-94ff11abda22"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "477dc2f1-e1db-4a5b-9457-60ff03055094"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "4b0f940e-8418-4319-87b4-54030eaa9ed2"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "05a427f7-0915-49de-bc9a-73af80a50d92"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f5158f3c-7d36-4c26-8881-aabf08ceff7c"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "437940ea-1e4a-45f3-943e-d827b286fc7a"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "5fcac5a1-e6bd-4b98-9a14-0b1f34fa44a0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "6e40002b-5628-46dc-af39-50e102ffb7e5"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "94e423fd-8989-456d-a11e-06d54e326404"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "11938ed4-694c-4b2d-8964-117fa2948345"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "574f6e27-6a3c-438b-a2ce-dcdbb6836d8e"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "786cbec7-d64a-45f9-9832-458ca4f78a28"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b7b0cbc7-c87c-426d-88b9-2ea2372ee57b"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "bbf6c556-07c0-4150-a0b9-1632382a8bc5"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "7af59dcf-4f7f-4663-a3e9-51f7fb5b47da"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b5fe9fbb-d056-4128-a560-5de145eab328"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f2556acb-a5a0-40d5-b608-af507a24d870"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "83b0af9b-8000-41c3-a89a-ac7b4325eef0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "3935fa6e-1bc9-4be3-9fc9-0da25000ca08"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f10925ba-4bda-438d-a122-2dc03777a2ad"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "7988c834-1190-4f6d-b107-e5053444b9e6"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "aa12c344-9114-47a5-b6fd-23bec40134a4"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "94bf9210-6fc3-4b5c-b31f-d27969b07d50"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "6ea5cf8f-f32a-440e-9dca-d14f1cecd7f4"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "8cf5e181-029e-4a51-b041-314cd6a627d0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "ffe42a05-1044-4f5e-b419-742241646f28"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "53fe4ba4-f13c-48ad-8f4c-38020d87adb7"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f6961812-1e9e-4c1e-bc83-0220bb9e6718"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "8e8a721e-6b72-43a5-87e0-17ea3be38553"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "565da2a3-d922-4d12-8118-8eaa7a3bf203"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f6cf0648-f2de-45e8-be93-2e648b6ccff7"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "9ee92aac-2840-4449-9b8b-8405f35b41a5"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "3d466711-4515-4941-8468-5eb3ccc5d3e3"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "7fa20a49-3874-44c6-938f-45138a376812"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "c6d0ee39-d733-4533-a819-a478575c6bfe"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "d74e3754-f8d2-4fbe-82ea-da1c001d115b"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "032034b4-20a2-49a0-8da1-05cfa5bce07b"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "5bc0f328-cbb5-41c8-8eaa-97599017f702"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "3b388e33-5d45-4f0d-8a1b-bd80e222f94b"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "6b47df1c-488d-4ae1-811d-a063a1539270"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "0c831708-ecce-4e8a-870c-7b71a5789a67"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "a7f0305b-a7a8-4593-b63e-70fbd7e2340f"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "aeb7d2e7-c83b-4213-9202-b5a6c7a967a1"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "414729cb-71f7-4e3b-a5fb-a5ce9e54a49d"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "2677b034-c663-4cef-9b68-3b434eba1d14"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "c91b7ad7-264d-4cc8-afe7-300510abcf75"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "9afb98ec-0b3f-49e3-bcf1-a1498eac51c1"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "17b43a4b-fd60-4120-89fd-4e5ca932534a"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "fec89566-8016-4836-97de-4e917f4b3ec4"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "0e83c7c1-600e-4ec2-83af-dd6b3804cbae"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "bc3ddbe6-43c2-49e7-b84f-a9aaaae154fd"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "1f6ef305-20df-4649-aea2-a642ebe0768e"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "ea042fcb-7737-423b-929d-8ea72b3d17f4"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b82014de-c4fd-4ebc-93be-2f4b79423a2b"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "6ecf3789-f90d-4740-999d-a13b5809aa37"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "fe747cad-a19d-495a-b048-37aaf78953b2"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "13d81eac-f7a2-4057-8af6-2150e852a72f"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "1b0789f6-b5d5-4805-a10f-78d1236aac02"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "0feff2bf-3fe9-47ab-a450-4332f69c4c18"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "0f8d1c5d-a941-4c74-aebf-481c551d3133"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "49fd0ddf-7eac-40ca-9dba-5022bfd83541"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "9f0342f1-3043-40c5-b994-8001ceec036f"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "18624676-d797-4715-b873-5098488ec405"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "4020ed14-c0ea-41e7-b04a-7a69aaddd1c5"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "473b8dc2-04c6-4689-98c3-43287870baf3"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "49a8b58d-caa7-4458-96d9-4aa26607eeb6"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "ae7f530b-c910-4d14-b172-484b102e63a2"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "885d73be-5722-4599-ba37-57fc315eb7eb"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "d92e47a7-f36f-4a08-98ef-9436a57a5302"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "69c93d6a-6fd4-42d8-90cd-554daca543eb"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "e05c63e8-cc73-4009-ba87-faa9fec3abf8"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "211a3a32-3bcc-4ea1-91d7-bca8915e1e29"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "83d59d9b-d93d-4e18-9514-affac13c064c"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "34c3b461-d9ea-4ccd-9d86-2efff8cdc783"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "6ac0ccb8-7499-442e-86ee-dc1ceb65a089"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "06c088fe-843e-4c35-aa54-55060ccd1035"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "c65af275-d8e8-4368-8d0d-c4d8364e6d85"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "3813a713-7bea-4f3d-9009-334eae1feab0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "1a945375-92e2-4acd-98b4-e165d312f19d"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "19daa41f-f621-4aec-b402-d6a621d32732"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "389b88af-da31-4086-b917-51a0115a2a62"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "5d75361f-6b30-49c6-b41f-b5509036ae01"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b5cbda86-b981-4e91-99ac-5ed0aa8c7e6c"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "39c7ee0f-b16a-4afb-86de-d4e87d110605"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "5af36eea-356c-40ef-9cf3-fd5ffa531181"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "ad8c053a-d600-4c02-af85-dc571e74a16e"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "1de8318d-16f3-4aa6-837c-6e852660936c"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "487079ac-683e-4b64-a377-f50bb369416a"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "44f4e612-ea33-4187-8684-714ae881bc7a"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "ff0a2f60-bf76-42d3-b66e-4b388466d2e6"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b9d91f95-40df-425c-8d43-955e5928d83c"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "dfda9b77-5bd9-4847-902d-98a4f25ad646"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "f623bdba-b7c6-4827-98ef-4151fe7288a5"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "18a328ae-57c8-4b7c-8f1c-f0dccb3c3689"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "e4f318fb-527a-48b4-bd74-39f024596468"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "4acc97e3-6f39-479e-8ae7-353e82983d82"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "9005e310-8a5c-4632-8c42-cb238d063d99"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "996256aa-d54c-4d25-8ea6-b3fab9db02d6"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "70e2f50c-cc35-4ff7-a09c-1f9dfdac97d7"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "7262ba27-4b88-4a96-8124-3e445b7ce25f"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "a771a458-3690-4276-a877-c4e849151c39"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "20f193f1-5f9a-4961-b550-3cb6fbbe9280"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "b0cade23-c4ba-496a-ac56-e5326bd3164f"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "cc5f66d0-5a88-4425-b6fe-ac0ab5f9d330"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "7a760c82-6934-4f01-8221-6a2ef0d69577"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "e0fb23c5-d2d6-4d39-999b-ccde02f29a79"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "01557297-4d2f-4603-a77f-d3e5b4949cd9"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "9d4e996f-dd0d-4083-92fe-9541d8456950"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "120e6eec-1f68-4d0a-8f4e-c3587d7cc9c0"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "fae6c5cd-2474-408b-86c3-11e0d7d59f4e"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "bdbf2adb-226f-4a69-a3d0-70d311e40a07"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "d165d65a-80d7-4b20-a73e-cfbcba3574c4"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "72460300-c229-4e5d-aa2b-365691043f8e"}, {"source": "363bfb70-6d6b-40f4-b041-9d44510b61c0", "target": "641c86a8-9e71-41ef-bb14-a7bb654ae856"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "7e250707-0616-471f-a42f-0ae96ba349cb"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "d2c61390-496c-4eaa-aa00-046bb0e3f188"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "83e44fdc-af37-45a0-a68e-c1832d19aebd"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "3f6e2422-0c51-451d-acbd-e5f00904ffe1"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "100df787-a1e7-4f95-adc4-15c9d0886461"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "605b697b-e926-4c44-8f21-2a9461635e6d"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "f4d1c9c8-2f54-48d8-929b-349ebbf4c111"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "f07b453e-b36c-414f-b8f0-c52140849344"}, {"source": "e9be7e84-c4c8-4bbb-889d-01771ad8c1a4", "target": "de80cf90-5972-4cc5-a206-9836b4e5f6c0"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "9d4c3a06-68f6-43f7-aa86-f896d3275341"}, {"source": "9d4c3a06-68f6-43f7-aa86-f896d3275341", "target": "70515647-44c3-4ba9-803d-8116b1be0ca0"}, {"source": "9d4c3a06-68f6-43f7-aa86-f896d3275341", "target": "c7e8c442-881e-4d03-9ca5-57264be4cce1"}, {"source": "9d4c3a06-68f6-43f7-aa86-f896d3275341", "target": "32776b69-c91e-44bd-a2ca-7f7e7d4b9108"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "89f50736-9e3a-4095-9863-486c0bc35c01"}, {"source": "89f50736-9e3a-4095-9863-486c0bc35c01", "target": "f9c2a37c-ecea-4f8c-9b76-b791e3919851"}, {"source": "89f50736-9e3a-4095-9863-486c0bc35c01", "target": "4ecaefb1-3844-4031-8ffa-49586589b993"}, {"source": "89f50736-9e3a-4095-9863-486c0bc35c01", "target": "cf277a4a-e2b1-489a-8343-3ff4c19ee9f9"}, {"source": "89f50736-9e3a-4095-9863-486c0bc35c01", "target": "b98db071-4d35-497d-9efc-cbe7e45c3601"}, {"source": "89f50736-9e3a-4095-9863-486c0bc35c01", "target": "0e524ed3-3129-4896-8aac-0e0f1974a798"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "d4461547-da57-4e48-8fe4-8b658c3f8158"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "94ba4a86-698f-4050-88c9-f2b48606634f"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "bf749216-50d8-4286-a9aa-c689651910bc"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "e3e59b5a-70a6-416f-8f36-3294d2c7e120"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "b2426894-6d30-4483-be99-d3d823cccda0"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "eefeb6fc-34f8-4b34-8920-7532a7370c26"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "368ce8bf-782a-4d38-accf-2051834017ee"}, {"source": "d4461547-da57-4e48-8fe4-8b658c3f8158", "target": "6ccdb336-39b6-4220-ae28-feb84b816a86"}, {"source": "e078d34b-b800-4e25-a283-0abcb1bde121", "target": "fafda261-518d-408f-947c-56ce939e7f48"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "e2b174ed-aeaa-49af-aef3-f7f70cd2b492"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "9ca4df29-65f2-4138-a1d6-68ffcdd639d6"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "513c5628-c398-4b51-b84b-75023922300c"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "15905da5-1850-4d01-9775-437ab6437f23"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "58a51edf-67e5-43fb-8bf3-b74e96fd419f"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "d4d038c2-f160-41cf-816c-453f6ef8d1aa"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "79a8646d-d018-4f67-ac01-caf900cbcaed"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "9872ed1f-6807-4010-8ccf-d30e20afd735"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "d1234e57-189d-40fb-b647-83352f630138"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "79597bef-17aa-4bd5-b3aa-254800d8840e"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "2e5e2553-775e-49ce-950a-91fb0fa08baa"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "146918de-8b99-474f-af3f-a33ee3105b73"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "47cf754f-5b92-4979-ab39-33508cd3a255"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "baf20e7b-313c-4b3b-b0a7-bc4d8c6b02c2"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "189d34e1-af14-41e3-b4a6-85f19a41d462"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "838e9932-e578-4a5f-93d8-80c5f88169fc"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "c7b693a7-54bd-478b-bf21-1899b5217eb6"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "0ec81ec8-68c9-4b10-b9df-c911c9773add"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "e3f8d505-c566-4514-b2ae-94c02066554f"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "238b388c-29b7-4675-878e-f9b6d4475126"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "d129b107-a319-4863-a482-67f3b6444de7"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "4e7e6727-cb10-4377-9469-2846ff2c26b1"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "c19d7e04-5727-47d1-9942-0f29ba772ce5"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "2755e516-6336-4762-9c76-d5ab8e83a812"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "a0449ff2-e5c6-45d2-b11d-8e6a89a0e7f3"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "b118c509-502b-4e37-8f94-cc81a8713839"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "4ed97f18-2f79-4c73-873b-f00f45f4a5ff"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "b28c8e11-ecdd-4f3d-8f60-c9c91fe32fba"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "cdaa40d6-beab-4406-8cc2-52ab369ae91f"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "aa4d41e6-ed32-476e-8c80-12155463eef7"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "afe70485-00a6-437f-a8f8-c8e28e7cbd82"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "3bb4b4d9-29a1-4da0-a382-62b58e69bd7a"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "81623471-86ce-4679-a992-cf681cc75f43"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "c72351ec-d232-47a0-9bb9-01b91249d5a3"}, {"source": "fafda261-518d-408f-947c-56ce939e7f48", "target": "515ab736-0427-4537-80a0-3b3a17141efb"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "d4ea06ed-4c91-4e0b-b144-da9a021b7fa0"}, {"source": "d4ea06ed-4c91-4e0b-b144-da9a021b7fa0", "target": "fc47e110-fd2a-47ee-b3aa-ec4a3f61ff27"}, {"source": "d4ea06ed-4c91-4e0b-b144-da9a021b7fa0", "target": "bdaa74bf-4059-4b06-a7d6-f3fcc99f1122"}, {"source": "d4ea06ed-4c91-4e0b-b144-da9a021b7fa0", "target": "c6c4e65a-ea46-48dc-98b5-efb7efb2369d"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "bfcf6330-a328-4f34-98d9-50c07faeb19b"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "fc507e9d-3134-4c90-a9a9-52e738aeab33"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "f84849e0-4a73-4e2d-91b5-5047e113a8cf"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "6c57c57d-56e6-49ba-a9e5-0b97cf811ac4"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "48b2aa8a-7fa5-44d5-abbf-70d9e757c1e3"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "5ea6c804-1411-4750-8756-f06edd620ac9"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "153a80a9-ae42-40de-ba58-8f80ee05e480"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "dac41db6-17fd-42e1-9b8b-f567b1776e6d"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "276ba9a1-dd4c-44e4-aed6-bbbe6c43cc6c"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "8d314bd2-7aca-48fc-a286-4429026fa0d1"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "a0076bdb-d29a-476d-8b16-34a9447273bc"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "bde148b2-3b83-4051-95eb-dfe8530c5360"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "7c5367b0-5e04-45c7-9b51-519a9e49e1d2"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "0884cf0e-f46e-43bc-be3a-49b2c5e885e7"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "f4e9ba9e-a010-4736-a693-637ed88b77a8"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "8fbbdded-f82f-4b7b-ad3e-6b3f9e4b028c"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "7ca3cacb-68ad-43cc-ad8d-321d68e0a594"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "1cccbd4a-7ab7-4d8a-8974-cf749d0171e9"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "bd316430-6147-4c34-b1c7-24e5c9c536f6"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "9df38132-c39e-4720-9d55-d6e8006569a1"}, {"source": "4b7e8751-3596-4ae0-8a68-d5abc7daccfd", "target": "d78a1cc4-f600-468e-8eb7-b983cd130c90"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "1b1a297a-5075-427d-a0c1-700d1bf470f0"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "33db6608-612f-49e2-90cb-9f1fc1e2f600"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "1eccd0b7-67f9-4c53-bbd0-7a55b1183b4c"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "51d12e7a-f03d-4603-a206-440778323f27"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "97b85b8e-a152-4301-bd39-28b585328cfc"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "b0ad26c2-a1d0-4781-937c-9dc4bce94a8b"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "740e89e5-06c0-44e0-805f-cbf0769682cc"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "c44183c6-e26f-443f-b4e4-fd1a366786e5"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "5bb3d49a-9596-48d7-8be8-2a4064410db3"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "61ec4fb4-405f-49a7-bc5b-8110ed143720"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "079d0587-1979-418c-884e-63975f26e37d"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "93007ec3-a920-4abc-b52a-eb6046fa8d84"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "dc6142f1-c521-4e47-a314-fc76ac775779"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "b32a7018-406f-4501-8b03-dc9e2f95c564"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "69c0e2ff-cd89-4787-9e7a-825db6b1a89d"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "7ae03b6c-ad93-4923-a3a4-2f91251ad352"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "87fbe8bf-809f-49b5-b81c-cbd3d2f00964"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "f328b1e6-22e2-46c3-809d-ad4444b6782d"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "50f484ab-4d38-49b2-81a9-88282c12a4f6"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "e0c03e10-d1c0-475a-99c5-06ac140bdd7f"}, {"source": "1b1a297a-5075-427d-a0c1-700d1bf470f0", "target": "a7acb01f-8cd6-4b92-95ce-c3b14a44eff9"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "2e5188c5-f208-43e3-ab16-dc88b06c1e1a"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "bb72f593-4647-4951-aeed-ce7b71466ef0"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "6f80b18a-011d-48a1-9028-e2a3e36c883b"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "ff33e33d-9de4-40bb-bd82-5a84bfd5f076"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "acaaed8b-5013-4399-ac88-7ba921f3e6fc"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "5cce76c5-a462-4a20-a743-d8079979828f"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "a00b8b90-5c7e-464a-8d6b-d19b90035e59"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "cdbb8e5a-7131-4726-84a1-c0158c5c2f12"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "2fe9fa4c-5477-4a34-a16f-859ba0420d5c"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "f7726b53-8974-48f4-9b82-0c28ce70f29d"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "2fd0edb2-f8ac-440e-83a4-070e274a06c4"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "6550b33e-95a7-4680-8610-9000f146edfa"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "95649467-4ca5-4364-8c70-a84845dbf292"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "5b581003-da37-4029-a67b-c026297ed148"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "707cf3b6-d17a-456a-81b1-3107f1245c75"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "ac13eb06-fd66-4b4f-a005-8527348e118e"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "2a6e4655-bc83-4440-a803-fef683aec7f4"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "1fad9970-a38f-42cd-b5b6-2dd5f166a036"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "5a3a262c-e0c4-46d4-b264-7f1e080939ed"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "98c9cc8d-fbb5-4aec-8a3f-b2d78805c085"}, {"source": "a74250f4-28c2-485b-9c1b-4bfdcf7948ec", "target": "5f27436f-35c1-4a82-8bb7-ae0d40736d27"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "5652c766-5e93-4995-a750-06af49522bde"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "3ec9bc3a-d6c4-41d4-80e9-e3ec42f67c24"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "5d39521c-a223-482c-99a7-a5f6e828e6b0"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "e72a4694-43df-4467-87c3-d8d9df6da142"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "de0cc862-6b00-4625-86cf-fd834d08ee3a"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "710176f3-953e-4ba6-8ec1-9d0cada2374d"}, {"source": "5652c766-5e93-4995-a750-06af49522bde", "target": "46749a07-99c7-4c4b-b939-585c7a37ac23"}, {"source": "8da00874-11db-488b-8351-c53dc0d78471", "target": "7b72ae23-713d-4ff4-af87-ccf478de426b"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "82211c41-e8bd-433e-a106-b47393f2c691"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "8a85fda6-13aa-424d-9f11-a80db69f7746"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "3ff895bf-1fcf-4f40-93dd-4cde59a92627"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "2e46664e-4879-42d8-b4b9-a3ab3ea0040f"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "574148f0-55f4-46ba-8cc0-b138f64a9937"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "ac6a7841-49e5-4503-a4d3-3aea189a6326"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "2d844019-9666-485a-82c5-874412b042c3"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "8283ebbc-2ce2-450e-9716-6d545f48a392"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "d434259b-8a2a-4159-8935-39bdb1402616"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "4825d19f-d8a2-4757-a2db-8774b6d6a74a"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "f3777fa0-9b10-4301-9a10-43042c67b441"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "f8586f85-3886-462a-b378-4641935b1c67"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "3938cd04-3ea5-4e60-842e-e52aaa3f5398"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "878b3b2a-1fc5-4489-9a19-17a057906d2d"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "6815d8ed-a63a-4b0e-b3d4-3e5a750e2b9e"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "7c7455e9-918c-4d7c-93de-88835073bc65"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "c2a12df8-7d24-4943-89d7-88f62cad82bd"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "fbd5ed9c-01e8-4085-8602-dc146095fb8c"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "f4fac133-2d51-4dfd-890b-4d50feca35de"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "bd63206b-7366-4ebb-bd5f-55e6fbf8b1b8"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "4540cadd-1583-4eb7-a31a-88132a98ebb2"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "966ecc59-c877-4055-ab76-a6ccb62f9f69"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "60e0c8c4-61d1-4138-b5e3-d578c063c659"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "63253a03-8c94-481e-96d5-3d3f0faa280c"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "c39e6418-d7b9-462b-9ca8-1aac229c2a28"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "b03b84ec-d2df-45bb-89d5-1504f14885fc"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "6676059b-5556-4554-872c-1b22d064f791"}, {"source": "7b72ae23-713d-4ff4-af87-ccf478de426b", "target": "5155c8ff-0cc6-4e31-8416-5f941014334b"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "258db62d-1929-40c8-afe0-385f0e182428"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "db9dee4c-31de-48c7-9012-ed50a67f70db"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "88fde8ac-af22-4fd6-888d-3e12a4172e8c"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "552918f0-72a5-4438-aa27-fd08f1a72894"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "45e478c1-d85f-4171-9f64-eff35f9645ac"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "871ed99e-ec91-4108-a9ac-56062f790630"}, {"source": "258db62d-1929-40c8-afe0-385f0e182428", "target": "1673f5a9-dcfc-41c8-9393-f3581d25740b"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "e057d1ad-6899-4a4c-9cc0-74d48f969d90"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "f76a80bb-f251-4fe9-9ee6-c09ca9d8799c"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "d8b8324a-6e82-467e-822f-83cdd58ead02"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "11249ce3-4b3c-41ea-813f-e5c91576a30a"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "bee251d7-aba7-4c16-a46d-148b54e70acc"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "bf87d395-4424-4ea9-9a25-1386bd06b3e5"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "3e2539b8-fb8f-4d26-9d47-c3e8ef4a1433"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "511b6eae-a5ce-40f1-91c6-11bac5697acf"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "ed93277c-2908-4687-a569-2b40f3f992b6"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "76d6aa0e-0d17-4ddf-84cf-dcce843139ee"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "f8ad2cd6-59ec-4c0f-a367-91a55afbdb80"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "a5d44008-9b3c-482d-990c-6f86b24f34dd"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "6eff4254-044b-485f-a05c-38d69de870da"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "172a576e-ecf8-4801-bbfd-141e2e3f149c"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "a434416a-c869-4cc7-9a32-62d1caa37b1f"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "1c333806-de7f-4d52-841c-a35baec59695"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "28e67728-ab29-4827-915e-60cecfaea09a"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "f4b86217-f25a-4251-992d-379564a85fe4"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "06020d99-680f-4240-9e4f-39215e7fc222"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "3131e974-f567-42de-b8c3-0b95318f7e38"}, {"source": "e057d1ad-6899-4a4c-9cc0-74d48f969d90", "target": "1c3e4ffe-7943-44ab-afd5-c4f097064126"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "fae974ba-261d-4e05-a53b-428d050242dd"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "c365f2b9-5385-4f97-8a26-f014be97cfe7"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "0cabba36-302f-4e5c-8bef-a133cf9ad0a4"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "617553dc-db99-4b4f-a5c6-53d7232d7453"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "8dbabbe3-ab25-4c73-a4c2-69174b56c495"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "ea41c6a1-53a3-42c8-baf4-ea2a50781dd1"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "373e62ee-ca71-4e03-810a-256bfc95233e"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "4b31c0e1-76c6-4336-a012-4b612bb0cc1a"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "b0b37bd8-2245-4d96-8659-c4716722fd81"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "dc9ea710-c830-4d7b-a8be-4f4ae2f224f1"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "7fb98f90-8a43-4f3b-a3e6-ddd35467678a"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "eab4b4c7-cb36-4efa-97aa-1189dc9e1a12"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "b7e61cf1-2b0f-4056-a89e-6b4f89c18e17"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "41c8248e-de7b-4b3d-9a3f-5146a8c25b4f"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "ba941b2c-d47c-4f49-a1af-93bbe6b69621"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "8435f514-9ba0-440d-9efd-4cdb20a45a53"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "d482d47b-7df5-4bc8-acb6-62f33203b19b"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "dc0b0e89-8a7f-4237-b497-dd0cef6bbc09"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "1f67a386-8a0c-4f17-8cf7-72c0cf796358"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "1361f705-941c-447d-8b41-d196c966dda8"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "af7db23a-c6e3-4b64-86ab-af7ec1ffc257"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "09164c53-d9d0-492d-92cc-5bdcc0790566"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "d3586df3-decf-4155-963f-8bc19e456ce1"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "173ee379-e4bc-46ab-9c8a-0c0b365cfcd1"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "d7018ff5-54ab-4ffe-90ea-e52071855ef5"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "5c8cd405-ca4a-4dd8-8892-7e2ef488dd93"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "e62f7e25-52d5-4536-8c59-5e9b6cfe4a47"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "4630246f-b1e5-4a17-baff-088517e98e25"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "6f947af9-ee7b-46d2-8d99-5f9514e13e6f"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "e1fff94c-a6c6-4903-99e7-3103dc464ed8"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "e13cd0c9-343d-40fa-9329-2d6edd97f472"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "ea72f74a-a9e1-47f4-8474-562e456443bc"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "ccc9e104-e4c0-4fd3-8b3f-761eb1ef5bd8"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "c218184b-72d0-409c-96ce-a99d7e8807ec"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "3e775a4f-f4b0-4c7e-a613-d333a9b9bc7f"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "1867254e-7c57-4a8a-a312-c0a9db79b3ad"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "24ed5c94-2c64-4895-a7fc-a7a6a5af93b6"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "74d1c785-ee3b-4075-bab7-f09506c32a73"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "eaeef958-7219-460b-8ac4-0929b0f7e039"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "67d56e3f-51d2-4e97-b39a-47659dcdd1ec"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "608a3fbe-08f7-45d9-9936-a8dbd3d70a35"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "d7c87005-b75c-4bfb-91ff-a3f67c4234ba"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "1dc586de-596f-4f07-b213-89e9029f937e"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "c4d44553-b236-4cdb-a002-1954dd5a2586"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "11252096-edd6-43a5-af27-a425f807d9cb"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "c13d8383-4aa2-4130-8200-8896fb209898"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "ddce4a1c-de2d-4bb8-be4a-4e71f179f323"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "2532b86b-3a8c-41bb-92e0-95d97d3e9816"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "6b80db8d-a2b4-43cb-bc0e-b1a030dba797"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "0e5cac48-7d55-47d3-9c1d-2ea483f9568e"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "4018c2d0-2557-406a-abe7-a9cfc8a58464"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "60f4fd0c-404b-481c-a52b-640e0313d050"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "42a3c5c8-ce99-433e-9ce4-694214704488"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "63fd4773-9d3e-44e7-a208-086a3e789cda"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "d7064796-9b28-415a-acd1-83fb0c856e68"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "f9db6dfb-6ded-474a-a9b6-3ceebee00fb3"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "f453849f-514c-4d48-908e-278fcc2b311c"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "7c02f60c-7cd7-4667-823a-47cc6373df77"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "f4f402af-11b4-4406-8728-9111568e8ba7"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "b0981b51-3059-422e-a2d6-b27461860cc3"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "bb75f242-f716-4994-96d5-22a132bab5ff"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "0405c72a-ab63-4b5e-b6ca-2daa3122bfa9"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "df2f4565-44bb-4b64-be66-0fe7f10e372c"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "2db05a78-6c90-41eb-a439-e7bedef7fc8e"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "dd28958b-3404-4f83-bb50-13152b8af3fd"}, {"source": "fae974ba-261d-4e05-a53b-428d050242dd", "target": "3ed9acce-a23f-4d28-b2e8-fd27fecf98c2"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "6d7bc1aa-05c0-4c70-8ab6-f8981bbabd6d"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "10dba3bb-e40e-4acc-8c56-8d4f5bb0cb58"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "c098cdb8-15d0-4856-8c85-3ff907c0a5ce"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "5efb9541-75a5-4b3c-9d51-2e21da22340e"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "fc262b28-e9f1-4ce1-aed1-8b252018efdd"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "20f7cc88-8ff1-4c69-8293-60a197f495c4"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "0571f88e-26f6-4821-86f0-0107f3153403"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "48ed2c82-398c-4ca7-83b3-874ea397b624"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "7b341a76-0c7d-42f0-be8d-efa9db09d04b"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "c15c206a-e097-4ca9-a8d0-d6145e615cdc"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "65429266-a7b0-445c-98c7-c9005446560f"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "5db93692-57aa-4403-bf5b-0aa3b4d82248"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "208d12fe-1eed-4d9e-afd7-17c32a719702"}, {"source": "9ed441b7-810b-44eb-a0f5-0c8c824e2e91", "target": "945882e7-51e0-47a0-957b-7fcf0e30ae42"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "471067d7-5979-4cc2-b2a4-af2f8122a6bf"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "3da79470-4fb6-4005-9cf7-1e756919a017"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "7f07b8a5-51f6-4b35-bb99-e0cf39329c70"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "c4a27d02-4640-40d7-a97d-75c4499f9a27"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "47f32352-aa78-4386-869a-8bc45c06f1d8"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "b3618fc7-1b54-4ea9-a51a-4264ca588a7d"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "36da6b1d-a80b-44cc-af8d-4dd7700c361f"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "d7677747-bc2d-425c-b67b-8d3cae881abb"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "fed96d98-6361-4390-87ff-18a6c2b773b8"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "7cb09a80-a684-4a5d-ac00-83138fd9974d"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "c7a8ba36-1555-4d57-840a-c10eeb756b0d"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "0e099cc6-bf71-49e2-ac2c-b4800707ed4c"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "ef87e3a3-7172-4656-8f44-e25176ff83ef"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "bf941c98-47a9-40b7-940c-e1b7ec2ca805"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "6aeb9075-f100-4061-bc81-01513fcb300c"}, {"source": "471067d7-5979-4cc2-b2a4-af2f8122a6bf", "target": "c12b07a1-050a-4bc2-a842-cbb0e0818c1a"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "0d2078be-c9bf-465d-8ef7-9f0521b582f6"}, {"source": "0d2078be-c9bf-465d-8ef7-9f0521b582f6", "target": "fa8a269a-a72f-4098-96aa-84a739a1b683"}, {"source": "0d2078be-c9bf-465d-8ef7-9f0521b582f6", "target": "244234fc-70bd-49ea-8216-b01fa5df3739"}, {"source": "0d2078be-c9bf-465d-8ef7-9f0521b582f6", "target": "ed4d4536-0b5e-41b0-984d-b82d95187d16"}, {"source": "0d2078be-c9bf-465d-8ef7-9f0521b582f6", "target": "3ce2c6f7-d5ff-43f0-9378-33f8a4c3bb62"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "83aa5002-0317-4b83-a959-f0bec5b75a5e"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "55fd600e-1a04-4f8b-ab43-bb3b225668ad"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "28c9b6c0-127b-472f-bdbf-f8978c6f5d97"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "e0acbb5c-c211-4d9c-b59c-0c920739bca9"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "ce6d293b-76c5-49f7-9917-f41c08b29f4c"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "80bf785e-5be2-460d-9591-2364ca92a606"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "1e9cdd05-c351-44ff-86d8-f0d916015003"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "b160a12b-b6ce-4efa-bf19-b990471485a8"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "6b71557f-7846-4edf-93d5-ba0d13b95641"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "fabf067e-22ec-49cd-a200-77dec1af9920"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "94ae887b-0dc0-4004-ba44-b770d23ebf9d"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "a8299613-becb-46f9-b400-dd69473818dd"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "b214740d-c5f7-420f-a3ce-ee913bbcd2bb"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "bb3e1274-d41d-4c4c-9732-888edfc2932c"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "99ac7e7c-8b2c-46ab-ad7b-e5536e31e627"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "161f12e4-3866-4a0d-b22b-be2b52800836"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "ff09956a-62b2-4030-abb2-954195509c1c"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "2972ca42-95fc-4b19-87be-74a6276b60c1"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "2cff36b1-9336-4f73-9052-fb2d5f251fbf"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "eaae25d9-c12e-43f8-bb48-7cb9a689f32c"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "308fa6e3-6fcf-469e-b52d-b2d831689a66"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "952c38cd-047d-48a6-a65b-0628ebe70916"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "ce11c7c6-32ed-4203-a8d3-58fea07bfc2d"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "44cff836-5d9a-40bd-955a-330d6cbbb960"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "0f407efa-04b6-4699-bbed-c5d5bdeaac4c"}, {"source": "83aa5002-0317-4b83-a959-f0bec5b75a5e", "target": "8a433dd5-0628-48a6-8fd0-4b2d89f228c6"}, {"source": "31ff3873-09dd-4a41-a50c-71bd7924bc3a", "target": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "25e574af-386b-44ea-9176-3792f7839da4"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4885871a-4ae4-4bf1-9b45-32781b07249c"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4b6a00fe-8499-4f5b-91e1-288dc59a93a0"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "afc7cb35-d295-4e9c-8270-c7ada78defa3"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "a9457134-a261-4aa4-a42b-7e520b8eddcc"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "70fc08ed-bb9d-4509-ab01-e9b116b42958"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "f3dbec27-2b5c-4a52-8d84-950f27a3453e"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "14cc114d-3893-4bae-9926-8be2de2a87b5"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "6abf01c0-70b8-4451-b2eb-f2536e8f1b9f"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "f8cdd3a4-7da3-4e56-a7a1-2fd1559e3dbc"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "622439b8-70e3-49c8-a59b-48b4e53f7137"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "f1bbd085-638f-4a81-a2f7-73a8c2eb8792"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "58bff0ac-6f1a-4f1a-af00-a8a184fb97eb"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "9fc8a0d8-27e4-4389-b587-700eacf7e7ba"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4213e274-4db3-4041-b010-5ec1fa9f9cfe"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "0a78dc1a-552d-423a-8137-445ce028ca02"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "64b72e19-f281-4eba-a95d-7f2a2ee072fd"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "ff921a61-2f90-423a-a100-136999ce9fc8"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "2ee87191-74f9-4b78-98bd-bea7f8663c1a"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "83c78fe3-d46b-46ba-b11d-2abe110a2476"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "d72b0abd-f2ed-486b-a216-e748bd91582e"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "b73afef1-2878-4b75-98b4-b5cb5c1e692f"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "70e15733-e266-463b-a0b6-14d5818e5132"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "7cedd658-f372-4832-981f-27f6b5a74805"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4d10b3b2-2a71-4b14-9d9d-ad2148d43b6b"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c0fc2cb1-5a45-474d-a1e8-bbba29c319e0"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c0057c7c-a8a4-4986-a829-dd676c50ba9a"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "1409e1e4-8feb-4721-86f7-83a6e5385c68"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "fbea2a33-d84a-4ad1-9037-370e7b4290e5"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "ae309c5d-335b-4812-a802-462408b768d7"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "97030319-e6ac-4676-aa70-9bcf3016ef40"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "d0fc6765-5a98-4ae1-a828-58bf5c65a234"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "3681811b-4706-4a24-8fd3-7e2190f3d9df"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "07f07ed5-9b04-45f9-95f3-b88ebf28fd9f"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "6da87815-75d3-4ead-8cfe-47252eaff103"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "a78c39e1-34ba-4978-9401-dc2c6842888f"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c708e930-ab96-4be5-b912-04596a032371"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "1d1c1334-95f0-4325-8067-d7339b02d4d4"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c42b32f5-e288-4175-b003-d22db149c380"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "e5e4f747-ee5b-4df0-806a-1bd758fb5f3e"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "1a00da82-634d-46c4-89ee-334c451a1226"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c0f0aba9-df57-40a3-a9d2-858fb62fc0c7"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "54890076-7a6f-40db-a709-dd788f272b9d"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "2ce54cc1-74a3-46b2-8bfb-fa37a83a3c3d"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "5ce82d2d-49be-4f10-b11c-5a428653ff12"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "112ba019-bc64-41fa-8500-256661bbe22f"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "8978b73a-19bb-4e0b-8f4a-111622e2d90a"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "3f3fbf5f-6ec1-476f-be78-14a3cde380d2"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "e73219b5-800d-4862-8751-47efbc2eadae"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "493676d9-3f81-4619-817a-f65d222c7e55"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "8d14474b-814d-4231-be2a-3de0253dcec8"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "e0d5a696-05ec-46de-9d20-d8a5f76c7528"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4063f482-e8ed-450f-8ee8-c66d19a75545"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "a602d998-f4c3-4466-801f-a8c242642b5a"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "b403e2a6-e8f7-4556-8361-44317bbf3b9d"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "55a89b0b-7747-49e0-bd69-5b5c8ec02a39"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "0247c6a6-df63-4bfa-b447-7a8787a96903"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "20cebf61-c5e3-4cfe-967f-6aa6636fdcd2"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "4d31e014-74c8-405e-80ff-7082b8162403"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "c63f6bb0-c298-4820-b11d-9e22c5ac6ca7"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "115fde3c-f0f9-4b55-b790-1c347e310d82"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "e10d7ffa-94f0-4fc9-8ef2-c42480673dd5"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "17b5e47e-6587-45d9-891d-98df002c55ef"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "38b40071-a579-4059-b80f-90ba01417e2b"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "120118ab-5a64-4082-9ba3-772cbbf7e9d5"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "f0929d30-1595-464f-922a-288386db3d91"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "7911435b-d559-4c88-9bff-d2c705dbe017"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "670d463b-1ca4-4ae6-9726-c448b4112c1b"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "6cc3660f-3f34-44ee-98a8-a78de8af99b6"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "aacced62-941c-4b4c-b8af-637ede53d1b4"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "b62939a5-ad41-46ef-a09f-ac321ee3d918"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "d96cf0d9-add6-4476-831c-1aa32c89f3ee"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "e4174ad2-ca67-4bcd-96ec-fcde3adbb7a9"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "a26926e6-5f5a-48a8-a1fa-fbcec83e15b2"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "29c97baf-6378-40db-a102-7d41e0534934"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "8b0f4fa1-9de4-4792-89fa-8641c7a0714a"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "312eeb96-af3d-4da1-8501-eaba55b024bd"}, {"source": "d90d8c11-6a19-4968-a3dd-ed4c132d73cc", "target": "474ba388-fcc7-4ecd-867c-2650fddec9af"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "127956c5-13e1-498a-8ab9-afeae5c1fd3c"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "53c0e8a3-2c7a-4677-9c41-76489270a44b"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "44e56576-6bba-4011-a2c5-4849f19debe6"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "b24b1d66-c47a-4ed0-b0d9-38c00ef33532"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "b6d45939-90f8-4193-b52c-4c4f533244c7"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "06863c2f-71ea-4a73-889f-ae2d80fbbe3b"}, {"source": "127956c5-13e1-498a-8ab9-afeae5c1fd3c", "target": "66954204-d341-40aa-bc31-32d238d96925"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "53179e4d-922c-494f-af07-1dbd6bf44942"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "5ac8a4a5-4a12-4e7e-b18c-f8b9fb9d78dc"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "1029598b-37b6-448d-906f-a1059cdc3fa6"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "6ebce659-cbed-431a-a5c8-3f7af83a7f0c"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "d0aa601c-0192-44d1-a64a-1eeae67ecf04"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "1a5c2f37-ddad-449e-9cf8-cccdd2b63bac"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "8193bf84-783e-4b98-887e-3ae6ae24fbb5"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "a5c2082e-96ab-48f5-9a32-42820cbf3e79"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "0ac57517-bf71-4419-a62b-d854d474ef9c"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "a2199c46-ba4d-4b9f-b84b-8b43042f2a21"}, {"source": "532a9e23-1c3f-4f3e-ade1-5d60b8f6db59", "target": "cd4cacf5-a2b7-4085-9370-17162f838175"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "880fda2a-aaa3-4656-b7a1-e977a00c3200"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "f1f78dcc-0ff1-4fe0-9fc9-01d97500823c"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "4335f7c1-747b-4301-8d49-17f6d4f74b55"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "61b0f024-ea77-4f94-a179-b49cec865168"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "5829f823-fab5-4b24-baaa-5439b77dde07"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "1e0ac4ec-332e-461d-a557-3eb078542fda"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "02582b86-0b07-4d78-8dc4-0ab685051a3b"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "30ff53d2-7a78-4649-b1a5-65fb2e4f80a8"}, {"source": "880fda2a-aaa3-4656-b7a1-e977a00c3200", "target": "99055e15-a3c9-4e37-a50c-345c4dc6aed4"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "02b6cf98-6a41-4b83-9340-6e358e37690c"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "ad235b72-8099-40df-9d23-9e5f014f219f"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "e10ffca0-7bec-420f-9ef2-dfa0af1d8956"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "78a23a46-0755-491c-a768-b355bf9ac883"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "75ba7211-5d66-402c-b352-870c5c5fc7df"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "c2e74431-530b-4a9d-9ee8-4e729130edc2"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "8c1f0265-66f0-4b10-b202-76a2f1242c9a"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "5410b4e9-8754-49f3-92d7-940dedfcfd78"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "90d5922d-e61f-46a9-8e04-a5812d90421c"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "ee999324-921c-4e7e-9a2e-8674c6bd5b26"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "4ee8137f-1f61-4518-bca1-731110789368"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "84793bf9-7fd3-4552-8bf9-d7d5f37b944d"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "95f66dd4-14ee-44fe-95fb-539c21e972d6"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "43ca2678-654b-4127-99f6-2b042a9709cf"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "b96fddd5-0821-4f12-adf9-22c4cfdb5bc5"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "a946c6dc-3d6a-4957-ab5a-21b391cd3631"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "d8a6cf0f-e44e-4b06-aa4d-d956048eb493"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "f2eda3b7-2d30-404f-81ee-774f0d81efcb"}, {"source": "02b6cf98-6a41-4b83-9340-6e358e37690c", "target": "61d84297-720e-4822-81f4-924697a68574"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "b4878d9f-3e12-4b43-aae4-0c88f75c9014"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "5ff4d33e-ba01-4974-8f95-7f6d71687021"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "64a019bd-166c-410c-8b41-2f65bf2767de"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "d6e47542-eaed-4285-88a2-e8022631a777"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "1018273e-e8c3-4a40-843b-57825f2f7848"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "551136b1-0d08-4743-92aa-3cf9c94f527c"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "adf37d2b-064b-49fc-ae58-ca50a90cf438"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a2c86e8b-e3a5-4198-b6ae-b34e8229ea80"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a006e90f-5cc6-472b-9d24-389daf69147a"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c6cf97e8-230d-4785-81b7-66eb22a53928"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "241756b2-394d-4391-a938-f6d5b3000829"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ed0fe35c-4ac3-47c3-9783-2c7e0c1eaec2"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c63cdc88-b46c-4653-9863-9eb9d940c545"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c8ae4372-85eb-435d-8ad5-a8baf8975d38"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "6dab5bd2-ea2a-420d-aa74-3a65d5a34232"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "62b6a91c-1547-4bb3-a95a-e915235f34ec"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ac70c371-4503-44dd-9eaa-4eb528dde5d0"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "1c428715-c7e6-48f6-b68d-ba4c0bfcd8aa"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "cad68049-9259-4de0-8890-6e7cb3c44c99"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "d2e90be1-6ead-4fde-85af-f1def78f216a"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "80ace8e7-54f6-4f95-9694-df6348b6bb59"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "b4a7c50b-2151-42ae-9f4b-20f3ae205e61"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "0d1d5fb4-1646-46bb-9521-720c042b9034"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a688162d-b557-4ab8-b466-ca9ede84e97c"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "22c2bf2b-efc3-44e0-bfa1-9217d6454e5c"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c6f6c99a-5961-4e68-9bff-26a5d91b8e03"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a6325a21-086c-444e-b532-cf5136789ffd"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "80d8127a-6460-4f5c-b034-502ea81deaf4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "d864c113-363f-4a69-aa56-1273249c8ea2"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c8c59822-8fc5-4491-9148-ed7525bba2c3"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "4261b786-2ebf-4139-adfc-61fd531868dd"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ddb721ee-e9a8-455b-8f30-059d9e2c6fc4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e200c332-5782-40b1-9ed3-8cb0927dbe53"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "511d84a1-2caf-460d-aaf4-76018970175d"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "09a63235-081a-4ed9-8e06-8f7574277a99"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "67082d3d-9a1f-477c-859f-384136f58bff"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a2d7732f-6dd7-4e06-a954-28160f50016d"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "56e49134-eb55-4470-97e1-f288a240ccc5"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "54d8937a-7069-4963-b72f-eda366e12513"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "77a8b0e9-9649-4828-90a0-744537f6c67b"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "b5acea46-265f-485d-9699-83c910a82da1"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "f19b309e-0520-4e28-9c2c-073fac1e2d93"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "030d2fc5-8905-40d7-a175-24f88c033ce4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ef0f63ae-aa28-4f95-acab-0fade158759b"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "f93afa9e-5e92-4f14-8441-f151adf3ae39"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ea82d8f3-c73a-4530-a540-5b76e6ba451f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "cfe0f768-6f13-4c47-9fd1-011a740ccff0"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "0f80087f-b874-403f-94bb-db4c44d25c81"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "6c18544c-e0b9-4bd7-a3f8-048779362226"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "a7aa4f1e-f03b-4f8f-a871-b73eb9e3365f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "48c43715-defd-4cc9-9a45-7cb08ada61ea"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "37c89b41-2e4e-49a2-aed9-eafab37b1aca"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "5a586b01-3463-4cfe-997f-7b08daccb1cb"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e4375589-721a-42ed-9911-4ddb75cf96a9"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "2f239278-08af-4526-a835-316875404d01"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "79368f37-5e69-493e-9ead-7b6b59aa1187"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "9782fe7a-7f49-4a3b-bd82-8ef9737f6224"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "31ce7234-8ff4-4ae9-86e1-f60681e436e8"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "bc50c2c9-b572-428c-b0ad-3dfc21f5f2e5"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "db940594-d6a4-4111-a60c-f89e9c4f8042"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "9ea57142-bbf4-412e-91e2-b1aa22200af5"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "35d75adc-9744-478a-82e8-e44d147daf33"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "2666627d-41cb-4e9e-9377-0d1060606c3d"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "3155e340-3bde-46a2-bedc-acf6be48fc58"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "2d94bf94-c5ab-418f-823b-b99afa484eb2"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "50d74c6d-536c-461a-b22a-33bf42d787c6"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "5c17b2df-9c3e-48c6-9567-1fefb7810ee4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "2e191fed-47d6-4f93-843f-3851d596536b"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "70fca0fd-e91e-44e7-b34f-f85f76e0c197"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "bb0929f6-151c-4a88-ae53-e6078ae0ac5b"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "105b14c1-ca7a-434b-a885-ef8cb85d3043"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "d4557f39-e40a-4a0a-8c8d-2b4a6b7d2231"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e893a1eb-04c1-4fbf-8f2f-b9d8ec09a998"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "2693aeb8-e2a1-445a-a3b3-67e29d0833b2"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ee1dce28-fe6c-4fdb-9b94-f47bfa6b1b0f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "3bd57603-e8fa-4dd9-bf88-a7821d85f0d5"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "96d6bad0-e955-4af7-8737-f000c6ecb7b4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "46c30c4a-5e55-4185-b93b-05385f96aac4"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e1898f92-5649-4c9b-98a8-34c482e8fcec"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "0c983fcb-c5b7-4bd6-8356-20d61c33a95e"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "0cca377d-6fd8-4f9d-95d2-9719901e6ec8"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c5f4c355-5af4-4517-a3d6-3bae8c1bd7df"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "f9bd494e-a9e0-49b2-870c-a81ddf1894c1"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "b9b2d7a7-fc3a-47cf-8d20-859dc216f6a5"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "93c5b5e6-b563-4f6a-a7a5-fb173e47eae1"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "9af9a9ea-20e4-402f-b673-8e0a541ca07a"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "7fb4c939-5150-4de0-8dc9-f09d5575ca8a"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "85e39d0f-d8fd-47d9-94d2-92db32cc720c"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "dc2b4e3d-226b-4f38-89af-a0061767669b"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "41b87317-0bbd-4fe7-817d-3c4243e86fcf"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "5809df15-9228-473c-830f-a1d599667f93"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "dcb97a28-729e-4826-b0a3-6875547927ad"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "aad67ffd-0be2-4018-8afc-a121494bb3e7"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ccf1968a-ab72-4c87-8274-2c4e15704ffc"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "3a3edcc0-1595-4805-94b6-39e201d18116"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c908d9c3-4f86-4b4b-aae6-0e908084f9ac"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c754ce2b-d6e6-44bc-aff2-13041329f839"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "8b5f7ed8-4213-428f-8203-dcc6799d2082"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e542009e-ec20-4962-87c4-cc580f65cfff"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "ccef06f3-8887-4aac-b63f-4726ff8ba804"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "e7c2789d-ca31-496b-81f9-77ec4b243fc0"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "f89364ab-16c8-44ec-a26f-10ec6cdb841d"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "493da9f7-eb6a-40e8-ba38-642f7893e2cf"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "669426c9-3ab7-462f-b205-dffffe7292fd"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "39ccab5d-913b-4e02-977f-bc15a95f8564"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "c66c0656-1bd9-4f98-8964-9192733ad73f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "12c68bbf-6a84-4a4f-9dad-c639274b9784"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "92d4f84e-3533-4c9a-a156-aa18dcf148d7"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "8ecd6f40-8d47-4326-be4e-9cd5929f7442"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "7c6635c8-f52e-4f21-8d8c-76b25c6c69b8"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "1e3e16f7-6d2a-41b5-8a46-8f24ea1ce55f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "22829fc7-e112-4258-8f11-48d2df6f461f"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "652944c5-28a7-4740-81f5-bffe40280c26"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "93697130-8a90-483d-807f-45a3a325679c"}, {"source": "b4878d9f-3e12-4b43-aae4-0c88f75c9014", "target": "4d720143-554f-4b0a-981a-c4a6ec88817b"}, {"source": "a2ad232d-ce37-4701-ba85-fcc32868545e", "target": "dea98105-49ef-4357-9bca-83febeaf3bdd"}, {"source": "dea98105-49ef-4357-9bca-83febeaf3bdd", "target": "4d2c0210-9803-4524-a994-a2b258b84d31"}, {"source": "dea98105-49ef-4357-9bca-83febeaf3bdd", "target": "9f03a1af-dd49-464b-98f3-90c15e2d9f31"}, {"source": "dea98105-49ef-4357-9bca-83febeaf3bdd", "target": "8f7840de-3989-4831-8af4-6376856c04c8"}, {"source": "dea98105-49ef-4357-9bca-83febeaf3bdd", "target": "10790fc5-772b-4451-9a2d-48aa15a70f4d"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "5ba200b4-e4d4-490d-acd6-ad0d387726e1"}, {"source": "5ba200b4-e4d4-490d-acd6-ad0d387726e1", "target": "6ba50cd4-8fa7-4a90-9f78-8238bb653780"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "c04fd52d-7e05-4929-8766-58c9622b1165"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "da7872b2-59ee-467c-bad7-5eb767a2c650"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "1dd4574f-5615-4afa-9777-eb6f34b73a9c"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "1855b6fe-7e4d-4004-a38f-854543c4e2c8"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "f86d7117-7206-4e9b-93a6-abbb79c3842f"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "5da849b4-7a81-46c7-a591-b3b6d3476e29"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "c11ca88f-733a-4476-8efd-5824eada9587"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "c0636d6c-72ec-424a-9b49-3a34e6545075"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "b29c5138-ffcc-4900-9aba-1a0fc85a5e32"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "547e6f3d-e7ea-49c9-a8c2-679473f5a01d"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "d9d56341-0d93-43c4-8fe2-cc991391cee4"}, {"source": "d5a0bda5-5f27-4a28-ac27-7dfaaa515eba", "target": "94b350e9-a647-4650-bdc3-9e542e0841cd"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "69650cae-0632-4f4c-a2fe-63884f62de42"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "0179369a-195a-4efd-822c-7bf1c1b5690c"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "abf160df-9887-428d-a5a6-866daf23e7b9"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "6438495a-faf5-4fde-b57d-90d8a869e39c"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "ac4aaf87-519e-4685-8213-6549ed580cdf"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "3529fd4e-aaf9-4639-bb5c-db0f8630d910"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "a63f2c4f-c4de-4217-9b3e-873ed05b6469"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "50cd9636-1f1c-4d6e-a87a-47a992c6b6db"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "920b0af6-585e-496a-b0b6-fd11e8ad658d"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "3e8b51fc-9fae-4923-8023-899b5932ac26"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "99f39293-4ca4-43ed-9d90-9d62601aac64"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "19db0468-c708-4912-ad10-e4f9c5bed496"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "63f40038-facd-4864-bcce-dc186a4f675e"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "8a6aa43f-fd3b-4000-9779-e6b823dc128b"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "af21fc07-cb90-4339-96d2-f23d0c6fab7f"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "f69bfe69-e9fa-425e-baaf-377e717310d1"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "a00d13d0-5a1f-489d-a4e9-9172579e0d22"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "8930c715-a6b8-4699-a404-fe35540867c6"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "392def7c-2468-48b5-b11d-4df4c8f19d81"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "2c2d4436-d808-4b25-8aba-fbad03416450"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "5286b08e-a385-4d73-b59c-84ca4063bafe"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "e86faa1e-9c82-446d-8f45-98bb7572c3cd"}, {"source": "69650cae-0632-4f4c-a2fe-63884f62de42", "target": "6ab430f6-4ce7-46f1-a11a-c85c80d15ad2"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "a4bf0839-dede-4203-8df5-e2778701a546"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "25b6e815-19bf-4526-9de7-acf586f27b33"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "670cc1f1-01b3-434b-8b38-c1ddf74d2267"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "99c0153a-d881-4b9a-b9a4-a9d00c476014"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "41a57490-337d-427a-b2a4-a8cc7a245389"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "90add355-9990-4456-96d1-41d0b30cf129"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "95c801fa-dd41-4b1c-bd74-05f3ef1a7e44"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "39000609-3e2f-4270-b7f2-e3912295405d"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "088477f4-e9d9-45f7-91de-28f76f654c87"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "933b00b0-55f2-4d02-a530-f0e3a0aa843a"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "ec8c389b-d579-4053-bf6c-1c1528927d18"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "d9d9c72c-d34d-4adc-9051-614f695657d8"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "068f8e56-352e-4e0a-a505-a2a272ee3313"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "de72bb57-effd-4cca-8397-df5b7ff1fb2b"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "98100ed4-b0ec-4706-8e4d-1ae2625d2829"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "d1ba5a0e-46b8-46b8-beb5-8009f05379f3"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "9a7cd430-793f-41a5-a338-2ebbe17ccf41"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "9be5a5bf-5f21-4f06-8aa7-bc7359dc9119"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "911a426b-e759-4507-8fd9-69d317e7d34a"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "9df671fd-91ff-43a2-a02a-fbb53b696a74"}, {"source": "adfc3619-1d2e-4eee-b2c5-a1c5f2581926", "target": "db9a3d4b-d620-493f-8e20-4f6917e1f000"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "6e7df2de-c612-4414-afb8-9e1349a34202"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "c05bb7a5-e057-4b93-9861-979516641a47"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "f7ccc1d7-2740-45e4-8e1a-3e5438f0b8f4"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "334ae8b8-5b59-4b8b-b57a-53c12e521673"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "97682506-75b2-45bd-822b-6a8176e03630"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "7fb6638c-0871-4634-985b-200d79f90b85"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "2f0981c1-14de-4386-a9ad-902f0b0e73c1"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "d6273aec-a983-4035-9bcc-1996e991cf46"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "0d7614d0-6f9a-41d7-b363-0d41df1cd79f"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "821d57d6-b940-42f8-a8f3-b18a2fa06fde"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "f0160cf6-31c7-4c97-8a09-908d02cf515a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "e5899547-1aca-4ff4-9060-3cde79fdd42e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "bd363f9b-521e-48af-b82b-2dc07bf33c2e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "ccedeacc-e57c-437c-9568-f386ddf7b463"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "599871a5-c1a7-4d1a-9649-ccd977266132"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "1111309d-4d79-44e3-a96d-66f6850b4e96"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "cd897e6e-9229-494f-9f9d-974eadd91dba"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3cd61387-1476-4d5e-8874-d7ce9246b569"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "1e8b5624-92e6-480d-aaf5-fba2d411359d"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "9a8300d5-00d2-4adc-a039-d378c35f8f7e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "e14f1dc4-1d86-40e9-99f5-1a6300feb1b7"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "5979c2d9-0312-4d06-a9a2-98da0053316a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "bca40e4b-666f-4126-a7ad-68a0542461ab"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "8092a1f6-cd64-4f37-a8ed-601296ebdf57"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "14e02f2d-9855-4883-94ef-849ca527e025"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "ae219533-6a7c-4221-8d7c-c8099ecfbec7"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3f44089e-e81d-41be-a8a0-748a96e2b022"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "0ff71071-c3f0-4465-b470-b9fa46a5a99c"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "bee6f787-c768-4847-a3f7-78d265749e39"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "32aedde6-5854-4a6f-be33-1d88967d2502"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "5d93c846-f68c-4cac-8420-21204455d09d"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "d085f8c4-4ab1-4874-ac96-f74058c04145"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "edba0614-74c6-4d53-b436-eacfa1f637df"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "a058148e-52c2-4a76-8011-1daf1129538a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "b5970682-3d6e-4dce-8aef-ba4ebcc51860"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "6d3f9fad-8dcf-464c-bd44-c8ee7b3d902f"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "787ac569-8dc5-4973-b213-69442222460b"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "33d953d8-6d5a-4a6d-bd38-739c368d5538"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "fe6e768e-6713-4697-8161-456a770bff1a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "8d47088b-78d9-46bf-a56b-4159a4c78e5a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "2ae27f23-0eb9-4760-9ee6-3e9b9c827d60"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "63679998-cc2e-4447-9f7c-5d287f5e41c0"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "01760e1b-5844-4b01-9428-7743745fd3ed"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "687c65c9-d412-46ff-8933-3dbf77c3196a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "00f132a5-e96f-43a3-86b7-c95b59b6e0d8"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "493d78c2-3fd7-48f7-9d4b-bc737bbbb994"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "67dc4fa4-0cf8-4a41-9413-f7912f584a06"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "705e9794-a017-4859-b803-7be97a2f0553"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "f5d3c98c-07b5-4861-9f18-9e6b944aadcc"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "c838dcf4-02ee-4dcd-99cd-b91fbf3bcd83"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "df39b71d-37d7-4dbd-ac40-0b34e9860872"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "55fb8e36-dcaa-4d41-8ee5-9c0246eb8e74"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "83d8feef-1db4-4584-afca-e988daca225e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "fa59a660-0999-4dec-9539-f75abf1c6cd3"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "1e86d102-b350-4f4c-9c5e-be1da799d1d5"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "32b1f227-9767-4f26-ad6d-97726c2c09a5"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "f515593d-831d-4984-848e-3fc1a65e5f34"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "1535e79b-beab-47df-9a5a-51230b19e28d"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "ec007410-e3c0-4701-88a7-df058775aca1"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "e39ec269-76b1-4b5b-b27e-6094e293939b"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "2e61c890-560c-4756-aa3f-8346d289b52c"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "2bf6b590-df25-453f-aca2-7a4867b726cd"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "8dbfea40-98f6-45f3-a597-2c0cabf9367f"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "8eebccb9-0d28-4b0f-8e52-850d83878662"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "790cc66d-4a24-42fb-9f94-dee400be872b"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "ef79e439-cee8-49da-8931-af59dbb1b073"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "4ca23497-6873-4051-8551-cbea6a2927be"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "2c270d43-36ad-4b1c-98e2-42d22b653584"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "e19b7a14-963b-4a76-ad59-5b042fe0369e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "37403e65-7c2c-4da1-a0a8-dbbee42daeba"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "15ba275e-b31c-42c6-a0fa-c303c7d867c5"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "34015cab-1e61-45bf-963e-4df5976b674d"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "ddff309b-c024-4dcf-adc0-b4159653199e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "92734c90-e0dd-43df-9a7e-708b2fea37f1"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3a3f8f91-450f-4985-a0da-54fa94af6c28"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "0ad85553-ce77-4580-aa9e-61d96e36a2e4"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "eafd1f42-41f5-45d2-ac89-f0435aee133a"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3aebb518-f7a8-4edb-b5a8-4b00fb7f5612"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "31406826-d193-4c18-b416-6575c4675f50"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "15a143f3-96a1-418e-a325-c38586637271"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "768e597e-88d9-4ca2-8be1-17a3f36e0f23"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "e1a9e1fd-2719-44bd-8b64-4d94a3e35b38"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "a8ecc24d-5ab1-4d5f-b07d-fac6fd7345b8"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "a1a98e64-9baa-45e5-b575-139d7c4fe7ec"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "c259efae-b915-44a6-9c0c-c0d3ee88de69"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "0653e47f-47ac-41b6-8100-1b0dfc3b1aef"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "7c5848f2-a593-419f-a42b-bf12ad033e4b"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "dea3ed44-af9f-4d4d-a733-d43ed8208067"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3a6061e1-e2f6-4a3f-8bf5-0e8a8cbe460e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "a14001a3-e951-4858-9f84-413ebcf87ce0"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "aa1ea15e-0e1b-4f57-8412-8da9a72cd3d6"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "96a5a863-b376-4069-8feb-827b98775639"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "7ccefd34-1184-4477-b770-10ed89c86fe6"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "df95feeb-a004-42a7-8f5a-8edfa49fb237"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "3dcdd5a5-1547-44de-bb12-b1693289193b"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "bcbb67df-d90d-41fd-997f-4cb5eda12d8e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "cc4db44c-08d1-4773-9508-fb75e13c58ff"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "24eb285a-83f5-4328-9ca5-6f7ffba9d91c"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "912b6a12-33bb-4324-b66d-f051d012bc0e"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "f02ec76b-8c36-4a28-be69-a60bdc72a2f0"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "1713df67-49de-4eeb-b420-945ebf1653d8"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "5a772a20-3481-46d6-99a2-f93898a2cb67"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "0c4f4e02-4267-40d9-a5e9-d259ae26ec46"}, {"source": "6e7df2de-c612-4414-afb8-9e1349a34202", "target": "7f5cb0d7-a980-412f-a46d-4cec31d07c8b"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "c4156fb8-96ab-4886-b7f0-0ffe220a066b"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "aa0a640f-c1d1-4b00-b47f-08dee0661c0d"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "7239e606-0954-43cc-b1d8-a08c81c2211f"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "f5469713-a839-4e07-85ff-0383f8615388"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "88d776da-783d-4c80-a323-9318968880ac"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "7771a79e-36d1-4e5c-8402-2f1171d4ebbc"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "628789e0-b45d-40ef-bf25-4ecd9569a4cc"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "759a60a6-1cc4-426d-b221-c4aa026d6d05"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "68388a2c-8caf-45c2-b4db-7305a7f2e2db"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "1222c686-bee6-4a3a-bf30-a43a05c2283b"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "e9fc6b9b-73e5-4b2a-8b50-6b43e6b93af2"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "20eb3c3a-7dac-45e5-bc3d-82d2e4e20a0e"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "4f1550a4-632c-4188-8d93-801bfbe21642"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "ac34c46a-b528-49b2-bcbb-88e76590b21d"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "f65821e5-b369-4d84-9e98-d4a247029bcd"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "e2af4e08-62cc-40b7-b7c7-5f7e0963b520"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "8987e110-5491-4f39-8db2-026cbf42ca20"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "cf6f82d6-b772-454a-b122-9825a9fa86c4"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "8a20a6aa-b9c5-40d2-b0c1-aa312262e15c"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "9ab4e02a-d6e1-4c42-bd41-83e4592279f8"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "d1a417e1-8e3a-4cbc-bd53-7c90617cd02a"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "445c72c0-effe-4a2d-908a-d83af27f7627"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "2a0c5eec-7f23-4333-88ae-0e4736279dc7"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "a867c8f1-e4fd-4d80-991c-66f49605c6df"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "f848e8cb-67c8-4b1d-a22c-4107154518ab"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "470ff9ef-52ff-43c4-9edd-92c106054163"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "4ee97bfa-51da-4c23-8538-0c2e9057eadc"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "778e6e6b-5faa-448f-a42c-304b587d571e"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "c61f08f8-a1b8-46aa-9d51-732719233d27"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "5ca01379-9db9-4980-a351-9223e17a2a4e"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "b4d6fcc3-058b-4e2f-a532-6c7a9a15b254"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "5f177ff0-c26a-41fe-aa75-e857748fadd8"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "c509bf8b-d2a0-4f7e-9b64-f5c557ea854d"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "4ec1e8be-5825-47cd-9156-0f3b2b5fda5a"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "79e8e663-2594-4dc5-a10e-78835dc36cea"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "1e3040ee-6734-4047-a83e-b38f2301726e"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "5a21a5bd-d729-482d-a66f-432488f65593"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "329fd871-da0d-4183-88b9-e417c6fb242c"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "c647f2c2-8324-4bb7-9c78-cf50c89c3334"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "338a6c60-b250-45b9-b42c-efd1b68f4cf5"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "04648613-a4ee-4976-b703-236826289c68"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "572a8dd6-d7f3-4bfb-bf5e-e874eb0b65d1"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "e33e66e3-45ce-4b20-b9cf-d8cd33f47c8f"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "a0d4a1f2-4b9f-486c-bc81-2e17501ba8a0"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "e3361bdc-e465-4a69-96e9-c81c5d27dc83"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "0e213490-c77e-4f9b-962d-13984206f3ab"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "ed8e4748-0f0f-41f8-9a7b-fdbfbe091e83"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "34105398-0d52-4d70-8191-1d4e35e9348e"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "0dd40631-b674-4c9f-94bb-829e4d08e4de"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "250f80a3-546a-46aa-a6cb-9d8fbe497ee8"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "0fee9f5f-5a40-4f6a-8165-5426dcf36146"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "41f97cb9-f8f1-40dc-9c95-1d66bbbf4352"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "aaa279ff-7e30-43e4-a6b7-ea089f8dda29"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "f6f03617-dbdc-4310-8dbf-889159030c18"}, {"source": "c4156fb8-96ab-4886-b7f0-0ffe220a066b", "target": "2299ebba-5f4f-466b-881d-686f8607416e"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "61ea67f4-6ff6-4989-9b92-286f218dafe8"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "5984fc02-df9e-4886-938e-114589706396"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "c275cff1-74f9-421a-a760-a8b2e67dd83c"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "3a6f5e19-dab5-4b96-a3c5-745b22fe64a3"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "adc947d3-41f7-43e8-a0de-da98c628e5c2"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "61129ccc-5e38-4c01-bc9f-c224bd1506e9"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "9bf46afb-c32c-4144-80b6-7a1cbd4b963b"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "a5181f3f-390b-4551-ba1d-2a5d2a089985"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "ca1a3447-a095-4c4d-af99-d498c718c897"}, {"source": "e10d7ef4-ad8c-4dec-823b-5bb24f977da3", "target": "abf85f07-ecac-42f0-92a7-26f6e6d736ed"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "fd354cb0-f927-4b1f-ab7c-0a55625e361f"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "9d8507f1-dd92-4d1a-a690-9eda1f8c1bb6"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "535bf1c5-964b-4bd5-b5ab-9a70db44c638"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "a24ec338-38a0-408d-9c9b-c709ea813f0f"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "89a19c4b-9103-444a-8ecd-fae7ec427bbf"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "11f36576-de68-41b9-8e10-be7c03b6572a"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "06cfc48e-9a57-491d-b842-3ab646c079f8"}, {"source": "fd354cb0-f927-4b1f-ab7c-0a55625e361f", "target": "0d3b58d9-b7cd-4c73-ab15-9d60fe393f62"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "d8e5fcbd-2657-44b5-86b7-794cdff7b044"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "b1623b0f-7328-4c41-bc70-74a3f5e36873"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "7a9cbadd-42dc-4934-90a5-95e86a416d66"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "69fab4db-851a-4af1-9655-746e0186948b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "0e5deb96-8260-48bd-9ad0-6fa460904796"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "55ea90bc-4eaa-452c-88b5-c9f3a4492d70"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "48225add-0077-4bf1-b6a8-4e6dfd33b907"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "75b9d8be-5e36-469e-82a4-931ecc3ee81c"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "843f0f2b-5ec7-4933-925a-3f604fc95c57"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2666bd33-a5c4-475a-87bc-ed8eadb36674"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "216690c1-4e5f-4567-92f2-d8a681964a47"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "1b1ed431-a41e-4475-b812-4601765cce81"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "abeb7299-9ce0-4965-a78e-6d381563badf"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "cedbd97a-aef3-4d50-9e94-685ae4445355"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "d0b2b897-4b3c-4152-9bc7-4dbe27afa67b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "c6a59f15-e2a2-4cf8-a0b5-5570553f9df5"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "4dba5878-5cb9-4737-8e79-3f4fb4c68217"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "b5b84d4e-84e1-4f48-b7e9-69897998b417"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2dedc941-6592-4cd4-ae2c-5ac6e94bda21"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "3d25c386-97aa-4c45-8ff8-f85b0944fd8a"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2862143b-7eaf-4535-a0e8-d684805be7b7"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "655de17b-bc96-4193-98dd-55c9c5429fb2"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "dc50e231-0c8a-44e3-933a-afbd3203554f"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "533e56c5-4a57-4f3b-bb36-1f9521abc989"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "f9c9fab8-a195-4fdb-a4cf-323d875ed265"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "97da71b4-b9f8-4050-ac89-4fc480b30a12"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "88fa6a5a-0a9a-4f79-8428-8a337fe07c79"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2c89fe78-4f7e-44b3-81fd-102522d2bf61"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "4b228a8e-74a4-4733-9d69-a481fb4556a3"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "49569209-bbfb-4495-be0e-36f04959c919"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "5deb1abe-c2f5-4449-b8fc-c017f59753ec"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "f392d21c-daa6-47e4-aa97-11272f0b6807"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "9fa59c22-8a73-4996-89a4-a8d6e44d379d"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "67057cda-cbed-4e59-8bc6-f233ba224074"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "bfeed1f5-5f1c-42cf-a54e-abdae4a81b97"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "9afcda2b-477a-4eef-bb44-d41b587fb97b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "e83d1a4b-7563-41b4-b96d-7a15d4cec6e3"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "0669b0e5-2d26-4a97-8ca9-606f5266d67a"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "08e181de-bd53-45cc-951d-ffedc85ced48"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "f6ef6373-9f2b-40ce-b8d0-114ecaf10f7b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "0a3e0a67-92a9-47bb-8c66-fbc4e7d4a4c7"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2a20c15d-f0b0-42a6-afb8-2bfa41f07720"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "49468c0d-0e37-4102-9024-3e42b4c9372b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "bde6c473-0be8-44fa-874c-584c452c1a83"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "574af17b-b738-4f8c-8903-12e3e806b9da"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "5b48ee6b-058a-4632-9d3d-cc73589ee62f"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "8959be29-dad2-4b9b-8d05-f3de49aaebd7"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2fea4b4f-95f2-42bf-81bc-7d90315be28e"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "6bcb0e18-a874-4fe0-a82b-efba6001a76f"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "bc5df8ee-1b31-4196-bd88-3ccabef4e375"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "4a8e26b1-ca24-4649-9513-18b5a821a314"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "2878d5c5-daf1-480f-a7fd-8386eb81fd22"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "01012835-9cfc-4e50-9e7a-5981f1e92770"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "b935bd98-fda0-4ec4-8b72-3d86f6ca9eb5"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "91783241-db9d-4013-bd14-6953784f03ab"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "045318aa-d478-4b44-8584-79b386a5570e"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "d2f50a22-0165-419f-a8a9-33cd059f61b9"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "87869ad1-649e-4195-9b4c-e95c467a301a"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "90e528f1-860d-44dd-aa76-e2fdf4552132"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "984e2757-0b08-4037-8822-bfb75702b53d"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "486f530d-e06c-4ef1-bb42-d1212a994ba5"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "49d42f5a-30b0-4670-9753-9b8775a72c5b"}, {"source": "f88470b7-36f6-43d6-9a75-3dba5a8ab2be", "target": "00e3db42-1032-48c6-8db3-8dc3f9e13f74"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "e821fa93-7cca-43ca-981e-4124a6bec684"}, {"source": "e821fa93-7cca-43ca-981e-4124a6bec684", "target": "e309f28e-c0f5-4145-ba5c-aad0be9d6779"}, {"source": "e821fa93-7cca-43ca-981e-4124a6bec684", "target": "398bf631-fc48-4915-b749-73c87de888ce"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "b736dd1c-c42c-4326-86d1-df359cbd8f6b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b6afa81d-d158-481b-95af-55e3476df0d8"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f969bab9-9d5b-44dd-b3f1-687d2c4eac25"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "4583208f-55b6-41da-bc81-fc16fb37cc30"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f84836a4-333a-4387-aee7-8c05b6daee27"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d5dbe8f4-85a4-4552-bb1c-e31c4007e260"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f0ec2849-a349-4923-aa55-42dea3f772e9"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "714de004-757b-4b5d-b77e-2e3a2d29e032"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e724d383-bca5-4462-9be4-708634dace03"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "7fd4849b-046f-456e-a5a0-35c3f0a83666"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2006ea62-f48c-4704-b993-acfe22c969b4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "61f3b5a0-b503-4080-a27e-b3e92af48c51"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2e980fd2-ed34-4a37-90f1-79cd654ee631"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0dab2cd2-3752-4586-a06e-39f136cc63a3"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "39fc2299-3734-4e2d-96c6-530ddac09e33"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0439ab2d-53aa-4eb0-8f5c-61e17ade8198"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d029aaa2-3d04-4841-930d-e3c6df7d4ba8"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b0d72b1e-edf0-4bad-9a78-61b3b9fa06f0"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "12474f75-ea2c-49df-a59d-91df055c05c1"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e809ce24-c629-48c6-b4cb-0896ca645561"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "af5dda23-a3ec-463e-bebe-8bc1058a0a62"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d0678b3e-c7e5-4c91-b4a1-60c06b5a8532"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "9487284b-d0d4-4d59-a513-0f45f2a9f6f6"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "415275ce-0323-4783-8fba-92e29e848d7d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2acd478e-0b2f-489f-9bc9-23cb89913e5d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e32b26cc-b42f-47a3-aca7-387e814822bc"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0d2e8add-8b47-4dc3-bf6e-d46ac15b958c"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "40d43d69-b2e1-490d-a1b6-c1673a54aea4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "7a7e601c-7416-4e44-913b-eb6de0c61d70"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "71289ccf-cd59-4084-8cff-e8a22f80e0f4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "6adea3b8-04f8-4250-aadd-1ec3177f838e"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b890c11d-33e8-4fe6-869a-7a47ce2e1bac"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f2e767d2-460c-46b5-a030-1edafa2bf4f6"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "3d9395c4-9e02-4246-be11-47e84327b384"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "01397be1-956b-4921-9b5b-8c39ccb83e33"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "7904aa15-5845-4387-ad7e-a463c1bed719"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "8c0c778e-eb07-4624-82c7-6cc462857961"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f154c7c5-5b43-4e5b-a3c7-ab2f85e214d9"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "bdfc512b-d01a-48c5-b825-89de1f64a1be"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "c18b9568-e5db-4ef2-9b48-ac85ec46e11c"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a83961f3-6089-4e5b-bc0e-d1ca8979c24b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f031def9-0161-4bad-9c97-18a3be526b66"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "1ee4ef90-6142-4144-9021-f155a6c1740f"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "38032a37-6089-41f6-a8eb-6f928f4f0d2a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "11b87c89-0659-4aaa-8f98-ed9d0ba506de"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "053fa0af-06a1-4d84-86b7-abf7741b95aa"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "49b53910-2c01-4858-9701-c4fb29656cca"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e0c6f50b-d981-49d6-befc-edc3bb00a95b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "cedd0114-dac4-4f1c-8d2f-a036c3e06f79"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "81766f45-bfa7-4311-9bc6-d4f35691aa1f"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "cb88d45e-0c4b-4bd4-9de6-342a744ff66b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "c29e0563-61a1-471b-9ead-214190d09175"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b7dcf6e3-6bf0-4afd-ad25-372ce03ccc67"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "52b358e1-7bed-4d2f-880a-734c49c3f686"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a9170781-9dc9-427f-9fdf-bee6ebcf59d5"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "ed2adaf5-fde7-4465-b6fe-72377251213d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "244fbaba-1afb-4c13-b1e2-f0766364be43"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "efdda2e5-c373-4df9-a729-f65a8740394d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "cfb5a0a3-9247-48b5-b8ab-041922e1371a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "8ab7dd30-a8ff-4acc-878b-2f12c2ef72bb"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "1a9b7031-6fa5-4844-9d42-a9a7c51e1a61"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0cd3e108-9487-49cd-b984-d1ed99e65a38"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "ff540799-92e6-462b-8b56-ed09fe526ed2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "aff23301-63af-4350-8697-e6538daa68b3"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "329123ef-74f7-41db-91fa-cf0de6e3a0e7"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "794966b4-b7a8-4f56-bc71-ee5d25853890"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a076f14c-44cd-4469-b5ef-b44a352a318f"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "facbc9d4-7a58-4e27-a213-aaf6b4431dbf"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "9725a3aa-e0c2-469c-9487-65b66d63a9c4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b036e77d-0913-4ab1-bda9-f5aa78b7d1be"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "1b7ffbec-b89d-438e-957e-51a6d2743301"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "bcd2dd22-185f-4a09-89d4-50b9c6e9e4fa"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "639e3362-ea0a-4f98-bb30-93cb8cacb7e6"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "39afe640-5ab0-4025-aafb-34cf52b0fe6d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "21deba6a-e7f5-4e0d-aaea-7e62ca56b246"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2564eb75-f21c-4180-8a28-405dcc72d77c"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "8356b2f2-d12c-4756-bdc1-3e84bcce4fbc"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5fcfcb98-0d79-4f5e-af57-a328d33a4744"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "bb594c20-1c53-4211-916b-e8ff10fcf808"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "1279d805-3788-4156-8ca6-ecec00c2a101"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "9b6984ac-df6e-497f-a88c-1260dd065190"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "3c893731-819a-4971-97e3-9641ac9ab3e9"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "cc5b5d4b-5083-4bc8-8e64-6523b3e06ef6"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "572fcccc-8c58-4530-a401-9277ac3d6bfc"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "9ba325d2-e86a-4fa4-b89b-fe18486c7de4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "ea53814d-c5fd-454d-9534-ee49355d3ae2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "9c463f28-d382-4d27-9da6-8ef89614cc5a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b02212fa-2341-4000-a62e-f4f20411fe16"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "47c0d86d-87fe-487b-8345-79a0484c2f51"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b9684df4-d926-4937-b2e8-faf538dfe695"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "ddf1fda0-83fc-499d-ab9f-8a8a366b3925"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5a7efbff-23e1-4fce-becd-02002d7876d1"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d66c5047-b466-4291-ac8c-d24edc056c78"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "c2110a81-4d5c-4ac9-b6e5-7289fcea2cc1"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "42f6a348-2e1d-4808-b7e0-3c0698329b62"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e66ec2a7-f9b4-47bb-a9a6-e1ef7c2db276"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d208c70a-5858-4546-936a-27ed90a2af67"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "23484c7e-9b9b-4337-87b9-f77ade2adcd7"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "4174beac-d379-4313-aaa0-a2a9c80d5849"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5a35cb57-ecfc-4112-a417-aeb38fcfa936"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a64e337d-59a4-4af9-a151-83d581b44928"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b4f7a37d-caa4-4197-b94b-de94810eb76b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "6629c3f7-1dc9-456e-8acf-b6590b32ef19"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "4b85978c-fdd8-4e58-8f06-b31065f0fce7"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0d2e7d41-9e78-413f-81a5-8fce5c12e6e8"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5f8df9a7-159b-4bf0-98a2-a6f46812e8de"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5058e1fc-90ea-4102-b616-ef02c7fab3b3"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "46c59ac5-5003-4d37-95bb-2d0450d1c34c"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "4fdae50b-99dd-4921-9f55-5a0ff6d86c1a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "6038996d-f42e-4819-b502-83ec39f1761c"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "3bd2756b-774e-4614-942e-19540f1ecb6f"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "c64ff34f-13f7-4a27-b633-d2c52b7f6024"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "15a82e2e-a68b-43dd-8b0b-597572134ab3"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "eed26829-e48d-4d35-9c54-064a3dbbedab"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "dcf99e33-0a79-42cb-bc1d-ba0cc343c8c4"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "c7bbccc7-84a6-4065-9142-8655271a00b2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "fa84cae5-201e-44a4-8287-dc3270e23eff"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "4a57b3ff-3982-4bd5-b7bb-1b079fe7f45d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "14541594-9656-4318-9081-85c5f67840a7"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d3ae541e-ff11-4793-8414-0bb816dc8671"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "00549f9e-d682-47e3-9d26-24c825f28821"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "08ebe1c6-0f5d-4bf2-a014-2e051cb27a4f"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "0ca3f744-a9ab-4f2b-b190-dc97092bd2b1"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "b534f622-6978-4b55-9118-66a7400c3ff7"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5ed3553a-89ac-47bb-b234-6fffef819a4e"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "1bc04093-0ce7-44ac-a3aa-a0b4ad581a25"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "732e86a4-2610-4a7b-a4eb-90602f716173"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "e22fbc7a-19a0-4dd3-a92a-afc75797b325"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2e84cc5a-2bb3-4723-b68d-11c3f3b4a12a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "d1f0443f-189d-4311-a876-00ad6a085d68"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f472b1df-4524-4c2b-b186-3b9d778326d2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "59d5970e-1e8f-478b-93cb-e635ba7e8b4e"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "96e17db6-614a-438e-9558-dedcce348e82"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "33219e9e-74a3-4cae-8462-da694d6d96b2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f12db879-4814-4ea3-8efe-dc407d6c3cbe"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a9cf58e9-c512-4753-90e0-e032924521c2"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "eafa22b0-7cd4-4b23-899f-1c5895936715"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "85f625d7-afa4-4336-ac0a-3265bae42fd9"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "033f3bbf-be39-430e-a6e3-c4e3c5e901e6"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "6c6b7bdb-1ebf-4fad-98a1-7b26b794ca7e"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "26f4c237-625c-4c47-b971-07254e567aaf"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5a5a35ac-5d58-41a5-a0de-73583683d41e"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "5dca1c64-fdc9-4d10-84e3-cac41c76a4b1"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "fc5c5c26-7e4e-4713-84ff-92964954355a"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "2deae15c-0ea1-45c2-b637-3eb73de17d77"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "975f8684-a616-4c24-ad8c-0293fc5b1e96"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "17b3a00b-9827-4e19-817a-6f14da19b323"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "a260c9f6-99d8-46e5-bab2-614ac158927d"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "dca7bfa1-1d5e-4c5a-bdd3-e399ad82b100"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "f983d72f-f156-464b-822b-7e195380139b"}, {"source": "b736dd1c-c42c-4326-86d1-df359cbd8f6b", "target": "539f0350-b2a3-4963-8d89-70c12c04d11b"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "b11bf143-b2cb-4263-afa1-361f8e29a436"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "f8dcb302-a770-4229-ac35-592eee1d1bda"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "c9c0448d-d5a0-4b0a-a5d0-0419a838be98"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "f8a8d58d-b38d-4714-ba5b-0309c8eb74d2"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "28a624e0-857e-433d-96ce-33a784682512"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "94580d45-07a5-40f9-907e-4eace2e6a15c"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "01f0e759-31a5-409c-a382-a3830258c955"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "7c554e9c-1d36-483e-a260-acede11e66b0"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "eff60450-8818-4b6f-b1da-7152d70f344e"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "d9687f9f-deb4-472a-80ad-e2370ce12dff"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "f63ddde1-43dc-4811-afc8-e8927bcd2247"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "722fa632-e47a-4d8e-89d8-be6edc7a89b3"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "0fa8d34b-692d-4b16-9697-eb39bf681340"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "40a291f9-20e7-47b1-b7d7-269140593406"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "b3eeebda-1940-4335-a649-41459a2c9d75"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "d33343a9-65c4-42bf-a98f-d6bc9ec96f92"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "ef943b65-ad82-45ec-b844-0f26c9df4eb1"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "23afc194-33cf-4b90-9ea9-8da3fa2c4a9b"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "5e8e03ab-71f6-4b39-9330-94e6cdf9d39a"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "59122db3-206a-43de-a95c-14232732dec6"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "3f982c93-0558-425f-8ef1-5b71d27507eb"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "d85fabf1-cee9-448a-bc15-af79cc620575"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "89059221-8da8-4329-9831-3fde160aa6a0"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "59a822e9-a6db-4e78-9e10-624587e9dc70"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "bfff7359-53bf-412e-9ddd-8ab263118895"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "aea8806c-6dd9-4d13-a9b8-38e84802848f"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "16fae81f-8711-4f49-a073-55b99483f2f3"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "0b32488d-9cc4-4292-8179-ed00faafec5a"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "588a1df2-7c68-4341-83e6-c87fa79f6b69"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "4c1ec541-a420-425f-8d15-16839a7ddf51"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "e5ffe131-9b32-42f9-aa89-edf72ecf9afe"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "c6ae10b1-a178-42a1-b77b-4911643a9cec"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "c7eb709f-80c7-4326-a4f5-ca75c7dd9bdc"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "ec3f9528-8fe5-43f0-8aec-7d047d69d02e"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "7c72bacf-e80f-4cf7-a67f-062469e9ee8a"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "d5445b3b-928f-4e5b-b20a-547c1f37a38e"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "f96b638f-8675-4683-9e28-2cdf755de86e"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "216abebe-bee1-4a25-b3da-1c4fc02a4025"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "0717a96d-56ba-453e-8207-08119aecd0ad"}, {"source": "b11bf143-b2cb-4263-afa1-361f8e29a436", "target": "799c3e79-c508-43a7-9f25-739bfe6137e9"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "c1061e81-8d07-45e0-a7c8-24f379317d17"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "f1a165d9-ad85-4526-9016-6e9115be8659"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "edeee891-ece3-4927-8ecd-3c331c28eb04"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "b9b48caf-66f5-4444-a88f-0f3c28a362e3"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "7d897331-c5b3-441b-ba6d-01f6c7b04404"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "b36893e5-c265-46d1-8ed8-735d0a84c006"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "e86a35aa-b811-4143-b21a-8ff82bcc01f3"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "dafa0eb7-d7f1-428d-9ee9-707ae76e742a"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "ac7ebda6-2e2c-46e5-a5b4-6be49e683157"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "e07d1c9c-2fad-413b-8916-a91544f58260"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "3de91d72-fed1-4b72-99b0-1e02ad678b02"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "082e4b4b-2de3-4948-9a8a-7c0e546030c2"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "f0b30f1d-8a67-4b38-b3c4-fcb022d01a10"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "0b11ee58-bdd5-4607-a229-96c7d138db97"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "d4af2926-5653-49fe-a42d-42d3f7cb7f84"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "6e5af12e-754c-42ed-8391-055b32a6081f"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "eb9bf095-9d67-4a54-bbb5-4937638c33f0"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "538db44b-96e0-4beb-8e17-c5a9835d0f13"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "8309a196-0ee6-46b6-a088-57a29fd3f91a"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "e1505d56-401e-4b4f-aaed-3e17ca74aacd"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "1213f842-e42f-4c12-b633-f237069be6cb"}, {"source": "c1061e81-8d07-45e0-a7c8-24f379317d17", "target": "7459b7ca-66f2-4f18-8980-c19c77d9315a"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "091371a3-dff7-49ae-84c9-131644fc746b"}, {"source": "091371a3-dff7-49ae-84c9-131644fc746b", "target": "b033aa12-8f12-45ad-8eae-f46505b7341e"}, {"source": "091371a3-dff7-49ae-84c9-131644fc746b", "target": "aca5c7d9-4be6-483c-9840-7fe93a2eb8bc"}, {"source": "091371a3-dff7-49ae-84c9-131644fc746b", "target": "9f9e2f8a-e338-4fa3-875e-7a3a6a3830ae"}, {"source": "091371a3-dff7-49ae-84c9-131644fc746b", "target": "c7a77a69-17c5-40c0-bb9d-43598f4f1f17"}, {"source": "091371a3-dff7-49ae-84c9-131644fc746b", "target": "fd5c7d35-b6e4-4321-a49e-30e49b6f2a35"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "b6a06a87-870d-481b-a5e5-6b884e102aca"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "31cfd2ef-72d8-43af-b9bf-b0ad9c64e82b"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "290fcf1e-ce5c-4c4e-9265-a51724689dce"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "870af129-a380-4e69-bc63-fe28bcaecf68"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "37c20f55-0d6d-4402-86df-bdc4255ec596"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "af277c11-2fc4-4d10-924e-2f3d2f6913ac"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "a94cf33b-a68b-4fe5-9d2d-c51115635496"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "dee9d891-373c-4d2b-b357-d5be3711da86"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "c2b39edf-0e79-4ac0-ab06-710fb0597bcb"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "c0255e9d-f568-44bc-a420-cc494d872bb0"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "737d53ca-8f61-4ad1-80a5-687824226242"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "1d19409c-7698-44da-ad03-1e636d0ab223"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "aa7d36a4-d288-49b2-b524-e5df980062a2"}, {"source": "e2f85281-acd6-4f9f-be7d-b1c76eb9336d", "target": "4e9639d9-2dd8-4ede-b71e-54444186a73e"}, {"source": "5abe140c-9fc3-4ae6-aae1-40f931d178fa", "target": "510c0569-37f0-4f0c-8600-114a083ae502"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1ca6de4-c438-4ad2-9864-ec7c32556aa8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9434a4ec-cc5b-4503-a7e3-3ee61c0936e8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b455b21f-d9f6-4c95-952a-b7080e311579"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a3594096-7b12-4c1c-9e7c-4cc91973c6bf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b86b299-cbcd-44df-b66b-19635b19689a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b7df26fa-743e-4eba-a376-ca1c418325f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7cb41fcd-83e0-418f-ab77-86feb7cc3ab2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d110b516-abec-4fd6-8fea-d8b085563c0d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1915cbc5-7194-4605-8be4-83e971ec2b12"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aa419d4c-5ebe-4ffa-b34d-b570a700edad"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f8ae59e0-b33b-4dea-8784-0598752b7b92"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4b2668c-ff16-4575-91dc-0454efdd7e52"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aed5e3ba-f89b-44ac-b33a-1fcd55d3657e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "852eb35a-bb84-483f-b92e-32e33c13cbee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb2cc655-e612-4738-bf32-c51f25fa8a7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "33c35fc6-9d63-4e10-a474-91e6c9fbca1b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eedb2735-b16d-40f8-9c60-8841cb9f90ca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a91b8c62-ddc1-44f7-87e8-420d0b9f5cb1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a3ff3af2-b3ab-486d-94d3-780590930f76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "147549a2-37a3-4d44-a49d-ba353b3ae830"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35aa39e4-642b-4f06-8d81-331016d4b315"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "28e042e9-6732-4625-8337-801d230203c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eacc632d-036c-4386-9576-70e408e1f601"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "40725b2a-afa3-4518-aced-45d8be6d727c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7a518cc6-2c8e-4963-839d-26db35ac1f52"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef8e9640-ed2a-483d-bbff-be6df281a52d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e575651e-a20b-469e-9460-359ae8e03a6b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c70b1f68-69c9-43db-bf13-f07e2fcf71a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e490c2f0-bf71-4bb4-83d9-431b1d459507"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1d7f5715-c7c7-4e4d-a191-b246d1c6fb02"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4541d277-c1ec-4ae8-911c-209cd794a21a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0e2dd2ad-5dbf-4ad1-96b2-fa1b0c0cf933"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c930598c-de85-4a00-98ed-c479d915f370"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7aabf9d2-19b5-4389-949a-b4c893085416"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7be28ec0-96b2-4f3e-a3e7-66450e6ba6c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a4bf290b-cf9d-4906-a7bf-a6f569d83cf1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cdab84d3-26e2-42c8-a6a4-c8378e5facae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "105a4050-4c5b-46cc-a33e-b2688e642412"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3027efd3-3f0b-4202-96a9-e31756d287f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8dfc751-231e-49c8-8de0-076432960046"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7db10503-3c12-4b26-8ece-f10beefd38c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6145a3a-9257-4e4d-8a0e-e407614b0e4b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4f07e24-af46-4dbf-9154-392fb160a8a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "62243b06-0634-4bfa-a4fa-b74df13ea87c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7a9b89fd-8292-42e0-8be5-d1bdb0ecec6e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef00b035-6597-4062-920b-8e94811423b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9f1d0518-611b-489d-aa6c-d528692d793c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d11e1e72-2370-414f-bfc3-ebd3fd73eba2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8889dcf9-e897-4eac-ae4d-842383b58aaf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9a90459-b93a-46d5-ac26-bec4b2f8e1cd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "13b6c075-2e11-4d77-8d4f-8a2fe9b16c0e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "91aefe66-4f0c-4c7e-8e1e-c314b3068788"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "65f44f20-26c5-4d0c-9b32-a70170b8b7bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "765ef07a-c6b9-47b3-8340-a0f102458b61"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "579a3192-f1f7-43d2-a77a-9258fb4b3882"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2a9a5d87-742a-463a-a9bc-dd6bd4dc0e4c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1236c589-7970-43f8-a405-190f3418147e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e344d7b-763e-4acc-bef4-2822971b1d36"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "932903e5-7031-4986-abac-51c6a0a93c6c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "942a9be1-d827-49d5-b9e4-2baccc1ea349"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a019e357-e57b-479e-b272-af63f7b7f39f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dd235aa2-3b6e-4ff0-80bf-9c0434fa918d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b987882a-4936-4f96-9163-ac6e6e7e0566"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a784bc9d-276c-4f41-979f-4a9f019cfd85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2b307fa7-29dd-4979-b696-5ad7325dcfdb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4c332ea-c17a-48a2-86ec-a8cc76fd8544"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ea513f2c-d8be-4091-8f0e-04dc2c59c4bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6c99abb-1361-4fc0-8291-7d84c38051e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "61dfa7a0-cce6-4f48-a1b8-d84627d0019a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8db4375e-3f01-4dfc-b1bd-141fa6acaa9a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "079f78f9-bf35-4374-926a-a04cd2e7385f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "622ea381-7399-401e-8497-bf84c439ef21"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1918833b-dbbe-4c1c-b5ad-25d738467075"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c818560-9332-42bd-b8b6-28234081a99b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "746b10fe-e255-4b68-804e-e0cbf405ab65"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f809b202-9cc7-49bb-9e85-e4bea1ca431b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7e72c67-1907-43c0-8936-eae09789c937"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "367fc427-e521-4716-92fb-ab0511a5c46d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ca80ae4-cd2c-4384-b732-d96045afae7e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a36e44ca-0651-4046-9ca7-28f9fd34ea7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cd3e3b1a-e5be-4d02-a149-e5dc1c677f5c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "38a6d065-0825-4051-9a60-f7f23021a0b5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92f5e9db-3d0c-4fd8-b794-3dcb5386b4e0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "558d7c54-2d72-4d94-b12b-0ee654d2a9c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e68954b0-01cb-44d4-97d1-b9d16c52f4e8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b7be88e-0388-48b7-9837-a1d354ca40b1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ef63336-cf24-451d-8805-d4d978c182a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4cdcbf54-18d5-4b9d-81a4-d6196461d569"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0341e172-a981-42f7-a09d-5d1978535342"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "978060ea-e949-4307-973e-afdf9e90de57"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "be57c1af-3ee8-47ef-8920-b78bea9451d8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5f021a2f-bdd7-4d9e-842b-c66a98f7fa4d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7ccfdf23-4f7a-4d6f-a012-cbe33cfabf74"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "44b885c2-c145-4e4c-840d-b34c0e6d3a69"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "17a039f4-9de1-4545-b2bd-7d1070d04c60"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b69a0b3d-b8bd-46a7-8cef-1d8977877adc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab8eff68-7952-4fe8-adc7-43645ec3b8c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f2dabba2-f71e-48bc-93a8-f8e76937bcd4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f459f051-9b89-4888-a141-635b208ecaae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96b32d06-e9d4-407f-94ac-0a173ea943bc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed38a95c-3e3e-49e0-9210-f6343a6f04de"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f59a5dd-9ba5-4480-b543-ca3081c3b6b2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4f91b30d-0f7e-47f5-b117-945865797dc1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "79fb35d7-eae8-4e03-a742-c80cd545e195"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a34506c0-b074-40b5-8dff-81fff5ce287e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a2633753-6157-49cb-8ca8-f5b858e52147"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6827336-3233-419d-a501-5bd44b468205"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7dd8c1c7-fdc8-4131-892b-5575ae0115ec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0d13bf0e-a9e4-4c36-bd4d-4439acb4c0f1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "905de49c-1528-4385-b901-b95e19c9c096"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0bdf7eab-0340-4edc-bb86-f350f77a5b94"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a798912c-0bfd-4bb7-9308-6762957aa6e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b816f65a-d479-43d9-851f-f43277a3c03d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1615517e-ac63-411d-b66a-16e7dd22e3c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7467e15d-4c1e-4548-9d33-5a398878061c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fadf53b1-1a3e-42a6-a96b-a8c46bf455a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "216013d2-d0ea-483a-b25a-ac4bbdc48504"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "14b0ed66-dbce-4c85-9086-9c899158a6bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90fe7cf7-ab33-4547-883c-3c019f038f9c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c08ae35c-f109-4ea2-8542-a83f9d26975c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b926b1cc-28a0-4be9-98e2-e1cde1a168e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b96971e7-2281-415b-a451-4e0615b11b74"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "13a97942-750b-44d0-b51c-ba995aafbc4c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "878046e8-3805-46c9-b064-9fdbc2eeece9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e5fd877a-2495-407c-b27f-9c2682a0605e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb180cb5-ce61-43a7-a155-67a8005318c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab6f9e80-4f95-46c5-aa56-3f52014d509d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee80ceeb-bffe-4add-aedc-2a5bb3a7c582"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "18ee684b-22bc-41ac-ba55-031175940344"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2df60063-d1de-45bc-9c7b-cd63fe9fe621"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5486ece5-a734-4b23-a8b3-af71f79c3ef3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6814550-8b48-4f0e-a516-18a3fd152405"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ea1f49b4-3097-4fec-8c0b-23f938e5d80d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c54dd257-d762-4919-a30b-5420f2f07bd8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "016252e4-9ce4-4818-ada0-85e806b11e92"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92d8f65e-e01e-4415-8700-53d0620cea09"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2e6e1e27-1200-4638-9f6c-7146676a9f76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1626eb3-4ebf-4356-8a22-5fde7ed4b4d9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb5c3282-e649-4d80-a07b-19942255f2f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "50624163-0ec0-424a-8051-53298cccddb9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "89177513-4300-4469-8886-605db97b87ba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "61da8540-797e-45f9-bdc6-6f1e40cb5c82"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "06c70ff7-fcf9-464b-a953-409b385777d8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "350283b0-4972-4b90-9878-61ac28eb7dc4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "542aee8d-0d2b-4582-b588-ac51973bc837"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "710518fc-07ee-44dc-8a67-7d32cc9c2685"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f290ac1-447a-45cc-afe7-8b223177d16a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5f419233-f245-4dd9-ac35-8cc6ee0c1005"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb941abc-0e8d-4eaf-be3e-ea031cce0215"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f04bcf7f-6a06-43cf-aaf8-94a99a5515bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6300c32-315b-44b0-98c0-778ed6f0d8b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2bc1c6e-f64f-4d40-add2-e97a748d40ed"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4d0a777-2cff-4a95-bbdc-3ff42f51518e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bfb22cf7-118c-4d2f-bb59-3018e3fbcd73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2b4b6340-25a0-4ca7-96e6-6977ec3be147"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5863a1e3-ca00-4640-98be-1e5b12cd8cbd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f7145cb8-4737-410f-ba91-910fc21c6ee3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bffe1a28-133e-40fd-a086-24ab433bb27e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6ba5adb2-223b-4aca-ade1-3d66a2d78ba9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "698d2156-2929-4f65-a004-1366e0649b2a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57d06413-8ca8-4ab2-99c2-243b7c355e48"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "21b082f0-8c82-45b7-9cf4-3bc0c41a4bb8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc0d2d5f-a5ed-4976-86ab-4940f3c30837"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f4934de-9793-42c2-8dfd-7afb5be85187"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6344d2d6-4cca-4c56-b492-955a8a3b202b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "476341ec-0dd2-4c50-af9e-8153b3001eeb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c0e404f-82e6-49f7-8c3b-b124b1b721a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7910c3b7-579e-40a3-aa6b-b59156d2c94b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2268d4b7-75ef-4065-9c62-f751d5eda68c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "12f9e7cd-7b68-4d8b-b2ad-59aa588b8826"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cb2d47eb-6223-43c5-8b64-6554bfea869a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8c57ebcb-1d54-4cd0-a8f5-b9d3c4896b77"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6a63f0ea-1371-4345-b407-d67dc4412ef5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "99881361-0d90-4cec-9b9c-ecdc62e0b8f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d964fe22-fd62-4b98-a5c9-f7c2ccc6e341"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c44d8529-6198-4a1a-a18c-bbacbaa4d554"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ad96089a-32b1-48dc-9703-c47f472f685d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8ed5e0ba-b3a1-459e-96a2-5decf5b2fb14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "21bfe57b-87c3-42a3-a183-c82f8f52d6e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d3fe327-8a22-4377-9911-3b81eafbe18b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbc7e130-ff70-4d32-88ff-16aca88ce428"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "002132d4-0a7d-443b-b32e-c6b02686fb95"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d498a3d6-8319-4242-8f2e-66d1e2835b83"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8119230-7aa9-4630-9d28-20d549cd2c14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb448ae3-8924-4546-86b5-d4d5264d8614"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8469a28d-5f3a-456d-8699-78e583ca0eaa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "acc16f2c-b637-44b1-989a-deace6fe0719"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "832951dd-8836-4eb0-b198-df24befe3b23"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "057e163d-3a4b-4b01-b84c-a58554724404"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c7b4c2b-d577-4865-a9f5-26be1444cbaa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8cc55668-7b3c-4c52-9cfd-5111dc3b4a37"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e3bd1f93-07a9-41ee-917f-81131e8d9262"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "be804bfa-cbb1-4767-b06c-3be57b788ea3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "da1c052b-4d17-4b5a-ab9b-4f349525488d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "46590df4-49eb-4bfe-bb70-1ad5baa61d9d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e57de46-a821-4235-a606-1037ca418d7a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "332d312d-0555-4aa6-a8f8-71ac0d39dd7a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "03852dce-082e-4890-919b-991778f921c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2a7cd845-0af0-4db7-a1be-c1b70c84a7dc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "34e33e5a-592d-4c45-8620-c6b51a23eee5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "258a3d67-79d0-4376-a699-86e335ec0811"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef9f0e0c-35a9-48c0-8f39-8abd9a52147f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e3c2d48-632a-49ac-8f0d-81f239d240bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7860071d-d791-4ffa-a4aa-4100e104ad10"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6736d79-43a7-4bd7-914a-fa7d5cf07858"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1c5c8aa0-55c5-4db9-80d5-ed5fbf8723b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aa332e0b-d8ab-4d09-a447-dc07038305c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bab2b06a-20b3-4181-9212-837b84e624d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ecb1e42a-4434-4edc-874b-501874431e0c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b406b570-82c1-4922-b65c-b01b57512f53"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a4083288-e5af-4e91-a393-e24c9460912c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3467591-7ff3-4f16-8842-8efaeb3953c8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "810286db-9db8-4e75-ae82-521d1db1b510"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe6b6bcd-c1c3-4c44-81e7-06ec95d646ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "655543a2-e08d-4bf6-a248-750444af1ec5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ff13e4f-44f3-4eb8-8048-ccf6b8395da8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d0d984aa-17a7-4bb9-b78b-a76220dd4926"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "db950230-3c06-48ae-80b9-8adba2829876"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4b9f79d9-eaa9-4ee9-b55c-07cc10904bff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eed83a95-6ce6-47e4-af8e-9a90679a7746"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6967cde1-4ecc-40b4-a5fd-e4f6c4c92e7f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "236565d6-41dd-4b02-b82c-15a126b1ef28"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "76e80402-719a-4206-bcd2-08252b43e0c8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7efbdc6-a60b-4537-ade6-7bd6e9c9064b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1c9e7ec4-c934-43d9-85b3-dcb32fcd3a47"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c0699bfd-6c50-44a4-a429-24878a9a5fcb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "606a1064-fe87-463c-929f-632f9a87f67a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "88784f4f-c20e-4119-b9db-6aedea1373f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5953b4c7-d25b-4aab-bc42-52a77032529e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4958503b-69ca-42d7-94e8-fba4dc679fbe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b826b4ff-dba6-43b3-8750-5e0ada76af44"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e85af87f-517f-4881-8535-00b10adf83b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1f3b985f-c1c6-4420-a4b9-f1eb3a54ec6f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d04b4229-82a7-430c-8823-9c8b0e9ff6d3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9c08e92-eed3-40a2-abaa-6e6db0d1297a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce9e9385-2cf4-4126-951d-794fc51ca3ce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9097d801-48f3-4dc5-9ede-ea61571bfb05"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e5f494c-a8f6-4064-acdc-f60597374249"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bcc80631-cde2-41b5-a3a2-e21d12c47628"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c7f0b0e5-0f68-479c-8860-28d558bda31c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5b0eaae5-5439-4869-89d0-4f33a6b58a7c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "abe83164-9186-4485-b0e4-d5b0113861df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1fbdd2ce-d9f1-49c3-8200-d47c308c0a64"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d0079693-8df9-4524-ac17-eea16b5ff72b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "208b5110-2bab-47aa-97da-8a18e37f20bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c93f1a6-d582-4244-a1e8-076e4d115640"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "11aa7fdf-dda6-4aff-89f2-1841127efc97"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0240f8bf-fd48-40f1-b2b8-8efb0cb2f468"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9d3958d-d3f0-44ff-8f03-c1de21d44cb7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "06361cba-bf28-46be-a267-559d06ae6718"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c32242fb-bed4-42ee-aa18-1bec6b0d6e1f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b681f0df-e440-4c9c-a03b-0e8d3dd9e886"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6673a64-732f-407a-a225-038bc08f4250"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "db1c20e5-37d4-44c5-8b0b-473461a79690"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "801163d9-ed3b-424b-9a4a-4258f0b3ff29"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6acb3e36-efa6-43b4-be04-3bc9d7332619"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "80b8d7c3-0c72-4d63-8eaa-c160282fa63f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "46de96ae-e9f1-4962-8509-05f8c664a7cf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2134a31f-af94-420d-8778-5178edd4edce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d7bd14f-de28-413e-91b8-729ea83304bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "25195b51-e378-4c1b-b6e9-c6a94aba0b00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab166451-8d8b-4c02-a9a2-be52c37fef86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35c9ffc0-8958-432f-9050-0a8b6142d04f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f548d127-97f8-426c-800c-41e851630088"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "be803f6a-3eea-4ca5-907c-c35f5aa9622c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e0bd3490-cb55-45f1-96f5-f4736bfafeb9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef0e14c7-e045-414b-bbaf-d5091d11bcb0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd689eec-01d3-47bb-9148-7e1194baf753"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "69e2ab19-d770-44e9-838c-19c82904ba52"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f9663024-4604-44f5-86d6-5cb690cf450f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "881b9d14-f9fe-458f-b6c2-99971d5deecc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd04f356-3b46-44d7-a0c2-7e3959a182ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26df16e1-a34e-45af-a6ca-5541b141b389"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4f7c95cf-428f-47fe-96de-8bc5ee122028"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "692cfc9c-4a65-44e0-a194-bea104e9b326"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3fd4c45b-28be-4e61-a282-7ed3d61af3aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5368585d-c180-4498-8024-16cf04ede703"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "277d45cf-603f-43de-8940-645a7fcd757b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4dc95af-1f0f-4acc-bc62-2d2622b34c6c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e0caae4f-9a63-483a-8057-3e6e60f4f350"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "53cf31d3-2056-44a4-8e50-9e044a3edaeb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d989e8f-ffa7-47f3-b378-1e9e22b12377"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7af92d44-fe0d-435d-b480-a92668f66b8d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5e1ca5d2-335b-4e39-aa7e-f6e892545beb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "84e24f5c-40bb-4a04-bedb-c067ad9064c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4f8a2507-407c-4cae-ac86-3edeb24fe98d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "41f06694-7e9a-4e95-9d9e-a45eb8d862b1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2e4d4584-acf5-4240-9ed5-8b2431df7311"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ee7277b-787a-4c8e-b24a-37db6d4687ce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "61ede7dd-2d84-415e-a1c2-f17d731b2dfc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9df3549b-2ecf-4960-96c1-4aaa9668b627"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7ae48a2b-0db5-48ee-8156-03a4ad7d5e8b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0c03d54f-2a24-4bda-86db-c2be4ae31174"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "04985514-1aa8-4e8e-819a-60cc00c07e19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6944c0e3-8e1d-47c7-b399-9bd9b3b025f1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6f225454-014e-48f2-b83f-d860a3265111"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "db547ad8-a5b2-4afa-961d-c226139fb4a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd7671d4-5911-45bd-b9f6-96220c2e3126"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "51f85681-ff6a-4508-9cb9-36bbbeee5ba9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4bd59de-676c-446d-8b07-8a278bb02bfd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "857958ba-1fb3-4252-b10a-95690aafffc2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "be68dd2e-6ec1-4012-9e9b-b2692baa9323"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d5f9c773-5650-4c69-b193-e455f7270003"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d49eace2-5318-49a3-b5a1-99fdbec7c362"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "448d5815-8504-4cc8-af53-c076de779d01"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "64fe9912-babc-4538-b3f5-c567c4c543f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9cfb6c9d-eb16-4f9d-ae5a-8896fb410e9f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "48095291-8680-4041-8d70-a8df1913262d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ea28393c-bc89-4c55-97a4-e7c444ef847c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb8f7e74-ecdd-43b2-b2a0-b66e45dd7306"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5aef522b-e3ca-4f81-8250-de3cef5e982b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac7d4f56-9400-409d-addd-a693a89c11c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f7205d4-e16a-40e6-86db-0ca68f4621cc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd4520e5-e485-4491-84d9-be2d672d4cbb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2d042b8-a5eb-410e-aa97-2b4d888c1fb6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7d7263b1-9da2-42d4-860a-17e946322aa3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85f91175-2d41-4fd9-98be-80e740e8bd7b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd0248d9-0f0b-4197-b61d-8ae37022c9d5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0454c497-084f-4b73-8100-602a1d982535"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5f03ca3f-5e27-47e3-918a-7ad8f5d9aee6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "52eafbf8-4a1a-4994-b2d9-59804cb5d99a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f5e581e0-6bcf-490b-b2d0-89c8a9f37b8b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "62cfcced-7f66-402d-a3ed-2aa3126c304f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "94f64844-672a-4c50-8ae6-09dfb83f61dc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "986ebc0c-047c-49a0-b2c5-1dc510e0c178"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b470b75-a757-4068-8b10-a127610caa2b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ebe0626a-4c31-4e9c-a515-509b74cf5715"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "feb3b721-4f6e-42ff-92ca-ec0e3da2db99"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc6a4ff4-2340-4836-bb26-03575413e7f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c646880-3f6d-4012-856f-fcc827529847"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1c925112-7364-4578-868a-b483d785f60f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6b35ad8-d7df-4928-8b3d-73bf7e3086ec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f5e6d641-61d5-4bbf-ae63-0ccadae86ce9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "54176966-d87f-49d8-9bd7-7c48ff11cd29"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "de24102d-77a6-4713-9cbf-e24c492fe964"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a190bbb9-e2d6-4a6a-ad80-d7a094b944cd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c392168-4fbd-4dce-a607-a22a50dd5620"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7682d612-aa65-4c36-8749-6c6e7775936d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "945b2194-320a-42d2-9b83-3a7ba70fd4c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e04aac6f-4a87-4274-b8af-8b280f45825f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d4d78b9-7258-4f4b-b5a0-a0ea09780e7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9baf9915-d0d2-45b0-94a9-f3eb669d9277"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7e318268-7fd1-477f-b2bd-85a039bd1dee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "999d4043-ad39-40ac-b29e-375c71068106"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5da42cc2-0660-4861-9342-d3c6d42dd600"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b2a90027-18ee-433e-a169-6d13235088d5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eece3b94-a6ac-4b91-9a68-6823dfd9f25d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6fc649bf-67d6-4831-8d19-dd8863a242fc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "54fc279a-1a0b-4ee2-bc1a-a86daf72ef73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9f0c7fd-58e9-42c4-a2ff-18c7c48d70c0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "72eeed3e-c787-41d8-a607-5f98e5308cc3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a9780bf-624c-4831-8d5b-31ecd6a7a84f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d977084f-5012-4421-8d31-0d99a50cb271"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4aed8761-45a1-41b2-b70e-39bb46f22106"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "495105b0-c999-4564-8d7e-baae8a7be674"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "110e60bd-61c9-4042-b654-07f575d1b640"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a0f253a1-8dfd-4899-b2ed-03f856d1e5d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "69282ef7-ed63-49a7-8b4c-7ae81eac5a7f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c3ebdb13-f1e7-4f3f-96f8-918e524e6424"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2141fc68-d7a6-43d1-87b1-f1774a43a3aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "afd2c1aa-a448-4cba-918c-96a58f6dc292"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "190667b7-eda1-42c2-9a45-a872580c001c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fecc95b7-4139-4920-9eca-dfd283148ff7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6509afc7-4bfa-4d90-bc16-9b2afe5271b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb1cbf15-8c1c-4fd8-8204-aae639c28d13"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8c9c8512-d4c0-4a47-98b6-51a20e605c89"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "346d8d7b-9468-4d29-912b-5e3361248395"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd3cc355-53b2-4835-a116-9822fba65e7e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "754709ed-1061-49e1-9246-7e1007e93cb1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc28c358-88f3-4557-9ba3-1af13af17053"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cde3b958-b852-4332-8e4b-4bb826893210"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c205868c-9526-4cd2-9c73-4556fdb7a4fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bcdc9d6c-a386-4a67-bd15-f654ca13c10a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c26a5c26-6990-40e3-ba72-19673c2103ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f2d4cba2-c5b2-4116-bedc-360100f82766"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "67145436-3481-479d-93bc-edcbe7011f14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7dc81ffe-a449-4138-88d5-089f9d5b02ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4ba4fe5-cb18-445b-b250-fb2368c20f01"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7e7c56c0-1a5b-48d1-8cba-1ac2d69341b2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1bcfd405-b781-41c6-81d6-85b93a16e544"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e796fc1e-a50d-4867-997b-f3ae1ec5b42b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "79b90a12-9a4f-4015-af34-2315e89223b2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e396cfb-ea41-4635-8741-03736f461bee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab981c8d-d8df-4978-8fa6-d05c09f32032"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2cf84268-71d6-48fb-b859-bfa928bab7c4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b332446-3de4-43e5-82ed-266a4ef57c55"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "02374c63-ad40-40bd-b243-356ebfc3b272"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "64cd39c6-8f05-47f7-949c-b6544d86641d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bfc4c636-5f11-4bc0-9521-254b249faefa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc700391-a50c-4428-8a0a-a0eb4b532b1b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f4b1abd8-21e9-4846-a27e-9d33fdb53f2e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "521b0de5-7d42-4fcb-b509-a2597b104b36"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5775069d-8e8b-4d13-8797-8d74da448e05"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "44c96d0c-1ba1-43f9-ab59-7ea62de3cb5c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8fb6f7b2-dacc-416d-8084-660b25c72a15"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6b3258b-5e95-428a-9feb-c7a80817d9c4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e8cf9cb6-4b77-4488-abf8-74d4ba1f5f5f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f7932641-ff92-4e7e-84b2-befa57807a59"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b7626451-6256-46d1-99b7-26be124f9d35"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9bd15bc5-5b0b-436e-8965-b92e6d8300d7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ee26ae4-2ab7-4497-864a-ad518bdf1014"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cf672f4f-ff11-4b8a-86e6-6e4c89a99089"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "845b8652-82a7-48e8-84cf-66fedbd6e795"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "81250811-e30e-4094-a2c2-1ebf8c24a467"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bba9e571-b8f3-4e2f-af96-74122e9c8a01"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a9a4e6d-770e-468d-9392-d1a84ebda035"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "994a1ea1-10b2-4212-a44c-bf959f0382d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c83e3476-5b87-4091-8086-34d5475e2d83"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2e717cfc-feff-4066-83eb-5e9b2be9cad6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "485b13b6-5d72-4bbc-98f2-d43de40684c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f4e76ba2-fc2f-415d-b575-caa9c663094f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ca79927c-358d-4ac3-9a8b-f7364e0b6e00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "efdc4231-27b0-4f7b-a453-ad98c7155786"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f7cebf3-64de-4fe7-b49d-55634caf6b84"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9fd35091-f269-4bbe-afbd-5d6e70d11d78"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "db162b25-628b-4e0f-ad07-c47a5d50d5dd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70d82fd1-a7b4-439f-99e7-aec03af41f67"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d001aefb-637b-40ec-bc26-ff8d6d28b90a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a4b68f9-9006-400c-950a-16983aca4ab5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "812f2b4b-e421-4a02-a39f-722474c3b26c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1763e944-efb4-4b0c-9bb4-cc4fc5d7b61c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ccd80220-c7cf-40e7-82b1-b81727dd97fb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6f5a3cbe-6ca9-4d63-a4a2-e97266f70d6d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "09b0d7d6-b6cb-4861-b547-2a5d4a81b15d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "05d84d83-fbb6-401b-9685-516d401de5fe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b02573e6-98e8-4505-b3b8-f9bcaa74dfac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bacce4f0-11d6-4810-8485-5da51297768e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1e842290-ca5a-4252-8c0b-4b13f688ccf1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fef6b78d-229e-4179-8655-39a24af404e0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7e63da56-e69d-40f3-83ce-2ace30bed47e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2a86581a-d3b5-4cce-8a38-12dceaf0e88d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "52983bd1-1b16-463f-ad79-9462b5ba224f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed3ed082-9fe6-4473-903e-f3ee7e8645a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1fce9b26-390f-4a33-a97d-18a7e5cbab9a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2035b5cc-619d-4c1a-b6a6-e2f31f8973c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c77593b8-d0ba-46c3-96ad-ae028284558f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85216a23-3a52-49f4-bf07-85ca8ae2e9a0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "22d9f154-dc67-4f32-810c-68e51280de18"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1a9ef593-17d5-47ed-8b01-e726b9c0d858"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "60f8146e-b28a-4835-9e78-7359e7742c8d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "41130a1b-70ec-4897-b078-2751992150f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1f461bec-0a78-4783-ba15-da9e49007c63"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "796ae6f6-45f7-4f60-ba64-093f8076d3f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "78ffb7a8-05bd-4b0e-ae5f-ffde0e5b994e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26e1ec4d-8eef-4b6b-99a3-6d8523e28fe6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b4701766-e175-4df1-86d8-71b4c1d202be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "538631f9-ff48-43d3-8535-6abf32a2cc5e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3d796a84-241f-4675-9d9e-ab40aa78ca5f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2fecc78a-b6ed-4f8b-a793-1cfaf8999ef4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c891489b-5f91-4d9a-9e6e-a541959d1c07"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70e4263d-d6a3-4245-bb81-b18869b69541"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8bd9a941-e053-4bbe-9da0-4112d14ce55c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1886a39-e58f-4797-a408-2f106d6330fe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4df745d-c092-4295-9346-7f7ed58c705a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9265481b-37cd-43f1-8304-4f1c3a1b4eab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "081e8e8f-c3ab-4443-bac9-3a46e1d6305e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0eaba158-dbe6-4bb1-a8c1-c675a3eea6cb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd9de90c-ce71-47d3-ae92-ed4402d4c65c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "42a84d1b-2661-4f2d-baa9-cdf80f6bd14c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a6074a9-0eb6-4e31-98e9-98252044b373"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "582af15c-ab5e-4bfb-a1f4-2fac480c6f45"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b503ad8a-bd03-414e-9413-d7f6cee589f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90da5f68-ed53-4ab3-81a6-1bb5d3a772f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "405a7491-1d8a-4142-ad29-1eff5d3b1dab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9bba5b5c-2b22-4a5e-988e-d76f8e8b70a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bdd43ea7-328e-4b91-8db6-fe0ffbd713a0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c02b1f4d-d6d8-4b0f-8009-d19cd00a5cba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cac75e5d-6724-42d9-ab98-fcd8821f8c45"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b59f410f-b1e2-46df-9717-d91c20b90bb9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e386d13-c215-41e4-8294-ea70f1853dec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7becd120-620f-45a8-b140-7f47ab741cae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5a1c0670-3096-4e58-b94d-d30abd0e1bfa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6c0c8e53-eb00-4b1b-93c5-4abc76799727"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab6d138e-2fd3-4c50-8193-0ac4b3010373"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f023cf4-4e71-4560-b630-8500e75053bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "54f8d37e-6422-4fc2-9a44-4fde2ae417c0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e40d840d-eb02-42ce-a5bf-4be262e0b809"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "49138223-c3f6-45a7-a451-a8e224f65a09"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d79eeeab-9bf8-4dc0-b104-0a861ebb1ad2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "088af560-f64d-4994-96cb-540c7617c1a3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ffb5c2c5-406a-47a2-a4a6-45fd444f5f57"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6bd3b749-5550-4103-914e-ce3f9cfc7e4e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0ce3ae93-bd5a-470e-8f0b-c847d0d981e0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dbabe366-d7c6-453c-864b-fe283b0b78c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "040d587f-bc05-436d-9b50-2f361786f2e1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dba28983-cbb4-4558-889c-e417621d0262"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a02cd2e5-103d-4a1c-87f0-f95785698fca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cadafd0e-8f8e-4517-bb9f-af70978120bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b838172-748c-4e86-bc87-6e14a7b0ad62"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b37d839e-b489-4bb9-9d1f-90c9d624345e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e84dea9-67fc-4085-b97c-c6a46eae0ef5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6f162b5-cb04-4d34-ab76-3cf65f33bd76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "27db8c74-11e5-4424-b93b-8b6154a9a4fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "577468f2-7008-4959-948c-5e577cc062a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0c509e7f-31b8-4439-acf9-4f22a6ccc972"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "511db899-19a6-44af-a49e-3615d13e8b80"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc1eb4bc-e9d2-4eca-8cdc-df4ffb747724"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0b16ca79-bce5-4640-a639-3980ceaa4ec5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a01836f-5213-42a7-8487-f34b1c3925be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0541279c-781f-4eed-bfab-0c74cbecf160"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f3ab4b5f-6f6c-4892-9f52-b434de15b5a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b54c1676-3602-4a9c-8a3e-d0d0fb1159a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "39f5c70a-e670-4f68-a979-b06ab6ef6fc5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c27cf2be-90a8-4fb5-9f87-fe0062295676"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1141b853-d6cc-4a38-833a-b5c3b27ab5eb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f5b58bab-5f84-46df-94bd-514c1243279a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "da9af60f-f3f6-468e-b34b-77332edcd9b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9073712-5cbc-47da-ba9b-5457fd07b0db"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "928307d5-d565-4b34-a1f1-ac1e1a6d1e98"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b45ba5e-05d9-4c8a-aa3b-771790ff274d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "54b43a2b-85cf-4ba3-ab80-aba187da89ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a99a3e21-98f6-45ac-9376-a04f7ef1a4ae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dcb1dc71-8d0d-4e80-9fe6-41f2e90e492b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3c58ac0-e8ed-48b5-b80f-0cbff318c976"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "05dda31a-e31f-445b-9d24-baefb472300b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0b5d82e3-b26e-4828-9b7d-918421713499"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4bdab45f-da3c-47cf-ab2d-7cf74040e049"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b0a3325b-585d-4109-975d-d1ab6266b6c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb0c7595-acd9-4f9b-9e5b-922ef61bedf5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "296b919b-57b8-4c8f-a6f2-f9841c67366b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cdbaa112-bbd3-429d-93c1-f188e8b3d237"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a8cb3449-a203-4b78-9f3b-80a9f5021665"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "07e2ca1f-9871-4986-9eb1-fcd7ee99d31d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b4421b65-2d78-4987-bead-59a0700d9773"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e38ee92c-2d5f-4b61-bdb4-777ee9b7b341"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "131a494a-9516-4d85-899d-e253d3d5246c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3de19145-efd1-4acc-8cc4-09a376a1ef24"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cdd7c4f0-3952-42a9-9642-f262f462864e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85ef6e2a-e669-4468-b0cf-39e396fd6a3a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d67e262c-4e16-49cf-b28a-d68d56be6146"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "471308f7-1f02-4bd6-bbf8-3405fa1b36a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "83cf94e8-79ac-4b11-833f-cf2e4331e430"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8235a677-5e8a-4e21-b8a8-e6c5c6c27855"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7899302a-5085-4c54-9f43-4b44f393affe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b3ce20c1-c896-4ffb-a37c-2020146a0b08"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "48313e69-5300-41df-abc9-8212d0bb5f25"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90256c1a-1d11-4c62-8fc8-7d2ab4714de6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8cbc2a42-c3d0-4765-943e-b66816a03bcf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1b078d24-4c3b-408f-85e1-440457c7ac2e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eafe2af3-941f-4803-8e2c-c1f9c2730dea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc74a9cf-1190-41b9-9fcd-f2516a1b93e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "42938016-af0f-4d0f-bd71-dcd68fa0d852"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eae37aef-9999-4bcb-b55d-9e5e02965fb0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7f4abbb2-467f-4b57-85be-eabd5e35fc35"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8cf016c9-2a05-4c24-8468-d5ffbab71e61"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fa4fec72-63e3-4a32-af61-388bd93fc6f1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "76eba7b4-8bf8-4cf6-8d4b-31fd97867fea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "313b1ffb-ce8e-4495-a6e0-65e27d814a3c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4ff26254-f6e8-4fb9-964c-2f8c1a5d0ebe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a31b227-f206-4c6d-a343-6738056e01df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "074a93a6-7ed9-41b3-9e79-4ed41488e7ad"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c55bc37-3281-4e17-8a99-b5feba73dfab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b1231f5a-53ac-4b54-afc8-2b06d1ea0cf4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4c23618-aade-496b-ab65-70fc94686b7f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bffff4aa-f2fe-457e-8952-4731ef23c1db"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fbc61709-c9b3-48e0-9da4-d1834e991a19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e61eb2d4-cc0c-471a-90c3-63506f98e086"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0bb872f8-025a-472e-8670-b02f4c52b0c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "25053729-c446-45b5-9ce2-33424ce6028c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96edd576-80ac-4083-acaf-4626ae2966d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cee1bae8-af39-4fbb-96f4-086194767bc0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "245d3e1e-8099-4b07-bf30-df2abd4549e8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe29d3ef-66c6-48c5-9549-5a0c2fd43d1c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f302f408-d6f6-4018-aa84-c3093acabd96"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6a323dc0-f8d8-46b6-ae65-1d75af7b457a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb860a74-3f85-462c-b708-a0a6d0a841c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fdc6a62b-b3fe-4218-8cfe-42bdfa57ca51"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5cb5ecb0-05ac-4928-bfb5-de7cf179ac0d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "379d3ba5-2323-4660-bc5b-965e0808d03e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "08f52353-bcd4-4887-b079-c66472cbfc51"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9543d44f-b9b8-44b5-9094-92e569c0d19e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a8643ee-43af-4db7-80b0-28518a475b1f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aaa4d13c-b11c-4956-a5be-c25eea7796a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "79ced9e3-eb28-479e-bf80-1462570b2da2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f813b2d8-d5f9-4fff-b870-4a8eb50a38b1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "68e7c984-c0c4-4a86-835a-fd59998c86f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "569ab5ab-6782-4297-8542-56346fda73ba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "efce8520-5320-4fef-8790-0389aa1f87c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5c422fcc-e502-4a6c-bf16-e0e58d4ff5f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f49bd2b2-73df-4171-92fe-6a49a08f2e5f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3fcb88e0-82c0-49a9-beca-fe2eae63040d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "07fe8ad6-a7de-46df-83b1-852cc042932f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "370e8a60-53e1-432e-a699-09042f37d4fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "62b4f904-46b3-4a25-ad57-e551239db41d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26196d0f-edaf-4681-917f-cc3f4a7a5d94"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "761fa902-8212-4e0b-ad24-c4d9f1657a24"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26ac41ce-5478-46c7-9bc6-2cbc201465d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "de4f4a78-c3b7-4f35-83d1-af32df92da73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "93fd2b47-2c4f-445a-b908-5ac862a6ec15"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f0b87138-f485-4c79-a5e1-052bc365391f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2cb443c5-7ae2-4d26-b2b2-45eb9493990d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "87f378b7-9b1f-4696-9997-c7c87ee974a6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "51bf364d-9b0a-49b4-9107-9e7284603115"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1006def5-72af-4a65-b31e-b3b03960ac89"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96be4292-c185-421b-bd12-52ef3d6e0548"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd103523-ae88-4bd8-b580-a6a2266f2fd1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "42dfe928-58ea-4999-a178-397973c256b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "098222c2-1385-4406-ab6e-3469a7b266b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "be98bb5d-78af-4f54-869e-8ac949603e9a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7de21fac-c9b6-42f4-b982-615d3992c06f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7de89386-64e0-4e24-afcf-c569a2efaf37"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "23d801d4-b4dc-4ed9-8db7-f54bcd43b077"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9ec19bfa-e0e2-48bf-a23f-45efd75e7244"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3b6ab179-504a-447e-bfa9-8c37c54aa17b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce1cf0d9-4b5f-41ec-bf33-7570370f59fc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb8e5063-c13c-42b6-b451-312b1d869c5b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2832d77c-6acf-41c2-ba4f-5b709e521c84"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "38501de8-74a2-43af-9be1-8e843566c1c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b602e866-3c35-4d7c-bad8-6c4ba5a16424"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "870173e0-c6d1-432b-b94c-59884eb70ea9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc52324f-0419-4080-9b5e-5ff706ff5584"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c04c2e6e-c4b6-4edc-b2ec-5f2fc8881df2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8464a0d-246c-4f5a-8148-43742f544f30"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2dc32422-f66d-4bf9-a913-69ee8396265f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aacd5402-de15-4643-9c9d-d80ad0ce1298"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9df2f0e4-36b3-4470-a379-3803fca624bf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9bf1134d-b33d-4fcd-8e41-051c980053b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96da28ba-54de-487c-a31a-de3f323a8579"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9a243f8d-7cf6-4333-8a30-8c27e1a69782"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e72d59cf-edfa-4522-bcaf-e146e23ecbbd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "43f84ebb-0f0b-412a-a944-7d956b6a2726"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2215f602-c429-4866-a4a5-f1e298c96481"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c974117f-cc68-4202-a979-2c787fc37022"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6260794b-11da-46e7-832c-09515cfe8a65"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "24bbc21c-b7d5-42f2-b1cc-98a4d38c11f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a5b129f7-cdbd-49ef-a3b6-33a13492cd99"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35ffd7d3-968f-427a-81db-3363df0de495"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2339a603-d065-4aa9-aaab-c73ef8b150e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "42762836-fc99-4063-9bcd-1f22a78dc045"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e1b7d5a-7669-4ab0-a67a-c531812ef47b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4b061e2e-a3eb-4613-acc0-144e0ba84307"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7737e182-80a0-4e4d-b828-7344e5445df6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1a1ebb9-1733-4277-bf39-ea3216bd3580"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ca301adc-2675-446c-97ad-0908e1b08ba2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b23b1f2f-2deb-4a6e-8535-267502bbb703"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1b6a366f-7608-4ff6-9012-fb998a297f23"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "77293f3c-c936-440f-af13-7bd4f10339f8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "faf66f77-35ad-4440-9a59-8daebb3fbde9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0bdc47b7-2a2b-45e5-8ab2-a76d9f78d59b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8750a137-a56a-4b9e-b5a9-ac12c445f921"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "273cd2fe-4733-42e0-a718-75d410b15754"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc203b5d-b5e3-47a3-a405-ac66f33596fa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9e966ad-d41e-41ea-b29d-4f6eef551027"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7924974e-f628-4c46-8434-bcd22c77869a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0be47b38-0a6b-4a6b-8beb-5aa027a7a8c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8b62ee2-48a1-4935-8497-365b8b0d8949"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c081d789-3468-4731-a0c1-61ee8f1a8a56"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eed0180c-d0b4-4365-9869-af0c258bf307"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ffef63f4-7680-475b-9f1c-a0495a6e8092"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "47fecc3a-2d07-4210-bb45-1534087a575b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f0a14ffa-4a18-4301-9bcb-4f44230f4d2e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "82ad4f04-bffe-4b37-ae13-11fbe7a318f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1cba289a-4893-4c1e-87a1-0b820f135930"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a078db6-e96a-490c-bc08-b6e19fe92f44"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a4dd784-8661-44a6-93c5-8c59f08eed76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "888b0e25-0d8a-4429-a7bb-7d1775f3b3d8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d8e61da-f0ba-4e3c-823f-5db0a819eec6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7bf0cf1-7b98-40bd-9326-16214c016249"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "696c39ff-4e4c-4671-b82d-9dec256fd33f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70f4e133-8179-4c1e-ab28-fe7fdacc656d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "efb463aa-7bb8-4257-a8f1-eacfc52eac22"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "46f8a36f-4051-4d6c-85db-d089b5eba4ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "228af6ec-7b03-48d3-81b1-6b448444caf3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e13dd717-bc2e-4dd2-a44a-26a655d73a8a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb77ed52-d7f4-4c11-9e95-666bc4f7ef89"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ec2e16d5-2531-464b-b8c5-255eb246f5ca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a934b339-0732-418c-b76b-9bdfae2f9130"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a45ccc69-311d-4229-9d4a-22180b8ae455"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0002268b-df21-42cc-89de-6fa2536d5bf8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9fc6e4e5-ddb9-4ce2-8f63-fbd645d31690"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "16569334-0aa9-44da-81e2-5ce9d0bde1c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f3cc6fdb-1d47-4ab4-801b-22b1b1b623b1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "928f6384-4244-4c8a-b724-25500dd66aaa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c5456a61-1566-41ef-88b4-f5180cb340dd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "73a14d61-f433-45aa-979d-e8e15c5ace1e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "75ae5f65-d7e5-4ff2-b1fb-b30a13953822"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bf62521f-027e-4239-9161-41944a937941"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a16dcd7-13cd-43d0-be71-e7f040638733"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "63e36dbc-2b18-47fa-99a1-1e7d9b3f41f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed257d73-1af9-4a49-804f-43379db812b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f53114ca-7c26-4313-8d36-645bbf5e17cd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "326abab5-1eef-4603-b005-7fa240c7fc8f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "da397531-f513-4d11-b82c-104abb5f9884"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b9d912eb-ddc4-41eb-ac07-4310229f6db7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "abafd816-2899-47fe-b2ed-5636699400c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1e8dea8-32ce-4533-a80f-292be8d756fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90385686-c707-4245-b028-808f7b727cc1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f06bc8ff-00e3-45e9-a778-28f72884cd84"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "edc610aa-a851-4fda-8fb5-eef95c1faebd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9c3eb56-fa15-4d62-9b33-1f3c2798a06f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f14a11b-150c-4f7b-af3e-d21d923e0d68"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ccf637c-69a4-47a5-a5fc-d0e72dcb62d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "93573b7c-5fca-4dd7-a398-2f9543ad060d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "02df418f-2490-4d13-b52d-99a2879e0b3e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9f21b44d-6431-4ee7-8beb-723d0d31f749"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8bffce91-6bfd-4d15-9d3d-3af9f9a9316e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1dd596e6-c150-4f53-b988-f06ddf44736e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a73ad598-9b34-45f0-a40c-e8742730f1f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3d572d80-83cc-41e2-aa65-649cd1a933df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee432024-f60c-4d3e-9f5b-e9e9ef2b0921"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ec2cbfc0-dced-4d2b-a117-455a2e1f2ac5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "60c7dadc-6534-4d3d-ad7f-c025540f6c35"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57e63622-df50-479e-935b-da77ac48cf74"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e1f9363-925e-4d2c-ab15-b6fe8cbe49fa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c2d229e2-7cd9-415d-a8bb-86ae5e83556b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bff7ba6e-74f2-4895-82c0-b22576d7a178"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9b285a0f-22dc-4801-a6ac-f117418f57a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "918d4a6b-5011-4129-9a75-c874868b5e00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a07a240-45c6-4b61-903d-63f51935ea85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "411af478-c0f6-48bf-902a-c43f3774a719"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9977399c-3a2c-4135-92e3-c960ac551974"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7234caa3-fc14-4961-bf11-e0ae2d005e1a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3fcd05a2-95ee-4bdc-a1a4-4e0f3a25d8b2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d4eee254-f2b7-48ce-a56b-fd274a7c5ef2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f8e32710-da28-4d80-bbad-f5c4a7d592e9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "39573a3c-87f9-4adc-9808-d3609dc219ce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "55adf4f4-a171-401a-a8bf-3f6b2be00418"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a97985bb-55c0-458f-8b3b-744bb97a80ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e15d33e6-b999-4ff1-a6a2-dbf7698266a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a467b3d0-11b1-480f-b351-f207b87270f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9284a414-cb91-49f9-b84d-e2a365b3595a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee4aae85-848d-4a58-94d0-230b7f8114bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3249a29a-99d6-4c8e-9148-cfc4ca132fa4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8ab14c53-3712-4d0f-9306-00a43c6a7df7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9bd1da4a-29f2-4f8c-9c59-af6f49d6e336"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "894a9644-6d67-4937-9f5c-6fd3e4a2c019"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b30dabe-7988-48e0-84b3-f5933ad670a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1fe119f1-7be8-4ebe-b803-deb716c6797e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a5468038-d531-438a-a0d8-219b76ed046b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7a9ba6ee-9ec3-4fa5-9cad-3c1846656f50"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "58d45b86-ff5b-45ef-9f9a-1a884fdd5474"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c148e9d3-bddc-433c-888d-9b010e3ca5d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac03baa0-75e0-4858-990e-e242ccad7fe5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1afc13aa-10f2-4699-9f5b-f9b2db587557"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ba53266c-40c2-4823-80b6-172161c4689d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b7a556d7-a90f-4d60-805e-6b90ab455063"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb8c7ccc-cba7-497e-9b5d-fd88f61ac523"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb2f3764-5893-4095-8bb9-5c732adc64f9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc11afca-1ba0-44d5-8983-7bb45d7a6172"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f3011899-308d-46db-8e61-11954bc686b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1d4a17ca-5688-4557-bffc-fc289347eb8e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "55814098-8d36-489c-8075-75f8c99bc417"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e38c3e9b-364f-4f4b-b2b8-0f82277bdc0c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3cac73ef-0f06-458c-ab73-85649142114b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb2b148a-348f-44a0-8fcc-1bb643402aa8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5466001a-436f-43c8-bfc2-ce90f5f23ca7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f2a97b3-7a4b-4b9c-9950-8b3c7bcf1555"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7cad9256-eda3-4ac3-9026-c162ea43bee5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6512396e-7d52-4827-b130-defc84af4b41"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2da64a3c-3476-485e-b18d-17d5b57ef5e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e6501641-c6d0-4c47-b7ad-48e658781e64"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb90ced6-88ab-45ee-9ae8-7cb12efd54b5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "818e69c0-2f35-41e9-8421-9ef5566e3586"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d8933c7-427c-401e-8338-0389fa20e110"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a774ae1-b8c2-4297-bdda-25ff404a9b06"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "217d7be9-3c44-4939-91ef-75bd5021710d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6c28aefe-efc5-44e3-9469-bf2ea308d6e9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3bfc3bc3-540c-483f-b0c1-9cefacf6d343"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f70c9201-6b2a-4053-a7b1-87cdcb8a5f86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bba41b09-bdca-456e-ba48-bd43a4ecd65a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9697e4c0-0e37-4ff8-91a1-0ab3059f241a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7a32676a-0293-4ef1-8cc1-89ceedcf2e7c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "309a03dd-5ff5-44b1-a697-4902f8c6d124"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb298215-2079-45e9-ba4f-a00a2da50771"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "94234d07-11c4-44b1-a00b-436c5f05ec41"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "00df4187-c98d-42e9-87ce-28f5a5ebc5f9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f2eb256-a8a5-477b-9824-2f1ed53ed5ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "59691d62-182e-4b81-ad5e-279f41605a6a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "16ac96d8-5e09-4cd1-b0b9-0dc6125b1a0a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "64af77f2-7c2c-46b2-a012-63d0047e0166"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8d86525a-bf27-4409-9ae0-7ba838e4b170"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a2ff8a23-b3bc-45d4-928f-c8d152679580"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "58b62cc1-508e-4dd4-a16b-f50b13d92892"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e502b22-f141-4ceb-8d12-265c057258aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e6bd3a0-c0a1-48c8-9e20-a1faa8479e5a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4c68832-b9e7-465f-9a47-f1e44a2195f5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f789b26d-8a5e-4a21-98b6-b693e9051b41"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5fce4cb4-80f5-4042-b846-2049f2af0160"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a0bfe36b-05b3-4114-934c-0b7d469b6eee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d5c82bd-e9d2-4534-adba-eb934f9032d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "45c05fd4-99d8-4238-b2b6-fb8408071b85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0fb51779-8559-4d0a-9129-2f61866b1d78"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0f038b17-36e2-41dd-b622-106e19ca8b7b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "31350b89-3abf-4cd8-b02e-6c29d4f1ee17"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2909f2e3-cc31-40c5-bbee-18afd79ba968"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "56860e80-bd10-441b-ad23-5637f4e6b22b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d53a4559-08ee-4a3d-a186-da07bb95d73e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dbeb9d3a-9330-4477-858d-c6173b227578"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8485945e-f111-4aba-844c-72fd767bfbe1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e64514c-4ecd-481d-9091-76580e7e0fb7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b4eae1d-0724-4b55-90ac-ce0e3c894ac7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "74d30897-90ac-4d5f-b84f-24c12eb0673e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66fd37ad-d9e2-49f4-938f-071f78545012"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8bf412c2-7b57-499e-8e57-affaf21412aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b9fb1d25-962d-40fe-b706-76c5f60a9bcf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dfc940f4-f2f9-40db-b25d-29d26dd5b776"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3999502e-0527-4354-99fd-652df97ef215"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5238f8a8-826e-4170-9743-3efe32dedb4a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "62de9671-f6bb-4551-8eb3-c8df073d0f13"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "defc4f85-7e1d-4426-a5f5-190c2f811cd9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "29bcd34b-55b1-4808-9138-2d20cdaa8301"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "73a15000-efdf-4431-8022-34701469bbce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f2e3f117-492f-48cc-9460-458d2ab006ba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "346af852-2f13-4eda-98f0-e1c6a2a52e56"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b91e72ab-f4da-4ed8-84c6-38f4419aa49a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b870af44-00f3-4cd1-a4e3-09b0d11deb92"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aadaa803-499a-4ef4-8fda-ca7a109e6b7f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "34524b52-1b2a-4120-9f56-1529632938c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cf2e3c6b-9da9-45d1-839b-f00b4cabbd0d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d9b02f1c-1be3-4641-9714-2ea65ba13379"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c5b45cce-f60c-40cd-b5a0-1a3b24e4c2e9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b5e49b93-4867-48c6-818a-7f0f50c1f4d8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7106685-669b-4fb3-8a43-7e4b367ab9d5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2470617-95ea-4caf-afdf-867622ce12ee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "599f83a1-c2f0-4528-b591-f67fa3eb2c04"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aab81041-bba1-4b69-ade8-41407d70dade"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "03beac6b-e379-4f51-8f6b-f70f88b9d579"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b105d8e-8337-4043-a363-ba371ef5c405"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "323eafb4-63df-4416-a341-262a12b22652"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "abc32962-a382-496b-b31c-b06b30b51044"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9a7d791-729a-416d-bcfd-e8c4f021fe44"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "131ad22d-2b36-477b-bfa7-39b35e1b257f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f9d5afca-7503-4b92-a316-8486921d3376"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "88ae028b-ddf9-46ae-bb33-dd1ddd217135"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ec8bc53d-933b-42e4-ae43-fbb3569d95f1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a923cbf7-13ba-4297-98ad-3f59f16171e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7f6e18c-f5cb-4e3b-83af-1349ee71de00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f53e56a-8bf0-4a44-b4a0-809a3312a7c0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a636acca-a09f-4009-87bc-16f90220ed1d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "93b710c8-3308-4263-83f2-244ba467e193"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbb39d30-cbba-498b-a735-36478f084d9f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "efde423d-6cce-4ab8-a514-4384684be129"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a885a47f-b5db-4e54-8461-a9b37245e338"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7dfb5220-1adf-4b95-98a9-9a7516d81fa9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "51456cf2-3985-48e5-b175-93ce37f137a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c455a286-0940-49d0-9f88-393142ff09aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb0a05e6-5b24-41c6-9ad2-1f28ae35034a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1186283d-3017-41dd-924b-cfb055373ffc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "212082e1-4826-448a-9063-e3fec9c88c23"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e0fe7bcf-4000-4ef4-af89-071351f9d492"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7ed810ab-fe27-451b-8755-7f1595821aaa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f96774f1-ac07-4cda-a625-2a4b6a1d7634"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5953b6df-153b-4e7f-a5a2-beec5b991ec2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9f9b4f87-c2bc-479f-b282-f4550b8192d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f5e916ae-aca0-43bb-9952-c043deafa7f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "19e1a56a-90c9-49e0-a70d-2e306bbb1e19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e3b89ff6-6bf2-475a-a392-bf8be8dba394"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0c0f5d7e-da5f-4496-8924-5706c362f758"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e5b5b5da-a795-40a7-9dba-d2dccb8eec6b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f0069497-4022-401f-a443-e75f0667e7ac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dcb3309b-e11d-4921-af63-7d4c604a20e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9295dd0e-5a40-46ae-96e1-9ffb203f25fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "98224d58-be43-4778-b527-ef258b51cafd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c24c75b6-2e91-49b7-ad01-4c5b46c877a6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dbdc3786-a225-48ad-8cfe-a42161e6a7ee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "20a7004f-91e3-4438-983a-70787e09b4e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "12f86a4c-4581-47c1-800a-041658235a35"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d9111ea-f479-4359-8b39-2f5c732eda5c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4f905225-53b9-485f-be62-fc9623abe77b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "86f094ac-8539-4705-b382-693be1f07c46"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "22f08e24-4590-4a15-9c4e-a01fa6695165"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7c584591-b8c9-424b-ada7-fcdd805dc6d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2637070f-a1d1-42bb-afb9-ed4fdbc6d370"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5e11a6f1-0997-409d-9396-466e2124237a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4dd6da57-0c1c-4634-8c8d-1e6df31292a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "774f5a57-b235-4553-a43d-a28c83491ad4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "12251a69-20ae-4861-aef9-0476a9b04252"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd18c165-143e-44b4-b0c3-3b55b73c876d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "24092809-f151-4297-a531-0b7a82e32ce3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "146cc79e-7195-4fbe-9236-89ed90c9d325"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8ce0d06f-9403-45d2-86d3-f6a4c0836ccb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3953d11a-38d9-4b99-b78b-7d060c38679b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ae4796f-eb33-4cc5-a161-88ff7f9eca73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ad6ccda9-ed01-45b3-8252-5d3e5a8fdc86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b75966cf-a30d-41f3-9eb7-3fa244e5b385"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b244ad12-0127-46c9-a78c-070ed2e81a24"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9ceef5c7-cb0d-43d2-8c62-ec8e71931f16"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "719738a5-ca12-4270-8929-16fb5941239b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f42b7e38-e59e-4cb2-b45f-b33d704444f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ac8aa73-7b86-4527-b095-cbe0dd39f2f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "109e819c-584d-4afe-bbc9-4ded18e249e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc0a7f0e-833b-4d42-92d2-fd565dd578b2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "201690bc-7ffa-49d6-94b4-a27c44cf312a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2251ff64-b2e9-43dd-947e-985c45dfada4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "37e347da-4a6a-43e6-802a-bd61515a83f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3c34db9f-a8bc-47bc-893c-d5a02cabe5e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "54e80577-2184-4037-bf92-5ba734b3af94"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f015e1fe-cec4-42d9-9d4c-2caa1596d85b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "09f4dc00-d5a1-4c79-be05-406777dad609"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbc3bd4f-64cc-4b28-98ed-0fa43f6df8e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc22eb9e-b96a-4c67-a5ab-8366db512bb2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fa624b4e-0a0f-4981-b2f0-02e28225dec1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b2686e20-1db5-4af9-aa2f-c22e61c8dbe6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d1cfbc1-67b7-485c-a094-416d4162acb4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7bdffaf7-22e8-438d-a33d-3fc2e762d855"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc301605-2ddb-4b8e-aa0e-77712d603b4e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cee4c2ae-d899-4967-adf3-5eceb4222eec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "054eba31-2066-4685-a72d-f9737cae6876"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66ce97c7-c8b7-4dc5-bc80-10e078f82cc3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "71e33967-b136-4fe9-a6f7-9f53981231ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4343f298-cb28-46a4-8170-50d91be6b0c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "07cd08e2-027f-45f2-8626-cc6610861c86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f68beb63-61f8-4110-a0b0-75ec1de7b3f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "45e6eb00-c649-47e5-b8a0-6737ab0c3cb3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d97d5aa0-d1d1-4c42-ac78-19d31bf9f0c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "68c1b29f-c92c-47f6-851c-f868cbecb05d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "15be360e-de13-43fe-a647-af2756b4faf4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef86d9fe-c898-4a05-9372-5b65c15357b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b262a827-d343-4319-ae1b-e44173e229ea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "45808e73-38f2-4a95-b41d-5c469339abbb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d8b1d7e-c078-4a4f-83a1-71a4e426e06f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9b581f47-c863-4825-b5cd-18a880be2f6c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aa2afec3-492f-4b34-8b89-1e15024a4f10"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4f2fa30-5bf6-40ba-86b5-a3926ef28368"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ad42c08-823f-4f8a-a8d2-a45e0cc697e2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8d1c8d25-e10e-496c-8ad4-c13a83d0941f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cafbc88e-b168-4da9-9c16-973b7de5e36d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "56b971ab-6f55-4ad6-b0d9-8c0f308002c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f7172105-3a5a-428b-8ad1-edf7c575c8af"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0cc1ce5d-f29f-42bf-963e-efb1cdd9016a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ddb8db1b-7a34-4543-a9ab-acc049c26880"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "964251a1-ec8d-47b8-9555-0c4e38da63be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f9f3770-d5af-44db-b99b-d932fbbe1b49"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a04edbed-4e4d-455f-90e9-f69089a3ec5d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c3ad9d3-3159-4a04-a641-3adc84d8ac28"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e6fc8384-1c1a-4d7c-b77d-7c3c48023107"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "468e0402-d281-412e-a756-904b5a80260f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1413d267-ab5b-4dd1-8059-e31ee6acd8a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2f323a6f-69ea-4074-a233-6ed101d0dc3a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "05e3ffae-4ab5-4694-8070-3a0555e87ffb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "93f78308-cd89-4847-8956-dddda9e72aa7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "49dd8e05-8732-4e4a-b58a-e17a034ed959"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9b40ba4e-146a-45d2-a632-c05e044044d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c81b74a5-3bda-4fc6-80e2-164baaf5d002"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e25207d0-9549-457f-be2f-8d5bcb79a467"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5884cfd9-f2cd-44f8-b0d9-13c8e68d8bb6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0cbd0bd6-88d3-49e9-9fdb-cd7b7a620c67"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0245d0ad-42ae-4248-a09f-0ce704d940cf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "68733f79-35c0-4627-be26-e0ec75b9e4e8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "914e36d5-5519-465f-8b02-846d10d3d2c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0bc13cab-447d-4082-99dc-7bf72423de14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6179c9d7-d22d-45f5-a2ac-3a5172f38a1a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3df4ab8a-7846-467a-abb0-06d6a6a98507"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aca07dc9-4d35-452d-9d3b-d2a94a64504c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "10654fcb-afd4-4cbc-be99-fc1499b4b083"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c082d68-a92d-496d-bee1-b33f4422d540"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2794bf3f-218d-417f-8429-aae1fe5e1466"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3c9c2559-b828-4765-9468-65fbe422a1c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8aaf794a-99ad-459b-b273-1dcdc497a44d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "73faa22d-0332-42b6-b7ae-5818af13a250"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96f9b325-3ccd-4f51-b437-6aa6af719353"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1d8fda89-d3da-46c4-a23f-2bd24c6c1b16"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c5275af3-356f-474a-b040-9a894a8659c0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8de1fa7-5421-4e49-9151-59174890c1d6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92d013ad-4ed0-43e2-9543-ac0bcdf5ebc3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9ad6bf7a-9d66-43ac-8ece-5e7e0b5bad46"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef1ee924-135b-4e82-b303-da7c26cb80ea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5516346a-652c-4c7a-bcf4-08d81332a1ba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "114e0534-314f-49dc-9bb5-c8eeb7af3a66"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "95f4cc4f-578c-4b3b-a0e6-a707316c2f09"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3016eaa-32e0-4b66-8ea1-d9e6ea6a2781"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5b89764c-a176-4fdb-a156-c498761dd660"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f62edbc4-a0aa-46e5-ba3e-a32cccf884c4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb0b180a-6179-4ee5-98e6-df44ac076750"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1473f91f-dfa5-409d-aeae-de9c8c1d95b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "22174dac-949e-49c4-83a0-5b4e1d597670"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2aebcb2b-b673-4613-bd95-46841fe41d3b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cf1e1f95-4d78-4d65-bdab-d8d8666b2255"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "674c39f2-8289-4074-bef1-5c507a953458"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b3781dee-a561-41b9-a7fe-de5a3b885574"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9f66779e-4de5-4de9-89e0-e5992b2388a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c23daa8d-515d-4149-935a-1da4825b8f72"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4092aeb9-1c1d-42d2-9156-e5ac008ecada"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a8860813-3a12-41eb-817e-284b9eed34e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4cedd6f1-2f17-4d51-89c3-a53707dd4f37"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fce6091a-b061-4182-8588-253d681e5ed5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fa7f5456-9c1c-43b3-b5f6-536937a29c34"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "80ccdfda-a25f-42b5-a109-874c41f21b81"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c10fb1c0-e5fe-4b99-abcf-57bf8df964fa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c3be173-a6e1-42f0-8dae-a7d56f543eac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cea4841c-5389-4f29-89c5-e78caf28f593"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b47f5276-63c9-4744-9c5e-273ade75ad2c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "32ce6cad-0648-43e8-ac5c-463154bb1313"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e478cdbf-f92c-4a3a-a44b-1b534eceb9e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "049b435d-7b7e-4ac2-8ef2-f7eb77177851"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0e2020e5-700b-48c7-8ec2-f1df3fb3d296"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "deaf49ab-eda5-4fe8-9365-cdde9cc3ee7c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ccdf832b-9d5c-4325-aa45-b2ba2554f948"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bc049e35-4650-4f6f-9e9e-6dd13d487e0c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9596472-ad3f-4352-a319-cf65025d39a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b12708be-1a03-4a4f-9f1a-75731017c60a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "329ddac2-e6bb-43d0-89a1-936ea2094373"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e6a74237-6d6a-47aa-8192-776329763d9d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0518f960-d1bb-4d9f-88b9-1f62439d43cb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9cbad110-0a2f-4974-a9dc-141b780d004d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "31fcea58-ebe4-46c4-b35d-9a96c1ab577f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fdd549c4-cfcf-4f37-83a0-7fefa9fb1c73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5febecf3-8391-4d71-8378-49ba6d52701c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0ed26b9d-3bb4-431f-8c62-8e3cf93ba50c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ec460907-0cb3-464e-8c51-dcb6b68d3bba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a624ec40-6f35-4b39-8acc-6f9e51cfc583"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "59d61704-4250-40de-8374-19575e8a98f5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "86332ad4-4934-4293-a77c-0dfaf2e7c445"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "15ae4fe5-952d-43c7-8f2f-6285c0198cd0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f1e12765-4bb2-4605-940b-d344b2149fce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1bf6af41-6eae-4c97-96ed-b8057d9a325b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ad21ce3e-224a-4700-a8f7-2d8e75c88e42"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66a78bc7-c472-4bbd-bcdd-47e8cd4091e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b5b1fbc-b7dc-4962-9e26-3e73d0daddc4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d51e6fca-efd3-4add-b580-32c314f78713"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "018edb96-f311-4afb-9502-689b94c55a91"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "15b6f31e-a3b3-494b-98b6-f1b48c51afa1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "50814cea-8721-451e-ab9e-b8839bd27234"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f9dcd043-0bfc-4efb-98ec-b85b7c44d33f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "97340a65-a431-483b-8db7-2e8c6a3c8198"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b262168c-4b7f-4d82-9788-3a09f3265daf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aa6674fc-af42-4a3c-9727-20d642196c1a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "decbc8c2-9a85-4abd-a1a3-15bf3978e0fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a4f0707-e334-49f0-bbf2-0b1ac69c2c0b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4837a07a-ec9a-4801-833a-4d3da02f99af"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fdb53456-ad96-4228-a206-1ac4529f2d19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5034d585-3662-4b60-81d4-43e1280d77c7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "df849a5f-0365-4286-b228-23a33115931a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4ca4cf4f-3cf5-4895-a28d-32e9f00bd005"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "614600c5-dc79-46b9-b49c-5106e651d508"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aee8f965-1167-4328-b813-bff899a83fdd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "af368f73-5565-45d9-a0ce-404392bf94f6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff2065b9-3157-4f73-a541-225bc39d0764"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70f9898e-29d2-4593-9d14-998c0d64649e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7bcc8d55-eebd-436f-8c0e-af963a00f5ce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ebd36837-d407-473a-95e9-240e72d38532"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1dec00e9-3fe9-4080-919a-b8e7af56c293"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "053f4375-ca33-4227-9ba4-bfca1f92745f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ad38d04c-b1c4-4957-b841-f696dcd07280"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5b388383-10fd-4a06-aab2-f36b806b975c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "576eae01-7cdf-43c4-9c88-3a586485d224"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9ca70ce-eac4-49e8-9d6b-a38813fe35e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26aabe82-019c-4888-8693-2bbd60d6a450"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b66be9f2-9104-424a-9429-1b06f0c7cb8e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c14ebc16-4ffb-4e32-bd71-5cb8f933a693"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8af9a4bd-d989-45d8-8ec1-83190c01bcd8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "891f5d59-0f2b-4e93-b97e-f9696347c1c6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a929edec-d05e-436e-b8b9-e4b865399f77"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5abbe1d3-8139-4d7f-bcdc-81a2a8dd8ae9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e379e5f0-75ef-48ff-b1b4-4ddec2e0432d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7f3143f0-0e4a-4e6e-ade4-268bb2576283"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "478c85df-bd95-4edc-88cf-c0d85de0e97b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4895bfb2-f3a1-4b91-8bea-45f906f6e948"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f1ab7116-b7bb-42d7-b91b-3403c9c55142"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e8c93b1-cea4-4f64-a001-6e215793f51b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7564ba2c-f791-46f6-8c93-dac9b5fb1fd9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ce85def-d156-4b10-9087-d90e39442846"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "de720ca0-f681-4106-9bc5-f62896a007f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e6ec5b06-e577-414d-9c45-c9f4b7835dd9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a46f4b80-cb2e-443c-9e8c-c263d883b887"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b3f2d95e-dd12-4676-85bc-cb6916f76aa8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "414164cc-8d0e-42c6-9f42-84ab3dcab792"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "457de901-d6d8-45b2-bcee-205b07c971aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d896e5c3-ee99-4dad-b680-3fc02f38016b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5abc2a73-f727-4e04-8bfe-3a5aac4ca806"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b1c25a06-d8be-48b6-9369-486356676700"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d797041-3731-4fe7-a06c-e9f5fa82b889"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8394f490-b0a4-4fc9-a3d0-3b10bcc187f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbbd115d-2776-4a63-aa76-15e0eed40df9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "196229c0-0b2d-4cf8-9211-5c9108b97bcf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "14d526fb-bac5-40fd-9fab-8f288fe64675"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "861777e1-6f92-406a-9cb8-6694535adc30"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9480e79e-0e8d-49d3-a275-93a46203129f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dd01b488-a0ab-4888-bb14-48467057fa2b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e5eff35-de36-4508-9383-f6a81e601ed2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "296ef32c-d2ac-445d-b8f7-8f277ec6eefb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "29fd7bc0-2134-4f17-96d2-6e401d3a391e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "97f7aa3d-0179-4ff8-bbc4-550815db87a1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab4978a1-bc9b-4a45-b8c7-c49996fa7988"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "86102360-b560-46ff-9465-eda8caefc07f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9d7de1a4-0165-4651-b161-fe4fad796c90"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe450c1d-00ce-45b4-8670-672e772213d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "775c122e-e1ef-4eb9-8174-15a1d467d300"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8dd2ccee-9cd1-4c57-834b-39cff9413171"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f21d608e-8f31-4794-b3c1-fdb1c87fafb3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "898b9b2b-dc7e-46de-9918-34270619aa6f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1207a04d-2e0e-4cf4-991c-a24999a89d53"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dbe7a91b-c1d8-48a6-8a45-8c5d6c04d5d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f730a274-5dd2-4a7d-a2d2-9f63a73a55c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "156bf1a8-457a-4029-b1be-b63d55ecf913"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f74678ca-5499-499c-bfd9-02e5262f0e42"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1381b32-35f4-4b50-873d-04bd70ea0249"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "275776fc-53a1-49a4-8967-9028a0214f4d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "20712598-8eff-4cb4-af08-10fe5cce66c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d482a70-d99a-47e1-bb83-f132fb6ece68"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ccbb6a74-df09-4c61-bcf1-8b33045fbd72"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1a132ae4-431b-4728-9192-9722ed882ba0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "33d9929e-4c17-4e5c-ad03-ac8a91eec7ac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb71f547-c55c-4d22-9fff-10172bcc1cdf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a26a75d5-c24f-43f8-84a2-7bd290b0d77a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8532a7f5-48d7-4185-8249-b9315bddb7e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6468535-265c-401b-a3ca-94c4fcd4d79c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9d9b8ea1-6356-4df9-963e-b271ac3094c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2bfb912f-ffda-4116-a25b-32a4e43de36c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "75001a21-78e3-4beb-90a9-42105d8e0383"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dfa48661-0c76-4e18-8052-69eaa4da0338"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "726ca841-ce78-41d3-9d7f-d6a98a8cfd24"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd5a48be-9f0e-4ac4-aa1c-8bcaeb7f8051"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "64237624-8b2a-41ca-a838-26a60b8d256b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "12f723cd-50b5-4dde-8bd5-e77030b046ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "183431b5-8035-4fea-ad58-98536ecf79c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "76ca9a81-1f33-4dad-b209-a9dc7a4b88de"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "37e1066b-b5ef-4219-ba2d-652aa9e967f8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0d9ebd06-5cef-4059-bb80-ca3a7ac6b3b4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9616fb7c-eff6-4665-89ed-f2206617c612"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e67608ab-dc55-4b3c-8a35-b2ff225b2693"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d5743ea5-273e-4fd8-9622-504a3f2ac767"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "beaffc82-a022-49b9-99fb-e60497064165"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b0058ca4-4f7e-4416-849d-19cc1cac57b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dd2e606b-b05d-4b7e-bce7-b398a181d517"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e577d306-5927-4bf9-8590-07aa23159133"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "15067f89-baa3-448d-9b20-6eb6c4c4a2a0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8a755eae-cc50-4e02-b019-3002e2f7ca40"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "88500607-fc48-4ff6-bb86-e3df81184fdc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "20c4efff-0ed7-4109-910c-69af340a07fa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66fb4be7-c7d1-4266-a9b6-67aec23bf61d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "164c0cc6-21dc-4cdb-bfb4-0939456b3551"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d809d30-76df-4993-8ad5-e2c25ee8b300"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe18604e-04fd-4921-b85e-92fcf28bee98"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "edc5e95e-e95c-4cd0-a6c9-4d559bee5b6d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d322aa7-6d6b-4de3-bef1-e4f92e832365"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e42680d6-1535-48db-b0b0-dee70b7a8508"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "128158c9-87a8-4422-bcf7-125f352a290e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9db4d1d8-7a44-4873-8833-bde1815f0414"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "451becc8-7b87-4c83-9bde-bccee35b65e3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f79f93bf-b19d-43d4-89c7-923010863a7e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "59b97997-e889-4dd5-b94f-90170b953863"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d195153a-6f4a-49cf-a28e-aeb760cb40a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e333382-c00a-4c96-887b-8f4e8eb1438a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2552156-0d6e-4755-9305-6944d0bfa4c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3fcc1c57-e04e-4cd6-bbda-750f5c0c086f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7a26165b-3389-4978-a6d3-0f1a2692943a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5149ed10-e49f-4adc-ab92-3f0db7c3ae07"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57490bff-14fe-4047-8b06-99b480dedd4d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85f08b44-7666-4fd7-ac9b-4c36f5fb1e85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "807ee459-9725-423e-8e81-cf54ba829ccb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5e1dff5e-e3de-4e54-bbaa-ed7178ef6dfa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d6eb2243-fbe2-4efc-90e4-c1270d751966"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "28df0e24-a26e-41d9-9a60-95f0732355fc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "82f4dea2-723c-4c9e-88dc-e7e5dcf9cde9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "058c1c81-6aa1-46f2-8a89-5b54249bea7f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5f54b6d6-0b49-44ec-ae5b-eff2a10145f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e76c21b0-2eab-4ac2-90e7-37cf9c40704c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b4ff280c-1b87-417c-afad-7711be087106"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ca15bcf6-529e-4ff0-8f4f-ace3374bd8e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e705a7d5-9ed8-418f-a9dd-e67becf2bae6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5b598962-40c3-4310-8c00-828d9ec8ca33"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "016a74f2-ee4f-480f-aefd-660283351ec7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e557f109-7bb8-4c75-bd56-acaef2966248"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a88ec194-de86-4af4-beb4-bcee6da7c955"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2e6a7ed-7674-4f73-a549-5684a000bc85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c8314026-60ce-4a26-8cc7-480a47b51a43"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff7f5256-dd82-4210-812f-2cc7a61e1931"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "705c7fa5-314a-4ea2-a016-8d2342fa458e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d86861d-0f3c-4c3e-b3c5-4ac97b901cfd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "11c8d981-91ca-4e82-8af2-52be20487c85"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0431e440-7bfa-44e0-8c5d-18e4ec57954a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9098ac84-7ffe-4a43-b3b9-ebe5d14616c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92c37f1a-3465-4194-b6d3-c4cbcb254922"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f2cecc4a-3eca-420b-b437-6e815309eb22"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "72791cc5-3d20-43ba-aa49-2729722778ac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c6b199c-6ad5-4cdb-a2e1-b695aa7c917c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6dbc039-d7e9-43af-9aeb-55fd6dc1cc1d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "17045df8-74cb-447b-8790-4f9943b886c6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "58809010-5e0d-4e4a-89a3-4ccd859f15fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0f31e5b4-2951-41ca-9ba1-0f83d8ac02cf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "385a4898-03d8-4ba8-93ec-0899c562e13a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc9b1e82-e880-43ff-bec6-063fc83d77f1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e26d4cd7-824b-41f6-93b0-1b886949c0d7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "359db781-64fa-4447-9a9b-537d79f20c9c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed7d0b8a-bd7d-4e67-85c0-ac9b04b9daa6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "38cfb725-5132-4dd4-9846-8a95464354a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eba3d43f-3660-49eb-867c-25b5274544bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9f0b961-6a43-46be-aaf8-d356061ad515"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e710af3-ee28-49cd-9d24-f3e0483f37d6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f4c96648-1a76-4f16-8771-9f19bc7cd500"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5c623f4e-db47-489f-a1f3-9e0328ba98df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "95e4c996-16bf-48cf-90cb-37954b3fa405"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "52286b28-d084-4f58-af78-73182186df30"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a8e98371-4493-46c7-961b-f6f742586fe1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1c40a9b-098d-4d24-80ee-ad93f68d09f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb8b156e-ec6f-4895-b799-7e4209bd606b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "14153b41-771c-4348-abd9-05e7fc04ecfb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d86488ab-841c-4bab-a508-6209071c47ed"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c906d63-4917-4fa3-8135-67a7cfd29011"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6141f4a2-9224-48ab-b10d-06ea7c2841e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3a046cf-89f1-4d59-8c23-73a7dc4a025c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "edd4b322-5595-4f1c-92d4-09cbe40213b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7f88d26-3fde-4929-9ebc-ce30e2de80ea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e572ad0b-d46f-4afa-8c95-41870aa49bce"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "81168c6f-8381-41e4-bb0d-1123e85cf7e9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd6074c9-73bd-4128-a027-f5de65f61ae1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d4a9da7b-69b0-41c3-bf84-f4a7bf854cfa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "644c4f4c-6796-4ddd-a1b9-1250cebd6b55"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2f34d07e-3939-42e6-a4f4-ecb770a924a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d922e45-75b2-4f50-9ff4-5eea3f359414"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed38fa4e-cb1a-4e15-9566-92c093c3d8ec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "665d4aae-9063-427b-b627-507788714f29"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "65bdfd96-5953-447a-8b67-40a6ab3b95db"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c48e94e1-89ed-411b-92fb-44800cc6dcde"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6c63fd2d-c195-40f8-9443-d3f6cc1e788d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a2f2662-16db-4c26-a6c6-339fe3a6d663"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "74fb2fe8-1f3f-44e1-8943-9211c516245b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "919c3b7b-b234-48f4-90e9-907fbb7dcd1d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc1eecfb-e787-4a42-a37e-840061e49772"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "73ba2ed9-f34e-4312-be95-35cafa1416fb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce94c54b-626c-4b6a-9111-a57cd921e533"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0c9a69f4-0c35-457b-bc8e-b789a1cc9329"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e916494-6c71-4a3f-97cd-1bfe8ae57322"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92bdf2d3-8a4c-4e33-9f68-b5f023c504cb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57a9af35-0926-41c5-b6ef-e463c8c07645"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3d7a657c-ce9f-460f-98c3-19daf79989b7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "603513fc-d87e-4ef3-afca-75dfb0ffaae5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ecf01cbd-1943-4199-9941-6e2d104425be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "afc54294-1f8c-4c35-aa9d-c4578c661547"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbd0800b-7875-4b7e-b23f-4bfcd93aae4d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "73c6bd4f-fd01-4ed3-8af7-c7287181fbba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "11c0b39a-fb4f-430f-8e57-59f66153875e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "97fea450-b370-41c6-b433-6534b6313b9e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc9a7019-8fe8-4792-bdad-9bbe2e5c6928"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e7a2477-35e5-4a77-bed4-3f135eb9b4c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc08d2f2-2b6f-44cc-b071-47fa7ab094ab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f4acc707-4b73-460b-9d9f-ffa54b7e6b93"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8f805c1d-3ead-48d2-96f3-4835658b6f95"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc400681-df15-4541-991d-707e654a686a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f23f9f62-9c34-4978-b5f2-ba0e055164d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c280c8a8-935e-490b-8371-c41dbeade1e2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d940dd4-d77c-42e9-a921-605deb3ef6c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e778fccf-75fb-49d2-9ef4-aba00a9042fd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e5d805c-5bd3-4477-8660-4bd04daf050c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a0aefb97-0675-4753-96c6-f67c1081dfa3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7d2a5e43-af9a-48ca-84a6-a4e0d00a7a69"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5a8c11b0-f38a-4812-a0c1-dc5523f3bf70"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b3c15777-378d-4c51-a6e7-6380087ca7a8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1fe7fd0b-5204-4dda-b9c3-67e885312c73"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "28a6f59b-0dab-45a6-b152-d63d49aef12b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "418555de-f51e-4508-957c-4a0abecdbc9b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "03a0ad20-80fc-43b6-a72d-430884bde136"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1dcf31fb-d5a7-4716-ba3b-d8a5c274275d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3622099a-62e2-4965-9d89-389de822f9a3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1a2b87e2-5628-42b5-aca1-a69fc606f1bc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "adf764a6-6cdc-47e3-a365-697de451f16b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "84a34988-e049-4b54-b831-74ec26700155"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e00e31f2-fbde-4ae5-b69c-f0efc53173b5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1401286-bf32-49ee-8ea3-33acbacca9bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "576532b0-f96e-4d3c-8032-98c52485ffd9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a67192b6-feb3-4c1e-afc4-ed7f2d1683c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d044677-9602-4fc9-bff2-4d836a770cbe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "86f1de81-a325-41b6-9e4f-93f72556b4be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab13b952-9390-41ee-b16a-85270ce57c59"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dffde187-a7d5-48d8-beee-ebe8589fbdf7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "19acc018-94a7-4d1f-9255-538d5d2566a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85982f77-43c2-4db4-a6f5-882065fa9cb0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "13166cb8-94a4-4d30-b366-ad44979356c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bd1aaf40-a58e-40d4-8576-2fdb368749f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "20aedc7d-e174-474d-95c0-b297dfcdd7af"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5e72519c-ab27-481b-83dc-4e5024527c17"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e35a8901-a137-488e-a261-7f493ae653df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a2c806b2-aed7-438a-a553-db25c4a5d36a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "159f5b03-2ae7-4181-b903-b1bce7793f38"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "457944e8-2f0b-4e49-8247-0f002ffdf118"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9d95a4e1-b858-424c-a23e-f46ef4a049c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0cd8fe1b-b740-4d25-b402-81a871b48b53"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "080c3a1d-12d0-47cd-ab61-b8bcabae9a48"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7c535ab6-b1f9-4f21-8e2b-ad2da112d9f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "de6c58f1-83a7-4bd2-a4ef-cb581324aa32"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e9c99ef-fcb0-4418-a62c-13945e0f5e4c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cd150082-59bb-47ac-93ba-02181cb73bb8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c81e2af0-b83b-4d26-aede-76e0fbc28fa0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4f581a0c-87fb-45d6-8cf9-5f9bdf1888bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "385b05c6-112e-4cd6-a77f-a5db04e0de0d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ed4b385-eaf8-4c17-a701-15d0c7362974"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "84c77f16-9f94-4112-a96a-e70ca8c364c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cf3350bb-c973-408e-b720-0010295958b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b4b2e6cf-b9b9-467c-9924-32aaebe1d184"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e84fe2b-2376-4246-aea4-c440bd164764"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4eb4b1d9-d5af-49e6-b86d-accb01445ebf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9dae7507-6d0d-492e-83dc-e508c4fa6b78"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a1fa1364-f45b-4312-bddc-cf1ad36c3883"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5a6f97d8-e14b-4923-b2b7-c4ab8d19649a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0adbe0e8-34ef-4079-be16-24124cb934fe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96853a33-564f-4d33-80ce-7ed3444b6c55"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c099f31b-f2ee-4bdb-aabd-e0ff5d406e40"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "704bc8ed-3b93-45da-96a8-60a737f28512"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b51abb3-ad24-4f3b-9a21-e44ac977e4b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "56dd625c-d8ec-4572-9438-77220cf48e11"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f23c0aad-1f56-4dac-b10b-3f7088c4e366"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "39a68e24-a11e-4bfd-8ad4-fd306e4cffd2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4adc9ee9-68c2-408f-81ca-555e6c3871a9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef080756-e911-4fc9-a238-b80ca85dc70c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "97643dbc-ef38-4b45-a507-c669f5e4460d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dad612e9-df4e-4063-8fea-7fcb2ceb945f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "effb674d-e60c-47a4-8849-c02d1857c1ab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "83f329d7-94eb-44cd-995d-c0def461be43"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e51d789-0907-4e0c-8316-7493f9626541"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9313fad9-2dd6-4cbc-b26a-ce78052067ec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d78c5c3c-d2f4-4236-bdee-a7df80563b37"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "33b288f3-0964-4d1f-b675-7c68e756910f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "af352c58-09bc-4595-9528-4fba7cd0dc8d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c0de949-9bcf-4d90-b16c-546a2787928c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7ee9847-e999-48bc-b83e-da739ad9a045"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8f2f554-2dc1-46a9-bd55-94b093e702ea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7f00c12-d54d-4c7c-8f59-2631fb81b818"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ffcabb1-bdad-4393-bbc6-43320f5d17be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bc09b5f9-96de-4a40-8560-f48fa11b68aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1ab82a5-221b-41c3-9027-9aa32efbc406"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0da676e6-b739-4665-9bdf-6cd7dfa13bc3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "21278d35-49b2-4c99-b2e4-1af552fcdb94"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c7b624ec-ff72-464a-9d51-d397c12f288c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4ee7b898-022f-44d7-9969-dc93d7e314f8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee3dca71-a951-406d-83ea-ccac095bda86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cbcd238f-51bd-4665-8836-28b7f817427e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e710d30-0429-418a-a9af-c0aed5e57990"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ffca7e3c-fcdd-45c9-89dd-b875080ea876"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "522d8dae-1df0-4403-be29-24542c914d25"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8c157dd-2930-40b6-88b8-2cf47ba3c309"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e129053-1ac1-4ead-97a6-8fe7e46dbda9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5b7fa4fb-89b0-4959-83d5-2ad223410260"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8acb3700-2385-4d07-acfc-ca7795f94792"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce9d6107-8b55-4b52-8646-00fdb78767ff"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6a77b45-9b0e-4334-9ce3-5cf8f91ae029"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c9fac61-e848-4370-875f-80855eb1c75a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5a0f8840-0d45-4c10-aa9d-41147a9c0486"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "762873fc-aa76-444f-9472-b667cd2d1f8b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff5ef79a-c2c6-482b-a318-e87ecde6b7c4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "825a1e0f-7fd6-4374-8795-f1b86dfa0342"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "355f6b52-16a7-4874-a99a-f2266efc883d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b9cd56ef-3e45-4937-b745-baf80c8931d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "55944ce0-d331-4903-afce-79fc89682be0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc315579-2032-474a-b8ec-7e8dcfdc696c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "22c9ba36-3dfe-4fea-8633-8342f83ee9cb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "80e06a0d-e8fb-4701-8e76-ec254715eaec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b64f6179-02de-474d-b00f-369789cf1dac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc45dc65-536b-4038-b584-5cef9972f07c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "522d31a4-97fe-49f0-a788-041c47454456"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8681e4b1-e1c4-4bfd-874c-fa5b804f8ca5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8bc1e7a6-b2c6-4ce9-a780-55127d522fcd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab40dffe-c632-477b-bcd6-fd6a130c3a33"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ca24d8a-7902-4452-b3b5-a9654e632c5b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7d1897e4-f327-4c75-ade1-8938507f87d9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c33f804-b7b3-4bd3-9ed1-db3057006121"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "466ce51a-18b1-4daa-83c0-06c1ba95c889"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2753c4b7-0e4a-4f61-9145-a7848f9af8a6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8f37d76-3bfa-4ae6-b09c-cc3bc690b772"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3bcab797-86d9-464a-be93-f69918967501"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9641a442-95ad-43e3-8152-93e8be60ae7a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2825f87-c670-42c2-b67a-b340be5119b3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d24c8951-3b48-4eff-96fc-4bfb0824c34a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6dea9868-1934-448d-8e9a-c508591b8520"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "314e103d-c0d6-44d1-9063-faee68ef4339"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d2e02b17-6ce4-46a5-b1ea-8f7b61e0b735"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5fde5693-3de4-487c-8ab7-b8ca970fd01f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "653181f4-ac20-4ad1-8fe5-2b8f04568c78"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "606041fa-b4b1-49eb-9813-23b7f8da54dd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "974422b4-647d-4d38-a2f3-f8829f419c2b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d9426ab-27fa-4855-b944-64e9dd42ab7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5432390d-acf1-49fe-8118-37f46297ae1e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9a0aba99-7dba-49dd-87e8-f10c9736f37e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c63820eb-95ef-4354-8243-2598a1a1af00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e9b38d8-d765-4b30-aa65-7a751f356729"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b23ec7f7-b55b-4786-92d6-d0be665711a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d47973ab-2f57-497b-9210-8037efa58a78"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9d9d2a35-c446-4b96-b361-473fc410d0ec"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "256a0320-0825-4a30-9c1b-6b9bda7c04af"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c447e33-cb95-4eb0-a03c-e280a2384c0d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7daa4a7-ac27-4642-bc30-6f553e206afd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b1fe75c9-1417-43d3-b726-b0765917886e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2b3621d6-3ff7-44eb-9142-d2b31812beb4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c29b533c-b737-4c63-b5ba-31dd253469e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "899d6599-95a8-4a6e-b9b9-f5497cc7012d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a47a457e-7bf9-4b6b-add1-128a5765ff59"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e9441824-e9dd-4723-8df9-4a1f0344aa0b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8a924ea2-2364-4a44-9721-73905a77bfa6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ccb05c79-417c-4763-afab-15a7f48bd94c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e426e107-8328-49fc-8c78-08e120615407"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bcb43928-98fb-42c0-96a4-ea05d0d5aea5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd8c4efd-737a-467c-95f9-dc95b94d2222"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "efb26c0f-36b0-42d9-ae06-6d21a92e2caa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1cc5393b-3ea4-47c1-80e1-3b118496c014"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2fc88d5c-0e73-433d-886e-88d522af1f25"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f427fa8a-9f93-4b22-bafc-b374abafb935"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d89ea583-4809-4c6e-a4f0-c518dac8374e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "36bf5f3d-af0d-4eab-b242-33dde4495c48"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "00f3a121-7ec0-4165-bdf5-5bf901962b5b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70a0e7d8-61f7-4fa5-be48-bab3600db531"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "05fe5470-0eb6-475e-bf19-503ca91f0f99"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0e90e1a6-7251-44d4-a9ea-d9416dcf2465"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ad40cca-b865-41db-ba8c-808c7da41b6c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "604a5da1-0530-42b9-9dda-19ec8d47d36f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "568f7ffd-b49b-4c7b-a26b-9214e96af551"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c5321565-9078-4bc7-8059-56ce67fe3ef0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d5574986-2710-4c65-9a44-1097462160b7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ab0698b4-5805-453b-9770-4c228b2c6f27"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a6e74db-7bc3-40e4-8570-d984de726ac1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b916287-b888-4f7d-8734-f6c65f8b3629"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0fc28ad9-84f6-4f09-80a1-3262a0322304"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ebe27db1-e1fa-4a87-bcb4-530eebfeff8d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2f95512d-8f34-4c26-938c-9a745ff56e2b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "222e48fa-582a-47ec-8ce5-08f9008f06d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d09574b6-b3a8-4233-9351-882de99475e2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bcee3082-c06b-4b10-acbf-42d4bec8f28c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b16996d1-0b70-4ae0-8b37-d1cc3f0b0ec8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6dab18a1-06cd-471a-9bdc-af224f9081c2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "75e4cec8-30d8-4c96-80a3-368060b3f418"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "41d3a71c-c7de-470c-a15a-5b730b4370c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cd7abd56-f8c1-4e76-a3e4-2571db048096"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ae4f58c-0ff0-480e-9fde-29930fb4241c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "952d785e-1d83-43a9-9983-e88d04b51811"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff613971-e812-43e9-8d2c-a071c83bb4ab"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1a657b95-4284-4336-8861-6d4bec7733ac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e86f6a6-4ada-42e5-86ba-838840f4a128"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9da0e8e2-4f52-42dd-b1cc-b87fb56b5846"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "004a3492-6952-4a20-961f-04223b29d627"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8bef7bf1-df33-42bf-a567-cc5a2ff5cc24"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9110e6c9-4e5e-4da8-bc9b-c4a8133da1f2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e64b3077-ea0d-48e0-ba6c-9b3c71e8ff04"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f72659cc-bc6d-4ae7-bbc6-dd90675aa874"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a107161-ba65-427e-813f-9cf9a0a64ceb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "af0f2238-c84c-42ab-8c5e-0660b1c04c3f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ae1a26c0-12b9-4184-b4c7-aee21d8a04a6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f42e5619-5c46-450a-b13f-56ac42cb779e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "409341c1-3e0d-4b20-99a6-010a98bd0cb7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f2995770-9253-4f01-84a9-841fcd9c949c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fd297bf3-627e-407c-836e-f2305f8115ad"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d0179d15-acf6-411f-be4e-16860404187a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6301b00-f856-4ad9-8247-5251590c297c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9778a8a4-d52a-4b3c-9fae-3e67f3a46603"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ef1f3f5b-d91d-4d96-b380-a924190c8035"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dcc45564-730b-49dd-9b57-3503c75389a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c3b97151-46b9-4642-bc44-6436ff54ff40"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "06230ca4-1da2-4691-8cf4-d6431bfe5a6e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "20d203f7-cd60-4352-9805-db03b5616250"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e545701-423a-4be2-a3e8-4ecc69e731a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "47fb45a2-46c4-451c-83f0-a08aee12b9fe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "06bbc378-41f6-40f7-ad99-eb59fa9534c1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a488336-7a39-4cb8-a97c-c8ca2b2a20b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "78acb2f7-7b13-475f-8b63-c1b5f94d4f93"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e46e5ac-bdf9-4702-9fe8-7689d70c9a6b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f8813c33-893a-4ea1-bd34-0c89610550f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "565a0966-f90d-4c97-abba-27bb99237113"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8858476-5f5b-48ab-bfce-bc45b128f897"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66242d89-4da2-455c-8ee7-8104beb0a80d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "47a2caf2-9016-43ae-95fb-f4ea898ce8c4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bc51bc1c-f092-4ddf-9d1b-b49d8fe2abdc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "47267d48-4b7d-4361-b551-b54d27581a3f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "14b43c9c-6530-40a7-b933-6b24a1cfa5d9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bbc45329-148e-4180-8dc8-ff6aa86029df"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "40c04833-159b-4a7a-81a9-2a9619a48ad3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b43c6ff0-a16e-43f4-8203-91bd47a6b9c9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d63d2461-329b-4e97-9234-7c172b45eed9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35c17a7e-9443-4dda-9f31-ffe90aeab733"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85e4264f-0842-420a-b66e-274c8478feb1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "624b0311-8d75-4c5e-a53c-52c397e4c99b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d1de8f4d-1d69-4444-af82-1b47fe5b2e9e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8a036b05-44f8-444a-933c-c32e8fa5e154"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "67d0aeb9-84d2-404d-86fd-309bed264dac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b304f81-3083-4aaf-a218-ccee4cb42d05"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f88c7e9d-0ef3-49d7-9471-41f709888833"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "44d0c01c-194c-41ac-bc7e-3af691acbe9c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "55009a27-d911-489c-8d24-9a0762b3253e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d9da2e0-2346-4c66-8287-edfad241bd40"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "862d8eb3-d611-4b6e-b3f8-9f8e9d150c22"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce5b0a7d-6554-47e7-87c0-4ac7599c62bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f48da88e-a140-43de-a3d9-46b7beaf0140"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "769efea4-d989-4c8f-9471-5fd84579d7e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "69256b30-985b-4871-8414-41cac2707993"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6c00181-0f45-4b87-8eb1-acc91e968ce5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e5316de9-b894-403f-916b-18c58bb830d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7bff1dad-144c-4b3a-ad44-05fb8af1e3da"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "319c36ab-d83f-414f-9526-6887cf7895ca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8de2ca9a-8bce-480d-b152-e3b7afc2a89d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff72e8f6-d7ad-4bd6-bce7-ddcd846950f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "98a3ba25-3105-43b0-9045-5a81c3fe1f28"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cf8a06d4-cbd4-4f82-98b6-e5b3b86c2282"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce750b6c-1dd5-4301-9471-053f92de8950"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bbda788a-35e4-460d-9ec8-3901311af43e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "605038bf-d0fb-4eab-b82c-8bd16add272f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4558acd-63a9-41f7-8354-8768c942305d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0d38412a-b162-4993-8086-fa0bdc959b58"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "17214413-75f2-4a65-83a3-162c6c95ca7b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8debcba4-b3c4-47c5-9603-df37c73c4a91"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "23f65169-9104-4a26-b381-d26b09697615"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0ab4a2d2-2d03-4dbc-bd6f-8c8a405f09d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d0ce80ba-c073-47b9-9b90-36da7b614a1f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bbb88257-e88c-47f0-8173-8df97e14346f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bae0deec-873c-44fa-a54f-a38322491ce5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d0568af9-feb5-4f84-b442-b261194b5510"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0e6aa4ff-e7c8-458e-b47f-19a5b4c7feaa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3378ad1b-4ea5-4692-9ffd-f82a30e0ca8a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "72df93a6-8cd9-4d41-8c33-d675dac1888d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0e66ca06-3568-4f76-9bd6-9891c84c7482"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "241df6d4-9405-433e-ba29-445d29c5e220"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4894a382-3a85-4ac8-9ace-d9c59029c79e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee9477a8-ee81-4f0f-a976-d1a38f89f6ea"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7be530b2-4f85-4a85-b332-9985caf252d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "567e8c91-9be0-4b38-a525-2f4dd905229a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2758ff5e-98e4-408b-ba0b-81264e6eeae2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bc37ce4a-3590-418d-8721-ab1d1ef874a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2e533ab2-f9a5-40e5-b132-7f4b212ee086"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3c9d7e90-0be9-47b8-b68e-bfdb8cb3ab19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "faefc658-12c9-438b-9610-e4247e9e5aae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e5772138-52d7-4265-952c-9d81ab69cef9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9baa3057-0802-40d8-8b6f-c66561cb1e02"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e268b32e-f90b-4418-a1b4-beba030b119d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "335a6acb-29dc-43a1-b3e1-d03e9183d1f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a6748eea-6421-436d-a63e-419318bbee26"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ea1c08e-d75a-425b-bd84-d6b760b04770"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "21b42025-b195-4758-b480-45fb4e6f6998"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66d6ce0b-76fe-4112-af8c-7cfdda2e640b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3d9d3c12-5730-4962-8889-33986e1c49b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb76f7f7-61e2-4a13-8a81-52938beef5fe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6066a442-8ad1-4dc0-bfcb-0d2363defef1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "21559909-c5ae-421d-915b-b62719ba4365"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9f0cc0ce-0e40-4765-acbe-6025f7917531"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ea94157f-e843-463a-8eb7-0cd5103fbbbf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b0e0cfe2-e5d0-49c7-a514-8b8c5be5f0c7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ed0117a1-b837-4848-ab1c-e168809248d2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "25e07d20-680c-4deb-98df-4c2a0830ef70"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "775a764b-19ff-454c-b7ad-22378d649432"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e3fde322-b066-4ee6-9c52-62975745e777"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c59861e-5ea9-4ce2-9fd5-b524ff9c1772"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fa30dff0-d616-40b5-b43b-cde3c38a05ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9a553420-1b51-4595-8888-b82e9cae5977"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a9680564-f5a7-49cd-812d-d7b469c571d6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "91aaeca0-19e1-46df-8339-6ddf90479943"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "76ea4f77-ada9-4710-b1ed-971698b3f353"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8e6d8b78-fd2c-44f4-b5de-99a171643fc3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6155dc6-e709-4bdf-831a-b105a8199eae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "105e0fad-ec76-4d3a-b3d7-12637f5ab6cf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "128a21d3-8b0a-44b4-94d7-51b82686e2db"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4092d535-e00a-4035-94ff-6ed12a0d3337"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "47525475-a23d-401e-b91d-2c323c2ef40e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b5ffca0d-c6e7-4676-912f-a98a6cdd9cc7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "19721281-36e3-41e9-9de4-fa3387dfeead"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3a092b7a-33e0-4f73-ad0f-27c21b04cf8a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c2fd0e46-da3d-454d-8df9-c48c5f14a4d4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d6e24181-ce8d-4ec6-ba7f-dcab842db894"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac5e6c3a-1ff9-499b-993c-2f771bc72418"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "63daa044-060a-4da2-8a0c-dcbc48f47378"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2967f092-bc2c-4f45-b738-a211ce1fb56f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e81e2b3-c3fe-4ef6-b3c9-d0abf7a832b6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d64ec4bb-ac48-4aa8-a6ed-26c83e19c628"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a56c5e14-632a-49df-9f47-ac0ecfd18f7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b97ca494-a664-48f5-9533-8b7b5baa9ca8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6f5348f9-2882-4445-be86-8fd6b3d2d687"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "16f16947-5a57-4c13-a182-add81e6e91c7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a5338acd-8b68-439b-8d83-f3cd38eb9247"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ca3500e7-7d1b-48d5-8941-fecbc73be5e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "205ebbbc-e115-4093-88e2-55c5e9cd3e18"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c04b3a70-4f96-4fcb-a90f-356f427577ca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c282d0fe-9952-4c15-be67-74e338fbd30f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ce548fc-24a9-46fc-bb5e-376631d4c9b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "feb57ed2-71b3-465f-ada5-894e5c5f1d76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "80f465b8-490b-434a-b7d1-5bb5378d9348"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "88a84a02-aef4-4041-b642-6cbbada04da8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7366b26-1315-4b76-af6b-30048a35062e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "258169be-e5cd-4a51-a3cd-d71b4c4b2217"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eef4c550-e929-4ca4-8ce9-776c2886a191"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a9a7d17-03fe-4ea3-abb8-4280be134639"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d92f8434-2100-400b-91b2-a1b09a079e7e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce5a9e14-06ad-4761-be11-a429c91cc204"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "516f1984-8827-4e44-a6a2-36c3b2009b51"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fc15a1eb-171f-4c56-98af-a53cbb2aee0b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "65e69479-1de8-4ad7-8d3c-2d94b5c2de41"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66af8373-81d8-42c0-938f-e0db6bbcb936"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35380496-eec9-4cf6-b17e-e601d61c87f8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "938db7f6-b142-442d-8eec-49e8a98c6f9f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6435011-8ed8-403d-8e0e-e2bbb44ebb09"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e204fe6-306f-45aa-a711-56239cae04e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eeabfe2c-3f87-437c-b7e4-cd027580794f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac497737-f7ae-4923-8ff7-e72857f18f75"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb0eb814-4abe-4bcf-a147-476341618a8a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3714a163-582a-4073-ae4d-7de03bfd1070"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "743e1a98-4cd2-4f67-b2e4-32c50fcd3b56"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d15a0a0-6def-4106-85b2-8c652320091d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "26c04c4c-0c91-4730-94b5-a2ddedbc5fda"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "97baf3f3-1527-4152-b9ff-9d3694fb35fa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7b46a51d-3a3b-4295-8ff5-cb31af259d03"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1fa629e-98d2-4482-9682-fed92bc0a28d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0912ab4e-7e1b-40ab-8cb6-354e62c30acf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "39dff148-90c8-4cd0-a84f-922ac9f316cc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e20e30f3-926d-40dd-bfeb-bd97258d3a5a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f51895e1-9ce1-420e-a4bf-3e0aff38c5a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "27feb271-c8d6-4a0a-bba6-b2ae08185f86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3c840ce4-a100-4f52-8e50-baa326457938"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "529fbfe3-615c-476f-8094-c9cf66bbcc5c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a509cb84-7e1c-49ba-9998-58e16a65eb96"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57bdb80a-dae9-4bbc-b4eb-888811674821"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c0662df5-7532-496e-ad50-0725aec70aa8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe7f0dc9-342d-4f21-876d-7f12934e8301"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96c35b43-790f-4ddf-9ddc-7127393641a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b2cf249d-4ad3-4439-a2d5-d55651e494e0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b7121c0b-6c7d-4e62-b7eb-35e06bfc867d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1d82c075-3198-4327-88e1-443e048a1bcf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bc07046a-27ff-49d2-8eaf-4a8537faa19d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6b8d1df-883c-4d4d-ad15-74555106d167"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3ad1d48b-e46f-4518-9602-6e65ad3243e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e5903ed-599e-442c-8b3d-ac686d8f6324"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57ca71c3-edad-4a7b-9a5c-72f25617407e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "471f4214-49a1-4ca1-b538-031c384ffe31"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5caf4c26-d894-454e-9315-dedeefdbd233"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c0b3f182-4ff2-46c2-9177-309d00afabb6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7c85e29-ec03-44a1-ba5b-0f41304e811b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ded5b7f1-92b4-4542-bf1b-d0650bc0205b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "683723d0-d7e5-4623-b195-ce71a41398aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a5121dd4-5d93-432c-9ec5-1cfcc57c7455"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5242c2df-e48b-4e17-b1d5-38b8102fbc98"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f6fbbb58-5086-49ea-bd98-1eaa0e4263e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b3114a9-7014-40af-b7af-77e9f299535d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b89b411a-d16d-4158-9ee3-f050075e8e2c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fb39a21d-1cad-46e6-b3df-caccf77acdd2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "11b8fe08-ba4d-43a0-88ba-badd98ffc5e8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b2354b3-3cd4-4154-9198-cc0ace6d14f8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "67ccac61-2221-4477-aa31-3558e2054a8d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9bffa16d-cda6-4931-a650-85b5bab393cb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1cf169a8-f892-4454-9751-6c91c71d9d15"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5ea5561e-8689-4989-a2d8-43dbd396b194"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8a735b09-78aa-40a3-b1d6-0d6b8c813d99"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eb87b5f2-3ec4-4e47-8578-3e9163b0655d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7e83a51b-769e-407b-97ba-299a51990aa4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b08ed6ca-14e9-4620-9e01-3d5254b15550"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a6caad88-aad8-4ffd-8bd1-be9ddd37515c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "647937b4-866a-4029-9b2d-ead3f42b712a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aec3cdea-59a9-4bbb-9fb4-9299d79041d6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b746bfa-b218-475e-9108-ec9fe559b19c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b77b272c-7bfe-4546-8b7b-70d1846af913"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92dea853-e313-4270-b343-cd5d06f9ddee"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c216be8e-226d-422f-9323-50c6af3f9a72"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8628fc0b-4fac-4b7f-b48c-2953f499cbf6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e87acf29-a458-4bf8-ad83-29ce92ee92bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "865522ab-7801-4c92-a2eb-ead7b314430b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "49a2cc76-36c0-4fe1-921e-70f60f69efb9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6f906b8-60b8-4d52-a831-658a1d8021fb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "564ae929-485f-4baf-ae4f-de7a41c591ca"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4dd16764-87ed-42af-ae56-b45271b119be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f51eef40-f5cd-4d02-b3f3-23b3a19e9ea3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "db11534a-40d2-4444-82c0-2e4e2b6607a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a94530c5-66f6-443d-8bb0-2a99f2690e29"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e77fe044-84ba-444c-8644-1526553050f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "edf997a9-2ce6-4e38-9a80-2305a7861122"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6ca691ca-b35b-4698-96a1-6d9b7de2cc3d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90adb395-a161-4fd7-b265-33dd07c54cf4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "85182979-3c63-442d-abac-95293e9ebcd2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac5b4fe6-1502-49fe-937b-25078143fb07"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e1a5e39c-7441-47da-b37a-741f4decd945"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb0294c5-9b5d-4d20-859c-ccb82d4a4efb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "46f78876-4c0e-40f9-9e5e-3841b8da6373"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1df0f1f3-327d-4607-8227-e55db3c005de"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1563b5c6-7506-4399-9fdc-35a2ea7730c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c83259e-9dff-44a9-bf40-8cbfc2e6b7ae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2443185e-41c6-4411-8622-1d348f730ddf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1bdcfc52-63be-404c-9dce-4b627a44226f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7eb36de6-a3b4-444a-96c7-797a2de26b4f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "216e45d6-9d8f-47e0-99f8-ff2d024ae104"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c279ba7e-c90d-4069-9e62-cc98e7094499"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8c32cfdd-b2da-46f0-9d5c-b96279bf32ae"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b23dfdec-ddea-44ae-afde-0f9d5b876cd4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc94e85e-2558-43c4-bd96-a0ef9256f47e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c0756cf3-6ccf-402f-8021-48f9db71cdf6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "42582dac-b8e9-49fa-a6ce-508ef8480bc9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8f36d6f-d9b3-4e1a-ba25-9509251822f7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f8234042-24c9-4910-85a8-00f143290c7d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66ec3bbb-1e43-49cc-a7df-da2a3af6ca76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "48d605df-4956-48b0-a657-dee3f9f7579b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "779fbca0-d2ee-41bb-9e34-a878aa78f0f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6440b38f-0417-49af-8998-555918a3eaa4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aa82f65a-d3ea-4653-951f-cbb8d7edaf06"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9aa26e47-8833-416b-8de2-58a777a348d1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dea87fe7-fde5-4cd0-acc4-d3de571d230c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3c08d9ed-b140-4c67-836a-7b064e6e1db4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "561a642f-f05a-4efb-b582-6f0e6b4f5190"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "111e7df6-0cb7-4cc0-a3c5-a04da3563b97"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc4c765d-ee55-4724-b4ba-9930d5c76c3f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "93bb42bc-ab4b-4469-a58c-4f6c2e5184e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "09594cc6-0416-43cf-809e-fc736218f75c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "92834c23-46f5-4d84-85cf-d8496d6b8934"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4ef8dcf6-73e5-4435-a7df-97815f7fa313"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e3c4c627-2447-490e-9a61-c2d28d3f3760"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "44ea46b8-6990-4b38-a04c-4e02933da907"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6a8d1274-6a40-4292-ad0c-00d1aa9bbaa2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3546a734-d74a-41df-926a-83267363221c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "10b34cd5-544f-4a8b-8744-bd8cd6380961"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9927186a-a982-4082-9f19-5b04397ea193"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cb932ab9-a18c-45bf-b3ab-27d66b0f3050"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57d8bb0b-41ae-4c27-be53-ca63d88b947e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a1660b82-66ec-45ab-a8b9-c9fcc581ced8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d8a28e12-4fe1-4574-958c-c04b90ee514f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8de075ac-22e1-4e6c-939d-94c02c3df341"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "66bee100-e823-45ef-9162-076ddde5536b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c90cc9af-acc2-461f-9eab-23804ec6bf28"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee0472c0-029e-40e5-ae17-cff3aa493fc2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8230bc7f-0e6b-424a-84a6-42973bde2856"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6bd4b27c-f149-4803-ae06-93073b558f87"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c5a33346-5681-452e-b524-820bdf1b4de4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2d16f90d-c6ab-46e6-8e2f-e9a99a381c20"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9d071ff5-403d-487f-b2ad-6fdfac2ccb57"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "60b28248-593e-42f5-854b-0deff724fe91"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "954cc9ee-9029-4835-9137-89681132f727"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ff7ad482-c8be-44cc-ac0d-681711e7f34a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c11095e6-6a91-4ad7-a2ff-459ca6869fb2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ba94bdd-fea6-49d4-8f1d-07d2d464f275"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "705ae952-7fd8-431c-93bd-6bf05f12d25c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "35801e61-089a-4659-b105-cabec030adba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ece4946d-28ce-45a1-a34c-fb484c3ea761"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1f323c9b-a7d7-4877-b19d-623b92bda1ac"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "60d110fe-0e1e-4e8b-9591-0c99fb7d41b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1edd24cd-1abc-49c0-9ab0-c5839b9fe2bc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b2087224-92f8-4297-9659-608188932a4e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4d6e925-2a6e-4932-926b-271e649013c5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b5115a19-245d-41e3-a803-6b70c22cdb42"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0d16f24c-39ed-48e3-98c6-6982f19a6f9c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d6d9845-cd72-474c-9313-c9c038397622"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8d92c13f-221e-4856-b58f-bd5f6ac2886b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f021d450-2fce-4be8-9a28-2c67f4a04a69"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1691221b-c6a7-4ac5-a29b-2c058bf6a252"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4069e384-ebc9-42f5-b04e-7dd1d8516708"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee6f40b8-5fab-4361-89fb-1c033c09569a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b2693436-ec63-41bc-a4e1-9951ed3687c3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ce00d523-a56e-430a-bd7c-7091c4fe4d3b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8b0cdf3-570c-460f-b9d0-8eddaf2a48f9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "27bcca9b-3371-4e87-bc34-eee6dca1ea94"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3afeb0f0-936c-4030-8a0c-6d5ecf820d99"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "aaae78aa-e119-483e-ab04-9423a0459d84"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d681b87-ef14-4a93-b49c-6f20cff27ca4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cb93d4ca-87d9-4cab-b759-6d8355dcf228"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "478d02b4-a412-4654-bcff-67ff4713c644"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0bdf353d-666c-43bb-9b1e-bee2f6780133"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "616377b7-18f3-4c74-802a-ceeeeba35fba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "82b613ef-c8ac-4c0c-b53a-ccd130cab192"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fda74d23-e9fe-42ce-be5f-1f09c748b8a7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6fd90a16-2bc5-490e-b3cb-203261aa670f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4174e688-8bf5-41e8-975c-bb7f237bb375"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7c22e47d-96e4-49bc-beb5-1a8b9051b1bd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "57bf6928-8a54-476b-a68a-8d72c8e885aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "99c2166b-fdfc-4c60-abbb-51f969157bdf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8068c3be-379f-46d6-8d6a-adc876a3ef27"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7508eec6-0f0f-423c-a5f2-36dcb1aa7073"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "22b6dbec-2184-47cd-b11d-14b439cc9b48"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2c7019c8-19d2-4d65-a644-97682bd0636e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8d7b925-dff9-4806-8f94-602460876b0e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "215e3d51-e4e8-4b91-a40a-50ba09321697"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5776c66e-1b01-4b4f-88ca-af27e395b2ed"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "28e71c61-764e-4e71-ba4f-b7d51d5aeec3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6a096fb4-215d-44b5-88d2-f4487b9adfd8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4dee9fe9-4988-4608-93e1-a127044278e4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1114ca15-7419-48eb-9042-d16911f9475b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "614ae4fc-8e67-48a4-957a-d73540e8a5c7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c559127-6406-4be3-9ca4-c34bb3316ea0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e728acd-96a8-4761-8f0d-0802fb409433"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "68e0deb3-b95d-4770-8eee-4cbb7d1a6195"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f5a2062f-47ca-4a4c-956a-5fb5aed349b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1d00c209-2478-4e64-9bc0-189d42b59035"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9e366282-dc7f-48fb-a824-c814dc4d48e2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f843cb55-8f8e-4958-b04c-51bb92ccb651"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "073613d3-51e6-4f55-8776-9cbdbcf17197"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dee41ade-29ee-401b-b23d-ac0e520482d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9b2476f5-b5e8-40f5-87e1-54ef6ef6f47a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "da702c73-94ac-4c33-9120-6eb87333ca51"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a30a0bb5-6733-4875-a3a3-7cc3921430e2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4a0c3a8e-972b-4122-acca-08a26cb8f0aa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ee972375-d537-483b-b1fd-82ea6835f925"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a7a92211-b40f-438b-a33a-00136d62f37e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e4ad38af-e2f9-4b20-a182-f3f398ea0380"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "02076351-69a1-4803-956b-ed6adaffb6ef"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7107825e-6dd8-4141-bea8-20e150b82747"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "34583e46-7917-40ca-abc4-d936f6c205b9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "788ac67a-69f4-4a40-a14e-efeea8d56ece"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d065316a-e9d2-45b4-873f-a26db5317a1c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "195f6722-4b58-4263-b589-8b5d13a9d696"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "75de913b-1422-45f9-92b9-9fb3a174d115"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "09ba37e3-aa22-4f31-b587-326551fd5abc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f58a5835-891a-4ea4-b0dc-0bdf2affc730"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b9e25ea0-8200-49b0-8295-8fd71152d3bf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2a842783-f733-4e57-a6f2-c6354991351a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1eac39d1-ac2e-42fd-8786-75d4949bf5e7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8118013c-2f24-47a1-acaa-f8220c05b719"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5a2a5205-cb0d-4de1-9949-22371e2f70a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "550ea467-83d4-44fa-9358-dc3730d2c665"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ece9e516-97d7-446f-8be0-266bd3ba02a2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cd8cfe85-42c1-4c11-a378-c97722b89e9a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6fb3122a-a35c-4b31-bf48-a9b42edd0f79"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ffbc3565-4a19-436f-9c87-2384cc2571a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc719dd8-af94-4fef-8c3d-b39c9a337cfe"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d4734c1-b348-4701-8bca-41c9ea6f5855"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8b5a7702-4c66-40a9-8d45-b836fffc492e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b5acf89a-d7e6-489b-9779-e688121fe3bb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7c09417-0e00-4cf6-9ed3-942982472cd6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "939e4d90-689d-43ca-addf-dc315f15b34d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e3fb9079-d3b0-45f8-94d3-40cccdf5fa48"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0b9c520b-70f0-42df-84b7-94427238b6d3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "63fb2575-c557-4d06-94f7-80735358fbe7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a1cbf0a-fe2b-48c9-be39-c7f2c3d590f3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dc46548c-aa58-4c41-bb90-16809a7194cc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d6971fd9-60e5-43c4-a87a-c65820049d9c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1f41e069-92a3-42ae-90ed-d19ca1b04a65"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ba3906a5-d8d1-4c05-b04f-34dc93fbfe1b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2f010c24-19f9-4592-9489-a5878e98b4eb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b100dc15-63da-4c1b-8f54-533aad66302a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e039d61-8245-435b-980a-86dae9dbf78b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "58a7d1e3-d055-4a22-aafb-57530cd18cd6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ccaa31fa-ade1-48fc-a1f7-8fbbd09bcc1d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "688a0f6c-f617-445d-8729-bf7938c2c9be"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4529cf65-2cbe-4c49-8149-c278dedd5b19"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "637aa467-f8c6-4ed3-b3c0-f3b3e5957da2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4b1ed299-9ac4-40ac-8be3-c8e9915f904c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "65922510-4d0a-47ad-b528-0bffb5ca9379"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e0d811f8-3345-40ae-9961-651e9093f120"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dfc1228e-4c9e-4340-950e-1a7d45da856e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1667d82e-0d07-48da-a788-f89f48fa6d43"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "df576119-77fa-4509-a094-ceed2cfdc7d7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5126da3a-01be-4600-8c4c-ed2ec2893117"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "43170e57-57f6-4b14-b7a2-9a374db83cdb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2090ee82-3f06-4987-bf6e-f4d74aea9b14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9107c8da-51b2-4107-8372-499dbc5dfe83"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "27e745dc-8fd5-46f2-90fb-284db44b4da0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7c1f77f-6f54-4d2e-8119-d4871f63fb51"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "030bc5b8-0eda-4fc3-a959-910b9fc5207b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4d613057-480a-4420-9045-4338fe6985d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7ac97cd9-6d9c-4317-9b83-2c97e9e35bcb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6cf394a-a025-47c7-bdaf-90673df78d1a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f09cf473-8185-47de-a491-52c7598259b5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3ff2153-5bd7-4296-9c20-a7da4e865054"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "29e8ce6c-83da-4efe-8999-15964b5b86b0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f4962cea-a80e-439d-aa89-f518864af0b8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b05d2a8d-65b0-4dec-844a-a42897b0d92f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "366fb53d-387a-4671-89bf-bfa1412dcdcb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5d0f50cd-29db-4f02-b726-deac6c3546f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ad1a1188-2acf-4d7a-bf56-9f049d26b125"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "793c76fa-455a-4f6f-b017-755f1b0bb389"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a3de9080-8fab-44ff-bccd-4098e0ed6867"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9c751079-eaf9-49c8-8b31-b77200057db3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "118143c5-af4b-4c16-b7d3-a2d2d68e7f7c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "19c367d9-bce7-423c-b574-c56f768db8f5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2fbcd40c-0001-434b-aa52-2f0aa332d449"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "977a73b3-5808-4977-9f61-dd44381a69fb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0071167e-f273-4ddd-9177-9865a084718b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7d2ea136-10be-44cd-b883-74d13d9d8f0b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fe45499b-f826-4959-8012-4f18c8fe4490"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b6e2acf7-942b-4319-b456-8da9271d7e38"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "687016e1-d1dc-4c2e-91a2-935c143c20b7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7dd3caff-ec96-4a8d-b781-569b7a4365a4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d67c01c8-05fd-4ab7-a349-305a7d0a2e86"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "91905bd7-8121-4351-9034-2b7d19dd5f4f"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d3073e86-b875-48cd-91bb-dfed9542df71"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ebd22193-dd4d-44a0-808b-95e48bd7e5dd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1e0b5281-0abb-483b-8a36-e8c0647820f0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "83d0fa72-e623-479f-acb4-8a9a6b8c6d01"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a912625c-6c80-45c0-8e23-c43e77bf1f33"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ca1cc877-7782-4bec-8151-b7c0228bd262"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc85cdcf-1bd1-41a5-a7ac-cebf4753f365"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f3e0a296-1d99-4cff-846d-c671aeb8bacb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7fa94846-60cd-4f07-856b-6a2d17c88fcf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b145fa8a-18ac-47e5-b7e1-1b8549aacafd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5817fa11-57f1-48be-9aa3-cfa772b759dd"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b468e128-c430-4958-8239-c33d2d818daa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d04a8b7d-b204-4412-8946-71cbcdf8074d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b022f9ae-2e88-45a5-b0e8-d74a3e358e97"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b714630c-8db4-4fa3-b210-e387d8fd0116"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0a1a7507-6dd1-44ee-80da-71cb7bd22e4a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "96696bb4-93ba-4ee5-af7e-b7278e3c2903"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e7801109-7402-4fc2-96ab-6a5ef9b48623"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f61d55c2-c28e-48d5-9cc2-f9f0f8f94dd7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b8da8aa9-4e5f-42a1-a96c-3c31b4711a46"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "bb5dea0f-98ef-485d-ab1b-f980e764ac76"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c6f469c9-4348-4a19-a309-1d19e24bdee2"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b23841bb-a853-48c3-a3ca-4233a59534f9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c0556e5b-6387-456b-9766-6960cf5ab23d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "9735dcef-7694-4c4a-b177-7a5bade63cde"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c2185df8-6ea5-436d-9560-ec02423f0dc1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6e1d9f87-a816-40f7-b5bc-076c4a6f6fbf"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cb216a45-d047-44a2-8782-02cd52832e1a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "14b3daf4-e97e-4bb7-abf2-1ec02ce361ba"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "927d0c66-6771-408d-9093-ee4c518336b5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2abf625c-75df-4d56-9b8d-5b2226b56098"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b02c837a-741a-48cc-906b-81ab190a3819"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d136b97c-8a83-43e4-b241-58e9272a3e6c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d7f119d7-d9a1-4ef1-abc6-b83336be7248"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3f90cf4e-fe5f-44ba-bb24-362f7c6e6852"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "968bc6e1-22a8-402d-8409-4ebb7fd5902d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "dfbadb9a-4585-4d1c-b420-ef6ba5b82e89"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a4691ed7-3e27-46b9-8ce7-cb912d88cf28"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "971f8fa7-2f38-4ca2-bdd8-805b9ee8c731"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "609356df-3130-4ae3-8182-363671525dc0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3d05c684-4b2e-4ad5-b5e9-b39e64e92c15"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "32c5f984-4572-4c1a-ab99-5234de90b460"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b25adf29-8edb-4c82-947c-de2d1fbbdac8"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "0103854a-dc27-4885-8e62-b4644d08a793"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1ed1557d-88ae-46a2-9ee7-560461a088fc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "1abb7848-ee32-4d65-8ea6-e73ad3c98aa7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "809c4c3f-3c56-4949-91aa-117cc173b702"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c2b171a1-6c0f-4b9d-8283-7343e09b0d8a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "79a8ea1c-6bf2-482b-8ebc-455402d247d3"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4c78d87a-7f51-42bf-bc64-fe399c421f14"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "a1988b0b-97d3-44e3-ad91-d6e26ef991a6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ac8e5ea2-5ec3-4f32-9c60-c076ed40940b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "af56b359-b61f-4936-b76d-837863e1d237"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "61b661fa-0c97-4b43-a9f8-25b171d0e75a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5c8c082d-7ead-4d61-bc20-f7d255b530b1"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "469c6520-0037-444d-9fdc-200a4906ba37"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6a5c9e69-decc-4c62-b614-be85c7a8df9a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c15c22a8-7a5d-44d6-bcd2-cca076a21a6a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "28967bdf-b1d6-4252-ac99-8d79313a3a27"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "fbbb84d0-bd92-4121-a404-d51787a9e8d9"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "82e0e8af-0681-4c16-a57c-35785b3b5bed"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "10f2dc40-1ec9-4ae6-b6c4-60c08c5b08eb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "2042ae5a-109b-48e4-907b-b278bd699bdb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c2c447c8-dd93-4721-909d-0d6112e6b4fb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "af5ab1f1-4157-4bad-8402-0f73f16bd0fc"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "12126621-1480-4855-b06a-c0d1f7a3df3a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e95af88f-aad4-4f86-aee0-d47029f5a191"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c4ca7a42-627d-4870-84d5-93455dd4bda6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "90c546a2-4f44-4f8c-bd42-ebfefbf39ac7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "611284ed-d501-46ee-bf40-94545bae704c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "76449157-9d57-49e4-bd7f-6a8c19ed9d5a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "79d2cc59-935b-4e8c-a2ef-ce7f2a831e23"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "16e914fc-5545-4ca8-8ba6-ba6a5f3c6fde"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "17c327dc-1396-4e2d-bb99-f686f464e71e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6f93f102-0108-4f00-960c-14ed895a3a6d"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5077a948-afdd-4046-82d1-071df23b8e30"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "72aac68b-35b2-440b-8c0b-34f90bbe51c7"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "baf7b521-d97f-4a47-adf0-13f18351562b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3fea8eb3-5fc0-40db-a8ba-2207b53a1237"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6d913100-6043-4291-b39d-375a4e604a8b"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6071d270-a39b-4097-93de-d01733c48610"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "cc4e282a-6e59-482a-9d8e-85167509fced"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d71c6cc4-f337-4549-a03a-500d26803152"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "f990f881-b88c-4ed0-b7b1-b29f22fadf04"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5357db9e-45e6-4e7b-9461-2fd5d71cd46e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "5f70f335-e40b-4515-98b7-6e3af808862e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7f1c364a-ce75-401f-a763-9bcaf3242ceb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "30367593-4e5c-4563-bd5f-3b4d0327120c"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "7420e1bb-0d3c-4cc2-b5fd-ecf23ff968d6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e9a5a52e-0d1d-4ab9-b178-a3a67583ab00"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b375ed5b-6624-48bc-936b-073173844074"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3e016015-3269-4054-a08d-046338178ad5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "46e75559-78d4-4427-93da-2d00e8217e47"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "b48302f0-5a71-40ad-8f46-61087d002ec4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "d788b32f-cf6b-4e9a-98da-0d64c3099100"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "019537a9-054b-41f8-9de9-035b2549838e"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "ea6845c4-91c0-4a3a-9b14-0838a314e3d0"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8a034926-7b0f-4304-bf38-841759f3e9a5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "70fe53a5-e8d7-46ec-9840-3e6b3cb93d02"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3262d8a9-3d45-45de-ab56-182d152d6c42"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "584f970e-136c-4680-86a7-f914ec0a7feb"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "e042daa8-982f-472e-8533-04a921aac828"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "98a67908-20ae-4fda-a5c2-96c1b63697f4"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "3dc482d1-8290-449f-b12f-c6eb28c9ddfa"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c9215dd6-f1bb-44b9-9f8a-c8ea08c778f5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "eeecbfa2-a87b-4aad-88b0-57f580c6a2e5"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "6b3dffbc-fa89-41c4-93fb-48fdc663415a"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "8d5ce3bb-6d8f-4923-a2e8-af97ef59a1e6"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "83c454c0-d413-4620-8ba5-f6a959fa6744"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "4e382e9e-b949-4492-a47b-fa9affb5e511"}, {"source": "510c0569-37f0-4f0c-8600-114a083ae502", "target": "c458dbc7-a4e5-42db-9eb3-73837708806a"}]};

const overlay = document.getElementById('overlay');

ForceGraph3D()(document.body)
  .graphData(GraphData)
  .nodeAutoColorBy('group')
  .nodeLabel(node => node.label)
  .onNodeClick(node => {
    const info = node.info || '（無摘要內容）';
    const keywords = node.keywords || '（無關鍵詞）';
    overlay.innerHTML = `<strong>${node.label}</strong><br><br><b>摘要：</b>${info}<br><br><b>關鍵詞：</b>${keywords}`;
    overlay.style.display = 'block';
    MathJax.typesetPromise();
  })
  .onBackgroundClick(() => {
    overlay.style.display = 'none';
  });
</script>
</body>
</html>
