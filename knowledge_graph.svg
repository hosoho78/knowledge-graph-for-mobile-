<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.43.0 (0)
 -->
<!-- Title: G Pages: 1 -->
<svg width="2925pt" height="1979pt"
 viewBox="0.00 0.00 2924.75 1979.20" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 1975.2)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-1975.2 2920.75,-1975.2 2920.75,4 -4,4"/>
<!-- 第1章：引言 &#45; 1.2：深度学习的历史趋势 -->
<g id="node1" class="node">
<title>第1章：引言 &#45; 1.2：深度学习的历史趋势</title>
<polygon fill="lightgrey" stroke="black" points="732.88,-767 573.88,-767 573.88,-731 732.88,-731 732.88,-767"/>
<text text-anchor="middle" x="653.38" y="-746.5" font-family="Microsoft YaHei" font-size="10.00">1.2：深度学习的历史趋势</text>
</g>
<!-- 第1章：引言 &#45; 20.15：结论 -->
<g id="node2" class="node">
<title>第1章：引言 &#45; 20.15：结论</title>
<polygon fill="lightgrey" stroke="black" points="414.51,-767 332.51,-767 332.51,-731 414.51,-731 414.51,-767"/>
<text text-anchor="middle" x="373.51" y="-746.5" font-family="Microsoft YaHei" font-size="10.00">20.15：结论</text>
</g>
<!-- 第1章：引言 &#45; 1.2：深度学习的历史趋势&#45;&gt;第1章：引言 &#45; 20.15：结论 -->
<g id="edge1" class="edge">
<title>第1章：引言 &#45; 1.2：深度学习的历史趋势&#45;&gt;第1章：引言 &#45; 20.15：结论</title>
<path fill="none" stroke="black" d="M573.55,-749C525.74,-749 466.37,-749 424.78,-749"/>
<polygon fill="black" stroke="black" points="424.61,-745.5 414.61,-749 424.61,-752.5 424.61,-745.5"/>
</g>
<!-- 第1章：引言 &#45; 1.1：本书面向的读者 -->
<g id="node3" class="node">
<title>第1章：引言 &#45; 1.1：本书面向的读者</title>
<polygon fill="lightgrey" stroke="black" points="134,-767 0,-767 0,-731 134,-731 134,-767"/>
<text text-anchor="middle" x="67" y="-746.5" font-family="Microsoft YaHei" font-size="10.00">1.1：本书面向的读者</text>
</g>
<!-- 第1章：引言 &#45; 20.15：结论&#45;&gt;第1章：引言 &#45; 1.1：本书面向的读者 -->
<g id="edge2" class="edge">
<title>第1章：引言 &#45; 20.15：结论&#45;&gt;第1章：引言 &#45; 1.1：本书面向的读者</title>
<path fill="none" stroke="black" d="M332.49,-749C284.53,-749 204.12,-749 144.33,-749"/>
<polygon fill="black" stroke="black" points="144.17,-745.5 134.17,-749 144.17,-752.5 144.17,-745.5"/>
</g>
<!-- 第2章：线性代数 &#45; 2.11：行列式 -->
<g id="node4" class="node">
<title>第2章：线性代数 &#45; 2.11：行列式</title>
<polygon fill="lightgrey" stroke="black" points="2879.95,-1672.85 2790.95,-1672.85 2790.95,-1636.85 2879.95,-1636.85 2879.95,-1672.85"/>
<text text-anchor="middle" x="2835.45" y="-1652.35" font-family="Microsoft YaHei" font-size="10.00">2.11：行列式</text>
</g>
<!-- 第2章：线性代数 &#45; 1.2：深度学习的历史趋势 -->
<g id="node5" class="node">
<title>第2章：线性代数 &#45; 1.2：深度学习的历史趋势</title>
<polygon fill="lightgrey" stroke="black" points="2836.16,-1672.27 2677.16,-1672.27 2677.16,-1636.27 2836.16,-1636.27 2836.16,-1672.27"/>
<text text-anchor="middle" x="2756.66" y="-1651.77" font-family="Microsoft YaHei" font-size="10.00">1.2：深度学习的历史趋势</text>
</g>
<!-- 第2章：线性代数 &#45; 2.11：行列式&#45;&gt;第2章：线性代数 &#45; 1.2：深度学习的历史趋势 -->
<g id="edge3" class="edge">
<title>第2章：线性代数 &#45; 2.11：行列式&#45;&gt;第2章：线性代数 &#45; 1.2：深度学习的历史趋势</title>
<path fill="none" stroke="black" d="M2790.53,-1654.52C2790.46,-1654.52 2790.39,-1654.52 2790.33,-1654.52"/>
<polygon fill="black" stroke="black" points="2800.15,-1651.09 2790.12,-1654.51 2800.09,-1658.09 2800.15,-1651.09"/>
</g>
<!-- 第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量 -->
<g id="node6" class="node">
<title>第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量</title>
<polygon fill="lightgrey" stroke="black" points="2755.95,-1671.83 2570.95,-1671.83 2570.95,-1635.83 2755.95,-1635.83 2755.95,-1671.83"/>
<text text-anchor="middle" x="2663.45" y="-1651.33" font-family="Microsoft YaHei" font-size="10.00">2.1：标量、向量、矩阵和张量</text>
</g>
<!-- 第2章：线性代数 &#45; 1.2：深度学习的历史趋势&#45;&gt;第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量 -->
<g id="edge4" class="edge">
<title>第2章：线性代数 &#45; 1.2：深度学习的历史趋势&#45;&gt;第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量</title>
<path fill="none" stroke="black" d="M2676.8,-1653.89C2676.74,-1653.89 2676.68,-1653.89 2676.61,-1653.89"/>
<polygon fill="black" stroke="black" points="2686.44,-1650.44 2676.43,-1653.89 2686.41,-1657.44 2686.44,-1650.44"/>
</g>
<!-- 第2章：线性代数 &#45; 2.2：矩阵和向量相乘 -->
<g id="node7" class="node">
<title>第2章：线性代数 &#45; 2.2：矩阵和向量相乘</title>
<polygon fill="lightgrey" stroke="black" points="2624.73,-1671.37 2490.73,-1671.37 2490.73,-1635.37 2624.73,-1635.37 2624.73,-1671.37"/>
<text text-anchor="middle" x="2557.73" y="-1650.87" font-family="Microsoft YaHei" font-size="10.00">2.2：矩阵和向量相乘</text>
</g>
<!-- 第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量&#45;&gt;第2章：线性代数 &#45; 2.2：矩阵和向量相乘 -->
<g id="edge5" class="edge">
<title>第2章：线性代数 &#45; 2.1：标量、向量、矩阵和张量&#45;&gt;第2章：线性代数 &#45; 2.2：矩阵和向量相乘</title>
<path fill="none" stroke="black" d="M2570.69,-1653.42C2570.63,-1653.42 2570.57,-1653.42 2570.51,-1653.42"/>
<polygon fill="black" stroke="black" points="2580.34,-1649.97 2570.32,-1653.42 2580.3,-1656.97 2580.34,-1649.97"/>
</g>
<!-- 第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵 -->
<g id="node8" class="node">
<title>第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵</title>
<polygon fill="lightgrey" stroke="black" points="2517.12,-1670.91 2371.12,-1670.91 2371.12,-1634.91 2517.12,-1634.91 2517.12,-1670.91"/>
<text text-anchor="middle" x="2444.12" y="-1650.41" font-family="Microsoft YaHei" font-size="10.00">2.3：单位矩阵和逆矩阵</text>
</g>
<!-- 第2章：线性代数 &#45; 2.2：矩阵和向量相乘&#45;&gt;第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵 -->
<g id="edge6" class="edge">
<title>第2章：线性代数 &#45; 2.2：矩阵和向量相乘&#45;&gt;第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵</title>
<path fill="none" stroke="black" d="M2490.66,-1653.1C2490.61,-1653.1 2490.56,-1653.1 2490.51,-1653.1"/>
<polygon fill="black" stroke="black" points="2500.39,-1649.65 2490.37,-1653.1 2500.35,-1656.65 2500.39,-1649.65"/>
</g>
<!-- 第2章：线性代数 &#45; 2.4：线性相关和生成子空间 -->
<g id="node9" class="node">
<title>第2章：线性代数 &#45; 2.4：线性相关和生成子空间</title>
<polygon fill="lightgrey" stroke="black" points="2411.96,-1670.53 2239.96,-1670.53 2239.96,-1634.53 2411.96,-1634.53 2411.96,-1670.53"/>
<text text-anchor="middle" x="2325.96" y="-1650.03" font-family="Microsoft YaHei" font-size="10.00">2.4：线性相关和生成子空间</text>
</g>
<!-- 第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵&#45;&gt;第2章：线性代数 &#45; 2.4：线性相关和生成子空间 -->
<g id="edge7" class="edge">
<title>第2章：线性代数 &#45; 2.3：单位矩阵和逆矩阵&#45;&gt;第2章：线性代数 &#45; 2.4：线性相关和生成子空间</title>
<path fill="none" stroke="black" d="M2370.97,-1652.68C2370.92,-1652.68 2370.87,-1652.68 2370.83,-1652.68"/>
<polygon fill="black" stroke="black" points="2380.7,-1649.22 2370.68,-1652.68 2380.67,-1656.22 2380.7,-1649.22"/>
</g>
<!-- 第2章：线性代数 &#45; 2.5：范数 -->
<g id="node10" class="node">
<title>第2章：线性代数 &#45; 2.5：范数</title>
<polygon fill="lightgrey" stroke="black" points="2240.63,-1670.25 2170.63,-1670.25 2170.63,-1634.25 2240.63,-1634.25 2240.63,-1670.25"/>
<text text-anchor="middle" x="2205.63" y="-1649.75" font-family="Microsoft YaHei" font-size="10.00">2.5：范数</text>
</g>
<!-- 第2章：线性代数 &#45; 2.4：线性相关和生成子空间&#45;&gt;第2章：线性代数 &#45; 2.5：范数 -->
<g id="edge8" class="edge">
<title>第2章：线性代数 &#45; 2.4：线性相关和生成子空间&#45;&gt;第2章：线性代数 &#45; 2.5：范数</title>
<path fill="none" stroke="black" d="M2239.79,-1652.33C2239.71,-1652.33 2239.64,-1652.33 2239.56,-1652.33"/>
<polygon fill="black" stroke="black" points="2249.35,-1648.86 2239.34,-1652.33 2249.33,-1655.86 2249.35,-1648.86"/>
</g>
<!-- 第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量 -->
<g id="node11" class="node">
<title>第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量</title>
<polygon fill="lightgrey" stroke="black" points="2171.53,-1670.06 1999.53,-1670.06 1999.53,-1634.06 2171.53,-1634.06 2171.53,-1670.06"/>
<text text-anchor="middle" x="2085.53" y="-1649.56" font-family="Microsoft YaHei" font-size="10.00">2.6：特殊类型的矩阵和向量</text>
</g>
<!-- 第2章：线性代数 &#45; 2.5：范数&#45;&gt;第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量 -->
<g id="edge9" class="edge">
<title>第2章：线性代数 &#45; 2.5：范数&#45;&gt;第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量</title>
<path fill="none" stroke="black" d="M2170.57,-1652.19C2170.5,-1652.19 2170.43,-1652.19 2170.36,-1652.19"/>
<polygon fill="black" stroke="black" points="2180.16,-1648.71 2170.15,-1652.19 2180.14,-1655.71 2180.16,-1648.71"/>
</g>
<!-- 第2章：线性代数 &#45; 2.7：特征分解 -->
<g id="node12" class="node">
<title>第2章：线性代数 &#45; 2.7：特征分解</title>
<polygon fill="lightgrey" stroke="black" points="2014.74,-1670 1919.74,-1670 1919.74,-1634 2014.74,-1634 2014.74,-1670"/>
<text text-anchor="middle" x="1967.24" y="-1649.5" font-family="Microsoft YaHei" font-size="10.00">2.7：特征分解</text>
</g>
<!-- 第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量&#45;&gt;第2章：线性代数 &#45; 2.7：特征分解 -->
<g id="edge10" class="edge">
<title>第2章：线性代数 &#45; 2.6：特殊类型的矩阵和向量&#45;&gt;第2章：线性代数 &#45; 2.7：特征分解</title>
<path fill="none" stroke="black" d="M1999.25,-1652.02C1999.18,-1652.02 1999.11,-1652.02 1999.04,-1652.02"/>
<polygon fill="black" stroke="black" points="2008.83,-1648.53 1998.83,-1652.02 2008.82,-1655.53 2008.83,-1648.53"/>
</g>
<!-- 第2章：线性代数 &#45; 2.8：奇异值分解 -->
<g id="node13" class="node">
<title>第2章：线性代数 &#45; 2.8：奇异值分解</title>
<polygon fill="lightgrey" stroke="black" points="1907.32,-1670.19 1799.32,-1670.19 1799.32,-1634.19 1907.32,-1634.19 1907.32,-1670.19"/>
<text text-anchor="middle" x="1853.32" y="-1649.69" font-family="Microsoft YaHei" font-size="10.00">2.8：奇异值分解</text>
</g>
<!-- 第2章：线性代数 &#45; 2.7：特征分解&#45;&gt;第2章：线性代数 &#45; 2.8：奇异值分解 -->
<g id="edge11" class="edge">
<title>第2章：线性代数 &#45; 2.7：特征分解&#45;&gt;第2章：线性代数 &#45; 2.8：奇异值分解</title>
<path fill="none" stroke="black" d="M1919.59,-1652.08C1918.96,-1652.08 1918.33,-1652.08 1917.7,-1652.08"/>
<polygon fill="black" stroke="black" points="1917.4,-1648.58 1907.41,-1652.1 1917.41,-1655.58 1917.4,-1648.58"/>
</g>
<!-- 第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆 -->
<g id="node14" class="node">
<title>第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆</title>
<polygon fill="lightgrey" stroke="black" points="1818.12,-1670.78 1675.12,-1670.78 1675.12,-1634.78 1818.12,-1634.78 1818.12,-1670.78"/>
<text text-anchor="middle" x="1746.62" y="-1650.28" font-family="Microsoft YaHei" font-size="10.00">2.9：Moore&#45;Penrose伪逆</text>
</g>
<!-- 第2章：线性代数 &#45; 2.8：奇异值分解&#45;&gt;第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆 -->
<g id="edge12" class="edge">
<title>第2章：线性代数 &#45; 2.8：奇异值分解&#45;&gt;第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆</title>
<path fill="none" stroke="black" d="M1799.03,-1652.49C1798.98,-1652.49 1798.93,-1652.49 1798.88,-1652.49"/>
<polygon fill="black" stroke="black" points="1808.7,-1648.93 1798.72,-1652.49 1808.75,-1655.93 1808.7,-1648.93"/>
</g>
<!-- 第2章：线性代数 &#45; 2.10：迹运算 -->
<g id="node15" class="node">
<title>第2章：线性代数 &#45; 2.10：迹运算</title>
<polygon fill="lightgrey" stroke="black" points="1696.88,-1672.03 1607.88,-1672.03 1607.88,-1636.03 1696.88,-1636.03 1696.88,-1672.03"/>
<text text-anchor="middle" x="1652.38" y="-1651.53" font-family="Microsoft YaHei" font-size="10.00">2.10：迹运算</text>
</g>
<!-- 第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆&#45;&gt;第2章：线性代数 &#45; 2.10：迹运算 -->
<g id="edge13" class="edge">
<title>第2章：线性代数 &#45; 2.9：Moore&#45;Penrose伪逆&#45;&gt;第2章：线性代数 &#45; 2.10：迹运算</title>
<path fill="none" stroke="black" d="M1674.72,-1653.74C1674.67,-1653.74 1674.62,-1653.74 1674.57,-1653.74"/>
<polygon fill="black" stroke="black" points="1684.37,-1650.1 1674.41,-1653.74 1684.46,-1657.1 1684.37,-1650.1"/>
</g>
<!-- 第2章：线性代数 &#45; 2.12：实例：主成分分析 -->
<g id="node16" class="node">
<title>第2章：线性代数 &#45; 2.12：实例：主成分分析</title>
<polygon fill="lightgrey" stroke="black" points="1657,-1674.93 1505,-1674.93 1505,-1638.93 1657,-1638.93 1657,-1674.93"/>
<text text-anchor="middle" x="1581" y="-1654.43" font-family="Microsoft YaHei" font-size="10.00">2.12：实例：主成分分析</text>
</g>
<!-- 第2章：线性代数 &#45; 2.10：迹运算&#45;&gt;第2章：线性代数 &#45; 2.12：实例：主成分分析 -->
<g id="edge14" class="edge">
<title>第2章：线性代数 &#45; 2.10：迹运算&#45;&gt;第2章：线性代数 &#45; 2.12：实例：主成分分析</title>
<path fill="none" stroke="black" d="M1607.58,-1655.85C1607.52,-1655.86 1607.47,-1655.86 1607.41,-1655.86"/>
<polygon fill="black" stroke="black" points="1617.09,-1651.96 1607.24,-1655.87 1617.38,-1658.95 1617.09,-1651.96"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.3：概率分布 -->
<g id="node17" class="node">
<title>第3章：概率与信息论 &#45; 3.3：概率分布</title>
<polygon fill="lightgrey" stroke="black" points="1437.27,-1775.51 1342.27,-1775.51 1342.27,-1739.51 1437.27,-1739.51 1437.27,-1775.51"/>
<text text-anchor="middle" x="1389.77" y="-1755.01" font-family="Microsoft YaHei" font-size="10.00">3.3：概率分布</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.9：常用概率分布 -->
<g id="node18" class="node">
<title>第3章：概率与信息论 &#45; 3.9：常用概率分布</title>
<polygon fill="lightgrey" stroke="black" points="1449.69,-1702.03 1328.69,-1702.03 1328.69,-1666.03 1449.69,-1666.03 1449.69,-1702.03"/>
<text text-anchor="middle" x="1389.19" y="-1681.53" font-family="Microsoft YaHei" font-size="10.00">3.9：常用概率分布</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.3：概率分布&#45;&gt;第3章：概率与信息论 &#45; 3.9：常用概率分布 -->
<g id="edge15" class="edge">
<title>第3章：概率与信息论 &#45; 3.3：概率分布&#45;&gt;第3章：概率与信息论 &#45; 3.9：常用概率分布</title>
<path fill="none" stroke="black" d="M1389.63,-1739.35C1389.56,-1731.22 1389.48,-1721.45 1389.41,-1712.4"/>
<polygon fill="black" stroke="black" points="1392.91,-1712.21 1389.33,-1702.24 1385.91,-1712.27 1392.91,-1712.21"/>
</g>
<!-- 第3章：概率与信息论 &#45; 2.12：实例：主成分分析 -->
<g id="node19" class="node">
<title>第3章：概率与信息论 &#45; 2.12：实例：主成分分析</title>
<polygon fill="lightgrey" stroke="black" points="1408.82,-1637.23 1256.82,-1637.23 1256.82,-1601.23 1408.82,-1601.23 1408.82,-1637.23"/>
<text text-anchor="middle" x="1332.82" y="-1616.73" font-family="Microsoft YaHei" font-size="10.00">2.12：实例：主成分分析</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.9：常用概率分布&#45;&gt;第3章：概率与信息论 &#45; 2.12：实例：主成分分析 -->
<g id="edge16" class="edge">
<title>第3章：概率与信息论 &#45; 3.9：常用概率分布&#45;&gt;第3章：概率与信息论 &#45; 2.12：实例：主成分分析</title>
<path fill="none" stroke="black" d="M1373.49,-1665.98C1367.96,-1659.63 1361.63,-1652.35 1355.64,-1645.46"/>
<polygon fill="black" stroke="black" points="1358.03,-1642.88 1348.83,-1637.63 1352.75,-1647.48 1358.03,-1642.88"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.1：为什么要使用概率 -->
<g id="node20" class="node">
<title>第3章：概率与信息论 &#45; 3.1：为什么要使用概率</title>
<polygon fill="lightgrey" stroke="black" points="1319.62,-1601.4 1173.62,-1601.4 1173.62,-1565.4 1319.62,-1565.4 1319.62,-1601.4"/>
<text text-anchor="middle" x="1246.62" y="-1580.9" font-family="Microsoft YaHei" font-size="10.00">3.1：为什么要使用概率</text>
</g>
<!-- 第3章：概率与信息论 &#45; 2.12：实例：主成分分析&#45;&gt;第3章：概率与信息论 &#45; 3.1：为什么要使用概率 -->
<g id="edge17" class="edge">
<title>第3章：概率与信息论 &#45; 2.12：实例：主成分分析&#45;&gt;第3章：概率与信息论 &#45; 3.1：为什么要使用概率</title>
<path fill="none" stroke="black" d="M1289.47,-1601.21C1289.42,-1601.2 1289.38,-1601.18 1289.34,-1601.16"/>
<polygon fill="black" stroke="black" points="1299.79,-1601.72 1289.21,-1601.11 1297.1,-1608.18 1299.79,-1601.72"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.2：随机变量 -->
<g id="node21" class="node">
<title>第3章：概率与信息论 &#45; 3.2：随机变量</title>
<polygon fill="lightgrey" stroke="black" points="1192.3,-1594.83 1097.3,-1594.83 1097.3,-1558.83 1192.3,-1558.83 1192.3,-1594.83"/>
<text text-anchor="middle" x="1144.8" y="-1574.33" font-family="Microsoft YaHei" font-size="10.00">3.2：随机变量</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.1：为什么要使用概率&#45;&gt;第3章：概率与信息论 &#45; 3.2：随机变量 -->
<g id="edge18" class="edge">
<title>第3章：概率与信息论 &#45; 3.1：为什么要使用概率&#45;&gt;第3章：概率与信息论 &#45; 3.2：随机变量</title>
<path fill="none" stroke="black" d="M1173.43,-1578.68C1173.37,-1578.67 1173.3,-1578.67 1173.24,-1578.66"/>
<polygon fill="black" stroke="black" points="1183.26,-1575.81 1173.05,-1578.65 1182.8,-1582.79 1183.26,-1575.81"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.4：边缘概率 -->
<g id="node22" class="node">
<title>第3章：概率与信息论 &#45; 3.4：边缘概率</title>
<polygon fill="lightgrey" stroke="black" points="1085.41,-1608.45 990.41,-1608.45 990.41,-1572.45 1085.41,-1572.45 1085.41,-1608.45"/>
<text text-anchor="middle" x="1037.91" y="-1587.95" font-family="Microsoft YaHei" font-size="10.00">3.4：边缘概率</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.2：随机变量&#45;&gt;第3章：概率与信息论 &#45; 3.4：边缘概率 -->
<g id="edge19" class="edge">
<title>第3章：概率与信息论 &#45; 3.2：随机变量&#45;&gt;第3章：概率与信息论 &#45; 3.4：边缘概率</title>
<path fill="none" stroke="black" d="M1097.29,-1582.88C1096.68,-1582.96 1096.07,-1583.04 1095.46,-1583.12"/>
<polygon fill="black" stroke="black" points="1095.01,-1579.65 1085.54,-1584.38 1095.9,-1586.59 1095.01,-1579.65"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.5：条件概率 -->
<g id="node23" class="node">
<title>第3章：概率与信息论 &#45; 3.5：条件概率</title>
<polygon fill="lightgrey" stroke="black" points="977.38,-1633.74 882.38,-1633.74 882.38,-1597.74 977.38,-1597.74 977.38,-1633.74"/>
<text text-anchor="middle" x="929.88" y="-1613.24" font-family="Microsoft YaHei" font-size="10.00">3.5：条件概率</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.4：边缘概率&#45;&gt;第3章：概率与信息论 &#45; 3.5：条件概率 -->
<g id="edge20" class="edge">
<title>第3章：概率与信息论 &#45; 3.4：边缘概率&#45;&gt;第3章：概率与信息论 &#45; 3.5：条件概率</title>
<path fill="none" stroke="black" d="M990.21,-1601.62C989.3,-1601.83 988.38,-1602.05 987.46,-1602.26"/>
<polygon fill="black" stroke="black" points="986.55,-1598.88 977.61,-1604.57 988.15,-1605.7 986.55,-1598.88"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.6：条件概率的链式法则 -->
<g id="node24" class="node">
<title>第3章：概率与信息论 &#45; 3.6：条件概率的链式法则</title>
<polygon fill="lightgrey" stroke="black" points="901.76,-1664.5 742.76,-1664.5 742.76,-1628.5 901.76,-1628.5 901.76,-1664.5"/>
<text text-anchor="middle" x="822.26" y="-1644" font-family="Microsoft YaHei" font-size="10.00">3.6：条件概率的链式法则</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.5：条件概率&#45;&gt;第3章：概率与信息论 &#45; 3.6：条件概率的链式法则 -->
<g id="edge21" class="edge">
<title>第3章：概率与信息论 &#45; 3.5：条件概率&#45;&gt;第3章：概率与信息论 &#45; 3.6：条件概率的链式法则</title>
<path fill="none" stroke="black" d="M882.36,-1629.32C882.31,-1629.34 882.25,-1629.36 882.19,-1629.37"/>
<polygon fill="black" stroke="black" points="890.68,-1623.3 882.02,-1629.42 892.6,-1630.03 890.68,-1623.3"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.7：独立性和条件独立性 -->
<g id="node25" class="node">
<title>第3章：概率与信息论 &#45; 3.7：独立性和条件独立性</title>
<polygon fill="lightgrey" stroke="black" points="795.07,-1695.04 636.07,-1695.04 636.07,-1659.04 795.07,-1659.04 795.07,-1695.04"/>
<text text-anchor="middle" x="715.57" y="-1674.54" font-family="Microsoft YaHei" font-size="10.00">3.7：独立性和条件独立性</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.6：条件概率的链式法则&#45;&gt;第3章：概率与信息论 &#45; 3.7：独立性和条件独立性 -->
<g id="edge22" class="edge">
<title>第3章：概率与信息论 &#45; 3.6：条件概率的链式法则&#45;&gt;第3章：概率与信息论 &#45; 3.7：独立性和条件独立性</title>
<path fill="none" stroke="black" d="M759.27,-1664.53C759.23,-1664.54 759.18,-1664.55 759.13,-1664.57"/>
<polygon fill="black" stroke="black" points="767.65,-1658.49 759,-1664.61 769.58,-1665.22 767.65,-1658.49"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.8：期望、方差和协方差 -->
<g id="node26" class="node">
<title>第3章：概率与信息论 &#45; 3.8：期望、方差和协方差</title>
<polygon fill="lightgrey" stroke="black" points="689.81,-1719.02 530.81,-1719.02 530.81,-1683.02 689.81,-1683.02 689.81,-1719.02"/>
<text text-anchor="middle" x="610.31" y="-1698.52" font-family="Microsoft YaHei" font-size="10.00">3.8：期望、方差和协方差</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.7：独立性和条件独立性&#45;&gt;第3章：概率与信息论 &#45; 3.8：期望、方差和协方差 -->
<g id="edge23" class="edge">
<title>第3章：概率与信息论 &#45; 3.7：独立性和条件独立性&#45;&gt;第3章：概率与信息论 &#45; 3.8：期望、方差和协方差</title>
<path fill="none" stroke="black" d="M636.33,-1695.09C636.27,-1695.1 636.21,-1695.11 636.16,-1695.13"/>
<polygon fill="black" stroke="black" points="644.95,-1689.53 635.98,-1695.17 646.51,-1696.35 644.95,-1689.53"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.11：贝叶斯规则 -->
<g id="node27" class="node">
<title>第3章：概率与信息论 &#45; 3.11：贝叶斯规则</title>
<polygon fill="lightgrey" stroke="black" points="565.15,-1726.97 451.15,-1726.97 451.15,-1690.97 565.15,-1690.97 565.15,-1726.97"/>
<text text-anchor="middle" x="508.15" y="-1706.47" font-family="Microsoft YaHei" font-size="10.00">3.11：贝叶斯规则</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.8：期望、方差和协方差&#45;&gt;第3章：概率与信息论 &#45; 3.11：贝叶斯规则 -->
<g id="edge24" class="edge">
<title>第3章：概率与信息论 &#45; 3.8：期望、方差和协方差&#45;&gt;第3章：概率与信息论 &#45; 3.11：贝叶斯规则</title>
<path fill="none" stroke="black" d="M530.57,-1707.22C530.52,-1707.23 530.47,-1707.23 530.42,-1707.23"/>
<polygon fill="black" stroke="black" points="539.96,-1702.97 530.26,-1707.25 540.51,-1709.95 539.96,-1702.97"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节 -->
<g id="node28" class="node">
<title>第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节</title>
<polygon fill="lightgrey" stroke="black" points="505.36,-1708.01 327.36,-1708.01 327.36,-1672.01 505.36,-1672.01 505.36,-1708.01"/>
<text text-anchor="middle" x="416.36" y="-1687.51" font-family="Microsoft YaHei" font-size="10.00">3.12：连续型变量的技术细节</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.11：贝叶斯规则&#45;&gt;第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节 -->
<g id="edge25" class="edge">
<title>第3章：概率与信息论 &#45; 3.11：贝叶斯规则&#45;&gt;第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节</title>
<path fill="none" stroke="black" d="M451.06,-1697.18C450.99,-1697.16 450.91,-1697.15 450.84,-1697.13"/>
<polygon fill="black" stroke="black" points="461.13,-1695.69 450.62,-1697.09 459.71,-1702.54 461.13,-1695.69"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.13：信息论 -->
<g id="node29" class="node">
<title>第3章：概率与信息论 &#45; 3.13：信息论</title>
<polygon fill="lightgrey" stroke="black" points="403.62,-1650.46 314.62,-1650.46 314.62,-1614.46 403.62,-1614.46 403.62,-1650.46"/>
<text text-anchor="middle" x="359.12" y="-1629.96" font-family="Microsoft YaHei" font-size="10.00">3.13：信息论</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节&#45;&gt;第3章：概率与信息论 &#45; 3.13：信息论 -->
<g id="edge26" class="edge">
<title>第3章：概率与信息论 &#45; 3.12：连续型变量的技术细节&#45;&gt;第3章：概率与信息论 &#45; 3.13：信息论</title>
<path fill="none" stroke="black" d="M398.25,-1671.8C393.86,-1667.39 389.09,-1662.6 384.44,-1657.92"/>
<polygon fill="black" stroke="black" points="386.84,-1655.37 377.31,-1650.75 381.88,-1660.3 386.84,-1655.37"/>
</g>
<!-- 第3章：概率与信息论 &#45; 3.14：结构化概率模型 -->
<g id="node30" class="node">
<title>第3章：概率与信息论 &#45; 3.14：结构化概率模型</title>
<polygon fill="lightgrey" stroke="black" points="398,-1584 258,-1584 258,-1548 398,-1548 398,-1584"/>
<text text-anchor="middle" x="328" y="-1563.5" font-family="Microsoft YaHei" font-size="10.00">3.14：结构化概率模型</text>
</g>
<!-- 第3章：概率与信息论 &#45; 3.13：信息论&#45;&gt;第3章：概率与信息论 &#45; 3.14：结构化概率模型 -->
<g id="edge27" class="edge">
<title>第3章：概率与信息论 &#45; 3.13：信息论&#45;&gt;第3章：概率与信息论 &#45; 3.14：结构化概率模型</title>
<path fill="none" stroke="black" d="M350.61,-1614.3C347.59,-1607.85 344.13,-1600.44 340.83,-1593.4"/>
<polygon fill="black" stroke="black" points="343.9,-1591.71 336.49,-1584.14 337.56,-1594.68 343.9,-1591.71"/>
</g>
<!-- 第4章：数值计算 &#45; 4.3：基于梯度的优化方法 -->
<g id="node31" class="node">
<title>第4章：数值计算 &#45; 4.3：基于梯度的优化方法</title>
<polygon fill="lightgrey" stroke="black" points="288,-1842.25 129,-1842.25 129,-1806.25 288,-1806.25 288,-1842.25"/>
<text text-anchor="middle" x="208.5" y="-1821.75" font-family="Microsoft YaHei" font-size="10.00">4.3：基于梯度的优化方法</text>
</g>
<!-- 第4章：数值计算 &#45; 3.14：结构化概率模型 -->
<g id="node32" class="node">
<title>第4章：数值计算 &#45; 3.14：结构化概率模型</title>
<polygon fill="lightgrey" stroke="black" points="455.01,-1842.22 315.01,-1842.22 315.01,-1806.22 455.01,-1806.22 455.01,-1842.22"/>
<text text-anchor="middle" x="385.01" y="-1821.72" font-family="Microsoft YaHei" font-size="10.00">3.14：结构化概率模型</text>
</g>
<!-- 第4章：数值计算 &#45; 4.3：基于梯度的优化方法&#45;&gt;第4章：数值计算 &#45; 3.14：结构化概率模型 -->
<g id="edge28" class="edge">
<title>第4章：数值计算 &#45; 4.3：基于梯度的优化方法&#45;&gt;第4章：数值计算 &#45; 3.14：结构化概率模型</title>
<path fill="none" stroke="black" d="M288.24,-1824.23C293.64,-1824.23 299.08,-1824.23 304.48,-1824.23"/>
<polygon fill="black" stroke="black" points="304.81,-1827.73 314.81,-1824.23 304.81,-1820.73 304.81,-1827.73"/>
</g>
<!-- 第4章：数值计算 &#45; 4.1：上溢和下溢 -->
<g id="node33" class="node">
<title>第4章：数值计算 &#45; 4.1：上溢和下溢</title>
<polygon fill="lightgrey" stroke="black" points="650.39,-1842 542.39,-1842 542.39,-1806 650.39,-1806 650.39,-1842"/>
<text text-anchor="middle" x="596.39" y="-1821.5" font-family="Microsoft YaHei" font-size="10.00">4.1：上溢和下溢</text>
</g>
<!-- 第4章：数值计算 &#45; 3.14：结构化概率模型&#45;&gt;第4章：数值计算 &#45; 4.1：上溢和下溢 -->
<g id="edge29" class="edge">
<title>第4章：数值计算 &#45; 3.14：结构化概率模型&#45;&gt;第4章：数值计算 &#45; 4.1：上溢和下溢</title>
<path fill="none" stroke="black" d="M455.1,-1824.14C479.92,-1824.12 507.7,-1824.09 532.02,-1824.07"/>
<polygon fill="black" stroke="black" points="532.21,-1827.57 542.21,-1824.06 532.2,-1820.57 532.21,-1827.57"/>
</g>
<!-- 第4章：数值计算 &#45; 4.2：病态条件 -->
<g id="node34" class="node">
<title>第4章：数值计算 &#45; 4.2：病态条件</title>
<polygon fill="lightgrey" stroke="black" points="864.79,-1842.33 769.79,-1842.33 769.79,-1806.33 864.79,-1806.33 864.79,-1842.33"/>
<text text-anchor="middle" x="817.29" y="-1821.83" font-family="Microsoft YaHei" font-size="10.00">4.2：病态条件</text>
</g>
<!-- 第4章：数值计算 &#45; 4.1：上溢和下溢&#45;&gt;第4章：数值计算 &#45; 4.2：病态条件 -->
<g id="edge30" class="edge">
<title>第4章：数值计算 &#45; 4.1：上溢和下溢&#45;&gt;第4章：数值计算 &#45; 4.2：病态条件</title>
<path fill="none" stroke="black" d="M650.43,-1824.08C683.42,-1824.13 725.59,-1824.19 759.28,-1824.24"/>
<polygon fill="black" stroke="black" points="759.44,-1827.74 769.44,-1824.26 759.45,-1820.74 759.44,-1827.74"/>
</g>
<!-- 第4章：数值计算 &#45; 4.4：约束优化 -->
<g id="node35" class="node">
<title>第4章：数值计算 &#45; 4.4：约束优化</title>
<polygon fill="lightgrey" stroke="black" points="1079.14,-1842.27 984.14,-1842.27 984.14,-1806.27 1079.14,-1806.27 1079.14,-1842.27"/>
<text text-anchor="middle" x="1031.64" y="-1821.77" font-family="Microsoft YaHei" font-size="10.00">4.4：约束优化</text>
</g>
<!-- 第4章：数值计算 &#45; 4.2：病态条件&#45;&gt;第4章：数值计算 &#45; 4.4：约束优化 -->
<g id="edge31" class="edge">
<title>第4章：数值计算 &#45; 4.2：病态条件&#45;&gt;第4章：数值计算 &#45; 4.4：约束优化</title>
<path fill="none" stroke="black" d="M864.86,-1824.32C896.94,-1824.31 939.47,-1824.3 973.55,-1824.29"/>
<polygon fill="black" stroke="black" points="973.83,-1827.79 983.83,-1824.28 973.83,-1820.79 973.83,-1827.79"/>
</g>
<!-- 第4章：数值计算 &#45; 4.5：实例：线性最小二乘 -->
<g id="node36" class="node">
<title>第4章：数值计算 &#45; 4.5：实例：线性最小二乘</title>
<polygon fill="lightgrey" stroke="black" points="1296.37,-1842.14 1137.37,-1842.14 1137.37,-1806.14 1296.37,-1806.14 1296.37,-1842.14"/>
<text text-anchor="middle" x="1216.87" y="-1821.64" font-family="Microsoft YaHei" font-size="10.00">4.5：实例：线性最小二乘</text>
</g>
<!-- 第4章：数值计算 &#45; 4.4：约束优化&#45;&gt;第4章：数值计算 &#45; 4.5：实例：线性最小二乘 -->
<g id="edge32" class="edge">
<title>第4章：数值计算 &#45; 4.4：约束优化&#45;&gt;第4章：数值计算 &#45; 4.5：实例：线性最小二乘</title>
<path fill="none" stroke="black" d="M1079.34,-1824.24C1093.99,-1824.23 1110.61,-1824.22 1127.11,-1824.2"/>
<polygon fill="black" stroke="black" points="1127.36,-1827.7 1137.36,-1824.2 1127.35,-1820.7 1127.36,-1827.7"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.1：学习算法 -->
<g id="node37" class="node">
<title>第5章：机器学习基础 &#45; 5.1：学习算法</title>
<polygon fill="lightgrey" stroke="black" points="2186.13,-339.41 2091.13,-339.41 2091.13,-303.41 2186.13,-303.41 2186.13,-339.41"/>
<text text-anchor="middle" x="2138.63" y="-318.91" font-family="Microsoft YaHei" font-size="10.00">5.1：学习算法</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合 -->
<g id="node38" class="node">
<title>第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合</title>
<polygon fill="lightgrey" stroke="black" points="2162.15,-294 1990.15,-294 1990.15,-258 2162.15,-258 2162.15,-294"/>
<text text-anchor="middle" x="2076.15" y="-273.5" font-family="Microsoft YaHei" font-size="10.00">5.2：容量、过拟合和欠拟合</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.1：学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合 -->
<g id="edge33" class="edge">
<title>第5章：机器学习基础 &#45; 5.1：学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合</title>
<path fill="none" stroke="black" d="M2113.58,-303.2C2112.18,-302.18 2110.76,-301.15 2109.34,-300.12"/>
<polygon fill="black" stroke="black" points="2111.36,-297.26 2101.21,-294.21 2107.24,-302.92 2111.36,-297.26"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.4：估计、偏差和方差 -->
<g id="node39" class="node">
<title>第5章：机器学习基础 &#45; 5.4：估计、偏差和方差</title>
<polygon fill="lightgrey" stroke="black" points="2043.15,-295.13 1897.15,-295.13 1897.15,-259.13 2043.15,-259.13 2043.15,-295.13"/>
<text text-anchor="middle" x="1970.15" y="-274.63" font-family="Microsoft YaHei" font-size="10.00">5.4：估计、偏差和方差</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合&#45;&gt;第5章：机器学习基础 &#45; 5.4：估计、偏差和方差 -->
<g id="edge34" class="edge">
<title>第5章：机器学习基础 &#45; 5.2：容量、过拟合和欠拟合&#45;&gt;第5章：机器学习基础 &#45; 5.4：估计、偏差和方差</title>
<path fill="none" stroke="black" d="M1990.09,-276.92C1990.04,-276.92 1990,-276.92 1989.95,-276.92"/>
<polygon fill="black" stroke="black" points="1999.77,-273.31 1989.81,-276.92 1999.85,-280.31 1999.77,-273.31"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.5：最大似然估计 -->
<g id="node40" class="node">
<title>第5章：机器学习基础 &#45; 5.5：最大似然估计</title>
<polygon fill="lightgrey" stroke="black" points="1910.19,-305.77 1789.19,-305.77 1789.19,-269.77 1910.19,-269.77 1910.19,-305.77"/>
<text text-anchor="middle" x="1849.69" y="-285.27" font-family="Microsoft YaHei" font-size="10.00">5.5：最大似然估计</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.4：估计、偏差和方差&#45;&gt;第5章：机器学习基础 &#45; 5.5：最大似然估计 -->
<g id="edge35" class="edge">
<title>第5章：机器学习基础 &#45; 5.4：估计、偏差和方差&#45;&gt;第5章：机器学习基础 &#45; 5.5：最大似然估计</title>
<path fill="none" stroke="black" d="M1896.95,-283.6C1896.9,-283.6 1896.85,-283.61 1896.8,-283.61"/>
<polygon fill="black" stroke="black" points="1906.31,-279.25 1896.66,-283.62 1906.93,-286.22 1906.31,-279.25"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.6：贝叶斯统计 -->
<g id="node41" class="node">
<title>第5章：机器学习基础 &#45; 5.6：贝叶斯统计</title>
<polygon fill="lightgrey" stroke="black" points="1774.8,-314.81 1666.8,-314.81 1666.8,-278.81 1774.8,-278.81 1774.8,-314.81"/>
<text text-anchor="middle" x="1720.8" y="-294.31" font-family="Microsoft YaHei" font-size="10.00">5.6：贝叶斯统计</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.5：最大似然估计&#45;&gt;第5章：机器学习基础 &#45; 5.6：贝叶斯统计 -->
<g id="edge36" class="edge">
<title>第5章：机器学习基础 &#45; 5.5：最大似然估计&#45;&gt;第5章：机器学习基础 &#45; 5.6：贝叶斯统计</title>
<path fill="none" stroke="black" d="M1789.02,-292.03C1787.7,-292.12 1786.37,-292.21 1785.05,-292.31"/>
<polygon fill="black" stroke="black" points="1784.67,-288.82 1774.94,-293.02 1785.16,-295.81 1784.67,-288.82"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.7：监督学习算法 -->
<g id="node42" class="node">
<title>第5章：机器学习基础 &#45; 5.7：监督学习算法</title>
<polygon fill="lightgrey" stroke="black" points="1647.61,-318.52 1526.61,-318.52 1526.61,-282.52 1647.61,-282.52 1647.61,-318.52"/>
<text text-anchor="middle" x="1587.11" y="-298.02" font-family="Microsoft YaHei" font-size="10.00">5.7：监督学习算法</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.6：贝叶斯统计&#45;&gt;第5章：机器学习基础 &#45; 5.7：监督学习算法 -->
<g id="edge37" class="edge">
<title>第5章：机器学习基础 &#45; 5.6：贝叶斯统计&#45;&gt;第5章：机器学习基础 &#45; 5.7：监督学习算法</title>
<path fill="none" stroke="black" d="M1666.42,-298.32C1663.67,-298.4 1660.89,-298.47 1658.1,-298.55"/>
<polygon fill="black" stroke="black" points="1657.89,-295.06 1647.99,-298.83 1658.08,-302.05 1657.89,-295.06"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.8：无监督学习算法 -->
<g id="node43" class="node">
<title>第5章：机器学习基础 &#45; 5.8：无监督学习算法</title>
<polygon fill="lightgrey" stroke="black" points="1518.78,-316.78 1384.78,-316.78 1384.78,-280.78 1518.78,-280.78 1518.78,-316.78"/>
<text text-anchor="middle" x="1451.78" y="-296.28" font-family="Microsoft YaHei" font-size="10.00">5.8：无监督学习算法</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.7：监督学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.8：无监督学习算法 -->
<g id="edge38" class="edge">
<title>第5章：机器学习基础 &#45; 5.7：监督学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.8：无监督学习算法</title>
<path fill="none" stroke="black" d="M1526.57,-299.74C1526.41,-299.74 1526.25,-299.74 1526.09,-299.74"/>
<polygon fill="black" stroke="black" points="1528.99,-296.27 1518.94,-299.64 1528.9,-303.27 1528.99,-296.27"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战 -->
<g id="node44" class="node">
<title>第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战</title>
<polygon fill="lightgrey" stroke="black" points="1413.34,-311.22 1222.34,-311.22 1222.34,-275.22 1413.34,-275.22 1413.34,-311.22"/>
<text text-anchor="middle" x="1317.84" y="-290.72" font-family="Microsoft YaHei" font-size="10.00">5.11：促使深度学习发展的挑战</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.8：无监督学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战 -->
<g id="edge39" class="edge">
<title>第5章：机器学习基础 &#45; 5.8：无监督学习算法&#45;&gt;第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战</title>
<path fill="none" stroke="black" d="M1384.42,-295.98C1384.35,-295.98 1384.29,-295.98 1384.22,-295.98"/>
<polygon fill="black" stroke="black" points="1394.17,-292.89 1384.03,-295.97 1393.87,-299.88 1394.17,-292.89"/>
</g>
<!-- 第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘 -->
<g id="node45" class="node">
<title>第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘</title>
<polygon fill="lightgrey" stroke="black" points="1267.72,-302.89 1108.72,-302.89 1108.72,-266.89 1267.72,-266.89 1267.72,-302.89"/>
<text text-anchor="middle" x="1188.22" y="-282.39" font-family="Microsoft YaHei" font-size="10.00">4.5：实例：线性最小二乘</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战&#45;&gt;第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘 -->
<g id="edge40" class="edge">
<title>第5章：机器学习基础 &#45; 5.11：促使深度学习发展的挑战&#45;&gt;第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘</title>
<path fill="none" stroke="black" d="M1222.28,-287.08C1222.2,-287.07 1222.13,-287.07 1222.05,-287.06"/>
<polygon fill="black" stroke="black" points="1232.03,-284.2 1221.82,-287.05 1231.58,-291.19 1232.03,-284.2"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.3：超参数和验证集 -->
<g id="node46" class="node">
<title>第5章：机器学习基础 &#45; 5.3：超参数和验证集</title>
<polygon fill="lightgrey" stroke="black" points="1133.68,-295.57 999.68,-295.57 999.68,-259.57 1133.68,-259.57 1133.68,-295.57"/>
<text text-anchor="middle" x="1066.68" y="-275.07" font-family="Microsoft YaHei" font-size="10.00">5.3：超参数和验证集</text>
</g>
<!-- 第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘&#45;&gt;第5章：机器学习基础 &#45; 5.3：超参数和验证集 -->
<g id="edge41" class="edge">
<title>第5章：机器学习基础 &#45; 4.5：实例：线性最小二乘&#45;&gt;第5章：机器学习基础 &#45; 5.3：超参数和验证集</title>
<path fill="none" stroke="black" d="M1108.51,-280.09C1108.47,-280.08 1108.42,-280.08 1108.38,-280.08"/>
<polygon fill="black" stroke="black" points="1118.44,-277.19 1108.24,-280.07 1118.01,-284.17 1118.44,-277.19"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.9：随机梯度下降 -->
<g id="node47" class="node">
<title>第5章：机器学习基础 &#45; 5.9：随机梯度下降</title>
<polygon fill="lightgrey" stroke="black" points="1020.19,-297.65 899.19,-297.65 899.19,-261.65 1020.19,-261.65 1020.19,-297.65"/>
<text text-anchor="middle" x="959.69" y="-277.15" font-family="Microsoft YaHei" font-size="10.00">5.9：随机梯度下降</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.3：超参数和验证集&#45;&gt;第5章：机器学习基础 &#45; 5.9：随机梯度下降 -->
<g id="edge42" class="edge">
<title>第5章：机器学习基础 &#45; 5.3：超参数和验证集&#45;&gt;第5章：机器学习基础 &#45; 5.9：随机梯度下降</title>
<path fill="none" stroke="black" d="M999.53,-278.87C999.49,-278.87 999.45,-278.87 999.41,-278.88"/>
<polygon fill="black" stroke="black" points="1009.21,-275.18 999.28,-278.88 1009.35,-282.17 1009.21,-275.18"/>
</g>
<!-- 第5章：机器学习基础 &#45; 5.10：构建机器学习算法 -->
<g id="node48" class="node">
<title>第5章：机器学习基础 &#45; 5.10：构建机器学习算法</title>
<polygon fill="lightgrey" stroke="black" points="969,-338.51 817,-338.51 817,-302.51 969,-302.51 969,-338.51"/>
<text text-anchor="middle" x="893" y="-318.01" font-family="Microsoft YaHei" font-size="10.00">5.10：构建机器学习算法</text>
</g>
<!-- 第5章：机器学习基础 &#45; 5.9：随机梯度下降&#45;&gt;第5章：机器学习基础 &#45; 5.10：构建机器学习算法 -->
<g id="edge43" class="edge">
<title>第5章：机器学习基础 &#45; 5.9：随机梯度下降&#45;&gt;第5章：机器学习基础 &#45; 5.10：构建机器学习算法</title>
<path fill="none" stroke="black" d="M930.25,-297.69C930.09,-297.79 929.93,-297.88 929.77,-297.98"/>
<polygon fill="black" stroke="black" points="929.37,-294.12 922.68,-302.33 933.03,-300.09 929.37,-294.12"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.2：基于梯度的学习 -->
<g id="node49" class="node">
<title>第6章：深度前馈网络 &#45; 6.2：基于梯度的学习</title>
<polygon fill="lightgrey" stroke="black" points="1768,-1799 1634,-1799 1634,-1763 1768,-1763 1768,-1799"/>
<text text-anchor="middle" x="1701" y="-1778.5" font-family="Microsoft YaHei" font-size="10.00">6.2：基于梯度的学习</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.3：隐藏单元 -->
<g id="node50" class="node">
<title>第6章：深度前馈网络 &#45; 6.3：隐藏单元</title>
<polygon fill="lightgrey" stroke="black" points="1907.81,-1817.77 1812.81,-1817.77 1812.81,-1781.77 1907.81,-1781.77 1907.81,-1817.77"/>
<text text-anchor="middle" x="1860.31" y="-1797.27" font-family="Microsoft YaHei" font-size="10.00">6.3：隐藏单元</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.2：基于梯度的学习&#45;&gt;第6章：深度前馈网络 &#45; 6.3：隐藏单元 -->
<g id="edge44" class="edge">
<title>第6章：深度前馈网络 &#45; 6.2：基于梯度的学习&#45;&gt;第6章：深度前馈网络 &#45; 6.3：隐藏单元</title>
<path fill="none" stroke="black" d="M1768.1,-1788.9C1779.56,-1790.25 1791.37,-1791.65 1802.56,-1792.96"/>
<polygon fill="black" stroke="black" points="1802.29,-1796.46 1812.63,-1794.15 1803.11,-1789.5 1802.29,-1796.46"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.4：架构设计 -->
<g id="node51" class="node">
<title>第6章：深度前馈网络 &#45; 6.4：架构设计</title>
<polygon fill="lightgrey" stroke="black" points="2100.25,-1826.98 2005.25,-1826.98 2005.25,-1790.98 2100.25,-1790.98 2100.25,-1826.98"/>
<text text-anchor="middle" x="2052.75" y="-1806.48" font-family="Microsoft YaHei" font-size="10.00">6.4：架构设计</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.3：隐藏单元&#45;&gt;第6章：深度前馈网络 &#45; 6.4：架构设计 -->
<g id="edge45" class="edge">
<title>第6章：深度前馈网络 &#45; 6.3：隐藏单元&#45;&gt;第6章：深度前馈网络 &#45; 6.4：架构设计</title>
<path fill="none" stroke="black" d="M1907.88,-1802.04C1934.24,-1803.31 1967.23,-1804.89 1995.06,-1806.22"/>
<polygon fill="black" stroke="black" points="1994.9,-1809.72 2005.06,-1806.7 1995.24,-1802.72 1994.9,-1809.72"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法 -->
<g id="node52" class="node">
<title>第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法</title>
<polygon fill="lightgrey" stroke="black" points="2356.05,-1828.11 2159.05,-1828.11 2159.05,-1792.11 2356.05,-1792.11 2356.05,-1828.11"/>
<text text-anchor="middle" x="2257.55" y="-1807.61" font-family="Microsoft YaHei" font-size="10.00">6.5：反向传播和其他的微分算法</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.4：架构设计&#45;&gt;第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法 -->
<g id="edge46" class="edge">
<title>第6章：深度前馈网络 &#45; 6.4：架构设计&#45;&gt;第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法</title>
<path fill="none" stroke="black" d="M2100.25,-1809.24C2114.97,-1809.32 2131.84,-1809.42 2148.93,-1809.51"/>
<polygon fill="black" stroke="black" points="2148.99,-1813.01 2159.01,-1809.57 2149.03,-1806.01 2148.99,-1813.01"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战 -->
<g id="node53" class="node">
<title>第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战</title>
<polygon fill="lightgrey" stroke="black" points="2557.6,-1823.75 2366.6,-1823.75 2366.6,-1787.75 2557.6,-1787.75 2557.6,-1823.75"/>
<text text-anchor="middle" x="2462.1" y="-1803.25" font-family="Microsoft YaHei" font-size="10.00">5.11：促使深度学习发展的挑战</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法&#45;&gt;第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战 -->
<g id="edge47" class="edge">
<title>第6章：深度前馈网络 &#45; 6.5：反向传播和其他的微分算法&#45;&gt;第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战</title>
<path fill="none" stroke="black" d="M2356.23,-1808.01C2356.34,-1808.01 2356.44,-1808 2356.55,-1808"/>
<polygon fill="black" stroke="black" points="2356.43,-1811.51 2366.35,-1807.79 2356.28,-1804.51 2356.43,-1811.51"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.1：实例：学习XOR -->
<g id="node54" class="node">
<title>第6章：深度前馈网络 &#45; 6.1：实例：学习XOR</title>
<polygon fill="lightgrey" stroke="black" points="2718.82,-1814.86 2590.82,-1814.86 2590.82,-1778.86 2718.82,-1778.86 2718.82,-1814.86"/>
<text text-anchor="middle" x="2654.82" y="-1794.36" font-family="Microsoft YaHei" font-size="10.00">6.1：实例：学习XOR</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战&#45;&gt;第6章：深度前馈网络 &#45; 6.1：实例：学习XOR -->
<g id="edge48" class="edge">
<title>第6章：深度前馈网络 &#45; 5.11：促使深度学习发展的挑战&#45;&gt;第6章：深度前馈网络 &#45; 6.1：实例：学习XOR</title>
<path fill="none" stroke="black" d="M2557.62,-1801.34C2565.29,-1800.99 2572.98,-1800.63 2580.48,-1800.29"/>
<polygon fill="black" stroke="black" points="2580.74,-1803.78 2590.57,-1799.82 2580.42,-1796.79 2580.74,-1803.78"/>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.6：历史小记 -->
<g id="node55" class="node">
<title>第6章：深度前馈网络 &#45; 6.6：历史小记</title>
<polygon fill="lightgrey" stroke="black" points="2862.25,-1802.28 2767.25,-1802.28 2767.25,-1766.28 2862.25,-1766.28 2862.25,-1802.28"/>
<text text-anchor="middle" x="2814.75" y="-1781.78" font-family="Microsoft YaHei" font-size="10.00">6.6：历史小记</text>
</g>
<!-- 第6章：深度前馈网络 &#45; 6.1：实例：学习XOR&#45;&gt;第6章：深度前馈网络 &#45; 6.6：历史小记 -->
<g id="edge49" class="edge">
<title>第6章：深度前馈网络 &#45; 6.1：实例：学习XOR&#45;&gt;第6章：深度前馈网络 &#45; 6.6：历史小记</title>
<path fill="none" stroke="black" d="M2718.95,-1791.82C2731.44,-1790.83 2744.47,-1789.81 2756.75,-1788.84"/>
<polygon fill="black" stroke="black" points="2757.17,-1792.32 2766.86,-1788.05 2756.62,-1785.34 2757.17,-1792.32"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.1：参数范数惩罚 -->
<g id="node56" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.1：参数范数惩罚</title>
<polygon fill="lightgrey" stroke="black" points="723,-1326 602,-1326 602,-1290 723,-1290 723,-1326"/>
<text text-anchor="middle" x="662.5" y="-1305.5" font-family="Microsoft YaHei" font-size="10.00">7.1：参数范数惩罚</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性 -->
<g id="node57" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性</title>
<polygon fill="lightgrey" stroke="black" points="741.27,-1389.67 633.27,-1389.67 633.27,-1353.67 741.27,-1353.67 741.27,-1389.67"/>
<text text-anchor="middle" x="687.27" y="-1369.17" font-family="Microsoft YaHei" font-size="10.00">7.5：噪声鲁棒性</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.1：参数范数惩罚&#45;&gt;第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性 -->
<g id="edge50" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.1：参数范数惩罚&#45;&gt;第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性</title>
<path fill="none" stroke="black" d="M669.53,-1326.08C671.66,-1331.54 674.05,-1337.67 676.36,-1343.63"/>
<polygon fill="black" stroke="black" points="673.25,-1345.28 680.14,-1353.33 679.77,-1342.74 673.25,-1345.28"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享 -->
<g id="node58" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享</title>
<polygon fill="lightgrey" stroke="black" points="841.74,-1426.26 682.74,-1426.26 682.74,-1390.26 841.74,-1390.26 841.74,-1426.26"/>
<text text-anchor="middle" x="762.24" y="-1405.76" font-family="Microsoft YaHei" font-size="10.00">7.9：参数绑定和参数共享</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性&#45;&gt;第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享 -->
<g id="edge51" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.5：噪声鲁棒性&#45;&gt;第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享</title>
<path fill="none" stroke="black" d="M724.32,-1389.75C724.46,-1389.83 724.61,-1389.9 724.76,-1389.97"/>
<polygon fill="black" stroke="black" points="714.68,-1388.94 725.2,-1390.19 717.75,-1382.65 714.68,-1388.94"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 6.6：历史小记 -->
<g id="node59" class="node">
<title>第7章：深度学习中的正则化 &#45; 6.6：历史小记</title>
<polygon fill="lightgrey" stroke="black" points="899.27,-1454.05 804.27,-1454.05 804.27,-1418.05 899.27,-1418.05 899.27,-1454.05"/>
<text text-anchor="middle" x="851.77" y="-1433.55" font-family="Microsoft YaHei" font-size="10.00">6.6：历史小记</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享&#45;&gt;第7章：深度学习中的正则化 &#45; 6.6：历史小记 -->
<g id="edge52" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.9：参数绑定和参数共享&#45;&gt;第7章：深度学习中的正则化 &#45; 6.6：历史小记</title>
<path fill="none" stroke="black" d="M820.46,-1426.33C820.52,-1426.35 820.59,-1426.37 820.66,-1426.39"/>
<polygon fill="black" stroke="black" points="810.27,-1426.83 820.86,-1426.46 812.35,-1420.15 810.27,-1426.83"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚 -->
<g id="node60" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚</title>
<polygon fill="lightgrey" stroke="black" points="1034.24,-1461.48 875.24,-1461.48 875.24,-1425.48 1034.24,-1425.48 1034.24,-1461.48"/>
<text text-anchor="middle" x="954.74" y="-1440.98" font-family="Microsoft YaHei" font-size="10.00">7.2：作为约束的范数惩罚</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 6.6：历史小记&#45;&gt;第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚 -->
<g id="edge53" class="edge">
<title>第7章：深度学习中的正则化 &#45; 6.6：历史小记&#45;&gt;第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚</title>
<path fill="none" stroke="black" d="M899.34,-1439.48C899.39,-1439.49 899.44,-1439.49 899.49,-1439.49"/>
<polygon fill="black" stroke="black" points="889.42,-1442.27 899.65,-1439.51 889.93,-1435.29 889.42,-1442.27"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题 -->
<g id="node61" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题</title>
<polygon fill="lightgrey" stroke="black" points="1143.32,-1457.32 984.32,-1457.32 984.32,-1421.32 1143.32,-1421.32 1143.32,-1457.32"/>
<text text-anchor="middle" x="1063.82" y="-1436.82" font-family="Microsoft YaHei" font-size="10.00">7.3：正则化和欠约束问题</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚&#45;&gt;第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题 -->
<g id="edge54" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.2：作为约束的范数惩罚&#45;&gt;第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题</title>
<path fill="none" stroke="black" d="M1034.3,-1440.44C1034.37,-1440.44 1034.43,-1440.44 1034.5,-1440.44"/>
<polygon fill="black" stroke="black" points="1024.84,-1444.31 1034.69,-1440.43 1024.57,-1437.32 1024.84,-1444.31"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.4：数据集增强 -->
<g id="node62" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.4：数据集增强</title>
<polygon fill="lightgrey" stroke="black" points="1229.78,-1451.7 1121.78,-1451.7 1121.78,-1415.7 1229.78,-1415.7 1229.78,-1451.7"/>
<text text-anchor="middle" x="1175.78" y="-1431.2" font-family="Microsoft YaHei" font-size="10.00">7.4：数据集增强</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题&#45;&gt;第7章：深度学习中的正则化 &#45; 7.4：数据集增强 -->
<g id="edge55" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.3：正则化和欠约束问题&#45;&gt;第7章：深度学习中的正则化 &#45; 7.4：数据集增强</title>
<path fill="none" stroke="black" d="M1143.39,-1435.32C1143.46,-1435.32 1143.54,-1435.32 1143.61,-1435.31"/>
<polygon fill="black" stroke="black" points="1134.01,-1439.3 1143.82,-1435.3 1133.66,-1432.31 1134.01,-1439.3"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.6：半监督学习 -->
<g id="node63" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.6：半监督学习</title>
<polygon fill="lightgrey" stroke="black" points="1342.77,-1445.07 1234.77,-1445.07 1234.77,-1409.07 1342.77,-1409.07 1342.77,-1445.07"/>
<text text-anchor="middle" x="1288.77" y="-1424.57" font-family="Microsoft YaHei" font-size="10.00">7.6：半监督学习</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.4：数据集增强&#45;&gt;第7章：深度学习中的正则化 &#45; 7.6：半监督学习 -->
<g id="edge56" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.4：数据集增强&#45;&gt;第7章：深度学习中的正则化 &#45; 7.6：半监督学习</title>
<path fill="none" stroke="black" d="M1229.96,-1430.52C1230.06,-1430.52 1230.16,-1430.51 1230.26,-1430.5"/>
<polygon fill="black" stroke="black" points="1224.94,-1434.32 1234.72,-1430.24 1224.53,-1427.33 1224.94,-1434.32"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.7：多任务学习 -->
<g id="node64" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.7：多任务学习</title>
<polygon fill="lightgrey" stroke="black" points="1454.79,-1437.47 1346.79,-1437.47 1346.79,-1401.47 1454.79,-1401.47 1454.79,-1437.47"/>
<text text-anchor="middle" x="1400.79" y="-1416.97" font-family="Microsoft YaHei" font-size="10.00">7.7：多任务学习</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.6：半监督学习&#45;&gt;第7章：深度学习中的正则化 &#45; 7.7：多任务学习 -->
<g id="edge57" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.6：半监督学习&#45;&gt;第7章：深度学习中的正则化 &#45; 7.7：多任务学习</title>
<path fill="none" stroke="black" d="M1342.81,-1423.41C1342.97,-1423.4 1343.12,-1423.38 1343.28,-1423.37"/>
<polygon fill="black" stroke="black" points="1336.77,-1427.32 1346.51,-1423.16 1336.29,-1420.34 1336.77,-1427.32"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.8：提前终止 -->
<g id="node65" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.8：提前终止</title>
<polygon fill="lightgrey" stroke="black" points="1556.7,-1425.27 1461.7,-1425.27 1461.7,-1389.27 1556.7,-1389.27 1556.7,-1425.27"/>
<text text-anchor="middle" x="1509.2" y="-1404.77" font-family="Microsoft YaHei" font-size="10.00">7.8：提前终止</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.7：多任务学习&#45;&gt;第7章：深度学习中的正则化 &#45; 7.8：提前终止 -->
<g id="edge58" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.7：多任务学习&#45;&gt;第7章：深度学习中的正则化 &#45; 7.8：提前终止</title>
<path fill="none" stroke="black" d="M1454.99,-1413.37C1455.13,-1413.36 1455.27,-1413.34 1455.41,-1413.32"/>
<polygon fill="black" stroke="black" points="1452.1,-1417.22 1461.65,-1412.62 1451.32,-1410.26 1452.1,-1417.22"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.10：稀疏表示 -->
<g id="node66" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.10：稀疏表示</title>
<polygon fill="lightgrey" stroke="black" points="1662.04,-1408.92 1561.04,-1408.92 1561.04,-1372.92 1662.04,-1372.92 1662.04,-1408.92"/>
<text text-anchor="middle" x="1611.54" y="-1388.42" font-family="Microsoft YaHei" font-size="10.00">7.10：稀疏表示</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.8：提前终止&#45;&gt;第7章：深度学习中的正则化 &#45; 7.10：稀疏表示 -->
<g id="edge59" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.8：提前终止&#45;&gt;第7章：深度学习中的正则化 &#45; 7.10：稀疏表示</title>
<path fill="none" stroke="black" d="M1556.77,-1399.67C1556.86,-1399.65 1556.94,-1399.64 1557.03,-1399.63"/>
<polygon fill="black" stroke="black" points="1551.53,-1404.05 1560.85,-1399.02 1550.42,-1397.14 1551.53,-1404.05"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法 -->
<g id="node67" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法</title>
<polygon fill="lightgrey" stroke="black" points="1793.55,-1391.55 1614.55,-1391.55 1614.55,-1355.55 1793.55,-1355.55 1793.55,-1391.55"/>
<text text-anchor="middle" x="1704.05" y="-1371.05" font-family="Microsoft YaHei" font-size="10.00">7.11：Bagging和其他集成方法</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.10：稀疏表示&#45;&gt;第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法 -->
<g id="edge60" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.10：稀疏表示&#45;&gt;第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法</title>
<path fill="none" stroke="black" d="M1662.13,-1381.42C1662.17,-1381.41 1662.21,-1381.4 1662.25,-1381.39"/>
<polygon fill="black" stroke="black" points="1653.2,-1386.66 1662.38,-1381.37 1651.9,-1379.78 1653.2,-1386.66"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.13：对抗训练 -->
<g id="node68" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.13：对抗训练</title>
<polygon fill="lightgrey" stroke="black" points="1833.73,-1378.06 1732.73,-1378.06 1732.73,-1342.06 1833.73,-1342.06 1833.73,-1378.06"/>
<text text-anchor="middle" x="1783.23" y="-1357.56" font-family="Microsoft YaHei" font-size="10.00">7.13：对抗训练</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法&#45;&gt;第7章：深度学习中的正则化 &#45; 7.13：对抗训练 -->
<g id="edge61" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.11：Bagging和其他集成方法&#45;&gt;第7章：深度学习中的正则化 &#45; 7.13：对抗训练</title>
<path fill="none" stroke="black" d="M1783.17,-1360.07C1783.18,-1360.07 1783.19,-1360.07 1783.2,-1360.07"/>
<polygon fill="black" stroke="black" points="1773.96,-1365.24 1783.21,-1360.07 1772.75,-1358.34 1773.96,-1365.24"/>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.14：切面距离、正切传播和流形正切分 -->
<g id="node69" class="node">
<title>第7章：深度学习中的正则化 &#45; 7.14：切面距离、正切传播和流形正切分</title>
<polygon fill="lightgrey" stroke="black" points="1952.37,-1420.5 1710.37,-1420.5 1710.37,-1384.5 1952.37,-1384.5 1952.37,-1420.5"/>
<text text-anchor="middle" x="1831.37" y="-1400" font-family="Microsoft YaHei" font-size="10.00">7.14：切面距离、正切传播和流形正切分</text>
</g>
<!-- 第7章：深度学习中的正则化 &#45; 7.13：对抗训练&#45;&gt;第7章：深度学习中的正则化 &#45; 7.14：切面距离、正切传播和流形正切分 -->
<g id="edge62" class="edge">
<title>第7章：深度学习中的正则化 &#45; 7.13：对抗训练&#45;&gt;第7章：深度学习中的正则化 &#45; 7.14：切面距离、正切传播和流形正切分</title>
<path fill="none" stroke="black" d="M1803.92,-1378.31C1804.06,-1378.43 1804.2,-1378.55 1804.35,-1378.68"/>
<polygon fill="black" stroke="black" points="1800.88,-1380.28 1810.69,-1384.27 1805.5,-1375.03 1800.88,-1380.28"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.1：学习和纯优化有什么不同 -->
<g id="node70" class="node">
<title>第8章：深度模型中的优化 &#45; 8.1：学习和纯优化有什么不同</title>
<polygon fill="lightgrey" stroke="black" points="2275.1,-595 2090.1,-595 2090.1,-559 2275.1,-559 2275.1,-595"/>
<text text-anchor="middle" x="2182.6" y="-574.5" font-family="Microsoft YaHei" font-size="10.00">8.1：学习和纯优化有什么不同</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战 -->
<g id="node71" class="node">
<title>第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战</title>
<polygon fill="lightgrey" stroke="black" points="2114.48,-607.97 1942.48,-607.97 1942.48,-571.97 2114.48,-571.97 2114.48,-607.97"/>
<text text-anchor="middle" x="2028.48" y="-587.47" font-family="Microsoft YaHei" font-size="10.00">8.2：神经网络优化中的挑战</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.1：学习和纯优化有什么不同&#45;&gt;第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战 -->
<g id="edge63" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.1：学习和纯优化有什么不同&#45;&gt;第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战</title>
<path fill="none" stroke="black" d="M2089.84,-584.81C2089.77,-584.81 2089.71,-584.82 2089.65,-584.82"/>
<polygon fill="black" stroke="black" points="2099.13,-580.51 2089.46,-584.84 2099.72,-587.48 2099.13,-580.51"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.3：基本算法 -->
<g id="node72" class="node">
<title>第8章：深度模型中的优化 &#45; 8.3：基本算法</title>
<polygon fill="lightgrey" stroke="black" points="1887.97,-616.29 1792.97,-616.29 1792.97,-580.29 1887.97,-580.29 1887.97,-616.29"/>
<text text-anchor="middle" x="1840.47" y="-595.79" font-family="Microsoft YaHei" font-size="10.00">8.3：基本算法</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战&#45;&gt;第8章：深度模型中的优化 &#45; 8.3：基本算法 -->
<g id="edge64" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.2：神经网络优化中的挑战&#45;&gt;第8章：深度模型中的优化 &#45; 8.3：基本算法</title>
<path fill="none" stroke="black" d="M1942.46,-593.78C1927.59,-594.43 1912.45,-595.1 1898.54,-595.72"/>
<polygon fill="black" stroke="black" points="1898.01,-592.24 1888.18,-596.18 1898.32,-599.23 1898.01,-592.24"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法 -->
<g id="node73" class="node">
<title>第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法</title>
<polygon fill="lightgrey" stroke="black" points="1710.77,-619.3 1564.77,-619.3 1564.77,-583.3 1710.77,-583.3 1710.77,-619.3"/>
<text text-anchor="middle" x="1637.77" y="-598.8" font-family="Microsoft YaHei" font-size="10.00">8.5：自适应学习率算法</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.3：基本算法&#45;&gt;第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法 -->
<g id="edge65" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.3：基本算法&#45;&gt;第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法</title>
<path fill="none" stroke="black" d="M1792.95,-598.99C1771.45,-599.31 1745.41,-599.7 1720.84,-600.06"/>
<polygon fill="black" stroke="black" points="1720.74,-596.57 1710.79,-600.21 1720.84,-603.56 1720.74,-596.57"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.6：二阶近似方法 -->
<g id="node74" class="node">
<title>第8章：深度模型中的优化 &#45; 8.6：二阶近似方法</title>
<polygon fill="lightgrey" stroke="black" points="1491.16,-618.34 1370.16,-618.34 1370.16,-582.34 1491.16,-582.34 1491.16,-618.34"/>
<text text-anchor="middle" x="1430.66" y="-597.84" font-family="Microsoft YaHei" font-size="10.00">8.6：二阶近似方法</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法&#45;&gt;第8章：深度模型中的优化 &#45; 8.6：二阶近似方法 -->
<g id="edge66" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.5：自适应学习率算法&#45;&gt;第8章：深度模型中的优化 &#45; 8.6：二阶近似方法</title>
<path fill="none" stroke="black" d="M1564.75,-600.96C1544.23,-600.86 1521.95,-600.76 1501.55,-600.67"/>
<polygon fill="black" stroke="black" points="1501.41,-597.17 1491.39,-600.62 1501.38,-604.17 1501.41,-597.17"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法 -->
<g id="node75" class="node">
<title>第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法</title>
<polygon fill="lightgrey" stroke="black" points="1300.79,-614.22 1154.79,-614.22 1154.79,-578.22 1300.79,-578.22 1300.79,-614.22"/>
<text text-anchor="middle" x="1227.79" y="-593.72" font-family="Microsoft YaHei" font-size="10.00">8.7：优化策略和元算法</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.6：二阶近似方法&#45;&gt;第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法 -->
<g id="edge67" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.6：二阶近似方法&#45;&gt;第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法</title>
<path fill="none" stroke="black" d="M1370.07,-599.11C1351.58,-598.73 1330.91,-598.31 1311.18,-597.91"/>
<polygon fill="black" stroke="black" points="1311.04,-594.41 1300.97,-597.71 1310.9,-601.41 1311.04,-594.41"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分 -->
<g id="node76" class="node">
<title>第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分</title>
<polygon fill="lightgrey" stroke="black" points="1160.29,-606.97 918.29,-606.97 918.29,-570.97 1160.29,-570.97 1160.29,-606.97"/>
<text text-anchor="middle" x="1039.29" y="-586.47" font-family="Microsoft YaHei" font-size="10.00">7.14：切面距离、正切传播和流形正切分</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法&#45;&gt;第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分 -->
<g id="edge68" class="edge">
<title>第8章：深度模型中的优化 &#45; 8.7：优化策略和元算法&#45;&gt;第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分</title>
<path fill="none" stroke="black" d="M1154.64,-593.41C1154.59,-593.41 1154.54,-593.4 1154.49,-593.4"/>
<polygon fill="black" stroke="black" points="1164.46,-590.29 1154.33,-593.4 1164.19,-597.28 1164.46,-590.29"/>
</g>
<!-- 第8章：深度模型中的优化 &#45; 8.4：参数初始化策略 -->
<g id="node77" class="node">
<title>第8章：深度模型中的优化 &#45; 8.4：参数初始化策略</title>
<polygon fill="lightgrey" stroke="black" points="951,-596.93 817,-596.93 817,-560.93 951,-560.93 951,-596.93"/>
<text text-anchor="middle" x="884" y="-576.43" font-family="Microsoft YaHei" font-size="10.00">8.4：参数初始化策略</text>
</g>
<!-- 第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分&#45;&gt;第8章：深度模型中的优化 &#45; 8.4：参数初始化策略 -->
<g id="edge69" class="edge">
<title>第8章：深度模型中的优化 &#45; 7.14：切面距离、正切传播和流形正切分&#45;&gt;第8章：深度模型中的优化 &#45; 8.4：参数初始化策略</title>
<path fill="none" stroke="black" d="M918.08,-581.13C918,-581.13 917.92,-581.12 917.85,-581.12"/>
<polygon fill="black" stroke="black" points="927.82,-578.26 917.62,-581.1 927.37,-585.24 927.82,-578.26"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.2：循环神经网络 -->
<g id="node78" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.2：循环神经网络</title>
<polygon fill="lightgrey" stroke="black" points="1116,-1154 989,-1154 989,-1118 1116,-1118 1116,-1154"/>
<text text-anchor="middle" x="1052.5" y="-1133.5" font-family="Microsoft YaHei" font-size="10.00">10.2：循环神经网络</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略 -->
<g id="node79" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略</title>
<polygon fill="lightgrey" stroke="black" points="1249.54,-1172.15 1007.54,-1172.15 1007.54,-1136.15 1249.54,-1136.15 1249.54,-1172.15"/>
<text text-anchor="middle" x="1128.54" y="-1151.65" font-family="Microsoft YaHei" font-size="10.00">10.9：渗漏单元和其他多时间尺度的策略</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.2：循环神经网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略 -->
<g id="edge70" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.2：循环神经网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略</title>
<path fill="none" stroke="black" d="M1116.33,-1151.23C1116.38,-1151.24 1116.44,-1151.26 1116.5,-1151.27"/>
<polygon fill="black" stroke="black" points="1106.13,-1152.39 1116.67,-1151.31 1107.75,-1145.58 1106.13,-1152.39"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN -->
<g id="node80" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN</title>
<polygon fill="lightgrey" stroke="black" points="1335.36,-1178.98 1129.36,-1178.98 1129.36,-1142.98 1335.36,-1142.98 1335.36,-1178.98"/>
<text text-anchor="middle" x="1232.36" y="-1158.48" font-family="Microsoft YaHei" font-size="10.00">10.10：长短期记忆和其他门控RNN</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN -->
<g id="edge71" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.9：渗漏单元和其他多时间尺度的策略&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN</title>
<path fill="none" stroke="black" d="M1232.28,-1160.97C1232.29,-1160.98 1232.3,-1160.98 1232.31,-1160.98"/>
<polygon fill="black" stroke="black" points="1222.11,-1163.77 1232.34,-1160.98 1222.6,-1156.79 1222.11,-1163.77"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖 -->
<g id="node81" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖</title>
<polygon fill="lightgrey" stroke="black" points="1416.33,-1181.34 1283.33,-1181.34 1283.33,-1145.34 1416.33,-1145.34 1416.33,-1181.34"/>
<text text-anchor="middle" x="1349.83" y="-1160.84" font-family="Microsoft YaHei" font-size="10.00">10.11：优化长期依赖</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖 -->
<g id="edge72" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.10：长短期记忆和其他门控RNN&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖</title>
<path fill="none" stroke="black" d="M1335.42,-1163.05C1335.49,-1163.05 1335.56,-1163.05 1335.63,-1163.06"/>
<polygon fill="black" stroke="black" points="1325.76,-1166.35 1335.83,-1163.06 1325.91,-1159.35 1325.76,-1166.35"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史 -->
<g id="node82" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史</title>
<polygon fill="lightgrey" stroke="black" points="1576.85,-1181.4 1373.85,-1181.4 1373.85,-1145.4 1576.85,-1145.4 1576.85,-1181.4"/>
<text text-anchor="middle" x="1475.35" y="-1160.9" font-family="Microsoft YaHei" font-size="10.00">9.11：卷积网络与深度学习的历史</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史 -->
<g id="edge73" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.11：优化长期依赖&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史</title>
<path fill="none" stroke="black" d="M1416.63,-1163.37C1416.69,-1163.37 1416.75,-1163.37 1416.81,-1163.37"/>
<polygon fill="black" stroke="black" points="1406.98,-1166.86 1416.98,-1163.37 1406.99,-1159.86 1406.98,-1166.86"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图 -->
<g id="node83" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图</title>
<polygon fill="lightgrey" stroke="black" points="1663.39,-1180.04 1549.39,-1180.04 1549.39,-1144.04 1663.39,-1144.04 1663.39,-1180.04"/>
<text text-anchor="middle" x="1606.39" y="-1159.54" font-family="Microsoft YaHei" font-size="10.00">10.1：展开计算图</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图 -->
<g id="edge74" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 9.11：卷积网络与深度学习的历史&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图</title>
<path fill="none" stroke="black" d="M1576.98,-1162.34C1577.05,-1162.34 1577.11,-1162.34 1577.18,-1162.34"/>
<polygon fill="black" stroke="black" points="1567.42,-1165.95 1577.38,-1162.34 1567.34,-1158.95 1567.42,-1165.95"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN -->
<g id="node84" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN</title>
<polygon fill="lightgrey" stroke="black" points="1788.82,-1177.77 1690.82,-1177.77 1690.82,-1141.77 1788.82,-1141.77 1788.82,-1177.77"/>
<text text-anchor="middle" x="1739.82" y="-1157.27" font-family="Microsoft YaHei" font-size="10.00">10.3：双向RNN</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN -->
<g id="edge75" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.1：展开计算图&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN</title>
<path fill="none" stroke="black" d="M1663.75,-1161.06C1669.18,-1160.97 1674.68,-1160.88 1680.13,-1160.79"/>
<polygon fill="black" stroke="black" points="1680.54,-1164.28 1690.48,-1160.61 1680.42,-1157.28 1680.54,-1164.28"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构 -->
<g id="node85" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构</title>
<polygon fill="lightgrey" stroke="black" points="1989.59,-1174.96 1756.59,-1174.96 1756.59,-1138.96 1989.59,-1138.96 1989.59,-1174.96"/>
<text text-anchor="middle" x="1873.09" y="-1154.46" font-family="Microsoft YaHei" font-size="10.00">10.4：基于编码&#45;解码的序列到序列架构</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构 -->
<g id="edge76" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.3：双向RNN&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构</title>
<path fill="none" stroke="black" d="M1789.07,-1158.73C1789.14,-1158.73 1789.22,-1158.73 1789.29,-1158.73"/>
<polygon fill="black" stroke="black" points="1779.59,-1162.44 1789.52,-1158.72 1779.44,-1155.44 1779.59,-1162.44"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络 -->
<g id="node86" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络</title>
<polygon fill="lightgrey" stroke="black" points="2067.64,-1172.02 1940.64,-1172.02 1940.64,-1136.02 2067.64,-1136.02 2067.64,-1172.02"/>
<text text-anchor="middle" x="2004.14" y="-1151.52" font-family="Microsoft YaHei" font-size="10.00">10.5：深度循环网络</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络 -->
<g id="edge77" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.4：基于编码&#45;解码的序列到序列架构&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络</title>
<path fill="none" stroke="black" d="M1989.62,-1154.34C1989.69,-1154.34 1989.76,-1154.34 1989.83,-1154.34"/>
<polygon fill="black" stroke="black" points="1980.12,-1158.06 1990.03,-1154.33 1979.96,-1151.06 1980.12,-1158.06"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络 -->
<g id="node87" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络</title>
<polygon fill="lightgrey" stroke="black" points="2193.8,-1169.36 2066.8,-1169.36 2066.8,-1133.36 2193.8,-1133.36 2193.8,-1169.36"/>
<text text-anchor="middle" x="2130.3" y="-1148.86" font-family="Microsoft YaHei" font-size="10.00">10.6：递归神经网络</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络 -->
<g id="edge78" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.5：深度循环网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络</title>
<path fill="none" stroke="black" d="M2067.96,-1152.67C2068.02,-1152.67 2068.08,-1152.67 2068.14,-1152.67"/>
<polygon fill="black" stroke="black" points="2058.4,-1156.38 2068.33,-1152.66 2058.25,-1149.38 2058.4,-1156.38"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战 -->
<g id="node88" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战</title>
<polygon fill="lightgrey" stroke="black" points="2318.17,-1167.57 2178.17,-1167.57 2178.17,-1131.57 2318.17,-1131.57 2318.17,-1167.57"/>
<text text-anchor="middle" x="2248.17" y="-1147.07" font-family="Microsoft YaHei" font-size="10.00">10.7：长期依赖的挑战</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战 -->
<g id="edge79" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.6：递归神经网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战</title>
<path fill="none" stroke="black" d="M2194.06,-1150.39C2194.12,-1150.39 2194.17,-1150.39 2194.23,-1150.39"/>
<polygon fill="black" stroke="black" points="2184.45,-1154.04 2194.39,-1150.39 2184.33,-1147.04 2184.45,-1154.04"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络 -->
<g id="node89" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络</title>
<polygon fill="lightgrey" stroke="black" points="2416.08,-1168.35 2289.08,-1168.35 2289.08,-1132.35 2416.08,-1132.35 2416.08,-1168.35"/>
<text text-anchor="middle" x="2352.58" y="-1147.85" font-family="Microsoft YaHei" font-size="10.00">10.8：回声状态网络</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络 -->
<g id="edge80" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.7：长期依赖的挑战&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络</title>
<path fill="none" stroke="black" d="M2318.39,-1150.09C2318.47,-1150.09 2318.54,-1150.09 2318.61,-1150.09"/>
<polygon fill="black" stroke="black" points="2308.81,-1153.52 2318.83,-1150.1 2308.86,-1146.52 2308.81,-1153.52"/>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.12：外显记忆 -->
<g id="node90" class="node">
<title>第10章：序列建模：循环和递归网络 &#45; 10.12：外显记忆</title>
<polygon fill="lightgrey" stroke="black" points="2485.14,-1177.19 2378.14,-1177.19 2378.14,-1141.19 2485.14,-1141.19 2485.14,-1177.19"/>
<text text-anchor="middle" x="2431.64" y="-1156.69" font-family="Microsoft YaHei" font-size="10.00">10.12：外显记忆</text>
</g>
<!-- 第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.12：外显记忆 -->
<g id="edge81" class="edge">
<title>第10章：序列建模：循环和递归网络 &#45; 10.8：回声状态网络&#45;&gt;第10章：序列建模：循环和递归网络 &#45; 10.12：外显记忆</title>
<path fill="none" stroke="black" d="M2416.39,-1157.49C2416.47,-1157.5 2416.54,-1157.5 2416.61,-1157.51"/>
<polygon fill="black" stroke="black" points="2406.49,-1159.9 2416.81,-1157.53 2407.27,-1152.94 2406.49,-1159.9"/>
</g>
<!-- 第11章：实践方法论 &#45; 11.4：选择超参数 -->
<g id="node91" class="node">
<title>第11章：实践方法论 &#45; 11.4：选择超参数</title>
<polygon fill="lightgrey" stroke="black" points="931,-36 817,-36 817,0 931,0 931,-36"/>
<text text-anchor="middle" x="874" y="-15.5" font-family="Microsoft YaHei" font-size="10.00">11.4：选择超参数</text>
</g>
<!-- 第11章：实践方法论 &#45; 10.12：外显记忆 -->
<g id="node92" class="node">
<title>第11章：实践方法论 &#45; 10.12：外显记忆</title>
<polygon fill="lightgrey" stroke="black" points="1105.08,-36.07 998.08,-36.07 998.08,-0.07 1105.08,-0.07 1105.08,-36.07"/>
<text text-anchor="middle" x="1051.58" y="-15.57" font-family="Microsoft YaHei" font-size="10.00">10.12：外显记忆</text>
</g>
<!-- 第11章：实践方法论 &#45; 11.4：选择超参数&#45;&gt;第11章：实践方法论 &#45; 10.12：外显记忆 -->
<g id="edge82" class="edge">
<title>第11章：实践方法论 &#45; 11.4：选择超参数&#45;&gt;第11章：实践方法论 &#45; 10.12：外显记忆</title>
<path fill="none" stroke="black" d="M931.17,-18.02C949.22,-18.03 969.27,-18.04 987.76,-18.05"/>
<polygon fill="black" stroke="black" points="987.84,-21.55 997.84,-18.05 987.85,-14.55 987.84,-21.55"/>
</g>
<!-- 第11章：实践方法论 &#45; 11.1：性能度量 -->
<g id="node93" class="node">
<title>第11章：实践方法论 &#45; 11.1：性能度量</title>
<polygon fill="lightgrey" stroke="black" points="1309.11,-36.11 1208.11,-36.11 1208.11,-0.11 1309.11,-0.11 1309.11,-36.11"/>
<text text-anchor="middle" x="1258.61" y="-15.61" font-family="Microsoft YaHei" font-size="10.00">11.1：性能度量</text>
</g>
<!-- 第11章：实践方法论 &#45; 10.12：外显记忆&#45;&gt;第11章：实践方法论 &#45; 11.1：性能度量 -->
<g id="edge83" class="edge">
<title>第11章：实践方法论 &#45; 10.12：外显记忆&#45;&gt;第11章：实践方法论 &#45; 11.1：性能度量</title>
<path fill="none" stroke="black" d="M1105.17,-18.08C1133.57,-18.09 1168.56,-18.1 1197.95,-18.1"/>
<polygon fill="black" stroke="black" points="1198.1,-21.6 1208.1,-18.1 1198.1,-14.6 1198.1,-21.6"/>
</g>
<!-- 第11章：实践方法论 &#45; 11.2：默认的基准模型 -->
<g id="node94" class="node">
<title>第11章：实践方法论 &#45; 11.2：默认的基准模型</title>
<polygon fill="lightgrey" stroke="black" points="1543.12,-36.12 1403.12,-36.12 1403.12,-0.12 1543.12,-0.12 1543.12,-36.12"/>
<text text-anchor="middle" x="1473.12" y="-15.62" font-family="Microsoft YaHei" font-size="10.00">11.2：默认的基准模型</text>
</g>
<!-- 第11章：实践方法论 &#45; 11.1：性能度量&#45;&gt;第11章：实践方法论 &#45; 11.2：默认的基准模型 -->
<g id="edge84" class="edge">
<title>第11章：实践方法论 &#45; 11.1：性能度量&#45;&gt;第11章：实践方法论 &#45; 11.2：默认的基准模型</title>
<path fill="none" stroke="black" d="M1309.17,-18.11C1334.1,-18.12 1364.77,-18.12 1392.81,-18.12"/>
<polygon fill="black" stroke="black" points="1393.01,-21.62 1403.01,-18.12 1393.01,-14.62 1393.01,-21.62"/>
</g>
<!-- 第11章：实践方法论 &#45; 11.5：调试策略 -->
<g id="node95" class="node">
<title>第11章：实践方法论 &#45; 11.5：调试策略</title>
<polygon fill="lightgrey" stroke="black" points="1730.78,-36.06 1629.78,-36.06 1629.78,-0.06 1730.78,-0.06 1730.78,-36.06"/>
<text text-anchor="middle" x="1680.28" y="-15.56" font-family="Microsoft YaHei" font-size="10.00">11.5：调试策略</text>
</g>
<!-- 第11章：实践方法论 &#45; 11.2：默认的基准模型&#45;&gt;第11章：实践方法论 &#45; 11.5：调试策略 -->
<g id="edge85" class="edge">
<title>第11章：实践方法论 &#45; 11.2：默认的基准模型&#45;&gt;第11章：实践方法论 &#45; 11.5：调试策略</title>
<path fill="none" stroke="black" d="M1543.25,-18.1C1568.01,-18.09 1595.61,-18.09 1619.53,-18.08"/>
<polygon fill="black" stroke="black" points="1619.53,-21.58 1629.53,-18.08 1619.53,-14.58 1619.53,-21.58"/>
</g>
<!-- 第11章：实践方法论 &#45; 11.6：示例：多位数字识别 -->
<g id="node96" class="node">
<title>第11章：实践方法论 &#45; 11.6：示例：多位数字识别</title>
<polygon fill="lightgrey" stroke="black" points="1940.13,-36.01 1775.13,-36.01 1775.13,-0.01 1940.13,-0.01 1940.13,-36.01"/>
<text text-anchor="middle" x="1857.63" y="-15.51" font-family="Microsoft YaHei" font-size="10.00">11.6：示例：多位数字识别</text>
</g>
<!-- 第11章：实践方法论 &#45; 11.5：调试策略&#45;&gt;第11章：实践方法论 &#45; 11.6：示例：多位数字识别 -->
<g id="edge86" class="edge">
<title>第11章：实践方法论 &#45; 11.5：调试策略&#45;&gt;第11章：实践方法论 &#45; 11.6：示例：多位数字识别</title>
<path fill="none" stroke="black" d="M1731.1,-18.05C1741.71,-18.04 1753.21,-18.04 1764.8,-18.04"/>
<polygon fill="black" stroke="black" points="1765,-21.54 1775,-18.03 1765,-14.54 1765,-21.54"/>
</g>
<!-- 第12章：应用 &#45; 12.1：大规模深度学习 -->
<g id="node97" class="node">
<title>第12章：应用 &#45; 12.1：大规模深度学习</title>
<polygon fill="lightgrey" stroke="black" points="1903,-1928 1763,-1928 1763,-1892 1903,-1892 1903,-1928"/>
<text text-anchor="middle" x="1833" y="-1907.5" font-family="Microsoft YaHei" font-size="10.00">12.1：大规模深度学习</text>
</g>
<!-- 第12章：应用 &#45; 12.2：计算机视觉 -->
<g id="node98" class="node">
<title>第12章：应用 &#45; 12.2：计算机视觉</title>
<polygon fill="lightgrey" stroke="black" points="2070.85,-1928.34 1956.85,-1928.34 1956.85,-1892.34 2070.85,-1892.34 2070.85,-1928.34"/>
<text text-anchor="middle" x="2013.85" y="-1907.84" font-family="Microsoft YaHei" font-size="10.00">12.2：计算机视觉</text>
</g>
<!-- 第12章：应用 &#45; 12.1：大规模深度学习&#45;&gt;第12章：应用 &#45; 12.2：计算机视觉 -->
<g id="edge87" class="edge">
<title>第12章：应用 &#45; 12.1：大规模深度学习&#45;&gt;第12章：应用 &#45; 12.2：计算机视觉</title>
<path fill="none" stroke="black" d="M1903.18,-1910.13C1917.4,-1910.16 1932.33,-1910.19 1946.45,-1910.21"/>
<polygon fill="black" stroke="black" points="1946.56,-1913.71 1956.57,-1910.23 1946.58,-1906.71 1946.56,-1913.71"/>
</g>
<!-- 第12章：应用 &#45; 12.4：自然语言处理 -->
<g id="node99" class="node">
<title>第12章：应用 &#45; 12.4：自然语言处理</title>
<polygon fill="lightgrey" stroke="black" points="2288.09,-1928.36 2161.09,-1928.36 2161.09,-1892.36 2288.09,-1892.36 2288.09,-1928.36"/>
<text text-anchor="middle" x="2224.59" y="-1907.86" font-family="Microsoft YaHei" font-size="10.00">12.4：自然语言处理</text>
</g>
<!-- 第12章：应用 &#45; 12.2：计算机视觉&#45;&gt;第12章：应用 &#45; 12.4：自然语言处理 -->
<g id="edge88" class="edge">
<title>第12章：应用 &#45; 12.2：计算机视觉&#45;&gt;第12章：应用 &#45; 12.4：自然语言处理</title>
<path fill="none" stroke="black" d="M2070.88,-1910.35C2095.41,-1910.35 2124.41,-1910.35 2150.58,-1910.35"/>
<polygon fill="black" stroke="black" points="2150.83,-1913.85 2160.83,-1910.35 2150.83,-1906.85 2150.83,-1913.85"/>
</g>
<!-- 第12章：应用 &#45; 12.5：其他应用 -->
<g id="node100" class="node">
<title>第12章：应用 &#45; 12.5：其他应用</title>
<polygon fill="lightgrey" stroke="black" points="2493.95,-1928.29 2392.95,-1928.29 2392.95,-1892.29 2493.95,-1892.29 2493.95,-1928.29"/>
<text text-anchor="middle" x="2443.45" y="-1907.79" font-family="Microsoft YaHei" font-size="10.00">12.5：其他应用</text>
</g>
<!-- 第12章：应用 &#45; 12.4：自然语言处理&#45;&gt;第12章：应用 &#45; 12.5：其他应用 -->
<g id="edge89" class="edge">
<title>第12章：应用 &#45; 12.4：自然语言处理&#45;&gt;第12章：应用 &#45; 12.5：其他应用</title>
<path fill="none" stroke="black" d="M2288.19,-1910.34C2317.99,-1910.33 2353.33,-1910.32 2382.76,-1910.31"/>
<polygon fill="black" stroke="black" points="2382.91,-1913.81 2392.91,-1910.3 2382.91,-1906.81 2382.91,-1913.81"/>
</g>
<!-- 第12章：应用 &#45; 11.6：示例：多位数字识别 -->
<g id="node101" class="node">
<title>第12章：应用 &#45; 11.6：示例：多位数字识别</title>
<polygon fill="lightgrey" stroke="black" points="2736.98,-1928.21 2571.98,-1928.21 2571.98,-1892.21 2736.98,-1892.21 2736.98,-1928.21"/>
<text text-anchor="middle" x="2654.48" y="-1907.71" font-family="Microsoft YaHei" font-size="10.00">11.6：示例：多位数字识别</text>
</g>
<!-- 第12章：应用 &#45; 12.5：其他应用&#45;&gt;第12章：应用 &#45; 11.6：示例：多位数字识别 -->
<g id="edge90" class="edge">
<title>第12章：应用 &#45; 12.5：其他应用&#45;&gt;第12章：应用 &#45; 11.6：示例：多位数字识别</title>
<path fill="none" stroke="black" d="M2494,-1910.27C2514.28,-1910.26 2538.33,-1910.25 2561.56,-1910.24"/>
<polygon fill="black" stroke="black" points="2561.8,-1913.74 2571.8,-1910.24 2561.8,-1906.74 2561.8,-1913.74"/>
</g>
<!-- 第12章：应用 &#45; 12.3：语音识别 -->
<g id="node102" class="node">
<title>第12章：应用 &#45; 12.3：语音识别</title>
<polygon fill="lightgrey" stroke="black" points="2886.03,-1928.1 2785.03,-1928.1 2785.03,-1892.1 2886.03,-1892.1 2886.03,-1928.1"/>
<text text-anchor="middle" x="2835.53" y="-1907.6" font-family="Microsoft YaHei" font-size="10.00">12.3：语音识别</text>
</g>
<!-- 第12章：应用 &#45; 11.6：示例：多位数字识别&#45;&gt;第12章：应用 &#45; 12.3：语音识别 -->
<g id="edge91" class="edge">
<title>第12章：应用 &#45; 11.6：示例：多位数字识别&#45;&gt;第12章：应用 &#45; 12.3：语音识别</title>
<path fill="none" stroke="black" d="M2737.06,-1910.16C2749.68,-1910.15 2762.51,-1910.14 2774.56,-1910.14"/>
<polygon fill="black" stroke="black" points="2774.92,-1913.64 2784.92,-1910.13 2774.92,-1906.64 2774.92,-1913.64"/>
</g>
<!-- 第14章：自编码器 &#45; 14.2：正则自编码器 -->
<g id="node103" class="node">
<title>第14章：自编码器 &#45; 14.2：正则自编码器</title>
<polygon fill="lightgrey" stroke="black" points="2287.25,-724 2160.25,-724 2160.25,-688 2287.25,-688 2287.25,-724"/>
<text text-anchor="middle" x="2223.75" y="-703.5" font-family="Microsoft YaHei" font-size="10.00">14.2：正则自编码器</text>
</g>
<!-- 第14章：自编码器 &#45; 14.5：去噪自编码器详解 -->
<g id="node104" class="node">
<title>第14章：自编码器 &#45; 14.5：去噪自编码器详解</title>
<polygon fill="lightgrey" stroke="black" points="2238.91,-799.51 2086.91,-799.51 2086.91,-763.51 2238.91,-763.51 2238.91,-799.51"/>
<text text-anchor="middle" x="2162.91" y="-779.01" font-family="Microsoft YaHei" font-size="10.00">14.5：去噪自编码器详解</text>
</g>
<!-- 第14章：自编码器 &#45; 14.2：正则自编码器&#45;&gt;第14章：自编码器 &#45; 14.5：去噪自编码器详解 -->
<g id="edge92" class="edge">
<title>第14章：自编码器 &#45; 14.2：正则自编码器&#45;&gt;第14章：自编码器 &#45; 14.5：去噪自编码器详解</title>
<path fill="none" stroke="black" d="M2209.03,-724.28C2201.48,-733.65 2192.15,-745.22 2183.87,-755.5"/>
<polygon fill="black" stroke="black" points="2181.05,-753.42 2177.5,-763.4 2186.5,-757.81 2181.05,-753.42"/>
</g>
<!-- 第14章：自编码器 &#45; 13.5：PCA的流形解释 -->
<g id="node105" class="node">
<title>第14章：自编码器 &#45; 13.5：PCA的流形解释</title>
<polygon fill="lightgrey" stroke="black" points="2104.58,-776.12 1970.58,-776.12 1970.58,-740.12 2104.58,-740.12 2104.58,-776.12"/>
<text text-anchor="middle" x="2037.58" y="-755.62" font-family="Microsoft YaHei" font-size="10.00">13.5：PCA的流形解释</text>
</g>
<!-- 第14章：自编码器 &#45; 14.5：去噪自编码器详解&#45;&gt;第14章：自编码器 &#45; 13.5：PCA的流形解释 -->
<g id="edge93" class="edge">
<title>第14章：自编码器 &#45; 14.5：去噪自编码器详解&#45;&gt;第14章：自编码器 &#45; 13.5：PCA的流形解释</title>
<path fill="none" stroke="black" d="M2086.76,-767.3C2086.7,-767.29 2086.65,-767.28 2086.6,-767.27"/>
<polygon fill="black" stroke="black" points="2096.92,-765.64 2086.45,-767.24 2095.63,-772.52 2096.92,-765.64"/>
</g>
<!-- 第14章：自编码器 &#45; 14.1：欠完备自编码器 -->
<g id="node106" class="node">
<title>第14章：自编码器 &#45; 14.1：欠完备自编码器</title>
<polygon fill="lightgrey" stroke="black" points="1964.14,-753.54 1824.14,-753.54 1824.14,-717.54 1964.14,-717.54 1964.14,-753.54"/>
<text text-anchor="middle" x="1894.14" y="-733.04" font-family="Microsoft YaHei" font-size="10.00">14.1：欠完备自编码器</text>
</g>
<!-- 第14章：自编码器 &#45; 13.5：PCA的流形解释&#45;&gt;第14章：自编码器 &#45; 14.1：欠完备自编码器 -->
<g id="edge94" class="edge">
<title>第14章：自编码器 &#45; 13.5：PCA的流形解释&#45;&gt;第14章：自编码器 &#45; 14.1：欠完备自编码器</title>
<path fill="none" stroke="black" d="M1970.48,-747.56C1970.35,-747.54 1970.23,-747.52 1970.1,-747.5"/>
<polygon fill="black" stroke="black" points="1974.77,-744.69 1964.35,-746.59 1973.68,-751.6 1974.77,-744.69"/>
</g>
<!-- 第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度 -->
<g id="node107" class="node">
<title>第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度</title>
<polygon fill="lightgrey" stroke="black" points="1840.46,-736.98 1637.46,-736.98 1637.46,-700.98 1840.46,-700.98 1840.46,-736.98"/>
<text text-anchor="middle" x="1738.96" y="-716.48" font-family="Microsoft YaHei" font-size="10.00">14.3：表示能力、层的大小和深度</text>
</g>
<!-- 第14章：自编码器 &#45; 14.1：欠完备自编码器&#45;&gt;第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度 -->
<g id="edge95" class="edge">
<title>第14章：自编码器 &#45; 14.1：欠完备自编码器&#45;&gt;第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度</title>
<path fill="none" stroke="black" d="M1823.81,-728.03C1823.73,-728.02 1823.65,-728.01 1823.57,-728.01"/>
<polygon fill="black" stroke="black" points="1833.65,-725.56 1823.33,-727.98 1832.9,-732.52 1833.65,-725.56"/>
</g>
<!-- 第14章：自编码器 &#45; 14.4：随机编码器和解码器 -->
<g id="node108" class="node">
<title>第14章：自编码器 &#45; 14.4：随机编码器和解码器</title>
<polygon fill="lightgrey" stroke="black" points="1660.9,-728.45 1495.9,-728.45 1495.9,-692.45 1660.9,-692.45 1660.9,-728.45"/>
<text text-anchor="middle" x="1578.4" y="-707.95" font-family="Microsoft YaHei" font-size="10.00">14.4：随机编码器和解码器</text>
</g>
<!-- 第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度&#45;&gt;第14章：自编码器 &#45; 14.4：随机编码器和解码器 -->
<g id="edge96" class="edge">
<title>第14章：自编码器 &#45; 14.3：表示能力、层的大小和深度&#45;&gt;第14章：自编码器 &#45; 14.4：随机编码器和解码器</title>
<path fill="none" stroke="black" d="M1637.28,-713.58C1637.21,-713.57 1637.15,-713.57 1637.09,-713.57"/>
<polygon fill="black" stroke="black" points="1647.08,-710.6 1636.9,-713.56 1646.7,-717.59 1647.08,-710.6"/>
</g>
<!-- 第14章：自编码器 &#45; 14.6：使用自编码器学习流形 -->
<g id="node109" class="node">
<title>第14章：自编码器 &#45; 14.6：使用自编码器学习流形</title>
<polygon fill="lightgrey" stroke="black" points="1506.73,-729.25 1328.73,-729.25 1328.73,-693.25 1506.73,-693.25 1506.73,-729.25"/>
<text text-anchor="middle" x="1417.73" y="-708.75" font-family="Microsoft YaHei" font-size="10.00">14.6：使用自编码器学习流形</text>
</g>
<!-- 第14章：自编码器 &#45; 14.4：随机编码器和解码器&#45;&gt;第14章：自编码器 &#45; 14.6：使用自编码器学习流形 -->
<g id="edge97" class="edge">
<title>第14章：自编码器 &#45; 14.4：随机编码器和解码器&#45;&gt;第14章：自编码器 &#45; 14.6：使用自编码器学习流形</title>
<path fill="none" stroke="black" d="M1495.72,-710.86C1495.64,-710.86 1495.56,-710.86 1495.48,-710.86"/>
<polygon fill="black" stroke="black" points="1505.24,-707.31 1495.25,-710.86 1505.27,-714.31 1505.24,-707.31"/>
</g>
<!-- 第14章：自编码器 &#45; 14.7：收缩自编码器 -->
<g id="node110" class="node">
<title>第14章：自编码器 &#45; 14.7：收缩自编码器</title>
<polygon fill="lightgrey" stroke="black" points="1325.72,-737.76 1198.72,-737.76 1198.72,-701.76 1325.72,-701.76 1325.72,-737.76"/>
<text text-anchor="middle" x="1262.22" y="-717.26" font-family="Microsoft YaHei" font-size="10.00">14.7：收缩自编码器</text>
</g>
<!-- 第14章：自编码器 &#45; 14.6：使用自编码器学习流形&#45;&gt;第14章：自编码器 &#45; 14.7：收缩自编码器 -->
<g id="edge98" class="edge">
<title>第14章：自编码器 &#45; 14.6：使用自编码器学习流形&#45;&gt;第14章：自编码器 &#45; 14.7：收缩自编码器</title>
<path fill="none" stroke="black" d="M1328.62,-716.12C1328.5,-716.13 1328.39,-716.14 1328.27,-716.14"/>
<polygon fill="black" stroke="black" points="1335.57,-712.24 1325.78,-716.28 1335.96,-719.23 1335.57,-712.24"/>
</g>
<!-- 第14章：自编码器 &#45; 14.8：预测稀疏分解 -->
<g id="node111" class="node">
<title>第14章：自编码器 &#45; 14.8：预测稀疏分解</title>
<polygon fill="lightgrey" stroke="black" points="1180.68,-748.85 1053.68,-748.85 1053.68,-712.85 1180.68,-712.85 1180.68,-748.85"/>
<text text-anchor="middle" x="1117.18" y="-728.35" font-family="Microsoft YaHei" font-size="10.00">14.8：预测稀疏分解</text>
</g>
<!-- 第14章：自编码器 &#45; 14.7：收缩自编码器&#45;&gt;第14章：自编码器 &#45; 14.8：预测稀疏分解 -->
<g id="edge99" class="edge">
<title>第14章：自编码器 &#45; 14.7：收缩自编码器&#45;&gt;第14章：自编码器 &#45; 14.8：预测稀疏分解</title>
<path fill="none" stroke="black" d="M1198.6,-724.62C1196.01,-724.82 1193.39,-725.02 1190.78,-725.22"/>
<polygon fill="black" stroke="black" points="1190.42,-721.74 1180.71,-725.99 1190.95,-728.72 1190.42,-721.74"/>
</g>
<!-- 第14章：自编码器 &#45; 14.9：自编码器的应用 -->
<g id="node112" class="node">
<title>第14章：自编码器 &#45; 14.9：自编码器的应用</title>
<polygon fill="lightgrey" stroke="black" points="1063.94,-769.55 923.94,-769.55 923.94,-733.55 1063.94,-733.55 1063.94,-769.55"/>
<text text-anchor="middle" x="993.94" y="-749.05" font-family="Microsoft YaHei" font-size="10.00">14.9：自编码器的应用</text>
</g>
<!-- 第14章：自编码器 &#45; 14.8：预测稀疏分解&#45;&gt;第14章：自编码器 &#45; 14.9：自编码器的应用 -->
<g id="edge100" class="edge">
<title>第14章：自编码器 &#45; 14.8：预测稀疏分解&#45;&gt;第14章：自编码器 &#45; 14.9：自编码器的应用</title>
<path fill="none" stroke="black" d="M1053.39,-741.56C1053.34,-741.57 1053.28,-741.58 1053.22,-741.59"/>
<polygon fill="black" stroke="black" points="1062.32,-736.51 1053.04,-741.62 1063.49,-743.41 1062.32,-736.51"/>
</g>
<!-- 第14章：自编码器 &#45; 15.1：贪心逐层无监督预训练 -->
<g id="node113" class="node">
<title>第14章：自编码器 &#45; 15.1：贪心逐层无监督预训练</title>
<polygon fill="lightgrey" stroke="black" points="995,-779.12 817,-779.12 817,-743.12 995,-743.12 995,-779.12"/>
<text text-anchor="middle" x="906" y="-758.62" font-family="Microsoft YaHei" font-size="10.00">15.1：贪心逐层无监督预训练</text>
</g>
<!-- 第14章：自编码器 &#45; 14.9：自编码器的应用&#45;&gt;第14章：自编码器 &#45; 15.1：贪心逐层无监督预训练 -->
<g id="edge101" class="edge">
<title>第14章：自编码器 &#45; 14.9：自编码器的应用&#45;&gt;第14章：自编码器 &#45; 15.1：贪心逐层无监督预训练</title>
<path fill="none" stroke="black" d="M923.8,-759.18C923.71,-759.19 923.63,-759.2 923.55,-759.21"/>
<polygon fill="black" stroke="black" points="932.87,-754.67 923.31,-759.24 933.63,-761.63 932.87,-754.67"/>
</g>
<!-- 第15章：表示学习 &#45; 15.1：贪心逐层无监督预训练 -->
<g id="node114" class="node">
<title>第15章：表示学习 &#45; 15.1：贪心逐层无监督预训练</title>
<polygon fill="lightgrey" stroke="black" points="995,-466.17 817,-466.17 817,-430.17 995,-430.17 995,-466.17"/>
<text text-anchor="middle" x="906" y="-445.67" font-family="Microsoft YaHei" font-size="10.00">15.1：贪心逐层无监督预训练</text>
</g>
<!-- 第15章：表示学习 &#45; 14.9：自编码器的应用 -->
<g id="node115" class="node">
<title>第15章：表示学习 &#45; 14.9：自编码器的应用</title>
<polygon fill="lightgrey" stroke="black" points="1165.27,-466.05 1025.27,-466.05 1025.27,-430.05 1165.27,-430.05 1165.27,-466.05"/>
<text text-anchor="middle" x="1095.27" y="-445.55" font-family="Microsoft YaHei" font-size="10.00">14.9：自编码器的应用</text>
</g>
<!-- 第15章：表示学习 &#45; 15.1：贪心逐层无监督预训练&#45;&gt;第15章：表示学习 &#45; 14.9：自编码器的应用 -->
<g id="edge102" class="edge">
<title>第15章：表示学习 &#45; 15.1：贪心逐层无监督预训练&#45;&gt;第15章：表示学习 &#45; 14.9：自编码器的应用</title>
<path fill="none" stroke="black" d="M995.09,-448.11C1001.7,-448.11 1008.34,-448.1 1014.89,-448.1"/>
<polygon fill="black" stroke="black" points="1015.09,-451.6 1025.09,-448.09 1015.08,-444.6 1015.09,-451.6"/>
</g>
<!-- 第15章：表示学习 &#45; 15.2：迁移学习和领域自适应 -->
<g id="node116" class="node">
<title>第15章：表示学习 &#45; 15.2：迁移学习和领域自适应</title>
<polygon fill="lightgrey" stroke="black" points="1407.85,-466.01 1229.85,-466.01 1229.85,-430.01 1407.85,-430.01 1407.85,-466.01"/>
<text text-anchor="middle" x="1318.85" y="-445.51" font-family="Microsoft YaHei" font-size="10.00">15.2：迁移学习和领域自适应</text>
</g>
<!-- 第15章：表示学习 &#45; 14.9：自编码器的应用&#45;&gt;第15章：表示学习 &#45; 15.2：迁移学习和领域自适应 -->
<g id="edge103" class="edge">
<title>第15章：表示学习 &#45; 14.9：自编码器的应用&#45;&gt;第15章：表示学习 &#45; 15.2：迁移学习和领域自适应</title>
<path fill="none" stroke="black" d="M1165.4,-448.04C1182.58,-448.04 1201.29,-448.03 1219.55,-448.03"/>
<polygon fill="black" stroke="black" points="1219.64,-451.53 1229.64,-448.03 1219.64,-444.53 1219.64,-451.53"/>
</g>
<!-- 第15章：表示学习 &#45; 15.3：半监督解释因果关系 -->
<g id="node117" class="node">
<title>第15章：表示学习 &#45; 15.3：半监督解释因果关系</title>
<polygon fill="lightgrey" stroke="black" points="1638.27,-466 1473.27,-466 1473.27,-430 1638.27,-430 1638.27,-466"/>
<text text-anchor="middle" x="1555.77" y="-445.5" font-family="Microsoft YaHei" font-size="10.00">15.3：半监督解释因果关系</text>
</g>
<!-- 第15章：表示学习 &#45; 15.2：迁移学习和领域自适应&#45;&gt;第15章：表示学习 &#45; 15.3：半监督解释因果关系 -->
<g id="edge104" class="edge">
<title>第15章：表示学习 &#45; 15.2：迁移学习和领域自适应&#45;&gt;第15章：表示学习 &#45; 15.3：半监督解释因果关系</title>
<path fill="none" stroke="black" d="M1408.08,-448.01C1426.04,-448.01 1444.95,-448.01 1463.02,-448.01"/>
<polygon fill="black" stroke="black" points="1463.26,-451.51 1473.26,-448.01 1463.26,-444.51 1463.26,-451.51"/>
</g>
<!-- 第15章：表示学习 &#45; 15.4：分布式表示 -->
<g id="node118" class="node">
<title>第15章：表示学习 &#45; 15.4：分布式表示</title>
<polygon fill="lightgrey" stroke="black" points="1849.67,-466.04 1735.67,-466.04 1735.67,-430.04 1849.67,-430.04 1849.67,-466.04"/>
<text text-anchor="middle" x="1792.67" y="-445.54" font-family="Microsoft YaHei" font-size="10.00">15.4：分布式表示</text>
</g>
<!-- 第15章：表示学习 &#45; 15.3：半监督解释因果关系&#45;&gt;第15章：表示学习 &#45; 15.4：分布式表示 -->
<g id="edge105" class="edge">
<title>第15章：表示学习 &#45; 15.3：半监督解释因果关系&#45;&gt;第15章：表示学习 &#45; 15.4：分布式表示</title>
<path fill="none" stroke="black" d="M1638.29,-448.01C1666.71,-448.02 1698.18,-448.03 1725.25,-448.03"/>
<polygon fill="black" stroke="black" points="1725.39,-451.53 1735.39,-448.03 1725.39,-444.53 1725.39,-451.53"/>
</g>
<!-- 第15章：表示学习 &#45; 15.5：得益于深度的指数增益 -->
<g id="node119" class="node">
<title>第15章：表示学习 &#45; 15.5：得益于深度的指数增益</title>
<polygon fill="lightgrey" stroke="black" points="2105.62,-466.1 1927.62,-466.1 1927.62,-430.1 2105.62,-430.1 2105.62,-466.1"/>
<text text-anchor="middle" x="2016.62" y="-445.6" font-family="Microsoft YaHei" font-size="10.00">15.5：得益于深度的指数增益</text>
</g>
<!-- 第15章：表示学习 &#45; 15.4：分布式表示&#45;&gt;第15章：表示学习 &#45; 15.5：得益于深度的指数增益 -->
<g id="edge106" class="edge">
<title>第15章：表示学习 &#45; 15.4：分布式表示&#45;&gt;第15章：表示学习 &#45; 15.5：得益于深度的指数增益</title>
<path fill="none" stroke="black" d="M1849.76,-448.06C1870.31,-448.06 1894.13,-448.07 1917.22,-448.08"/>
<polygon fill="black" stroke="black" points="1917.42,-451.58 1927.42,-448.08 1917.42,-444.58 1917.42,-451.58"/>
</g>
<!-- 第15章：表示学习 &#45; 15.6：提供发现潜在原因的线索 -->
<g id="node120" class="node">
<title>第15章：表示学习 &#45; 15.6：提供发现潜在原因的线索</title>
<polygon fill="lightgrey" stroke="black" points="2301.66,-466.12 2110.66,-466.12 2110.66,-430.12 2301.66,-430.12 2301.66,-466.12"/>
<text text-anchor="middle" x="2206.16" y="-445.62" font-family="Microsoft YaHei" font-size="10.00">15.6：提供发现潜在原因的线索</text>
</g>
<!-- 第15章：表示学习 &#45; 15.5：得益于深度的指数增益&#45;&gt;第15章：表示学习 &#45; 15.6：提供发现潜在原因的线索 -->
<g id="edge107" class="edge">
<title>第15章：表示学习 &#45; 15.5：得益于深度的指数增益&#45;&gt;第15章：表示学习 &#45; 15.6：提供发现潜在原因的线索</title>
<path fill="none" stroke="black" d="M2105.84,-448.11C2105.93,-448.11 2106.03,-448.11 2106.13,-448.11"/>
<polygon fill="black" stroke="black" points="2100.45,-451.61 2110.45,-448.11 2100.45,-444.61 2100.45,-451.61"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.2：使用图描述模型结构 -->
<g id="node121" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.2：使用图描述模型结构</title>
<polygon fill="lightgrey" stroke="black" points="1541,-1541.08 1376,-1541.08 1376,-1505.08 1541,-1505.08 1541,-1541.08"/>
<text text-anchor="middle" x="1458.5" y="-1520.58" font-family="Microsoft YaHei" font-size="10.00">16.2：使用图描述模型结构</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法 -->
<g id="node122" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法</title>
<polygon fill="lightgrey" stroke="black" points="1762.67,-1541.05 1533.67,-1541.05 1533.67,-1505.05 1762.67,-1505.05 1762.67,-1541.05"/>
<text text-anchor="middle" x="1648.17" y="-1520.55" font-family="Microsoft YaHei" font-size="10.00">16.7：结构化概率模型的深度学习方法</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.2：使用图描述模型结构&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法 -->
<g id="edge108" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.2：使用图描述模型结构&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法</title>
<path fill="none" stroke="black" d="M1541.14,-1523.07C1541.19,-1523.07 1541.24,-1523.07 1541.29,-1523.07"/>
<polygon fill="black" stroke="black" points="1531.44,-1526.57 1541.44,-1523.07 1531.44,-1519.57 1531.44,-1526.57"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索 -->
<g id="node123" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索</title>
<polygon fill="lightgrey" stroke="black" points="1967.37,-1541.03 1776.37,-1541.03 1776.37,-1505.03 1967.37,-1505.03 1967.37,-1541.03"/>
<text text-anchor="middle" x="1871.87" y="-1520.53" font-family="Microsoft YaHei" font-size="10.00">15.6：提供发现潜在原因的线索</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索 -->
<g id="edge109" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.7：结构化概率模型的深度学习方法&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索</title>
<path fill="none" stroke="black" d="M1762.97,-1523.04C1763.93,-1523.04 1764.9,-1523.04 1765.86,-1523.04"/>
<polygon fill="black" stroke="black" points="1766.12,-1526.54 1776.12,-1523.04 1766.12,-1519.54 1766.12,-1526.54"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样 -->
<g id="node124" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样</title>
<polygon fill="lightgrey" stroke="black" points="2178.77,-1541 2038.77,-1541 2038.77,-1505 2178.77,-1505 2178.77,-1541"/>
<text text-anchor="middle" x="2108.77" y="-1520.5" font-family="Microsoft YaHei" font-size="10.00">16.3：从图模型中采样</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样 -->
<g id="edge110" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 15.6：提供发现潜在原因的线索&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样</title>
<path fill="none" stroke="black" d="M1967.55,-1523.02C1987.78,-1523.01 2008.93,-1523.01 2028.52,-1523.01"/>
<polygon fill="black" stroke="black" points="2028.61,-1526.51 2038.61,-1523.01 2028.61,-1519.51 2028.61,-1526.51"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势 -->
<g id="node125" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势</title>
<polygon fill="lightgrey" stroke="black" points="2421.47,-1541.18 2269.47,-1541.18 2269.47,-1505.18 2421.47,-1505.18 2421.47,-1541.18"/>
<text text-anchor="middle" x="2345.47" y="-1520.68" font-family="Microsoft YaHei" font-size="10.00">16.4：结构化建模的优势</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势 -->
<g id="edge111" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.3：从图模型中采样&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势</title>
<path fill="none" stroke="black" d="M2178.83,-1523.05C2204.09,-1523.07 2232.9,-1523.09 2259.37,-1523.11"/>
<polygon fill="black" stroke="black" points="2259.39,-1526.61 2269.39,-1523.12 2259.4,-1519.61 2259.39,-1526.61"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系 -->
<g id="node126" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系</title>
<polygon fill="lightgrey" stroke="black" points="2632.81,-1541.04 2505.81,-1541.04 2505.81,-1505.04 2632.81,-1505.04 2632.81,-1541.04"/>
<text text-anchor="middle" x="2569.31" y="-1520.54" font-family="Microsoft YaHei" font-size="10.00">16.5：学习依赖关系</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系 -->
<g id="edge112" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.4：结构化建模的优势&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系</title>
<path fill="none" stroke="black" d="M2421.56,-1523.13C2445.52,-1523.12 2471.92,-1523.1 2495.7,-1523.09"/>
<polygon fill="black" stroke="black" points="2495.72,-1526.59 2505.71,-1523.08 2495.71,-1519.59 2495.72,-1526.59"/>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.6：推断和近似推断 -->
<g id="node127" class="node">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.6：推断和近似推断</title>
<polygon fill="lightgrey" stroke="black" points="2829.25,-1541.03 2689.25,-1541.03 2689.25,-1505.03 2829.25,-1505.03 2829.25,-1541.03"/>
<text text-anchor="middle" x="2759.25" y="-1520.53" font-family="Microsoft YaHei" font-size="10.00">16.6：推断和近似推断</text>
</g>
<!-- 第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.6：推断和近似推断 -->
<g id="edge113" class="edge">
<title>第16章：深度学习中的结构化概率模型 &#45; 16.5：学习依赖关系&#45;&gt;第16章：深度学习中的结构化概率模型 &#45; 16.6：推断和近似推断</title>
<path fill="none" stroke="black" d="M2632.82,-1523.04C2647.59,-1523.04 2663.51,-1523.04 2678.91,-1523.03"/>
<polygon fill="black" stroke="black" points="2678.93,-1526.54 2688.93,-1523.03 2678.93,-1519.54 2678.93,-1526.54"/>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.1：采样和蒙特卡罗方法 -->
<g id="node128" class="node">
<title>第17章：蒙特卡罗方法 &#45; 17.1：采样和蒙特卡罗方法</title>
<polygon fill="lightgrey" stroke="black" points="1713,-896 1548,-896 1548,-860 1713,-860 1713,-896"/>
<text text-anchor="middle" x="1630.5" y="-875.5" font-family="Microsoft YaHei" font-size="10.00">17.1：采样和蒙特卡罗方法</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战 -->
<g id="node129" class="node">
<title>第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战</title>
<polygon fill="lightgrey" stroke="black" points="1954.65,-896.42 1751.65,-896.42 1751.65,-860.42 1954.65,-860.42 1954.65,-896.42"/>
<text text-anchor="middle" x="1853.15" y="-875.92" font-family="Microsoft YaHei" font-size="10.00">17.5：不同的峰值之间的混合挑战</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.1：采样和蒙特卡罗方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战 -->
<g id="edge114" class="edge">
<title>第17章：蒙特卡罗方法 &#45; 17.1：采样和蒙特卡罗方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战</title>
<path fill="none" stroke="black" d="M1713.09,-878.16C1722.27,-878.17 1731.73,-878.19 1741.19,-878.21"/>
<polygon fill="black" stroke="black" points="1741.45,-881.71 1751.45,-878.23 1741.46,-874.71 1741.45,-881.71"/>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法 -->
<g id="node130" class="node">
<title>第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法</title>
<polygon fill="lightgrey" stroke="black" points="2227.1,-896.44 1998.1,-896.44 1998.1,-860.44 2227.1,-860.44 2227.1,-896.44"/>
<text text-anchor="middle" x="2112.6" y="-875.94" font-family="Microsoft YaHei" font-size="10.00">16.7：结构化概率模型的深度学习方法</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战&#45;&gt;第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法 -->
<g id="edge115" class="edge">
<title>第17章：蒙特卡罗方法 &#45; 17.5：不同的峰值之间的混合挑战&#45;&gt;第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法</title>
<path fill="none" stroke="black" d="M1954.94,-878.43C1965.7,-878.43 1976.73,-878.43 1987.72,-878.43"/>
<polygon fill="black" stroke="black" points="1987.78,-881.93 1997.78,-878.43 1987.78,-874.93 1987.78,-881.93"/>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.2：重要采样 -->
<g id="node131" class="node">
<title>第17章：蒙特卡罗方法 &#45; 17.2：重要采样</title>
<polygon fill="lightgrey" stroke="black" points="2432.54,-896.35 2331.54,-896.35 2331.54,-860.35 2432.54,-860.35 2432.54,-896.35"/>
<text text-anchor="middle" x="2382.04" y="-875.85" font-family="Microsoft YaHei" font-size="10.00">17.2：重要采样</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.2：重要采样 -->
<g id="edge116" class="edge">
<title>第17章：蒙特卡罗方法 &#45; 16.7：结构化概率模型的深度学习方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.2：重要采样</title>
<path fill="none" stroke="black" d="M2227.26,-878.4C2259.52,-878.39 2293.35,-878.38 2321.13,-878.37"/>
<polygon fill="black" stroke="black" points="2321.46,-881.87 2331.46,-878.37 2321.46,-874.87 2321.46,-881.87"/>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法 -->
<g id="node132" class="node">
<title>第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法</title>
<polygon fill="lightgrey" stroke="black" points="2737.35,-896.25 2546.35,-896.25 2546.35,-860.25 2737.35,-860.25 2737.35,-896.25"/>
<text text-anchor="middle" x="2641.85" y="-875.75" font-family="Microsoft YaHei" font-size="10.00">17.3：马尔可夫链蒙特卡罗方法</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.2：重要采样&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法 -->
<g id="edge117" class="edge">
<title>第17章：蒙特卡罗方法 &#45; 17.2：重要采样&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法</title>
<path fill="none" stroke="black" d="M2432.75,-878.33C2462.25,-878.32 2500.55,-878.31 2536.3,-878.29"/>
<polygon fill="black" stroke="black" points="2536.3,-881.79 2546.3,-878.29 2536.3,-874.79 2536.3,-881.79"/>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.4：Gibbs采样 -->
<g id="node133" class="node">
<title>第17章：蒙特卡罗方法 &#45; 17.4：Gibbs采样</title>
<polygon fill="lightgrey" stroke="black" points="2916.75,-896.12 2812.75,-896.12 2812.75,-860.12 2916.75,-860.12 2916.75,-896.12"/>
<text text-anchor="middle" x="2864.75" y="-875.62" font-family="Microsoft YaHei" font-size="10.00">17.4：Gibbs采样</text>
</g>
<!-- 第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.4：Gibbs采样 -->
<g id="edge118" class="edge">
<title>第17章：蒙特卡罗方法 &#45; 17.3：马尔可夫链蒙特卡罗方法&#45;&gt;第17章：蒙特卡罗方法 &#45; 17.4：Gibbs采样</title>
<path fill="none" stroke="black" d="M2737.35,-878.2C2759.28,-878.19 2782.06,-878.17 2802.19,-878.16"/>
<polygon fill="black" stroke="black" points="2802.45,-881.66 2812.45,-878.15 2802.45,-874.66 2802.45,-881.66"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.7：估计配分函数 -->
<g id="node134" class="node">
<title>第18章：直面配分函数 &#45; 18.7：估计配分函数</title>
<polygon fill="lightgrey" stroke="black" points="1675,-1035.29 1548,-1035.29 1548,-999.29 1675,-999.29 1675,-1035.29"/>
<text text-anchor="middle" x="1611.5" y="-1014.79" font-family="Microsoft YaHei" font-size="10.00">18.7：估计配分函数</text>
</g>
<!-- 第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战 -->
<g id="node135" class="node">
<title>第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战</title>
<polygon fill="lightgrey" stroke="black" points="1852.59,-1029.24 1649.59,-1029.24 1649.59,-993.24 1852.59,-993.24 1852.59,-1029.24"/>
<text text-anchor="middle" x="1751.09" y="-1008.74" font-family="Microsoft YaHei" font-size="10.00">17.5：不同的峰值之间的混合挑战</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.7：估计配分函数&#45;&gt;第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战 -->
<g id="edge119" class="edge">
<title>第18章：直面配分函数 &#45; 18.7：估计配分函数&#45;&gt;第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战</title>
<path fill="none" stroke="black" d="M1675.17,-1014.53C1675.24,-1014.53 1675.31,-1014.52 1675.38,-1014.52"/>
<polygon fill="black" stroke="black" points="1665.76,-1018.45 1675.6,-1014.51 1665.46,-1011.45 1665.76,-1018.45"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.1：对数似然梯度 -->
<g id="node136" class="node">
<title>第18章：直面配分函数 &#45; 18.1：对数似然梯度</title>
<polygon fill="lightgrey" stroke="black" points="1991.98,-1026.24 1864.98,-1026.24 1864.98,-990.24 1991.98,-990.24 1991.98,-1026.24"/>
<text text-anchor="middle" x="1928.48" y="-1005.74" font-family="Microsoft YaHei" font-size="10.00">18.1：对数似然梯度</text>
</g>
<!-- 第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战&#45;&gt;第18章：直面配分函数 &#45; 18.1：对数似然梯度 -->
<g id="edge120" class="edge">
<title>第18章：直面配分函数 &#45; 17.5：不同的峰值之间的混合挑战&#45;&gt;第18章：直面配分函数 &#45; 18.1：对数似然梯度</title>
<path fill="none" stroke="black" d="M1852.74,-1009.52C1853.36,-1009.51 1853.99,-1009.5 1854.62,-1009.49"/>
<polygon fill="black" stroke="black" points="1854.73,-1012.99 1864.67,-1009.32 1854.61,-1005.99 1854.73,-1012.99"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度 -->
<g id="node137" class="node">
<title>第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度</title>
<polygon fill="lightgrey" stroke="black" points="2217.28,-1025 2026.28,-1025 2026.28,-989 2217.28,-989 2217.28,-1025"/>
<text text-anchor="middle" x="2121.78" y="-1004.5" font-family="Microsoft YaHei" font-size="10.00">18.2：随机最大似然和对比散度</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.1：对数似然梯度&#45;&gt;第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度 -->
<g id="edge121" class="edge">
<title>第18章：直面配分函数 &#45; 18.1：对数似然梯度&#45;&gt;第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度</title>
<path fill="none" stroke="black" d="M1992.04,-1007.83C1999.7,-1007.78 2007.68,-1007.73 2015.74,-1007.68"/>
<polygon fill="black" stroke="black" points="2016.01,-1011.18 2025.98,-1007.61 2015.96,-1004.18 2016.01,-1011.18"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.3：伪似然 -->
<g id="node138" class="node">
<title>第18章：直面配分函数 &#45; 18.3：伪似然</title>
<polygon fill="lightgrey" stroke="black" points="2364.28,-1025.16 2275.28,-1025.16 2275.28,-989.16 2364.28,-989.16 2364.28,-1025.16"/>
<text text-anchor="middle" x="2319.78" y="-1004.66" font-family="Microsoft YaHei" font-size="10.00">18.3：伪似然</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度&#45;&gt;第18章：直面配分函数 &#45; 18.3：伪似然 -->
<g id="edge122" class="edge">
<title>第18章：直面配分函数 &#45; 18.2：随机最大似然和对比散度&#45;&gt;第18章：直面配分函数 &#45; 18.3：伪似然</title>
<path fill="none" stroke="black" d="M2217.3,-1007.08C2233.54,-1007.09 2249.9,-1007.1 2264.63,-1007.11"/>
<polygon fill="black" stroke="black" points="2265.05,-1010.61 2275.05,-1007.12 2265.05,-1003.61 2265.05,-1010.61"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配 -->
<g id="node139" class="node">
<title>第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配</title>
<polygon fill="lightgrey" stroke="black" points="2596.08,-1026.54 2431.08,-1026.54 2431.08,-990.54 2596.08,-990.54 2596.08,-1026.54"/>
<text text-anchor="middle" x="2513.58" y="-1006.04" font-family="Microsoft YaHei" font-size="10.00">18.4：得分匹配和比率匹配</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.3：伪似然&#45;&gt;第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配 -->
<g id="edge123" class="edge">
<title>第18章：直面配分函数 &#45; 18.3：伪似然&#45;&gt;第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配</title>
<path fill="none" stroke="black" d="M2364.73,-1007.48C2381.49,-1007.6 2401.19,-1007.74 2420.68,-1007.88"/>
<polygon fill="black" stroke="black" points="2420.81,-1011.38 2430.83,-1007.95 2420.86,-1004.38 2420.81,-1011.38"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.5：去噪得分匹配 -->
<g id="node140" class="node">
<title>第18章：直面配分函数 &#45; 18.5：去噪得分匹配</title>
<polygon fill="lightgrey" stroke="black" points="2755.07,-1029.41 2628.07,-1029.41 2628.07,-993.41 2755.07,-993.41 2755.07,-1029.41"/>
<text text-anchor="middle" x="2691.57" y="-1008.91" font-family="Microsoft YaHei" font-size="10.00">18.5：去噪得分匹配</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配&#45;&gt;第18章：直面配分函数 &#45; 18.5：去噪得分匹配 -->
<g id="edge124" class="edge">
<title>第18章：直面配分函数 &#45; 18.4：得分匹配和比率匹配&#45;&gt;第18章：直面配分函数 &#45; 18.5：去噪得分匹配</title>
<path fill="none" stroke="black" d="M2596.32,-1009.87C2603.46,-1009.99 2610.65,-1010.11 2617.71,-1010.22"/>
<polygon fill="black" stroke="black" points="2617.88,-1013.72 2627.93,-1010.39 2617.99,-1006.72 2617.88,-1013.72"/>
</g>
<!-- 第18章：直面配分函数 &#45; 18.6：噪声对比估计 -->
<g id="node141" class="node">
<title>第18章：直面配分函数 &#45; 18.6：噪声对比估计</title>
<polygon fill="lightgrey" stroke="black" points="2895.41,-1034.97 2768.41,-1034.97 2768.41,-998.97 2895.41,-998.97 2895.41,-1034.97"/>
<text text-anchor="middle" x="2831.91" y="-1014.47" font-family="Microsoft YaHei" font-size="10.00">18.6：噪声对比估计</text>
</g>
<!-- 第18章：直面配分函数 &#45; 18.5：去噪得分匹配&#45;&gt;第18章：直面配分函数 &#45; 18.6：噪声对比估计 -->
<g id="edge125" class="edge">
<title>第18章：直面配分函数 &#45; 18.5：去噪得分匹配&#45;&gt;第18章：直面配分函数 &#45; 18.6：噪声对比估计</title>
<path fill="none" stroke="black" d="M2755.17,-1013.93C2756.12,-1013.97 2757.07,-1014.01 2758.03,-1014.04"/>
<polygon fill="black" stroke="black" points="2758.13,-1017.55 2768.26,-1014.45 2758.4,-1010.56 2758.13,-1017.55"/>
</g>
<!-- 第19章：近似推断 &#45; 19.4：变分推断和变分学习 -->
<g id="node142" class="node">
<title>第19章：近似推断 &#45; 19.4：变分推断和变分学习</title>
<polygon fill="lightgrey" stroke="black" points="982,-165 817,-165 817,-129 982,-129 982,-165"/>
<text text-anchor="middle" x="899.5" y="-144.5" font-family="Microsoft YaHei" font-size="10.00">19.4：变分推断和变分学习</text>
</g>
<!-- 第19章：近似推断 &#45; 19.5：学成近似推断 -->
<g id="node143" class="node">
<title>第19章：近似推断 &#45; 19.5：学成近似推断</title>
<polygon fill="lightgrey" stroke="black" points="1168.1,-165.14 1041.1,-165.14 1041.1,-129.14 1168.1,-129.14 1168.1,-165.14"/>
<text text-anchor="middle" x="1104.6" y="-144.64" font-family="Microsoft YaHei" font-size="10.00">19.5：学成近似推断</text>
</g>
<!-- 第19章：近似推断 &#45; 19.4：变分推断和变分学习&#45;&gt;第19章：近似推断 &#45; 19.5：学成近似推断 -->
<g id="edge126" class="edge">
<title>第19章：近似推断 &#45; 19.4：变分推断和变分学习&#45;&gt;第19章：近似推断 &#45; 19.5：学成近似推断</title>
<path fill="none" stroke="black" d="M982.04,-147.06C998.11,-147.07 1014.86,-147.08 1030.63,-147.09"/>
<polygon fill="black" stroke="black" points="1030.84,-150.59 1040.84,-147.1 1030.84,-143.59 1030.84,-150.59"/>
</g>
<!-- 第19章：近似推断 &#45; 18.7：估计配分函数 -->
<g id="node144" class="node">
<title>第19章：近似推断 &#45; 18.7：估计配分函数</title>
<polygon fill="lightgrey" stroke="black" points="1407.1,-165.22 1280.1,-165.22 1280.1,-129.22 1407.1,-129.22 1407.1,-165.22"/>
<text text-anchor="middle" x="1343.6" y="-144.72" font-family="Microsoft YaHei" font-size="10.00">18.7：估计配分函数</text>
</g>
<!-- 第19章：近似推断 &#45; 19.5：学成近似推断&#45;&gt;第19章：近似推断 &#45; 18.7：估计配分函数 -->
<g id="edge127" class="edge">
<title>第19章：近似推断 &#45; 19.5：学成近似推断&#45;&gt;第19章：近似推断 &#45; 18.7：估计配分函数</title>
<path fill="none" stroke="black" d="M1168.33,-147.16C1199.53,-147.17 1237.26,-147.18 1269.71,-147.19"/>
<polygon fill="black" stroke="black" points="1270.04,-150.69 1280.04,-147.2 1270.04,-143.69 1270.04,-150.69"/>
</g>
<!-- 第19章：近似推断 &#45; 19.1：把推断视作优化问题 -->
<g id="node145" class="node">
<title>第19章：近似推断 &#45; 19.1：把推断视作优化问题</title>
<polygon fill="lightgrey" stroke="black" points="1674.07,-165.21 1509.07,-165.21 1509.07,-129.21 1674.07,-129.21 1674.07,-165.21"/>
<text text-anchor="middle" x="1591.57" y="-144.71" font-family="Microsoft YaHei" font-size="10.00">19.1：把推断视作优化问题</text>
</g>
<!-- 第19章：近似推断 &#45; 18.7：估计配分函数&#45;&gt;第19章：近似推断 &#45; 19.1：把推断视作优化问题 -->
<g id="edge128" class="edge">
<title>第19章：近似推断 &#45; 18.7：估计配分函数&#45;&gt;第19章：近似推断 &#45; 19.1：把推断视作优化问题</title>
<path fill="none" stroke="black" d="M1407.13,-147.22C1434.98,-147.22 1468.21,-147.21 1498.75,-147.21"/>
<polygon fill="black" stroke="black" points="1498.99,-150.71 1508.99,-147.21 1498.99,-143.71 1498.99,-150.71"/>
</g>
<!-- 第19章：近似推断 &#45; 19.2：期望最大化 -->
<g id="node146" class="node">
<title>第19章：近似推断 &#45; 19.2：期望最大化</title>
<polygon fill="lightgrey" stroke="black" points="1887.64,-165.12 1773.64,-165.12 1773.64,-129.12 1887.64,-129.12 1887.64,-165.12"/>
<text text-anchor="middle" x="1830.64" y="-144.62" font-family="Microsoft YaHei" font-size="10.00">19.2：期望最大化</text>
</g>
<!-- 第19章：近似推断 &#45; 19.1：把推断视作优化问题&#45;&gt;第19章：近似推断 &#45; 19.2：期望最大化 -->
<g id="edge129" class="edge">
<title>第19章：近似推断 &#45; 19.1：把推断视作优化问题&#45;&gt;第19章：近似推断 &#45; 19.2：期望最大化</title>
<path fill="none" stroke="black" d="M1674.18,-147.18C1703.26,-147.17 1735.58,-147.15 1763.25,-147.14"/>
<polygon fill="black" stroke="black" points="1763.62,-150.64 1773.62,-147.14 1763.62,-143.64 1763.62,-150.64"/>
</g>
<!-- 第19章：近似推断 &#45; 19.3：最大后验推断和稀疏编码 -->
<g id="node147" class="node">
<title>第19章：近似推断 &#45; 19.3：最大后验推断和稀疏编码</title>
<polygon fill="lightgrey" stroke="black" points="2130.71,-165.02 1939.71,-165.02 1939.71,-129.02 2130.71,-129.02 2130.71,-165.02"/>
<text text-anchor="middle" x="2035.21" y="-144.52" font-family="Microsoft YaHei" font-size="10.00">19.3：最大后验推断和稀疏编码</text>
</g>
<!-- 第19章：近似推断 &#45; 19.2：期望最大化&#45;&gt;第19章：近似推断 &#45; 19.3：最大后验推断和稀疏编码 -->
<g id="edge130" class="edge">
<title>第19章：近似推断 &#45; 19.2：期望最大化&#45;&gt;第19章：近似推断 &#45; 19.3：最大后验推断和稀疏编码</title>
<path fill="none" stroke="black" d="M1887.9,-147.09C1900.83,-147.08 1914.97,-147.08 1929.2,-147.07"/>
<polygon fill="black" stroke="black" points="1929.57,-150.57 1939.57,-147.06 1929.56,-143.57 1929.57,-150.57"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.2：受限玻尔兹曼机 -->
<g id="node148" class="node">
<title>第20章：深度生成模型 &#45; 20.2：受限玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="1475.72,-1092.54 1335.72,-1092.54 1335.72,-1056.54 1475.72,-1056.54 1475.72,-1092.54"/>
<text text-anchor="middle" x="1405.72" y="-1072.04" font-family="Microsoft YaHei" font-size="10.00">20.2：受限玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机 -->
<g id="node149" class="node">
<title>第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="1483.27,-1013.71 1343.27,-1013.71 1343.27,-977.71 1483.27,-977.71 1483.27,-1013.71"/>
<text text-anchor="middle" x="1413.27" y="-993.21" font-family="Microsoft YaHei" font-size="10.00">20.4：深度玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.2：受限玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机 -->
<g id="edge131" class="edge">
<title>第20章：深度生成模型 &#45; 20.2：受限玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机</title>
<path fill="none" stroke="black" d="M1407.47,-1056.25C1408.39,-1046.7 1409.53,-1034.8 1410.56,-1024.08"/>
<polygon fill="black" stroke="black" points="1414.06,-1024.18 1411.53,-1013.89 1407.09,-1023.51 1414.06,-1024.18"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机 -->
<g id="node150" class="node">
<title>第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="1465.47,-933.74 1274.47,-933.74 1274.47,-897.74 1465.47,-897.74 1465.47,-933.74"/>
<text text-anchor="middle" x="1369.97" y="-913.24" font-family="Microsoft YaHei" font-size="10.00">20.5：实值数据上的玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机 -->
<g id="edge132" class="edge">
<title>第20章：深度生成模型 &#45; 20.4：深度玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机</title>
<path fill="none" stroke="black" d="M1403.45,-977.56C1397.91,-967.34 1390.89,-954.37 1384.7,-942.95"/>
<polygon fill="black" stroke="black" points="1387.6,-940.94 1379.76,-933.82 1381.44,-944.28 1387.6,-940.94"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播 -->
<g id="node151" class="node">
<title>第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播</title>
<polygon fill="lightgrey" stroke="black" points="1399.57,-869.19 1208.57,-869.19 1208.57,-833.19 1399.57,-833.19 1399.57,-869.19"/>
<text text-anchor="middle" x="1304.07" y="-848.69" font-family="Microsoft YaHei" font-size="10.00">20.9：通过随机操作的反向传播</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播 -->
<g id="edge133" class="edge">
<title>第20章：深度生成模型 &#45; 20.5：实值数据上的玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播</title>
<path fill="none" stroke="black" d="M1351.26,-897.42C1344.67,-890.96 1337.13,-883.57 1330.04,-876.63"/>
<polygon fill="black" stroke="black" points="1332.19,-873.83 1322.6,-869.34 1327.29,-878.83 1332.19,-873.83"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.10：有向生成网络 -->
<g id="node152" class="node">
<title>第20章：深度生成模型 &#45; 20.10：有向生成网络</title>
<polygon fill="lightgrey" stroke="black" points="1274.16,-853 1141.16,-853 1141.16,-817 1274.16,-817 1274.16,-853"/>
<text text-anchor="middle" x="1207.66" y="-832.5" font-family="Microsoft YaHei" font-size="10.00">20.10：有向生成网络</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播&#45;&gt;第20章：深度生成模型 &#45; 20.10：有向生成网络 -->
<g id="edge134" class="edge">
<title>第20章：深度生成模型 &#45; 20.9：通过随机操作的反向传播&#45;&gt;第20章：深度生成模型 &#45; 20.10：有向生成网络</title>
<path fill="none" stroke="black" d="M1208.28,-835.1C1208.18,-835.09 1208.09,-835.07 1208.01,-835.06"/>
<polygon fill="black" stroke="black" points="1218.26,-833.23 1207.82,-835.03 1217.1,-840.14 1218.26,-833.23"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.11：从自编码器采样 -->
<g id="node153" class="node">
<title>第20章：深度生成模型 &#45; 20.11：从自编码器采样</title>
<polygon fill="lightgrey" stroke="black" points="1177.2,-878.5 1031.2,-878.5 1031.2,-842.5 1177.2,-842.5 1177.2,-878.5"/>
<text text-anchor="middle" x="1104.2" y="-858" font-family="Microsoft YaHei" font-size="10.00">20.11：从自编码器采样</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.10：有向生成网络&#45;&gt;第20章：深度生成模型 &#45; 20.11：从自编码器采样 -->
<g id="edge135" class="edge">
<title>第20章：深度生成模型 &#45; 20.10：有向生成网络&#45;&gt;第20章：深度生成模型 &#45; 20.11：从自编码器采样</title>
<path fill="none" stroke="black" d="M1140.97,-851.44C1140.89,-851.46 1140.81,-851.48 1140.74,-851.5"/>
<polygon fill="black" stroke="black" points="1149.37,-845.76 1140.5,-851.55 1151.05,-852.56 1149.37,-845.76"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.12：生成随机网络 -->
<g id="node154" class="node">
<title>第20章：深度生成模型 &#45; 20.12：生成随机网络</title>
<polygon fill="lightgrey" stroke="black" points="1067.62,-925.74 934.62,-925.74 934.62,-889.74 1067.62,-889.74 1067.62,-925.74"/>
<text text-anchor="middle" x="1001.12" y="-905.24" font-family="Microsoft YaHei" font-size="10.00">20.12：生成随机网络</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.11：从自编码器采样&#45;&gt;第20章：深度生成模型 &#45; 20.12：生成随机网络 -->
<g id="edge136" class="edge">
<title>第20章：深度生成模型 &#45; 20.11：从自编码器采样&#45;&gt;第20章：深度生成模型 &#45; 20.12：生成随机网络</title>
<path fill="none" stroke="black" d="M1064.64,-878.63C1059.8,-880.85 1054.8,-883.14 1049.85,-885.41"/>
<polygon fill="black" stroke="black" points="1048.03,-882.39 1040.4,-889.74 1050.95,-888.75 1048.03,-882.39"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.15：结论 -->
<g id="node155" class="node">
<title>第20章：深度生成模型 &#45; 20.15：结论</title>
<polygon fill="lightgrey" stroke="black" points="936.99,-974.3 854.99,-974.3 854.99,-938.3 936.99,-938.3 936.99,-974.3"/>
<text text-anchor="middle" x="895.99" y="-953.8" font-family="Microsoft YaHei" font-size="10.00">20.15：结论</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.12：生成随机网络&#45;&gt;第20章：深度生成模型 &#45; 20.15：结论 -->
<g id="edge137" class="edge">
<title>第20章：深度生成模型 &#45; 20.12：生成随机网络&#45;&gt;第20章：深度生成模型 &#45; 20.15：结论</title>
<path fill="none" stroke="black" d="M961.97,-925.82C956.23,-928.47 950.25,-931.23 944.35,-933.96"/>
<polygon fill="black" stroke="black" points="942.78,-930.83 935.17,-938.2 945.72,-937.18 942.78,-930.83"/>
</g>
<!-- 第20章：深度生成模型 &#45; 19.4：变分推断和变分学习 -->
<g id="node156" class="node">
<title>第20章：深度生成模型 &#45; 19.4：变分推断和变分学习</title>
<polygon fill="lightgrey" stroke="black" points="868,-1006.09 703,-1006.09 703,-970.09 868,-970.09 868,-1006.09"/>
<text text-anchor="middle" x="785.5" y="-985.59" font-family="Microsoft YaHei" font-size="10.00">19.4：变分推断和变分学习</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.15：结论&#45;&gt;第20章：深度生成模型 &#45; 19.4：变分推断和变分学习 -->
<g id="edge138" class="edge">
<title>第20章：深度生成模型 &#45; 20.15：结论&#45;&gt;第20章：深度生成模型 &#45; 19.4：变分推断和变分学习</title>
<path fill="none" stroke="black" d="M854.85,-968.14C854.71,-968.18 854.58,-968.22 854.44,-968.25"/>
<polygon fill="black" stroke="black" points="856.79,-963.94 848.14,-970.07 858.72,-970.66 856.79,-963.94"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.1：玻尔兹曼机 -->
<g id="node157" class="node">
<title>第20章：深度生成模型 &#45; 20.1：玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="729.27,-1010.35 615.27,-1010.35 615.27,-974.35 729.27,-974.35 729.27,-1010.35"/>
<text text-anchor="middle" x="672.27" y="-989.85" font-family="Microsoft YaHei" font-size="10.00">20.1：玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 19.4：变分推断和变分学习&#45;&gt;第20章：深度生成模型 &#45; 20.1：玻尔兹曼机 -->
<g id="edge139" class="edge">
<title>第20章：深度生成模型 &#45; 19.4：变分推断和变分学习&#45;&gt;第20章：深度生成模型 &#45; 20.1：玻尔兹曼机</title>
<path fill="none" stroke="black" d="M702.91,-991.19C702.84,-991.2 702.77,-991.2 702.71,-991.2"/>
<polygon fill="black" stroke="black" points="712.36,-987.33 702.5,-991.21 712.63,-994.33 712.36,-987.33"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.3：深度信念网络 -->
<g id="node158" class="node">
<title>第20章：深度生成模型 &#45; 20.3：深度信念网络</title>
<polygon fill="lightgrey" stroke="black" points="626.89,-984.06 499.89,-984.06 499.89,-948.06 626.89,-948.06 626.89,-984.06"/>
<text text-anchor="middle" x="563.39" y="-963.56" font-family="Microsoft YaHei" font-size="10.00">20.3：深度信念网络</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.1：玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.3：深度信念网络 -->
<g id="edge140" class="edge">
<title>第20章：深度生成模型 &#45; 20.1：玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.3：深度信念网络</title>
<path fill="none" stroke="black" d="M614.96,-978.51C614.91,-978.5 614.85,-978.49 614.8,-978.47"/>
<polygon fill="black" stroke="black" points="625.19,-977.39 614.65,-978.44 623.55,-984.19 625.19,-977.39"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机 -->
<g id="node159" class="node">
<title>第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="533.55,-940.43 393.55,-940.43 393.55,-904.43 533.55,-904.43 533.55,-940.43"/>
<text text-anchor="middle" x="463.55" y="-919.93" font-family="Microsoft YaHei" font-size="10.00">20.6：卷积玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.3：深度信念网络&#45;&gt;第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机 -->
<g id="edge141" class="edge">
<title>第20章：深度生成模型 &#45; 20.3：深度信念网络&#45;&gt;第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机</title>
<path fill="none" stroke="black" d="M522.2,-948.06C519.53,-946.9 516.83,-945.71 514.12,-944.53"/>
<polygon fill="black" stroke="black" points="515.52,-941.32 504.96,-940.53 512.72,-947.74 515.52,-941.32"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼 -->
<g id="node160" class="node">
<title>第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼</title>
<polygon fill="lightgrey" stroke="black" points="492.19,-897.63 250.19,-897.63 250.19,-861.63 492.19,-861.63 492.19,-897.63"/>
<text text-anchor="middle" x="371.19" y="-877.13" font-family="Microsoft YaHei" font-size="10.00">20.7：用于结构化或序列输出的玻尔兹曼</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼 -->
<g id="edge142" class="edge">
<title>第20章：深度生成模型 &#45; 20.6：卷积玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼</title>
<path fill="none" stroke="black" d="M424.65,-904.4C422.84,-903.56 421.01,-902.72 419.18,-901.87"/>
<polygon fill="black" stroke="black" points="420.59,-898.66 410.05,-897.64 417.65,-905.02 420.59,-898.66"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机 -->
<g id="node161" class="node">
<title>第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机</title>
<polygon fill="lightgrey" stroke="black" points="354.36,-891.31 214.36,-891.31 214.36,-855.31 354.36,-855.31 354.36,-891.31"/>
<text text-anchor="middle" x="284.36" y="-870.81" font-family="Microsoft YaHei" font-size="10.00">20.8：其他玻尔兹曼机</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼&#45;&gt;第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机 -->
<g id="edge143" class="edge">
<title>第20章：深度生成模型 &#45; 20.7：用于结构化或序列输出的玻尔兹曼&#45;&gt;第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机</title>
<path fill="none" stroke="black" d="M284.42,-873.31C284.41,-873.31 284.4,-873.31 284.39,-873.31"/>
<polygon fill="black" stroke="black" points="294.62,-870.59 284.37,-873.31 294.08,-877.57 294.62,-870.59"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.13：其他生成方案 -->
<g id="node162" class="node">
<title>第20章：深度生成模型 &#45; 20.13：其他生成方案</title>
<polygon fill="lightgrey" stroke="black" points="304.58,-958.54 171.58,-958.54 171.58,-922.54 304.58,-922.54 304.58,-958.54"/>
<text text-anchor="middle" x="238.08" y="-938.04" font-family="Microsoft YaHei" font-size="10.00">20.13：其他生成方案</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.13：其他生成方案 -->
<g id="edge144" class="edge">
<title>第20章：深度生成模型 &#45; 20.8：其他玻尔兹曼机&#45;&gt;第20章：深度生成模型 &#45; 20.13：其他生成方案</title>
<path fill="none" stroke="black" d="M271.96,-891.32C267.18,-898.26 261.63,-906.33 256.41,-913.91"/>
<polygon fill="black" stroke="black" points="253.3,-912.25 250.52,-922.47 259.07,-916.22 253.3,-912.25"/>
</g>
<!-- 第20章：深度生成模型 &#45; 20.14：评估生成模型 -->
<g id="node163" class="node">
<title>第20章：深度生成模型 &#45; 20.14：评估生成模型</title>
<polygon fill="lightgrey" stroke="black" points="262,-1023.71 129,-1023.71 129,-987.71 262,-987.71 262,-1023.71"/>
<text text-anchor="middle" x="195.5" y="-1003.21" font-family="Microsoft YaHei" font-size="10.00">20.14：评估生成模型</text>
</g>
<!-- 第20章：深度生成模型 &#45; 20.13：其他生成方案&#45;&gt;第20章：深度生成模型 &#45; 20.14：评估生成模型 -->
<g id="edge145" class="edge">
<title>第20章：深度生成模型 &#45; 20.13：其他生成方案&#45;&gt;第20章：深度生成模型 &#45; 20.14：评估生成模型</title>
<path fill="none" stroke="black" d="M226.22,-958.69C222.07,-965.05 217.31,-972.32 212.81,-979.22"/>
<polygon fill="black" stroke="black" points="209.84,-977.37 207.3,-987.65 215.7,-981.2 209.84,-977.37"/>
</g>
<!-- 第9章：卷积网络 &#45; 8.7：优化策略和元算法 -->
<g id="node164" class="node">
<title>第9章：卷积网络 &#45; 8.7：优化策略和元算法</title>
<polygon fill="lightgrey" stroke="black" points="920,-1240 774,-1240 774,-1204 920,-1204 920,-1240"/>
<text text-anchor="middle" x="847" y="-1219.5" font-family="Microsoft YaHei" font-size="10.00">8.7：优化策略和元算法</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.1：卷积运算 -->
<g id="node165" class="node">
<title>第9章：卷积网络 &#45; 9.1：卷积运算</title>
<polygon fill="lightgrey" stroke="black" points="954.05,-1339.99 859.05,-1339.99 859.05,-1303.99 954.05,-1303.99 954.05,-1339.99"/>
<text text-anchor="middle" x="906.55" y="-1319.49" font-family="Microsoft YaHei" font-size="10.00">9.1：卷积运算</text>
</g>
<!-- 第9章：卷积网络 &#45; 8.7：优化策略和元算法&#45;&gt;第9章：卷积网络 &#45; 9.1：卷积运算 -->
<g id="edge146" class="edge">
<title>第9章：卷积网络 &#45; 8.7：优化策略和元算法&#45;&gt;第9章：卷积网络 &#45; 9.1：卷积运算</title>
<path fill="none" stroke="black" d="M857.92,-1240.34C866.99,-1255.56 880.01,-1277.43 890.3,-1294.71"/>
<polygon fill="black" stroke="black" points="887.57,-1296.96 895.69,-1303.76 893.58,-1293.38 887.57,-1296.96"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验 -->
<g id="node166" class="node">
<title>第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验</title>
<polygon fill="lightgrey" stroke="black" points="1165.18,-1347.82 929.18,-1347.82 929.18,-1311.82 1165.18,-1311.82 1165.18,-1347.82"/>
<text text-anchor="middle" x="1047.18" y="-1327.32" font-family="Microsoft YaHei" font-size="10.00">9.4：卷积与池化作为一种无限强的先验</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.1：卷积运算&#45;&gt;第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验 -->
<g id="edge147" class="edge">
<title>第9章：卷积网络 &#45; 9.1：卷积运算&#45;&gt;第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验</title>
<path fill="none" stroke="black" d="M954.16,-1324.64C954.24,-1324.64 954.32,-1324.65 954.4,-1324.65"/>
<polygon fill="black" stroke="black" points="944.46,-1327.6 954.64,-1324.66 944.85,-1320.61 944.46,-1327.6"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.5：基本卷积函数的变体 -->
<g id="node167" class="node">
<title>第9章：卷积网络 &#45; 9.5：基本卷积函数的变体</title>
<polygon fill="lightgrey" stroke="black" points="1285.66,-1313.93 1126.66,-1313.93 1126.66,-1277.93 1285.66,-1277.93 1285.66,-1313.93"/>
<text text-anchor="middle" x="1206.16" y="-1293.43" font-family="Microsoft YaHei" font-size="10.00">9.5：基本卷积函数的变体</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验&#45;&gt;第9章：卷积网络 &#45; 9.5：基本卷积函数的变体 -->
<g id="edge148" class="edge">
<title>第9章：卷积网络 &#45; 9.4：卷积与池化作为一种无限强的先验&#45;&gt;第9章：卷积网络 &#45; 9.5：基本卷积函数的变体</title>
<path fill="none" stroke="black" d="M1131.79,-1311.78C1131.86,-1311.77 1131.94,-1311.75 1132.01,-1311.73"/>
<polygon fill="black" stroke="black" points="1123.18,-1317.2 1132.23,-1311.69 1121.72,-1310.35 1123.18,-1317.2"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.6：结构化输出 -->
<g id="node168" class="node">
<title>第9章：卷积网络 &#45; 9.6：结构化输出</title>
<polygon fill="lightgrey" stroke="black" points="1428.44,-1276.64 1320.44,-1276.64 1320.44,-1240.64 1428.44,-1240.64 1428.44,-1276.64"/>
<text text-anchor="middle" x="1374.44" y="-1256.14" font-family="Microsoft YaHei" font-size="10.00">9.6：结构化输出</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.5：基本卷积函数的变体&#45;&gt;第9章：卷积网络 &#45; 9.6：结构化输出 -->
<g id="edge149" class="edge">
<title>第9章：卷积网络 &#45; 9.5：基本卷积函数的变体&#45;&gt;第9章：卷积网络 &#45; 9.6：结构化输出</title>
<path fill="none" stroke="black" d="M1285.86,-1278.27C1293.99,-1276.47 1302.17,-1274.66 1310.1,-1272.9"/>
<polygon fill="black" stroke="black" points="1310.98,-1276.29 1319.99,-1270.71 1309.47,-1269.45 1310.98,-1276.29"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.7：数据类型 -->
<g id="node169" class="node">
<title>第9章：卷积网络 &#45; 9.7：数据类型</title>
<polygon fill="lightgrey" stroke="black" points="1595.48,-1257.72 1500.48,-1257.72 1500.48,-1221.72 1595.48,-1221.72 1595.48,-1257.72"/>
<text text-anchor="middle" x="1547.98" y="-1237.22" font-family="Microsoft YaHei" font-size="10.00">9.7：数据类型</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.6：结构化输出&#45;&gt;第9章：卷积网络 &#45; 9.7：数据类型 -->
<g id="edge150" class="edge">
<title>第9章：卷积网络 &#45; 9.6：结构化输出&#45;&gt;第9章：卷积网络 &#45; 9.7：数据类型</title>
<path fill="none" stroke="black" d="M1428.88,-1252.71C1448.35,-1250.58 1470.35,-1248.18 1490.1,-1246.03"/>
<polygon fill="black" stroke="black" points="1490.63,-1249.49 1500.19,-1244.93 1489.87,-1242.54 1490.63,-1249.49"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.8：高效的卷积算法 -->
<g id="node170" class="node">
<title>第9章：卷积网络 &#45; 9.8：高效的卷积算法</title>
<polygon fill="lightgrey" stroke="black" points="1786.13,-1266.87 1652.13,-1266.87 1652.13,-1230.87 1786.13,-1230.87 1786.13,-1266.87"/>
<text text-anchor="middle" x="1719.13" y="-1246.37" font-family="Microsoft YaHei" font-size="10.00">9.8：高效的卷积算法</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.7：数据类型&#45;&gt;第9章：卷积网络 &#45; 9.8：高效的卷积算法 -->
<g id="edge151" class="edge">
<title>第9章：卷积网络 &#45; 9.7：数据类型&#45;&gt;第9章：卷积网络 &#45; 9.8：高效的卷积算法</title>
<path fill="none" stroke="black" d="M1595.66,-1242.27C1609.94,-1243.03 1625.98,-1243.89 1641.66,-1244.73"/>
<polygon fill="black" stroke="black" points="1641.72,-1248.24 1651.89,-1245.28 1642.09,-1241.25 1641.72,-1248.24"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.9：随机或无监督的特征 -->
<g id="node171" class="node">
<title>第9章：卷积网络 &#45; 9.9：随机或无监督的特征</title>
<polygon fill="lightgrey" stroke="black" points="1956.74,-1306.7 1797.74,-1306.7 1797.74,-1270.7 1956.74,-1270.7 1956.74,-1306.7"/>
<text text-anchor="middle" x="1877.24" y="-1286.2" font-family="Microsoft YaHei" font-size="10.00">9.9：随机或无监督的特征</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.8：高效的卷积算法&#45;&gt;第9章：卷积网络 &#45; 9.9：随机或无监督的特征 -->
<g id="edge152" class="edge">
<title>第9章：卷积网络 &#45; 9.8：高效的卷积算法&#45;&gt;第9章：卷积网络 &#45; 9.9：随机或无监督的特征</title>
<path fill="none" stroke="black" d="M1786.18,-1265.76C1789.42,-1266.58 1792.69,-1267.4 1795.96,-1268.23"/>
<polygon fill="black" stroke="black" points="1795.22,-1271.65 1805.78,-1270.7 1796.93,-1264.86 1795.22,-1271.65"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础 -->
<g id="node172" class="node">
<title>第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础</title>
<polygon fill="lightgrey" stroke="black" points="2109.75,-1349.2 1918.75,-1349.2 1918.75,-1313.2 2109.75,-1313.2 2109.75,-1349.2"/>
<text text-anchor="middle" x="2014.25" y="-1328.7" font-family="Microsoft YaHei" font-size="10.00">9.10：卷积网络的神经科学基础</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.9：随机或无监督的特征&#45;&gt;第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础 -->
<g id="edge153" class="edge">
<title>第9章：卷积网络 &#45; 9.9：随机或无监督的特征&#45;&gt;第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础</title>
<path fill="none" stroke="black" d="M1935.35,-1306.72C1938.99,-1307.85 1942.67,-1309 1946.35,-1310.14"/>
<polygon fill="black" stroke="black" points="1945.47,-1313.53 1956.06,-1313.15 1947.54,-1306.84 1945.47,-1313.53"/>
</g>
<!-- 第9章：卷积网络 &#45; 9.11：卷积网络与深度学习的历史 -->
<g id="node173" class="node">
<title>第9章：卷积网络 &#45; 9.11：卷积网络与深度学习的历史</title>
<polygon fill="lightgrey" stroke="black" points="2199.04,-1282.43 1996.04,-1282.43 1996.04,-1246.43 2199.04,-1246.43 2199.04,-1282.43"/>
<text text-anchor="middle" x="2097.54" y="-1261.93" font-family="Microsoft YaHei" font-size="10.00">9.11：卷积网络与深度学习的历史</text>
</g>
<!-- 第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础&#45;&gt;第9章：卷积网络 &#45; 9.11：卷积网络与深度学习的历史 -->
<g id="edge154" class="edge">
<title>第9章：卷积网络 &#45; 9.10：卷积网络的神经科学基础&#45;&gt;第9章：卷积网络 &#45; 9.11：卷积网络与深度学习的历史</title>
<path fill="none" stroke="black" d="M2037.01,-1312.95C2046.19,-1305.59 2056.93,-1296.99 2066.79,-1289.08"/>
<polygon fill="black" stroke="black" points="2069.2,-1291.64 2074.81,-1282.65 2064.82,-1286.18 2069.2,-1291.64"/>
</g>
<!-- 第13章：线性因子模型 &#45; 12.5：其他应用 -->
<g id="node174" class="node">
<title>第13章：线性因子模型 &#45; 12.5：其他应用</title>
<polygon fill="lightgrey" stroke="black" points="703,-1971 602,-1971 602,-1935 703,-1935 703,-1971"/>
<text text-anchor="middle" x="652.5" y="-1950.5" font-family="Microsoft YaHei" font-size="10.00">12.5：其他应用</text>
</g>
<!-- 第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析 -->
<g id="node175" class="node">
<title>第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析</title>
<polygon fill="lightgrey" stroke="black" points="911.2,-1971.15 752.2,-1971.15 752.2,-1935.15 911.2,-1935.15 911.2,-1971.15"/>
<text text-anchor="middle" x="831.7" y="-1950.65" font-family="Microsoft YaHei" font-size="10.00">13.1：概率PCA和因子分析</text>
</g>
<!-- 第13章：线性因子模型 &#45; 12.5：其他应用&#45;&gt;第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析 -->
<g id="edge155" class="edge">
<title>第13章：线性因子模型 &#45; 12.5：其他应用&#45;&gt;第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析</title>
<path fill="none" stroke="black" d="M703.37,-1953.04C715.41,-1953.05 728.61,-1953.06 741.81,-1953.07"/>
<polygon fill="black" stroke="black" points="741.88,-1956.57 751.89,-1953.08 741.89,-1949.57 741.88,-1956.57"/>
</g>
<!-- 第13章：线性因子模型 &#45; 13.2：独立成分分析 -->
<g id="node176" class="node">
<title>第13章：线性因子模型 &#45; 13.2：独立成分分析</title>
<polygon fill="lightgrey" stroke="black" points="1103.91,-1971.2 976.91,-1971.2 976.91,-1935.2 1103.91,-1935.2 1103.91,-1971.2"/>
<text text-anchor="middle" x="1040.41" y="-1950.7" font-family="Microsoft YaHei" font-size="10.00">13.2：独立成分分析</text>
</g>
<!-- 第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析&#45;&gt;第13章：线性因子模型 &#45; 13.2：独立成分分析 -->
<g id="edge156" class="edge">
<title>第13章：线性因子模型 &#45; 13.1：概率PCA和因子分析&#45;&gt;第13章：线性因子模型 &#45; 13.2：独立成分分析</title>
<path fill="none" stroke="black" d="M911.5,-1953.17C929.67,-1953.17 948.89,-1953.18 966.79,-1953.18"/>
<polygon fill="black" stroke="black" points="966.86,-1956.68 976.86,-1953.19 966.87,-1949.68 966.86,-1956.68"/>
</g>
<!-- 第13章：线性因子模型 &#45; 13.3：慢特征分析 -->
<g id="node177" class="node">
<title>第13章：线性因子模型 &#45; 13.3：慢特征分析</title>
<polygon fill="lightgrey" stroke="black" points="1313.56,-1971.12 1199.56,-1971.12 1199.56,-1935.12 1313.56,-1935.12 1313.56,-1971.12"/>
<text text-anchor="middle" x="1256.56" y="-1950.62" font-family="Microsoft YaHei" font-size="10.00">13.3：慢特征分析</text>
</g>
<!-- 第13章：线性因子模型 &#45; 13.2：独立成分分析&#45;&gt;第13章：线性因子模型 &#45; 13.3：慢特征分析 -->
<g id="edge157" class="edge">
<title>第13章：线性因子模型 &#45; 13.2：独立成分分析&#45;&gt;第13章：线性因子模型 &#45; 13.3：慢特征分析</title>
<path fill="none" stroke="black" d="M1104.09,-1953.18C1130.81,-1953.17 1161.92,-1953.16 1189.04,-1953.15"/>
<polygon fill="black" stroke="black" points="1189.22,-1956.65 1199.22,-1953.14 1189.22,-1949.65 1189.22,-1956.65"/>
</g>
<!-- 第13章：线性因子模型 &#45; 13.4：稀疏编码 -->
<g id="node178" class="node">
<title>第13章：线性因子模型 &#45; 13.4：稀疏编码</title>
<polygon fill="lightgrey" stroke="black" points="1515.8,-1971.08 1414.8,-1971.08 1414.8,-1935.08 1515.8,-1935.08 1515.8,-1971.08"/>
<text text-anchor="middle" x="1465.3" y="-1950.58" font-family="Microsoft YaHei" font-size="10.00">13.4：稀疏编码</text>
</g>
<!-- 第13章：线性因子模型 &#45; 13.3：慢特征分析&#45;&gt;第13章：线性因子模型 &#45; 13.4：稀疏编码 -->
<g id="edge158" class="edge">
<title>第13章：线性因子模型 &#45; 13.3：慢特征分析&#45;&gt;第13章：线性因子模型 &#45; 13.4：稀疏编码</title>
<path fill="none" stroke="black" d="M1313.6,-1953.11C1341.77,-1953.1 1375.77,-1953.1 1404.43,-1953.09"/>
<polygon fill="black" stroke="black" points="1404.73,-1956.59 1414.73,-1953.09 1404.73,-1949.59 1404.73,-1956.59"/>
</g>
<!-- 第13章：线性因子模型 &#45; 13.5：PCA的流形解释 -->
<g id="node179" class="node">
<title>第13章：线性因子模型 &#45; 13.5：PCA的流形解释</title>
<polygon fill="lightgrey" stroke="black" points="1710.59,-1971.06 1576.59,-1971.06 1576.59,-1935.06 1710.59,-1935.06 1710.59,-1971.06"/>
<text text-anchor="middle" x="1643.59" y="-1950.56" font-family="Microsoft YaHei" font-size="10.00">13.5：PCA的流形解释</text>
</g>
<!-- 第13章：线性因子模型 &#45; 13.4：稀疏编码&#45;&gt;第13章：线性因子模型 &#45; 13.5：PCA的流形解释 -->
<g id="edge159" class="edge">
<title>第13章：线性因子模型 &#45; 13.4：稀疏编码&#45;&gt;第13章：线性因子模型 &#45; 13.5：PCA的流形解释</title>
<path fill="none" stroke="black" d="M1515.91,-1953.08C1531.51,-1953.07 1549.07,-1953.07 1566.05,-1953.07"/>
<polygon fill="black" stroke="black" points="1566.52,-1956.57 1576.52,-1953.07 1566.52,-1949.57 1566.52,-1956.57"/>
</g>
</g>
</svg>
